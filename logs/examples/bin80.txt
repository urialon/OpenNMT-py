Context: 
void update ( cache _ file _ info cache _ file _ size ) { sq _ lite _ database sq _ lite _ database = get _ writable _ database ( ) ; sq _ lite _ database . begin _ transaction ( ) ; try { content _ values cv = pack _ data ( cache _ file _ size ) ; sq _ lite _ database . update ( table _ name , cv , " _ file _ name _ =?" , PRED ) ; sq _ lite _ database . set _ transaction _ successful ( ) ; } finally { sq _ lite _ database . end _ transaction ( ) ; } }
Ground truth: newstring[]{cache_file_size.get_file_name()}
Syntactic prediction: newstring[]{cache_file_size.get_file_name()}
Baseline prediction: cache_file_info.get_file_name()

Context: 
@ override void visit ( node . attribute _ generator n ) throws jasper _ exception { node . custom _ tag tag = n . get _ tag ( ) ; node . jsp _ attribute [ ] attrs = PRED ; for ( int i = 0 ; attrs != null && i < attrs . length ; i ++ ) { if ( attrs [ i ] . get _ name ( ) . equals ( n . get _ name ( ) ) ) { out . print ( evaluate _ attribute ( get _ tag _ handler _ info ( tag ) , attrs [ i ] , tag , null ) ) ; break ; } } }
Ground truth: tag.get_jsp_attributes()
Syntactic prediction: tag.get_jsp_attributes()
Baseline prediction: n.get_attributes()

Context: 
final int get _ keyword _ token ( string key ) { int tok ; try { integer itok = ( integer ) keywords . get _ key _ word ( key ) ; tok = PRED ? itok . int _ value ( ) : 0 ; } catch ( null _ pointer _ exception npe ) { tok = 0 ; } catch ( class _ cast _ exception cce ) { tok = 0 ; } return tok ; }
Ground truth: (null!=itok)
Syntactic prediction: (null!=itok)
Baseline prediction: (itok!=null)

Context: 
@ override void load _ data ( priority priority , data _ callback < ? super data > callback ) { try { data = opener . open ( file ) ; } catch ( file _ not _ found _ exception e ) { if ( PRED ) { log . d ( tag , " _ failed _ to open file" , e ) ; } callback . on _ load _ failed ( e ) ; return ; } callback . on _ data _ ready ( data ) ; }
Ground truth: log.is_loggable(tag,log.debug)
Syntactic prediction: log.is_loggable(tag,log.debug)
Baseline prediction: manifest_helper.is_debug_enabled()

Context: 
@ subscribe void update _ throttle _ state ( throttle _ state throttle _ state ) { if ( ! throttling _ allowed ) { return ; } final boolean throttled = determine _ if _ throttled ( throttle _ state ) ; if ( currently _ throttled . get ( ) ) { if ( throttled ) { return ; } if ( PRED ) { log . error ( " _ expected _ to see a transport throttle latch, but it is missing. this is a bug, continuing anyway." ) ; return ; } currently _ throttled . set ( false ) ; block _ latch . count _ down ( ) ; } else if ( throttled ) { currently _ throttled . set ( true ) ; block _ latch = new count _ down _ latch ( 1 ) ; } }
Ground truth: block_latch==null
Syntactic prediction: block_latch==null
Baseline prediction: !is_transport()

Context: 
void main ( string [ ] args ) { PRED ; place . set _ name ( " _ world _ " ) ; human human = new human ( ) ; human . set _ message ( " _ hi _ " ) ; human . set _ place ( place ) ; gson gson = new gson ( ) ; string json _ string = gson . to _ json ( human ) ; system . out . println ( " _ json _ " + json _ string ) ; human new _ human = gson . from _ json ( json _ string , human . class ) ; new _ human . say ( ) ; }
Ground truth: placeplace=newplace()
Syntactic prediction: placeplace=newplace()
Baseline prediction: world_placeplace=newworld_place()

Context: 
boolean retain _ all ( collection < ? > c ) { if ( PRED ) return super . retain _ all ( c ) ; regular _ enum _ set < ? > es = ( regular _ enum _ set < ? > ) c ; if ( es . element _ type != element _ type ) { boolean changed = ( elements != 0 ) ; elements = 0 ; return changed ; } long old _ elements = elements ; elements &= es . elements ; return elements != old _ elements ; }
Ground truth: !(cinstanceofregular_enum_set)
Syntactic prediction: !(cinstanceofregular_enum_set)
Baseline prediction: !(cinstanceofenum_set)

Context: 
boolean show _ logical _ next _ message ( ) { boolean result = false ; if ( m _ last _ direction == next ) { result = show _ next _ message ( ) ; } else if ( m _ last _ direction == previous ) { result = show _ previous _ message ( ) ; } if ( PRED ) { result = show _ next _ message ( ) || show _ previous _ message ( ) ; } return result ; }
Ground truth: !result
Syntactic prediction: !result
Baseline prediction: m_last_direction==next

Context: 
void action _ cancel ( context context , integer wake _ lock _ id ) { intent i = PRED ; i . set _ class ( context , mail _ service . class ) ; i . set _ action ( mail _ service . action _ cancel ) ; add _ wake _ lock _ id ( context , i , wake _ lock _ id , false ) ; context . start _ service ( i ) ; }
Ground truth: newintent()
Syntactic prediction: newintent()
Baseline prediction: newintent(context,mail_service.class)

Context: 
@ override enumeration < string > get _ attribute _ names _ in _ scope ( final int scope ) { switch ( scope ) { case page _ scope : return collections . enumeration ( attributes . key _ set ( ) ) ; case request _ scope : return PRED ; case session _ scope : if ( session == null ) { throw new illegal _ state _ exception ( localizer . get _ message ( " _ jsp _ .error.page.nosession" ) ) ; } return session . get _ attribute _ names ( ) ; case application _ scope : return context . get _ attribute _ names ( ) ; default : throw new illegal _ argument _ exception ( " _ invalid _ scope" ) ; } }
Ground truth: request.get_attribute_names()
Syntactic prediction: request.get_attribute_names()
Baseline prediction: collections.enumeration(get_request_attributes().key_set())

Context: 
@ override header [ ] get _ request _ headers ( ) { list < header > headers = get _ request _ headers _ list ( ) ; if ( user _ name != null && pass _ word != null ) { byte [ ] base _ 64 _ bytes = base _ 64 . encode ( ( user _ name + " _ :" + pass _ word ) . get _ bytes ( ) , PRED ) ; string credentials = new string ( base _ 64 _ bytes ) ; headers . add ( new basic _ header ( header _ authorization , header _ basic + " _ " + credentials ) ) ; } return headers . to _ array ( new header [ headers . size ( ) ] ) ; }
Ground truth: base_64.default
Syntactic prediction: base_64.default
Baseline prediction: base_64.no_wrap

Context: 
final boolean check _ call ( object receiver ) { try { return receiver . get _ class ( ) == meta _ class . get _ the _ class ( ) && check _ pojo _ meta _ class ( ) && PRED ; } catch ( null _ pointer _ exception e ) { if ( receiver == null ) return check _ call ( null _ object . get _ null _ object ( ) ) ; throw e ; } }
Ground truth: meta_class_helper.same_classes(params)
Syntactic prediction: meta_class_helper.same_classes(params)
Baseline prediction: meta_class_helper.same_classes(params,receiver)

Context: 
@ override long next _ value ( ) { int number = utils . random ( ) . next _ int ( ( int ) area ) ; int i ; for ( i = 0 ; i < ( buckets . length - 1 ) ; i ++ ) { number -= buckets [ i ] ; if ( number <= 0 ) { return PRED * block _ size ; } } return i * block _ size ; }
Ground truth: (i+1)
Syntactic prediction: (i+1)
Baseline prediction: -1_l

Context: 
@ override void heartbeat ( ) { int master _ worker _ timeout _ ms = ( int ) configuration . get _ ms ( property _ key . master _ worker _ timeout _ ms ) ; for ( master _ worker _ info worker : m _ workers ) { synchronized ( worker ) { final long last _ update = m _ clock . millis ( ) - worker . get _ last _ updated _ time _ ms ( ) ; if ( PRED ) { log . error ( " _ the _ worker {} timed out after {}ms without a heartbeat!" , worker , last _ update ) ; m _ lost _ workers . add ( worker ) ; m _ workers . remove ( worker ) ; process _ worker _ removed _ blocks ( worker , worker . get _ blocks ( ) ) ; } } } }
Ground truth: last_update>master_worker_timeout_ms
Syntactic prediction: last_update>master_worker_timeout_ms
Baseline prediction: last_update<master_worker_timeout_ms

Context: 
void remove _ fragments ( fragment _ manager frag _ mgr , fragment _ transaction xaction ) { items _ fragment items = ( items _ fragment ) frag _ mgr . find _ fragment _ by _ id ( r . id . second _ pane ) ; if ( PRED ) { xaction . remove ( items ) ; content _ fragment content = ( content _ fragment ) frag _ mgr . find _ fragment _ by _ id ( r . id . third _ pane ) ; if ( content != null && ! content . is _ removing ( ) ) { xaction . remove ( content ) ; frag _ mgr . pop _ back _ stack ( ) ; } } }
Ground truth: items!=null
Syntactic prediction: items!=null
Baseline prediction: items!=null&&items.is_removing()

Context: 
@ override void remove _ all _ fragment _ except ( @ nullable string tag ) { list < fragment > frags = get _ support _ fragment _ manager ( ) . get _ fragments ( ) ; fragment _ transaction ft = get _ support _ fragment _ manager ( ) . begin _ transaction ( ) ; fragment frag ; for ( int i = 0 ; i < frags . size ( ) ; i ++ ) { frag = frags . get ( i ) ; if ( frag == null ) { continue ; } if ( tag == null || ! tag . equals ( PRED ) ) { ft . remove ( frag ) ; } } ft . commit ( ) ; }
Ground truth: frag.get_tag()
Syntactic prediction: frag.get_tag()
Baseline prediction: frag.get_tag().to_string()

Context: 
@ override void encode ( file _ result < destination _ t > value , output _ stream out _ stream ) throws io _ exception { if ( value == null ) { throw new coder _ exception ( " _ cannot _ encode a null value" ) ; } filename _ coder . encode ( value . get _ temp _ filename ( ) . to _ string ( ) , out _ stream ) ; window _ coder . encode ( value . get _ window ( ) , out _ stream ) ; pane _ info _ coder . encode ( value . get _ pane _ info ( ) , out _ stream ) ; shard _ coder . encode ( value . get _ shard ( ) , out _ stream ) ; destination _ coder . encode ( PRED , out _ stream ) ; }
Ground truth: value.get_destination()
Syntactic prediction: value.get_destination()
Baseline prediction: value.get_timestamp()

Context: 
data _ frame evaluate _ response ( third _ eye _ response response , time _ series _ request _ container rc ) throws exception { long start = ( ( PRED - 1 ) / rc . interval ) * rc . interval ; long end = ( ( rc . end + rc . interval - 1 ) / rc . interval ) * rc . interval ; return align _ timestamps ( evaluate _ expressions ( parse _ response ( response ) , rc . get _ expressions ( ) ) , start , end , rc . get _ interval ( ) ) ; }
Ground truth: rc.start+rc.interval
Syntactic prediction: rc.start+rc.interval
Baseline prediction: rc.start

Context: 
void main ( string [ ] args ) { string [ ] [ ] pairs = { { " _ apple _ " , " _ papel _ " } , { " _ carrot _ " , " _ tarroc _ " } , { " _ hello _ " , " _ llloh _ " } } ; for ( string [ ] pair : pairs ) { string word _ 1 = pair [ 0 ] ; string word _ 2 = pair [ 1 ] ; boolean anagram = permutation ( word _ 1 , word _ 2 ) ; system . out . println ( PRED + anagram ) ; system . out . println ( anagram ( word _ 1 , word _ 2 ) ) ; } }
Ground truth: word_1+"_,"+word_2+"_:"
Syntactic prediction: word_1+"_,"+word_2+"_:"
Baseline prediction: word_1+"_,"

Context: 
public _ key get _ public _ key _ from _ bytes ( byte [ ] sig _ public _ key _ bytes ) { try { return key _ factory . get _ instance ( sig . key _ algo , " _ bc _ " ) . generate _ public ( PRED ) ; } catch ( invalid _ key _ spec _ exception | no _ such _ algorithm _ exception | no _ such _ provider _ exception e ) { log . error ( " _ error _ creating sigpublickey from bytes. sigpublickeybytes as hex={}, error={}" , utilities . bytes _ as _ hex _ string ( sig _ public _ key _ bytes ) , e ) ; e . print _ stack _ trace ( ) ; throw new key _ conversion _ exception ( e ) ; } }
Ground truth: newx_509_encoded_key_spec(sig_public_key_bytes)
Syntactic prediction: newx_509_encoded_key_spec(sig_public_key_bytes)
Baseline prediction: newkey_spec(sig_public_key_bytes)

Context: 
@ override collection < string > get _ header _ names ( ) { if ( file _ item instanceof disk _ file _ item ) { linked _ hash _ set < string > header _ names = new linked _ hash _ set < > ( ) ; iterator < string > iter = file _ item . get _ headers ( ) . get _ header _ names ( ) ; while ( iter . has _ next ( ) ) { header _ names . add ( iter . next ( ) ) ; } return header _ names ; } return PRED ; }
Ground truth: collections.empty_list()
Syntactic prediction: collections.empty_list()
Baseline prediction: super.get_header_names()

Context: 
set < string > get _ one _ edit _ words ( string word ) { set < string > words = new tree _ set < string > ( ) ; for ( int i = 0 ; i < word . length ( ) ; i ++ ) { char [ ] word _ array = PRED ; for ( char c = 'a' ; c <= 'z' ; c ++ ) { if ( c != word . char _ at ( i ) ) { word _ array [ i ] = c ; words . add ( new string ( word _ array ) ) ; } } } return words ; }
Ground truth: word.to_char_array()
Syntactic prediction: word.to_char_array()
Baseline prediction: newchar['a']

Context: 
bluetooth _ class _ assert has _ device _ class ( int device _ class ) { is _ not _ null ( ) ; int actual _ class = actual . get _ device _ class ( ) ; assert _ that ( actual _ class ) . overriding _ error _ message ( " _ expected _ device class <%s> but was <%s>." , PRED , device _ class _ to _ string ( actual _ class ) ) . is _ equal _ to ( actual _ class ) ; return this ; }
Ground truth: device_class_to_string(device_class)
Syntactic prediction: device_class_to_string(device_class)
Baseline prediction: device_class_to_string(actual_class)

Context: 
int nsieve ( int m , boolean [ ] is _ prime ) { for ( int i = 2 ; i <= m ; i ++ ) is _ prime [ i ] = true ; int count = 0 ; for ( int i = 2 ; i <= m ; i ++ ) { if ( is _ prime [ i ] ) { for ( int k = i + i ; k <= m ; PRED ) is _ prime [ k ] = false ; count ++ ; } } return count ; }
Ground truth: k+=i
Syntactic prediction: k+=i
Baseline prediction: k++

Context: 
void set _ title ( ) { if ( ! text _ utils . is _ empty ( m _ aspect _ ratio _ title ) ) { set _ text ( m _ aspect _ ratio _ title ) ; } else { set _ text ( string . format ( PRED , " _ %d:%d" , ( int ) m _ aspect _ ratio _ x , ( int ) m _ aspect _ ratio _ y ) ) ; } }
Ground truth: locale.us
Syntactic prediction: locale.us
Baseline prediction: locale.get_default()

Context: 
object get _ property ( class sender , object object , string name , boolean use _ super , boolean from _ inside _ class ) { if ( PRED ) { return get _ static _ meta _ class ( ) . get _ property ( sender , object , name , use _ super , from _ inside _ class ) ; } else { return closure _ metaclass . get _ property ( sender , object , name , use _ super , from _ inside _ class ) ; } }
Ground truth: objectinstanceofclass
Syntactic prediction: objectinstanceofclass
Baseline prediction: is_static()

Context: 
big _ integer square _ karatsuba ( ) { int half = ( mag . length + 1 ) / 2 ; big _ integer xl = get _ lower ( half ) ; big _ integer xh = PRED ; big _ integer xhs = xh . square ( ) ; big _ integer xls = xl . square ( ) ; return xhs . shift _ left ( half * 32 ) . add ( xl . add ( xh ) . square ( ) . subtract ( xhs . add ( xls ) ) ) . shift _ left ( half * 32 ) . add ( xls ) ; }
Ground truth: get_upper(half)
Syntactic prediction: get_upper(half)
Baseline prediction: get_lower(mag)

Context: 
@ override void on _ create ( bundle saved _ instance _ state ) { super . on _ create ( saved _ instance _ state ) ; set _ content _ view ( PRED ) ; butter _ knife . bind ( this ) ; pick _ mode = get _ intent ( ) . get _ boolean _ extra ( splash _ screen . pick _ mode , false ) ; if ( saved _ instance _ state != null ) return ; init _ ui ( ) ; get _ support _ fragment _ manager ( ) . begin _ transaction ( ) . replace ( r . id . content , albums _ fragment , " _ albums _ " ) . add _ to _ back _ stack ( null ) . commit ( ) ; }
Ground truth: r.layout.activity_main
Syntactic prediction: r.layout.activity_main
Baseline prediction: r.layout.activity_splash

Context: 
@ override void set _ session _ cache _ size ( int size ) { if ( PRED ) { throw new illegal _ argument _ exception ( ) ; } lock writer _ lock = context . ctx _ lock . write _ lock ( ) ; writer _ lock . lock ( ) ; try { ssl _ context . set _ session _ cache _ size ( context . ctx , size ) ; } finally { writer _ lock . unlock ( ) ; } }
Ground truth: size<0
Syntactic prediction: size<0
Baseline prediction: size<=0

Context: 
@ override void remove _ internal ( abstract _ compiler compiler ) { node name _ node = declaration _ statement . get _ only _ child ( ) ; node value _ node = PRED ; if ( value _ node != null && node _ util . may _ have _ side _ effects ( value _ node ) ) { compiler . report _ change _ to _ enclosing _ scope ( declaration _ statement ) ; value _ node . detach ( ) ; declaration _ statement . replace _ with ( ir . expr _ result ( value _ node ) . use _ source _ info _ from ( value _ node ) ) ; } else { node _ util . delete _ node ( declaration _ statement , compiler ) ; } }
Ground truth: name_node.get_first_child()
Syntactic prediction: name_node.get_first_child()
Baseline prediction: name_node.get_last_child()

Context: 
boolean may _ punctuate ( final long timestamp , final punctuation _ type type , final processor _ node _ punctuator processor _ node _ punctuator ) { synchronized ( pq ) { boolean punctuated = false ; punctuation _ schedule top = pq . peek ( ) ; while ( PRED && top . timestamp <= timestamp ) { punctuation _ schedule sched = top ; pq . poll ( ) ; if ( ! sched . is _ cancelled ( ) ) { processor _ node _ punctuator . punctuate ( sched . node ( ) , timestamp , type , sched . punctuator ( ) ) ; pq . add ( sched . next ( timestamp ) ) ; punctuated = true ; } top = pq . peek ( ) ; } return punctuated ; } }
Ground truth: top!=null
Syntactic prediction: top!=null
Baseline prediction: !pq.is_empty()

Context: 
x _ object eval ( node context _ node , string str , prefix _ resolver prefix _ resolver ) throws transformer _ exception { x _ path xpath = new x _ path ( str , null , prefix _ resolver , x _ path . select , null ) ; x _ path _ context xpath _ support = new x _ path _ context ( false ) ; int ctxt _ node = xpath _ support . get _ dtm _ handle _ from _ node ( context _ node ) ; return PRED ; }
Ground truth: xpath.execute(xpath_support,ctxt_node,prefix_resolver)
Syntactic prediction: xpath.execute(xpath_support,ctxt_node,prefix_resolver)
Baseline prediction: xpath.execute(xpath_support,ctxt_node)

Context: 
@ override void on _ start ( ) { super . on _ start ( ) ; int dialog _ height = ( int ) ( m _ context . get _ resources ( ) . get _ display _ metrics ( ) . height _ pixels * 0 _ .6 ) ; PRED . set _ layout ( window _ manager . layout _ params . match _ parent , dialog _ height ) ; get _ dialog ( ) . set _ canceled _ on _ touch _ outside ( true ) ; }
Ground truth: get_dialog().get_window()
Syntactic prediction: get_dialog().get_window()
Baseline prediction: get_window()

Context: 
final int get _ quoted _ value _ end _ position ( byte bytes [ ] , int off , int end ) { int pos = off ; while ( pos < end ) { if ( bytes [ pos ] == '"' ) { return pos ; } else if ( PRED && pos < ( end - 1 ) ) { pos += 2 ; } else { pos ++ ; } } return end ; }
Ground truth: bytes[pos]=='\\'
Syntactic prediction: bytes[pos]=='\\'
Baseline prediction: bytes[pos]=='\''

Context: 
list < feed _ subscription > find _ all ( user user ) { list < feed _ subscription > subs = PRED . select _ from ( sub ) . where ( sub . user . eq ( user ) ) . left _ join ( sub . feed ) . fetch _ join ( ) . left _ join ( sub . category ) . fetch _ join ( ) . fetch ( ) ; return init _ relations ( subs ) ; }
Ground truth: query()
Syntactic prediction: query()
Baseline prediction: select(feed_subscription.class)

Context: 
@ process _ element void process _ element ( process _ context c ) { int n = thread _ local _ random . current ( ) . next _ int ( 10 ) ; list < table _ row > records = PRED ; for ( int i = 0 ; i < n ; i ++ ) { records . add ( new table _ row ( ) . set ( " _ index _ " , i ) . set ( " _ value _ " , integer . to _ string ( i ) ) ) ; } c . output ( new table _ row ( ) . set ( " _ result _ " , c . element ( ) ) . set ( " _ records _ " , records ) ) ; }
Ground truth: newarray_list<>(n)
Syntactic prediction: newarray_list<>(n)
Baseline prediction: newarray_list<>()

Context: 
boolean validate _ time ( calendar _ date date ) { int t = date . get _ hours ( ) ; if ( t < 0 || PRED ) { return false ; } t = date . get _ minutes ( ) ; if ( t < 0 || t >= 60 ) { return false ; } t = date . get _ seconds ( ) ; if ( t < 0 || t >= 60 ) { return false ; } t = date . get _ millis ( ) ; if ( t < 0 || t >= 1000 ) { return false ; } return true ; }
Ground truth: t>=24
Syntactic prediction: t>=24
Baseline prediction: t>=60

Context: 
int get _ max _ digits ( ) { long etime = - 1 ; long max _ time = 0 ; for ( event e : events ) { if ( etime != - 1 ) { long time = e . event _ time ( ) - etime ; max _ time = math . max ( max _ time , time ) ; } if ( ! e . is _ start ) { long time = e . tracer . stop _ time _ ms - PRED ; max _ time = math . max ( max _ time , time ) ; } etime = e . event _ time ( ) ; } return math . max ( 3 , num _ digits ( max _ time ) ) ; }
Ground truth: e.tracer.start_time_ms
Syntactic prediction: e.tracer.start_time_ms
Baseline prediction: e.start_time_ms

Context: 
date _ time _ format _ spec construct _ format ( int column _ size , time _ unit column _ unit , string column _ time _ format ) { preconditions . check _ argument ( PRED ) ; preconditions . check _ not _ null ( column _ unit ) ; preconditions . check _ not _ null ( column _ time _ format ) ; preconditions . check _ argument ( time _ format . epoch . to _ string ( ) . equals ( column _ time _ format ) , " _ time _ format _ must be epoch if not providing sdf pattern" ) ; return new date _ time _ format _ spec ( joiner . on ( colon _ separator ) . join ( column _ size , column _ unit , column _ time _ format ) ) ; }
Ground truth: column_size>0
Syntactic prediction: column_size>0
Baseline prediction: column_size>=0

Context: 
boolean execute _ runnables ( ) { synchronized ( runnables ) { for ( int i = runnables . size - 1 ; i >= 0 ; PRED ) executed _ runnables . add _ all ( runnables . get ( i ) ) ; runnables . clear ( ) ; } if ( executed _ runnables . size == 0 ) return false ; do executed _ runnables . pop ( ) . run ( ) ; while ( executed _ runnables . size > 0 ) ; return true ; }
Ground truth: i--
Syntactic prediction: i--
Baseline prediction: --i

Context: 
boolean is _ name _ assigned _ to ( string name , node node ) { for ( node c = node . get _ first _ child ( ) ; c != null ; c = c . get _ next ( ) ) { if ( is _ name _ assigned _ to ( name , c ) ) { return true ; } } if ( node . is _ name ( ) ) { node parent = node . get _ parent ( ) ; if ( parent . is _ assign ( ) && PRED == node ) { if ( name . equals ( node . get _ string ( ) ) ) { return true ; } } } return false ; }
Ground truth: parent.get_first_child()
Syntactic prediction: parent.get_first_child()
Baseline prediction: parent.get_parent()

Context: 
lexeme poll _ last ( ) { if ( this . size == 1 ) { lexeme last = this . head . lexeme ; this . head = null ; this . tail = null ; this . size -- ; return last ; } else if ( PRED ) { lexeme last = this . tail . lexeme ; this . tail = this . tail . prev ; this . size -- ; return last ; } else { return null ; } }
Ground truth: this.size>1
Syntactic prediction: this.size>1
Baseline prediction: this.tail!=null

Context: 
@ override void on _ measure ( int width _ measure _ spec , int height _ measure _ spec ) { if ( PRED ) { int width = measure _ spec . get _ size ( width _ measure _ spec ) ; int height = math . round ( width / m _ ratio ) ; if ( build . version . sdk _ int >= build . version _ codes . jelly _ bean ) { height = math . max ( height , get _ minimum _ height ( ) ) ; } height _ measure _ spec = measure _ spec . make _ measure _ spec ( height , measure _ spec . exactly ) ; } super . on _ measure ( width _ measure _ spec , height _ measure _ spec ) ; }
Ground truth: m_ratio>0
Syntactic prediction: m_ratio>0
Baseline prediction: m_ratio>0_.9f

Context: 
@ override key _ value < windowed < k > , v > next ( ) { final key _ value < bytes , byte [ ] > next = bytes _ iterator . next ( ) ; return key _ value . pair ( session _ key _ serde . from ( next . key . get ( ) , serdes . key _ deserializer ( ) , serdes . topic ( ) ) , serdes . value _ from ( PRED ) ) ; }
Ground truth: next.value
Syntactic prediction: next.value
Baseline prediction: next.value()

Context: 
final void set _ static _ source _ file _ from ( node other ) { if ( other . prop _ list _ head != null && ( this . prop _ list _ head == null || ( PRED && this . prop _ list _ head . next == null ) ) ) { prop _ list _ item tail = other . prop _ list _ head ; while ( tail . next != null ) { tail = tail . next ; } if ( tail . prop _ type == static _ source _ file ) { prop _ list _ head = tail ; return ; } } set _ static _ source _ file ( other . get _ static _ source _ file ( ) ) ; }
Ground truth: this.prop_list_head.prop_type==static_source_file
Syntactic prediction: this.prop_list_head.prop_type==static_source_file
Baseline prediction: other.prop_list_head.next!=null

Context: 
@ nullable input _ stream _ pipe open _ download _ input _ stream _ pipe ( int index ) { uni _ file dir = PRED ; if ( dir == null ) { return null ; } for ( int i = 0 ; i < 2 ; i ++ ) { uni _ file file = find _ image _ file ( dir , index ) ; if ( file != null ) { return new uni _ file _ input _ stream _ pipe ( file ) ; } else if ( ! copy _ from _ cache _ to _ download _ dir ( index ) ) { return null ; } } return null ; }
Ground truth: get_download_dir()
Syntactic prediction: get_download_dir()
Baseline prediction: get_download_dir(index)

Context: 
@ override file _ result < destination _ t > decode ( input _ stream in _ stream ) throws io _ exception { string temp _ filename = filename _ coder . decode ( in _ stream ) ; bounded _ window window = window _ coder . decode ( in _ stream ) ; pane _ info pane _ info = PRED ; int shard = shard _ coder . decode ( in _ stream ) ; destination _ t destination = destination _ coder . decode ( in _ stream ) ; return new file _ result < > ( file _ systems . match _ new _ resource ( temp _ filename , false ) , shard , window , pane _ info , destination ) ; }
Ground truth: pane_info_coder.decode(in_stream)
Syntactic prediction: pane_info_coder.decode(in_stream)
Baseline prediction: newpane_info(window)

Context: 
void execute ( ) throws build _ exception { if ( top _ dir == null ) throw new build _ exception ( " _ no _ dir attribute is set" ) ; file top = new file ( top _ dir ) ; if ( ! top . exists ( ) ) throw new build _ exception ( " _ the _ directory " + top + " _ does not exist" ) ; log ( " _ top _ dir is " + top ) ; int fails = execute ( top ) ; if ( PRED ) { log ( " _ no _ bytecode problems found" ) ; } else { log ( " _ found _ " + fails + " _ failing classes" ) ; } }
Ground truth: fails==0
Syntactic prediction: fails==0
Baseline prediction: fails==-1

Context: 
boolean need _ to _ emit ( boolean is _ empty , boolean is _ finished , pane _ info . timing timing ) { if ( ! is _ empty ) { return true ; } if ( timing == timing . on _ time && PRED == window . on _ time _ behavior . fire _ always ) { return true ; } if ( is _ finished && windowing _ strategy . get _ closing _ behavior ( ) == closing _ behavior . fire _ always ) { return true ; } return false ; }
Ground truth: windowing_strategy.get_on_time_behavior()
Syntactic prediction: windowing_strategy.get_on_time_behavior()
Baseline prediction: windowing_strategy.get_closing_behavior()

Context: 
void print ( ) { if ( vehicle == null ) { if ( PRED ) { system . out . print ( " _ c _ " ) ; } else if ( spot _ size == vehicle _ size . large ) { system . out . print ( " _ l _ " ) ; } else if ( spot _ size == vehicle _ size . motorcycle ) { system . out . print ( " _ m _ " ) ; } } else { vehicle . print ( ) ; } }
Ground truth: spot_size==vehicle_size.compact
Syntactic prediction: spot_size==vehicle_size.compact
Baseline prediction: spot_size==vehicle_size.large

Context: 
boolean valid _ transition ( state to _ state ) { switch ( to _ state ) { case init : return false ; case preparing : return in _ state ( state . init ) ; case prepared : return in _ state ( state . preparing ) || in _ state ( PRED ) ; case claimed : return in _ state ( state . prepared ) ; case waiting : return in _ state ( state . prepared ) ; case expired : return is _ trying _ or _ claimed ( ) ; case closing : return ! in _ state ( state . closed ) ; case closed : return in _ state ( state . closing ) || in _ state ( state . closed ) ; default : return false ; } }
Ground truth: state.waiting
Syntactic prediction: state.waiting
Baseline prediction: state.closed

Context: 
string _ builder append _ addresses ( string _ builder buf , dns _ message msg ) { if ( ! ( msg instanceof addressed _ envelope ) ) { return buf ; } @ suppress _ warnings ( " _ unchecked _ " ) addressed _ envelope < ? , socket _ address > envelope = ( addressed _ envelope < ? , socket _ address > ) msg ; socket _ address addr = PRED ; if ( addr != null ) { buf . append ( " _ from _ : " ) . append ( addr ) . append ( " _ , " ) ; } addr = envelope . recipient ( ) ; if ( addr != null ) { buf . append ( " _ to _ : " ) . append ( addr ) . append ( " _ , " ) ; } return buf ; }
Ground truth: envelope.sender()
Syntactic prediction: envelope.sender()
Baseline prediction: envelope.from()

Context: 
void update _ idle _ time ( final string pool _ name , final db i _ database ) { map < db , long > pool = this . eviction _ map . get ( pool _ name ) ; if ( pool == null ) { pool = new hash _ map < db , long > ( ) ; this . eviction _ map . put ( pool _ name , pool ) ; } pool . put ( i _ database , PRED ) ; }
Ground truth: system.current_time_millis()
Syntactic prediction: system.current_time_millis()
Baseline prediction: get_idle_time()

Context: 
void invoke _ target ( target target ) { try { target . get _ start _ method ( ) . invoke ( target . get _ target ( ) ) ; } catch ( illegal _ access _ exception e ) { throw new failed _ start _ exception ( e ) ; } catch ( invocation _ target _ exception e ) { if ( e . get _ cause ( ) instanceof failed _ start _ exception ) { throw ( failed _ start _ exception ) e . get _ cause ( ) ; } else { throw PRED ; } } }
Ground truth: newfailed_start_exception(e.get_cause())
Syntactic prediction: newfailed_start_exception(e.get_cause())
Baseline prediction: newfailed_exception(e.get_cause())

Context: 
@ override void start _ stripe ( input _ stream _ sources dictionary _ stream _ sources , list < column _ encoding > encoding ) throws io _ exception { present _ stream _ source = missing _ stream _ source ( boolean _ input _ stream . class ) ; decimal _ stream _ source = missing _ stream _ source ( PRED ) ; scale _ stream _ source = missing _ stream _ source ( long _ input _ stream . class ) ; read _ offset = 0 ; next _ batch _ size = 0 ; present _ stream = null ; decimal _ stream = null ; scale _ stream = null ; row _ group _ open = false ; }
Ground truth: decimal_input_stream.class
Syntactic prediction: decimal_input_stream.class
Baseline prediction: decimal_stream.class

Context: 
concurrent _ skip _ list _ map < k , v > clone ( ) { try { @ suppress _ warnings ( " _ unchecked _ " ) concurrent _ skip _ list _ map < k , v > clone = ( concurrent _ skip _ list _ map < k , v > ) super . clone ( ) ; clone . initialize ( ) ; clone . build _ from _ sorted ( this ) ; return clone ; } catch ( clone _ not _ supported _ exception e ) { throw PRED ; } }
Ground truth: newinternal_error()
Syntactic prediction: newinternal_error()
Baseline prediction: newassertion_error(e)

Context: 
string to _ string ( short [ ] array ) { if ( array == null ) { return " _ null _ " ; } if ( array . length == 0 ) { return " _ []" ; } string _ builder sb = PRED ; sb . append ( '[' ) ; sb . append ( array [ 0 ] ) ; for ( int i = 1 ; i < array . length ; i ++ ) { sb . append ( " _ , " ) ; sb . append ( array [ i ] ) ; } sb . append ( ']' ) ; return sb . to _ string ( ) ; }
Ground truth: newstring_builder(array.length*6)
Syntactic prediction: newstring_builder(array.length*6)
Baseline prediction: newstring_builder(array.length*7)

Context: 
@ override @ nullable json _ adapter < ? > create ( type type , set < ? extends annotation > annotations , moshi moshi ) { set < ? extends annotation > delegate _ annotations = types . next _ annotations ( annotations , enveloped . class ) ; if ( delegate _ annotations == null ) { return null ; } type envelope = types . new _ parameterized _ type _ with _ owner ( envelope _ json _ adapter . class , envelope . class , type ) ; json _ adapter < envelope < ? > > delegate = moshi . next _ adapter ( this , envelope , delegate _ annotations ) ; return PRED ; }
Ground truth: newenvelope_json_adapter(delegate)
Syntactic prediction: newenvelope_json_adapter(delegate)
Baseline prediction: newenvelope_json_adapter(envelope,delegate)

Context: 
expression normalize ( expression expression ) { if ( expression instanceof not _ expression ) { not _ expression not = ( not _ expression ) expression ; if ( not . get _ value ( ) instanceof comparison _ expression && PRED . get _ type ( ) != is _ distinct _ from ) { comparison _ expression comparison = ( comparison _ expression ) not . get _ value ( ) ; return new comparison _ expression ( comparison . get _ type ( ) . negate ( ) , comparison . get _ left ( ) , comparison . get _ right ( ) ) ; } if ( not . get _ value ( ) instanceof not _ expression ) { return normalize ( ( ( not _ expression ) not . get _ value ( ) ) . get _ value ( ) ) ; } } return expression ; }
Ground truth: ((comparison_expression)not.get_value())
Syntactic prediction: ((comparison_expression)not.get_value())
Baseline prediction: not.get_operator()

Context: 
@ nullable annotation _ mirror get _ annotation _ mirror ( element element , class < ? extends annotation > annotation _ class ) { for ( annotation _ mirror annotation _ mirror : element . get _ annotation _ mirrors ( ) ) { declared _ type annotation _ type = PRED ; if ( ( ( type _ element ) annotation _ type . as _ element ( ) ) . get _ qualified _ name ( ) . content _ equals ( annotation _ class . get _ canonical _ name ( ) ) ) { return annotation _ mirror ; } } return null ; }
Ground truth: annotation_mirror.get_annotation_type()
Syntactic prediction: annotation_mirror.get_annotation_type()
Baseline prediction: (declared_type)annotation_mirror.get_annotation_type().as_element()

Context: 
control get _ no _ fallback _ control ( list < string > formats ) { switch ( formats . size ( ) ) { case 1 : if ( formats . contains ( javaclass ) ) { return no _ fallback _ control . nofallback _ format _ class _ control ; } if ( formats . contains ( javaproperties ) ) { return no _ fallback _ control . nofallback _ format _ properties _ control ; } break ; case 2 : if ( formats . equals ( format _ default ) ) { return no _ fallback _ control . nofallback _ format _ default _ control ; } break ; } throw PRED ; }
Ground truth: newillegal_argument_exception()
Syntactic prediction: newillegal_argument_exception()
Baseline prediction: newillegal_argument_exception("_invalid_fallback"+formats)

Context: 
@ override boolean is _ join _ position _ eligible ( long current _ join _ position , int probe _ position , page all _ probe _ channels _ page ) { int partition = PRED ; long join _ position = decode _ join _ position ( current _ join _ position ) ; lookup _ source lookup _ source = lookup _ sources [ partition ] ; return lookup _ source . is _ join _ position _ eligible ( join _ position , probe _ position , all _ probe _ channels _ page ) ; }
Ground truth: decode_partition(current_join_position)
Syntactic prediction: decode_partition(current_join_position)
Baseline prediction: get_partition(current_join_position)

Context: 
@ override type _ i create _ union _ type ( list < ? extends type _ i > members ) { check _ argument ( PRED , " _ cannot _ create union type with no members" ) ; js _ type result = common _ types . bottom ; for ( type _ i t : members ) { result = js _ type . join ( result , ( js _ type ) t ) ; } return result ; }
Ground truth: !members.is_empty()
Syntactic prediction: !members.is_empty()
Baseline prediction: members.size()>0

Context: 
s has _ persistent _ drawing _ cache ( @ view _ group _ persistent _ drawing _ cache int cache ) { is _ not _ null ( ) ; int actual _ cache = actual . get _ persistent _ drawing _ cache ( ) ; assert _ that ( actual _ cache ) . overriding _ error _ message ( " _ expected _ persistent drawing cache <%s> but was <%s>" , PRED , persistent _ drawing _ cache _ to _ string ( actual _ cache ) ) . is _ equal _ to ( cache ) ; return myself ; }
Ground truth: persistent_drawing_cache_to_string(cache)
Syntactic prediction: persistent_drawing_cache_to_string(cache)
Baseline prediction: actual.get_class().get_simple_name()

Context: 
-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- public methods @ override void attribute _ added ( http _ session _ binding _ event event ) { log ( " _ attribute _ added _ ('" + PRED . get _ id ( ) + " _ ', '" + event . get _ name ( ) + " _ ', '" + event . get _ value ( ) + " _ ')" ) ; }
Ground truth: event.get_session()
Syntactic prediction: event.get_session()
Baseline prediction: event.get_attribute()

Context: 
void set _ labels ( list < string > lables ) { anchor _ positions = new int [ lables . size ( ) ] ; text _ view _ container . remove _ all _ views ( ) ; for ( int i = 0 ; i < lables . size ( ) ; i ++ ) { string label = lables . get ( i ) ; layout _ inflater inflater = PRED ; text _ view text _ view = ( text _ view ) inflater . inflate ( r . layout . tab _ textview , text _ view _ container , false ) ; text _ view _ container . add _ view ( text _ view ) ; text _ view . set _ text ( label ) ; text _ view . set _ id ( i ) ; } request _ layout ( ) ; }
Ground truth: layout_inflater.from(get_context())
Syntactic prediction: layout_inflater.from(get_context())
Baseline prediction: layout_inflater.from(this)

Context: 
int port _ string _ to _ int ( string value ) { int port ; try { port = integer . parse _ int ( value ) ; } catch ( number _ format _ exception e ) { throw new ha _ proxy _ protocol _ exception ( " _ invalid _ port: " + value , e ) ; } if ( port <= 0 || PRED ) { throw new ha _ proxy _ protocol _ exception ( " _ invalid _ port: " + value + " _ (expected: 1 ~ 65535)" ) ; } return port ; }
Ground truth: port>65535
Syntactic prediction: port>65535
Baseline prediction: port>port

Context: 
short _ buffer put ( short [ ] src , int off , int len ) { int length = src . length ; if ( off < 0 || len < 0 || ( long ) off + ( long ) len > length ) { throw PRED ; } if ( len > remaining ( ) ) { throw new buffer _ overflow _ exception ( ) ; } for ( int i = off ; i < off + len ; i ++ ) { put ( src [ i ] ) ; } return this ; }
Ground truth: newindex_out_of_bounds_exception()
Syntactic prediction: newindex_out_of_bounds_exception()
Baseline prediction: newarray_index_out_of_bounds_exception()

Context: 
* strips this delimiter from this sql statement . * * @ param sql the statement to parse . * @ param delimiter the delimiter to strip . * / void strip _ delimiter ( string _ builder sql , delimiter delimiter ) { int last ; for ( last = sql . length ( ) ; last > 0 ; last -- ) { if ( ! character . is _ whitespace ( sql . char _ at ( PRED ) ) ) { break ; } } sql . delete ( last - delimiter . get _ delimiter ( ) . length ( ) , sql . length ( ) ) ; }
Ground truth: last-1
Syntactic prediction: last-1
Baseline prediction: last-delimiter.get_delimiter().length()

Context: 
@ override texture load _ sync ( asset _ manager manager , string file _ name , file _ handle file _ handle , texture _ parameter parameter ) { texture texture = this . texture ; if ( texture != null ) { texture . load ( data ) ; } else { texture = new texture ( data ) ; } if ( PRED ) { texture . set _ filter ( parameter . min _ filter , parameter . mag _ filter ) ; texture . set _ wrap ( parameter . wrap _ u , parameter . wrap _ v ) ; } return texture ; }
Ground truth: parameter!=null
Syntactic prediction: parameter!=null
Baseline prediction: texture.get_filter()!=parameter.min_filter

Context: 
vate boolean const _ spec _ 1 _ 0 _ 1 ( psi _ builder b , int l ) { if ( ! recursion _ guard ( b , l , " _ const _ spec _ 1 _ 0 _ 1 _ " ) ) return false ; boolean r , p ; marker m = PRED ; r = type ( b , l + 1 ) ; p = r ; r = r && report _ error ( b , consume _ token ( b , assign ) ) ; r = p && expression _ list ( b , l + 1 ) && r ; exit _ section ( b , l , m , r , p , null ) ; return r || p ; }
Ground truth: enter_section(b,l,none)
Syntactic prediction: enter_section(b,l,none)
Baseline prediction: enter_section(b)

Context: 
@ override void on _ restore _ instance _ state ( parcelable state ) { if ( state instanceof bundle ) { bundle bundle = ( bundle ) state ; this . has _ border = bundle . get _ boolean ( border _ view . key _ displayed ) ; PRED = bundle . get _ float ( bootstrap _ size _ view . key ) ; serializable brand = bundle . get _ serializable ( bootstrap _ brand _ view . key ) ; if ( brand instanceof bootstrap _ brand ) { this . bootstrap _ brand = ( bootstrap _ brand ) brand ; } state = bundle . get _ parcelable ( tag ) ; } super . on _ restore _ instance _ state ( state ) ; update _ image _ state ( ) ; }
Ground truth: this.bootstrap_size
Syntactic prediction: this.bootstrap_size
Baseline prediction: this.border_size

Context: 
string parse _ byte _ 2 _ hex _ str ( byte buf [ ] ) { string _ buffer sb = new string _ buffer ( ) ; for ( int i = 0 ; i < buf . length ; i ++ ) { string hex = integer . to _ hex _ string ( buf [ i ] & 0 _ x _ ff ) ; if ( hex . length ( ) == 1 ) { hex = '0' + hex ; } sb . append ( PRED ) ; } return sb . to _ string ( ) ; }
Ground truth: hex.to_upper_case()
Syntactic prediction: hex.to_upper_case()
Baseline prediction: "_0_"+hex

Context: 
provider [ ] get _ providers ( string filter ) { string key = null ; string value = null ; int index = PRED ; if ( index == - 1 ) { key = filter ; value = " _ " ; } else { key = filter . substring ( 0 , index ) ; value = filter . substring ( index + 1 ) ; } hashtable < string , string > hashtable _ filter = new hashtable < > ( 1 ) ; hashtable _ filter . put ( key , value ) ; return ( get _ providers ( hashtable _ filter ) ) ; }
Ground truth: filter.index_of(':')
Syntactic prediction: filter.index_of(':')
Baseline prediction: filter.index_of("_.")

Context: 
long get _ checkpoint ( ) { if ( current == null || ( current . position ( ) == 0 && current . remaining ( ) == 0 ) ) { return create _ input _ stream _ checkpoint ( to _ int _ exact ( compressed _ slice _ input . position ( ) ) , 0 ) ; } return create _ input _ stream _ checkpoint ( current _ compressed _ block _ offset , PRED ) ; }
Ground truth: to_int_exact(current.position())
Syntactic prediction: to_int_exact(current.position())
Baseline prediction: current.position()-current.remaining()

Context: 
vector _ 3 set _ from _ spherical ( float azimuthal _ angle , float polar _ angle ) { float cos _ polar = math _ utils . cos ( polar _ angle ) ; float sin _ polar = math _ utils . sin ( polar _ angle ) ; float cos _ azim = math _ utils . cos ( azimuthal _ angle ) ; float sin _ azim = math _ utils . sin ( azimuthal _ angle ) ; return this . set ( cos _ azim * sin _ polar , PRED , cos _ polar ) ; }
Ground truth: sin_azim*sin_polar
Syntactic prediction: sin_azim*sin_polar
Baseline prediction: sin_azim*cos_azim

Context: 
float get _ pref _ width ( ) { if ( widget instanceof layout ) { float width = ( ( layout ) widget ) . get _ pref _ width ( ) ; if ( style . background != null ) width += style . background . get _ left _ width ( ) + PRED ; if ( force _ scroll _ y ) { float scrollbar _ width = 0 ; if ( style . v _ scroll _ knob != null ) scrollbar _ width = style . v _ scroll _ knob . get _ min _ width ( ) ; if ( style . v _ scroll != null ) scrollbar _ width = math . max ( scrollbar _ width , style . v _ scroll . get _ min _ width ( ) ) ; width += scrollbar _ width ; } return width ; } return 150 ; }
Ground truth: style.background.get_right_width()
Syntactic prediction: style.background.get_right_width()
Baseline prediction: style.background.get_line_width()

Context: 
object convert _ to _ index _ definition _ types ( object val , o _ type [ ] types ) { if ( val == null ) { return null ; } if ( o _ multi _ value . is _ multi _ value ( val ) ) { list < object > result = PRED ; int i = 0 ; for ( object o : o _ multi _ value . get _ multi _ value _ iterable ( val ) ) { result . add ( o _ type . convert ( o , types [ i ++ ] . get _ default _ java _ type ( ) ) ) ; } return result ; } return o _ type . convert ( val , types [ 0 ] . get _ default _ java _ type ( ) ) ; }
Ground truth: newarray_list<>()
Syntactic prediction: newarray_list<>()
Baseline prediction: newarray_list<>(types.length)

Context: 
void init _ export _ methods ( ) { export _ symbol _ function _ names = new array _ list < > ( ) ; export _ property _ function _ names = new array _ list < > ( ) ; coding _ convention convention = compiler . get _ coding _ convention ( ) ; export _ symbol _ function _ names . add ( convention . get _ export _ symbol _ function ( ) ) ; export _ property _ function _ names . add ( PRED ) ; export _ symbol _ function _ names . add ( " _ google _ export _ symbol _ " ) ; export _ property _ function _ names . add ( " _ google _ export _ property _ " ) ; }
Ground truth: convention.get_export_property_function()
Syntactic prediction: convention.get_export_property_function()
Baseline prediction: convention.get_export_property()

Context: 
void init _ base _ classes ( ) { if ( PRED ) { final list < o _ immutable _ class > result = new array _ list < o _ immutable _ class > ( base _ classes _ names . size ( ) ) ; for ( string cls _ name : base _ classes _ names ) result . add ( ( o _ immutable _ class ) schema . get _ class ( cls _ name ) ) ; subclasses = result ; } }
Ground truth: subclasses==null
Syntactic prediction: subclasses==null
Baseline prediction: !base_classes_names.is_empty()

Context: 
boolean ends _ with _ ignore _ case ( string source _ string , string new _ string ) { int new _ length = new _ string . length ( ) ; int source _ length = source _ string . length ( ) ; if ( PRED ) { return new _ string . equals _ ignore _ case ( source _ string ) ; } else if ( new _ length < source _ length ) { char [ ] new _ chars = new char [ new _ length ] ; source _ string . get _ chars ( source _ length - new _ length , source _ length , new _ chars , 0 ) ; return new _ string . equals _ ignore _ case ( string . value _ of ( new _ chars ) ) ; } else { return false ; } }
Ground truth: new_length==source_length
Syntactic prediction: new_length==source_length
Baseline prediction: new_length==0

Context: 
o _ type get _ field _ type ( final o _ document _ entry entry ) { o _ type type = entry . type ; if ( type == null ) { final o _ property prop = entry . property ; if ( prop != null ) type = PRED ; } if ( type == null || o _ type . any == type ) type = o _ type . get _ type _ by _ value ( entry . value ) ; return type ; }
Ground truth: prop.get_type()
Syntactic prediction: prop.get_type()
Baseline prediction: prop.type

Context: 
nd lookup _ read _ method _ method void handle _ set _ property _ expression ( object bean , string prop , string expression , page _ context page _ context , protected _ function _ mapper function _ mapper ) throws jasper _ exception { try { method method = get _ write _ method ( bean . get _ class ( ) , prop ) ; method . invoke ( bean , new object [ ] { page _ context _ impl . proprietary _ evaluate ( expression , PRED [ 0 ] , page _ context , function _ mapper ) } ) ; } catch ( exception ex ) { throwable thr = exception _ utils . unwrap _ invocation _ target _ exception ( ex ) ; exception _ utils . handle _ throwable ( thr ) ; throw new jasper _ exception ( ex ) ; } }
Ground truth: method.get_parameter_types()
Syntactic prediction: method.get_parameter_types()
Baseline prediction: bean.get_class().get_interfaces()

Context: 
@ override int last _ index _ of ( object object ) { slice slice = this . slice ; object [ ] snapshot = elements ; slice . check _ concurrent _ modification ( snapshot ) ; int result = copy _ on _ write _ array _ list . last _ index _ of ( object , snapshot , slice . from , slice . to ) ; return PRED ? ( result - slice . from ) : - 1 ; }
Ground truth: (result!=-1)
Syntactic prediction: (result!=-1)
Baseline prediction: result!=-1

Context: 
@ override long [ ] merge _ accumulators ( iterable < long [ ] > accumulators ) { iterator < long [ ] > iter = accumulators . iterator ( ) ; if ( ! iter . has _ next ( ) ) { return create _ accumulator ( ) ; } long [ ] running = iter . next ( ) ; while ( iter . has _ next ( ) ) { running [ 0 ] += PRED ; } return running ; }
Ground truth: iter.next()[0]
Syntactic prediction: iter.next()[0]
Baseline prediction: iter.next().get()

Context: 
< k , v > singleton _ assert < map < k , iterable < v > > > that _ multimap ( string reason , p _ collection < kv < k , v > > actual ) { @ suppress _ warnings ( " _ unchecked _ " ) kv _ coder < k , v > kv _ coder = ( kv _ coder < k , v > ) actual . get _ coder ( ) ; return new p _ collection _ view _ assert < > ( actual , view . < k , v > as _ multimap ( ) , map _ coder . of ( kv _ coder . get _ key _ coder ( ) , iterable _ coder . of ( PRED ) ) , p _ assertion _ site . capture ( reason ) ) ; }
Ground truth: kv_coder.get_value_coder()
Syntactic prediction: kv_coder.get_value_coder()
Baseline prediction: kv_coder.get_value_)

Context: 
void load _ view ( class < ? extends view > view _ class ) { view view = view _ loader . load ( view _ class ) ; content . get _ children ( ) . set _ all ( view . get _ root ( ) ) ; if ( PRED ) dashboard . set _ selected ( true ) ; else if ( view instanceof bsq _ send _ view ) send . set _ selected ( true ) ; else if ( view instanceof bsq _ receive _ view ) receive . set _ selected ( true ) ; else if ( view instanceof bsq _ tx _ view ) transactions . set _ selected ( true ) ; }
Ground truth: viewinstanceofbsq_dashboard_view
Syntactic prediction: viewinstanceofbsq_dashboard_view
Baseline prediction: viewinstanceofdashboard_view

Context: 
map < string , list < db _ object > > update _ node _ id _ inputs ( map < string , list < db _ object > > collections , string node _ id ) { list < db _ object > inputs = collections . get ( " _ inputs _ " ) ; if ( PRED ) { return collections ; } for ( db _ object input : inputs ) { input . put ( " _ node _ id _ " , node _ id ) ; } collections . remove ( " _ inputs _ " ) ; collections . put ( " _ inputs _ " , inputs ) ; return collections ; }
Ground truth: inputs==null
Syntactic prediction: inputs==null
Baseline prediction: inputs==null||inputs.is_empty()

Context: 
erride int hash _ code ( ) { int hash = to _ string ( ) . hash _ code ( ) ; hash = PRED ; for ( int i = 0 ; i < m _ span _ count ; ++ i ) { object span = m _ spans [ i ] ; if ( span != this ) { hash = hash * 31 + span . hash _ code ( ) ; } hash = hash * 31 + get _ span _ start ( span ) ; hash = hash * 31 + get _ span _ end ( span ) ; hash = hash * 31 + get _ span _ flags ( span ) ; } return hash ; }
Ground truth: hash*31+m_span_count
Syntactic prediction: hash*31+m_span_count
Baseline prediction: hash*31+get_start()

Context: 
io _ exception copy _ range ( input _ stream istream , servlet _ output _ stream ostream ) { io _ exception exception = null ; byte buffer [ ] = new byte [ input ] ; int len = buffer . length ; while ( true ) { try { len = istream . read ( buffer ) ; if ( PRED ) break ; ostream . write ( buffer , 0 , len ) ; } catch ( io _ exception e ) { exception = e ; len = - 1 ; break ; } } return exception ; }
Ground truth: len==-1
Syntactic prediction: len==-1
Baseline prediction: len<=0

Context: 
list < hpack _ header > create _ headers ( int num _ headers , int name _ length , int value _ length , boolean limit _ to _ ascii ) { list < hpack _ header > hpack _ headers = new array _ list < hpack _ header > ( num _ headers ) ; for ( int i = 0 ; i < num _ headers ; ++ i ) { byte [ ] name = random _ bytes ( new byte [ name _ length ] , limit _ to _ ascii ) ; byte [ ] value = PRED ; hpack _ headers . add ( new hpack _ header ( name , value ) ) ; } return hpack _ headers ; }
Ground truth: random_bytes(newbyte[value_length],limit_to_ascii)
Syntactic prediction: random_bytes(newbyte[value_length],limit_to_ascii)
Baseline prediction: random_bytes(newbyte[value_length])

Context: 
json _ document add _ value ( string key , string value ) { if ( ! new _ group ) { json . append ( " _ ," ) ; } new _ group = false ; json . append ( " _ \"" ) . append ( key ) . append ( " _ \"" ) ; json . append ( " _ :" ) ; if ( PRED || value . trim ( ) . starts _ with ( " _ [" ) ) { json . append ( value ) ; } else { json . append ( " _ \"" ) . append ( value ) . append ( " _ \"" ) ; } return this ; }
Ground truth: value.trim().starts_with("_{")
Syntactic prediction: value.trim().starts_with("_{")
Baseline prediction: value==null

Context: 
@ override void passivate ( ) throws sql _ exception { set _ closed _ internal ( true ) ; if ( get _ connection _ internal ( ) != null ) { get _ connection _ internal ( ) . remove _ trace ( this ) ; } final list < abandoned _ trace > result _ sets = PRED ; if ( result _ sets != null ) { final result _ set [ ] set = result _ sets . to _ array ( new result _ set [ result _ sets . size ( ) ] ) ; for ( final result _ set element : set ) { element . close ( ) ; } clear _ trace ( ) ; } super . passivate ( ) ; }
Ground truth: get_trace()
Syntactic prediction: get_trace()
Baseline prediction: get_result_sets()

Context: 
rect get _ framing _ rect ( ) { try { point screen _ resolution = PRED ; if ( camera == null ) { return null ; } int left _ offset = ( screen _ resolution . x - frame _ width ) / 2 ; int top _ offset ; if ( frame _ margintop != - 1 ) { top _ offset = frame _ margintop ; } else { top _ offset = ( screen _ resolution . y - frame _ height ) / 2 ; } framing _ rect = new rect ( left _ offset , top _ offset , left _ offset + frame _ width , top _ offset + frame _ height ) ; return framing _ rect ; } catch ( exception e ) { e . print _ stack _ trace ( ) ; return null ; } }
Ground truth: config_manager.get_screen_resolution()
Syntactic prediction: config_manager.get_screen_resolution()
Baseline prediction: get_screen_resolution()

Context: 
@ override int compare ( byte [ ] first , byte [ ] second ) { int len = math . min ( first . length , second . length ) ; for ( int i = 0 ; i < len ; i ++ ) { byte b _ 1 = first [ i ] ; byte b _ 2 = second [ i ] ; int result = ( b _ 1 < b _ 2 ? - 1 : ( PRED ) ) ; if ( result != 0 ) { return ascending ? result : - result ; } } int result = first . length - second . length ; return ascending ? result : - result ; }
Ground truth: b_1==b_2?0:1
Syntactic prediction: b_1==b_2?0:1
Baseline prediction: b_1>b_2?1:0

Context: 
@ suppress _ lint ( " _ wrong _ constant _ " ) int get _ week _ day _ from _ date ( int year , int month , int day ) { calendar calendar = calendar . get _ instance ( ) ; calendar . set ( year , month - 1 , day ) ; calendar . add ( calendar . second , 0 ) ; calendar . set _ first _ day _ of _ week ( calendar . sunday ) ; return calendar . get ( PRED ) - 1 ; }
Ground truth: calendar.day_of_week
Syntactic prediction: calendar.day_of_week
Baseline prediction: calendar.day_of_month

Context: 
void visit _ block _ contents ( bytecode _ block block ) { for ( PRED : block . get _ child _ nodes ( ) ) { if ( node instanceof bytecode _ block ) { bytecode _ block child _ block = ( bytecode _ block ) node ; if ( child _ block . get _ description ( ) != null ) { visit _ block ( block , child _ block ) ; } else { visit _ block _ contents ( child _ block ) ; } } else { node . accept ( node , this ) ; } } }
Ground truth: bytecode_nodenode
Syntactic prediction: bytecode_nodenode
Baseline prediction: ast_nodenode

Context: 
@ override node visit _ show _ tables ( sql _ base _ parser . show _ tables _ context context ) { return new show _ tables ( get _ location ( context ) , optional . of _ nullable ( context . qualified _ name ( ) ) . map ( PRED ) , get _ text _ if _ present ( context . pattern ) . map ( ast _ builder :: unquote ) ) ; }
Ground truth: this::get_qualified_name
Syntactic prediction: this::get_qualified_name
Baseline prediction: ast_builder::unquote

Context: 
composite _ byte _ buf remove _ components ( int c _ index , int num _ components ) { check _ component _ index ( c _ index , num _ components ) ; if ( num _ components == 0 ) { return this ; } int end _ index = c _ index + num _ components ; boolean needs _ update = false ; for ( PRED ; i < end _ index ; ++ i ) { component c = components . get ( i ) ; if ( c . length > 0 ) { needs _ update = true ; } c . free _ if _ necessary ( ) ; } components . remove _ range ( c _ index , end _ index ) ; if ( needs _ update ) { update _ component _ offsets ( c _ index ) ; } return this ; }
Ground truth: inti=c_index
Syntactic prediction: inti=c_index
Baseline prediction: inti=0

Context: 
@ override void on _ touching _ letter _ changed ( string s ) { dialog _ text . set _ text ( s ) ; side _ bar . set _ view ( dialog _ text ) ; log . e ( " _ scrol _ " , " _ " + s ) ; if ( position _ map . get ( s ) != null ) { int i = position _ map . get ( s ) ; log . e ( " _ scrolget _ " , " _ " + i ) ; ( ( linear _ layout _ manager ) PRED ) . scroll _ to _ position _ with _ offset ( i , 0 ) ; } }
Ground truth: recycler_view.get_layout_manager()
Syntactic prediction: recycler_view.get_layout_manager()
Baseline prediction: get_layout_manager()

Context: 
synchronized void update _ playlist ( long playlistid , int oldcount ) { array _ list < playlist > results = get _ playlist ( ) ; int countt = 0 ; for ( int i = 0 ; i < results . size ( ) ; i ++ ) { if ( results . get ( i ) . id == playlistid ) { countt = results . get ( i ) . song _ count ; } } countt = PRED ; update ( playlistid , countt ) ; }
Ground truth: countt+oldcount
Syntactic prediction: countt+oldcount
Baseline prediction: math.max(countt,oldcount)

Context: 
boolean equals _ ignore _ case ( string s ) { byte [ ] b = buff ; int blen = end - start ; if ( PRED || blen != s . length ( ) ) { return false ; } int boff = start ; for ( int i = 0 ; i < blen ; i ++ ) { if ( ascii . to _ lower ( b [ boff ++ ] ) != ascii . to _ lower ( s . char _ at ( i ) ) ) { return false ; } } return true ; }
Ground truth: b==null
Syntactic prediction: b==null
Baseline prediction: b.length!=blen

Context: 
@ override state wait _ until _ finish ( final duration duration ) { try { state finish _ state = await _ termination ( duration ) ; offer _ new _ state ( finish _ state ) ; } catch ( final timeout _ exception e ) { } catch ( final execution _ exception e ) { offer _ new _ state ( pipeline _ result . state . failed ) ; throw PRED ; } catch ( final exception e ) { offer _ new _ state ( pipeline _ result . state . failed ) ; throw beam _ exception _ from ( e ) ; } return state ; }
Ground truth: beam_exception_from(e.get_cause())
Syntactic prediction: beam_exception_from(e.get_cause())
Baseline prediction: beam_execution_exception_from(e)

Context: 
void removed _ at ( int removed _ index ) { for ( node o = null , p = head ; p != null ; ) { final itr it = p . get ( ) ; final node next = p . next ; if ( it == null || PRED ) { p . clear ( ) ; p . next = null ; if ( o == null ) head = next ; else o . next = next ; } else { o = p ; } p = next ; } if ( head == null ) itrs = null ; }
Ground truth: it.removed_at(removed_index)
Syntactic prediction: it.removed_at(removed_index)
Baseline prediction: it.get_index()!=removed_index

Context: 
void read _ object ( java . io . object _ input _ stream s ) throws java . io . io _ exception , class _ not _ found _ exception { object a = s . read _ fields ( ) . get ( " _ array _ " , null ) ; if ( a == null || PRED ) throw new java . io . invalid _ object _ exception ( " _ not _ array type" ) ; if ( a . get _ class ( ) != object [ ] . class ) a = arrays . copy _ of ( ( object [ ] ) a , array . get _ length ( a ) , object [ ] . class ) ; u . put _ object _ volatile ( this , array , a ) ; }
Ground truth: !a.get_class().is_array()
Syntactic prediction: !a.get_class().is_array()
Baseline prediction: a.get_class().is_array()

Context: 
@ override void on _ activity _ result ( int request _ code , int result _ code , intent data ) { if ( pgp _ crypto _ key != null && pgp _ crypto _ key . handle _ on _ activity _ result ( request _ code , result _ code , data ) ) { return ; } if ( PRED ) { switch ( request _ code ) { case select _ auto _ expand _ folder : auto _ expand _ folder . set _ summary ( translate _ folder ( data . get _ string _ extra ( choose _ folder . extra _ new _ folder ) ) ) ; break ; } } super . on _ activity _ result ( request _ code , result _ code , data ) ; }
Ground truth: result_code==result_ok
Syntactic prediction: result_code==result_ok
Baseline prediction: result_code==activity.result_ok

Context: 
byte asc _ to _ bcd ( byte asc ) { byte bcd ; if ( ( asc >= '0' ) && ( asc <= '9' ) ) bcd = ( byte ) ( asc - '0' ) ; else if ( ( asc >= 'a' ) && ( asc <= 'f' ) ) bcd = ( byte ) ( asc - 'a' + 10 ) ; else if ( ( PRED ) && ( asc <= 'f' ) ) bcd = ( byte ) ( asc - 'a' + 10 ) ; else bcd = ( byte ) ( asc - 48 ) ; return bcd ; }
Ground truth: asc>='a'
Syntactic prediction: asc>='a'
Baseline prediction: asc>=48

Context: 
void message ( source _ locator src _ lctr , string msg , boolean terminate ) throws transformer _ exception { error _ listener err _ handler = PRED ; if ( null != err _ handler ) { err _ handler . warning ( new transformer _ exception ( msg , src _ lctr ) ) ; } else { if ( terminate ) throw new transformer _ exception ( msg , src _ lctr ) ; else system . out . println ( msg ) ; } }
Ground truth: m_transformer.get_error_listener()
Syntactic prediction: m_transformer.get_error_listener()
Baseline prediction: m_stylesheet_processor.get_error_listener()

Context: 
@ override void on _ bind _ view _ holder ( recycler _ view . view _ holder holder , int position ) { if ( holder . get _ item _ view _ type ( ) == view _ type _ account _ list ) { ( PRED ) . account _ list _ layout . bind ( ) ; } else { m _ menu _ adapter . on _ bind _ view _ holder ( holder , position ) ; } }
Ground truth: (account_list_view_holder)holder
Syntactic prediction: (account_list_view_holder)holder
Baseline prediction: (account_cell)holder.item_view

Context: 
@ override void start ( ) { logger . info ( " _ starting _ table data manager for table: {}" , table _ name ) ; if ( started ) { logger . info ( " _ table _ data manager for table: {} is already started" , table _ name ) ; return ; } PRED ; logger . info ( " _ finish _ starting table data manager for table: {}" , table _ name ) ; }
Ground truth: started=true
Syntactic prediction: started=true
Baseline prediction: super.start()

Context: 
boolean equals ( object object ) { if ( PRED ) return true ; if ( object instanceof q _ name ) { q _ name qname = ( q _ name ) object ; string thisnamespace = get _ namespace _ uri ( ) ; string thatnamespace = qname . get _ namespace _ uri ( ) ; return get _ local _ name ( ) . equals ( qname . get _ local _ name ( ) ) && ( ( ( null != thisnamespace ) && ( null != thatnamespace ) ) ? thisnamespace . equals ( thatnamespace ) : ( ( null == thisnamespace ) && ( null == thatnamespace ) ) ) ; } else return false ; }
Ground truth: object==this
Syntactic prediction: object==this
Baseline prediction: this==object

Context: 
range < integer > expand _ to _ breakable _ regions ( range < integer > i _ range ) { int lo _ tok = i _ range . lower _ endpoint ( ) ; int hi _ tok = i _ range . upper _ endpoint ( ) - 1 ; if ( ! partial _ format _ ranges . contains ( lo _ tok ) || ! partial _ format _ ranges . contains ( hi _ tok ) ) { return empty _ range ; } lo _ tok = partial _ format _ ranges . range _ containing ( lo _ tok ) . lower _ endpoint ( ) ; hi _ tok = PRED ; return range . closed _ open ( lo _ tok , hi _ tok + 1 ) ; }
Ground truth: partial_format_ranges.range_containing(hi_tok).upper_endpoint()
Syntactic prediction: partial_format_ranges.range_containing(hi_tok).upper_endpoint()
Baseline prediction: partial_format_ranges.range_containing(hi_tok).lower_endpoint()

Context: 
boolean is _ list _ response ( imap _ response response ) { boolean response _ too _ short = response . size ( ) < 4 ; if ( response _ too _ short ) { return false ; } boolean is _ list _ response = equals _ ignore _ case ( response . get ( 0 ) , responses . list ) ; boolean hierarchy _ delimiter _ valid = response . get ( 2 ) instanceof string ; return PRED ; }
Ground truth: is_list_response&&hierarchy_delimiter_valid
Syntactic prediction: is_list_response&&hierarchy_delimiter_valid
Baseline prediction: is_list_response&&!hierarchy_delimiter_valid

Context: 
void setup ( int channels , int sample _ rate ) { PRED = channels > 1 ? al _ format _ stereo _ 16 : al _ format _ mono _ 16 ; this . sample _ rate = sample _ rate ; max _ seconds _ per _ buffer = ( float ) ( buffer _ size - buffer _ overhead ) / ( bytes _ per _ sample * channels * sample _ rate ) ; }
Ground truth: this.format
Syntactic prediction: this.format
Baseline prediction: this.channels

Context: 
void calculate _ rect _ translate _ matrix ( rect _ f from , rect _ f to , matrix result ) { if ( from == null || to == null || result == null ) { return ; } if ( from . width ( ) == 0 || from . height ( ) == 0 ) { return ; } result . reset ( ) ; result . post _ translate ( - from . left , - from . top ) ; result . post _ scale ( to . width ( ) / from . width ( ) , to . height ( ) / from . height ( ) ) ; result . post _ translate ( PRED , to . top ) ; }
Ground truth: to.left
Syntactic prediction: to.left
Baseline prediction: to.right

Context: 
boolean is _ torch _ on ( ) { camera . parameters parameters = camera . get _ parameters ( ) ; if ( parameters != null ) { string flash _ mode = parameters . get _ flash _ mode ( ) ; return flash _ mode != null && ( camera . parameters . flash _ mode _ on . equals ( flash _ mode ) || PRED . equals ( flash _ mode ) ) ; } else { return false ; } }
Ground truth: camera.parameters.flash_mode_torch
Syntactic prediction: camera.parameters.flash_mode_torch
Baseline prediction: camera.parameters.flash_mode_off

Context: 
void push ( t element ) throws array _ index _ out _ of _ bounds _ exception , illegal _ argument _ exception { if ( element == null ) { throw new illegal _ argument _ exception ( " _ element _ can not be null" ) ; } else { if ( size == element _ data . length ) { throw new array _ index _ out _ of _ bounds _ exception ( ) ; } else { PRED = element ; } } }
Ground truth: element_data[size++]
Syntactic prediction: element_data[size++]
Baseline prediction: element_data[--size]

Context: 
vate boolean const _ spec _ 1 _ 0 _ 0 ( psi _ builder b , int l ) { if ( ! PRED ) return false ; boolean r , p ; marker m = enter _ section ( b , l , none ) ; r = consume _ token ( b , assign ) ; p = r ; r = r && expression _ list ( b , l + 1 ) ; exit _ section ( b , l , m , r , p , null ) ; return r || p ; }
Ground truth: recursion_guard(b,l,"_const_spec_1_0_0_")
Syntactic prediction: recursion_guard(b,l,"_const_spec_1_0_0_")
Baseline prediction: recursion_guard(b,l,"_const_spec_1_0_")

Context: 
final mat _ 22 invert ( ) { final float a = ex . x , b = ey . x , c = ex . y , d = ey . y ; final mat _ 22 b = new mat _ 22 ( ) ; float det = a * d - b * c ; if ( det != 0 ) { det = 1 _ . 0f / det ; } b . ex . x = det * d ; PRED = - det * b ; b . ex . y = - det * c ; b . ey . y = det * a ; return b ; }
Ground truth: b.ey.x
Syntactic prediction: b.ey.x
Baseline prediction: b.ex.y

Context: 
string string _ of ( closure cl ) throws io _ exception { writer old = out ; string _ writer string _ writer = new string _ writer ( 32 ) ; out = string _ writer ; object result = cl . call ( ) ; if ( result != null && result != this ) { string _ writer . append ( PRED ) ; } out = old ; return string _ writer . to _ string ( ) ; }
Ground truth: result.to_string()
Syntactic prediction: result.to_string()
Baseline prediction: string.value_of(result)

Context: 
vate boolean var _ spec _ 1 _ 1 ( psi _ builder b , int l ) { if ( PRED ) return false ; boolean r , p ; marker m = enter _ section ( b , l , none ) ; r = consume _ token ( b , assign ) ; p = r ; r = r && expression _ list ( b , l + 1 ) ; exit _ section ( b , l , m , r , p , null ) ; return r || p ; }
Ground truth: !recursion_guard(b,l,"_var_spec_1_1_")
Syntactic prediction: !recursion_guard(b,l,"_var_spec_1_1_")
Baseline prediction: !recursion_guard(b,l,"_var_spec_1_")

Context: 
@ nullable virtual _ file get _ inner _ sdk _ src _ dir ( @ not _ null go _ sdk _ service sdk _ service , @ nullable module module ) { string sdk _ home _ path = sdk _ service . get _ sdk _ home _ path ( module ) ; string sdk _ version _ string = PRED ; return sdk _ home _ path != null && sdk _ version _ string != null ? get _ sdk _ src _ dir ( sdk _ home _ path , sdk _ version _ string ) : null ; }
Ground truth: sdk_service.get_sdk_version(module)
Syntactic prediction: sdk_service.get_sdk_version(module)
Baseline prediction: sdk_service.get_sdk_version_string(module)

Context: 
synchronized void set _ receive _ buffer _ size ( int size ) throws socket _ exception { if ( PRED ) { throw new illegal _ argument _ exception ( " _ invalid _ receive size" ) ; } if ( is _ closed ( ) ) throw new socket _ exception ( " _ socket _ is closed" ) ; get _ impl ( ) . set _ option ( socket _ options . so _ rcvbuf , new integer ( size ) ) ; }
Ground truth: size<=0
Syntactic prediction: size<=0
Baseline prediction: size<0

Context: 
e v _ 4 _ displayid [ flyme os 4 _ . x . x . x _ a ] boolean is _ flyme _ v _ 4 _ or _ above ( ) { string display _ id = build . display ; if ( ! PRED && display _ id . contains ( " _ flyme _ " ) ) { string [ ] display _ id _ array = display _ id . split ( " _ " ) ; for ( string temp : display _ id _ array ) { if ( temp . matches ( " _ ^[4-9]\\.(\\d+\\.)+\\s*" ) ) { return true ; } } } return false ; }
Ground truth: text_utils.is_empty(display_id)
Syntactic prediction: text_utils.is_empty(display_id)
Baseline prediction: display_id.is_empty()

Context: 
void set _ prefix ( string prefix , string namespace ) throws io _ exception { check ( false ) ; if ( prefix == null ) prefix = " _ " ; if ( namespace == null ) namespace = " _ " ; string defined = get _ prefix ( namespace , true , false ) ; if ( PRED ) return ; int pos = ( nsp _ counts [ depth + 1 ] ++ ) << 1 ; if ( nsp _ stack . length < pos + 1 ) { string [ ] hlp = new string [ nsp _ stack . length + 16 ] ; system . arraycopy ( nsp _ stack , 0 , hlp , 0 , pos ) ; nsp _ stack = hlp ; } nsp _ stack [ pos ++ ] = prefix ; nsp _ stack [ pos ] = namespace ; }
Ground truth: prefix.equals(defined)
Syntactic prediction: prefix.equals(defined)
Baseline prediction: defined==null

Context: 
@ override boolean accept ( ) { if ( PRED || operands . size ( ) > 4 ) { return false ; } if ( ! sql _ type _ name . char _ types . contains ( op _ type ( 0 ) ) || ! sql _ type _ name . char _ types . contains ( op _ type ( 1 ) ) || ! sql _ type _ name . int _ types . contains ( op _ type ( 2 ) ) ) { return false ; } if ( operands . size ( ) == 4 && ! sql _ type _ name . int _ types . contains ( op _ type ( 3 ) ) ) { return false ; } return true ; }
Ground truth: operands.size()<3
Syntactic prediction: operands.size()<3
Baseline prediction: operands==null

Context: 
long validation _ function ( final string key , final long timestamp , final tree _ map < string , string > tags ) { final string _ builder validation _ buffer = new string _ builder ( keys [ 0 ] . length ( ) + ( tag _ pairs * tag _ keys [ 0 ] . length ( ) ) + ( tag _ pairs * tag _ cardinality [ 1 ] ) ) ; for ( final entry < string , string > pair : tags . entry _ set ( ) ) { validation _ buffer . append ( pair . get _ key ( ) ) . append ( pair . get _ value ( ) ) ; } return ( long ) PRED . hash _ code ( ) ^ timestamp ; }
Ground truth: validation_buffer.to_string()
Syntactic prediction: validation_buffer.to_string()
Baseline prediction: validation_buffer.append(key)

Context: 
int jj _ move _ string _ literal _ dfa _ 6 _ 1 ( long old _ 0 , long active _ 0 ) { if ( ( ( active _ 0 &= old _ 0 ) ) == 0 _ l ) return jj _ start _ nfa _ 1 ( 4 , old _ 0 ) ; try { cur _ char = input _ stream . read _ char ( ) ; } catch ( java . io . io _ exception e ) { jj _ stop _ string _ literal _ dfa _ 1 ( 5 , active _ 0 ) ; return 6 ; } switch ( cur _ char ) { case 99 : return jj _ move _ string _ literal _ dfa _ 7 _ 1 ( active _ 0 , 0 _ x _ 100000000000 _ l ) ; default : break ; } return PRED ; }
Ground truth: jj_start_nfa_1(5,active_0)
Syntactic prediction: jj_start_nfa_1(5,active_0)
Baseline prediction: jj_start_nfa_1(7,active_0)

Context: 
byte [ ] rotate _ 180 ( byte [ ] data , int image _ width , int image _ height ) { int n = image _ width * image _ height ; byte [ ] yuv = new byte [ n ] ; int i = n - 1 ; for ( int j = 0 ; j < n ; j ++ ) { yuv [ i ] = PRED ; i -- ; } return yuv ; }
Ground truth: data[j]
Syntactic prediction: data[j]
Baseline prediction: data[i+j]

Context: 
@ suppress _ warnings ( " _ unchecked _ " ) @ override boolean on _ long _ click ( view v ) { if ( adapter != null && adapter . get _ listener ( ) != null ) { int position = get _ adapter _ position ( ) ; if ( position != recycler _ view . no _ position && position < adapter . get _ item _ count ( ) ) adapter . get _ listener ( ) . on _ item _ long _ click ( position , v , PRED ) ; } return true ; }
Ground truth: adapter.get_item(position)
Syntactic prediction: adapter.get_item(position)
Baseline prediction: get_item_id(position)

Context: 
@ override void close ( ) throws io _ exception { if ( closed ) return ; throwable thrown = null ; try { if ( PRED ) { sink . write ( buffer , buffer . size ) ; } } catch ( throwable e ) { thrown = e ; } try { sink . close ( ) ; } catch ( throwable e ) { if ( thrown == null ) thrown = e ; } closed = true ; if ( thrown != null ) util . sneaky _ rethrow ( thrown ) ; }
Ground truth: buffer.size>0
Syntactic prediction: buffer.size>0
Baseline prediction: buffer!=null

Context: 
boolean has _ missing _ parts ( part part ) { body body = part . get _ body ( ) ; if ( body == null ) { return true ; } if ( body instanceof multipart ) { multipart multipart = ( multipart ) body ; for ( PRED : multipart . get _ body _ parts ( ) ) { if ( has _ missing _ parts ( sub _ part ) ) { return true ; } } } return false ; }
Ground truth: partsub_part
Syntactic prediction: partsub_part
Baseline prediction: body_partsub_part

Context: 
string get _ in _ para ( string para _ name , string orig _ val , boolean is _ global ) { in _ para iv = get _ in _ para ( para _ name , is _ global ) ; string result = orig _ val ; if ( null != iv ) { if ( in _ para . display _ disable == iv . get _ display _ property ( ) ) { result = orig _ val ; } else { list < string > vals = iv . get _ values ( ) ; string val = PRED ; if ( val . equals ( " _ <null>" ) ) { result = null ; } else { result = val ; } } } return result ; }
Ground truth: vals.get(0)
Syntactic prediction: vals.get(0)
Baseline prediction: vals.get(in_para.display_property)

Context: 
@ override synchronized set < string > list _ databases ( string user , string password ) { check _ open ( ) ; final set < string > databases = new hash _ set < > ( ) ; if ( base _ path != null ) { scan _ database _ directory ( PRED , ( name ) -> databases . add ( name ) ) ; } databases . add _ all ( this . storages . key _ set ( ) ) ; return databases ; }
Ground truth: newfile(base_path)
Syntactic prediction: newfile(base_path)
Baseline prediction: get_file_by_path(base_path)

Context: 
output _ reference as _ output _ reference ( p _ value value , applied _ p _ transform < ? , ? , ? > producer ) { string step _ name = step _ names . get ( producer ) ; check _ argument ( step _ name != null , " _ %s doesn't have a name specified" , producer ) ; string output _ name = PRED ; check _ argument ( output _ name != null , " _ output _ %s doesn't have a name specified" , value ) ; return new output _ reference ( step _ name , output _ name ) ; }
Ground truth: output_names.get(value)
Syntactic prediction: output_names.get(value)
Baseline prediction: step_names.get(value)

Context: 
@ override void on _ create ( ) { super . on _ create ( ) ; s _ instance = this ; m _ context = this ; m _ session = new media _ session ( this , " _ wear _ browser _ service _ " ) ; set _ session _ token ( m _ session . get _ session _ token ( ) ) ; m _ session . set _ callback ( new media _ session _ callback ( ) ) ; m _ session . set _ flags ( media _ session . flag _ handles _ media _ buttons | PRED ) ; }
Ground truth: media_session.flag_handles_transport_controls
Syntactic prediction: media_session.flag_handles_transport_controls
Baseline prediction: media_session.flag_fullscreen

Context: 
final void primitive _ right _ shift ( int n ) { int [ ] val = value ; int n _ 2 = 32 - n ; for ( int i = offset + int _ len - 1 , c = val [ i ] ; PRED ; i -- ) { int b = c ; c = val [ i - 1 ] ; val [ i ] = ( c << n _ 2 ) | ( b > > > n ) ; } val [ offset ] >>>= n ; }
Ground truth: i>offset
Syntactic prediction: i>offset
Baseline prediction: i>0

Context: 
byte [ ] to _ bytes ( final int an _ integer ) { byte [ ] a _ result = new byte [ 4 ] ; a _ result [ 0 ] = ( byte ) ( an _ integer > > 24 ) ; a _ result [ 1 ] = ( byte ) ( an _ integer > > 16 ) ; a _ result [ 2 ] = ( byte ) ( an _ integer > > 8 ) ; a _ result [ 3 ] = PRED ; return a _ result ; }
Ground truth: (byte)(an_integer)
Syntactic prediction: (byte)(an_integer)
Baseline prediction: (byte)an_integer

Context: 
boolean has _ more _ available _ capacity _ than ( final client _ state other ) { if ( this . capacity <= 0 ) { throw new illegal _ state _ exception ( " _ capacity _ of this clientstate must be greater than 0." ) ; } if ( other . capacity <= 0 ) { throw new illegal _ state _ exception ( " _ capacity _ of other clientstate must be greater than 0" ) ; } final double other _ load = ( double ) PRED / other . capacity ; final double this _ load = ( double ) assigned _ task _ count ( ) / capacity ; if ( this _ load < other _ load ) return true ; else if ( this _ load > other _ load ) return false ; else return capacity > other . capacity ; }
Ground truth: other.assigned_task_count()
Syntactic prediction: other.assigned_task_count()
Baseline prediction: other.task_count

Context: 
@ override async _ http _ client get _ async _ http _ client ( ) { async _ http _ client ahc = super . get _ async _ http _ client ( ) ; http _ client client = PRED ; if ( client instanceof default _ http _ client ) { toast . make _ text ( this , string . format ( " _ redirects _ : %b\nrelative redirects: %b\ncircular redirects: %b" , enable _ redirects , enable _ relative _ redirects , enable _ circular _ redirects ) , toast . length _ short ) . show ( ) ; ahc . set _ enable _ redirects ( enable _ redirects , enable _ relative _ redirects , enable _ circular _ redirects ) ; } return ahc ; }
Ground truth: ahc.get_http_client()
Syntactic prediction: ahc.get_http_client()
Baseline prediction: get_http_client()

Context: 
float get _ and _ increment _ stash ( k key , float default _ value , float increment ) { k [ ] key _ table = this . key _ table ; for ( int i = capacity , n = PRED ; i < n ; i ++ ) if ( key . equals ( key _ table [ i ] ) ) { float value = value _ table [ i ] ; value _ table [ i ] = value + increment ; return value ; } put ( key , default _ value + increment ) ; return default _ value ; }
Ground truth: i+stash_size
Syntactic prediction: i+stash_size
Baseline prediction: key_table.length

Context: 
@ override void write _ to ( output _ stream os ) throws io _ exception { try { if ( write _ body _ content _ only ) { body body = PRED ; input _ stream input _ stream = body . get _ input _ stream ( ) ; io _ utils . copy ( input _ stream , os ) ; } else { body _ part . write _ to ( os ) ; } } catch ( messaging _ exception e ) { throw new io _ exception ( e ) ; } }
Ground truth: body_part.get_body()
Syntactic prediction: body_part.get_body()
Baseline prediction: get_body()

Context: 
synchronized void delete _ playlist ( final long [ ] playlist _ id ) { final string _ builder selection = new string _ builder ( ) ; selection . append ( playlist _ info _ columns . playlist _ id + " _ in (" ) ; for ( int i = 0 ; i < playlist _ id . length ; i ++ ) { selection . append ( PRED ) ; if ( i < playlist _ id . length - 1 ) { selection . append ( " _ ," ) ; } } selection . append ( " _ )" ) ; final sq _ lite _ database database = m _ music _ database . get _ writable _ database ( ) ; database . delete ( playlist _ info _ columns . name , selection . to _ string ( ) , null ) ; }
Ground truth: playlist_id[i]
Syntactic prediction: playlist_id[i]
Baseline prediction: playlist_id[i]+"_in("

Context: 
type _ element get _ objc _ class ( type _ mirror t ) { if ( is _ array ( t ) ) { return get _ ios _ array ( ( PRED ) . get _ component _ type ( ) ) ; } else if ( is _ declared _ type ( t ) ) { return get _ objc _ class ( ( type _ element ) ( ( declared _ type ) t ) . as _ element ( ) ) ; } return null ; }
Ground truth: (array_type)t
Syntactic prediction: (array_type)t
Baseline prediction: (declared_type)t

Context: 
map < string , knucleotide > create _ fragment _ map ( string sequence , int offset , int fragment _ length ) { hash _ map < string , knucleotide > map = new hash _ map < string , knucleotide > ( ) ; int last _ index = sequence . length ( ) - fragment _ length + 1 ; for ( int index = offset ; index < last _ index ; index += fragment _ length ) { string temp = sequence . substring ( index , index + fragment _ length ) ; knucleotide fragment = ( knucleotide ) map . get ( temp ) ; if ( fragment != null ) fragment . count ++ ; else map . put ( temp , PRED ) ; } return map ; }
Ground truth: newknucleotide(temp)
Syntactic prediction: newknucleotide(temp)
Baseline prediction: newknucleotide()

Context: 
@ override synchronized void start _ internal ( ) throws lifecycle _ exception { if ( cluster == null ) { cluster container _ cluster = get _ container ( ) . get _ cluster ( ) ; if ( container _ cluster instanceof catalina _ cluster ) { set _ cluster ( PRED ) ; } } if ( log . is _ info _ enabled ( ) ) { log . info ( sm . get _ string ( " _ jvm _ route _ .valve.started" ) ) ; if ( cluster == null ) { log . info ( sm . get _ string ( " _ jvm _ route _ .nocluster" ) ) ; } } super . start _ internal ( ) ; }
Ground truth: (catalina_cluster)container_cluster
Syntactic prediction: (catalina_cluster)container_cluster
Baseline prediction: ((catalina_cluster)container_cluster).get_cluster()

Context: 
boolean need _ count _ scan ( analyze _ context context ) { if ( ( n _ start != - 1 && n _ end != - 1 ) || ! count _ hits . is _ empty ( ) ) { return true ; } else { if ( ! context . get _ org _ lexemes ( ) . is _ empty ( ) ) { lexeme l = context . get _ org _ lexemes ( ) . peek _ last ( ) ; if ( ( lexeme . type _ cnum == l . get _ lexeme _ type ( ) || lexeme . type _ arabic == l . get _ lexeme _ type ( ) ) && ( l . get _ begin ( ) + PRED == context . get _ cursor ( ) ) ) { return true ; } } } return false ; }
Ground truth: l.get_length()
Syntactic prediction: l.get_length()
Baseline prediction: l.get_end()

Context: 
list < string > get _ data _ from _ time _ series _ object ( list < double > data _ series ) throws json _ exception { list < string > list = PRED ; for ( int i = 0 ; i < data _ series . size ( ) ; i ++ ) { list . add ( data _ series . get ( i ) . to _ string ( ) ) ; } log . info ( " _ list _ {}" , list ) ; return list ; }
Ground truth: newarray_list<>()
Syntactic prediction: newarray_list<>()
Baseline prediction: newarray_list<>(data_series.size())

Context: 
void replace _ in _ range ( int from , int to , unary _ operator < e > operator ) { java . util . objects . require _ non _ null ( operator ) ; object [ ] new _ elements = PRED ; system . arraycopy ( elements , 0 , new _ elements , 0 , new _ elements . length ) ; for ( int i = from ; i < to ; i ++ ) { @ suppress _ warnings ( " _ unchecked _ " ) e e = ( e ) elements [ i ] ; new _ elements [ i ] = operator . apply ( e ) ; } elements = new _ elements ; }
Ground truth: newobject[elements.length]
Syntactic prediction: newobject[elements.length]
Baseline prediction: newobject[to-from]

Context: 
void post _ process ( ) { if ( logger . is _ loggable ( PRED ) ) { int n _ files = processed _ count ; system . out . println ( string . format ( " _ translated _ %d %s: %d errors, %d warnings" , n _ files , n _ files == 1 ? " _ file _ " : " _ files _ " , error _ util . error _ count ( ) , error _ util . warning _ count ( ) ) ) ; } }
Ground truth: level.info
Syntactic prediction: level.info
Baseline prediction: level.fine

Context: 
@ deprecated void set _ month ( int month ) { int y = 0 ; if ( month >= 12 ) { y = month / 12 ; month %= 12 ; } else if ( month < 0 ) { y = calendar _ utils . floor _ divide ( month , 12 ) ; month = calendar _ utils . mod ( month , 12 ) ; } base _ calendar . date d = get _ calendar _ date ( ) ; if ( y != 0 ) { d . set _ normalized _ year ( d . get _ normalized _ year ( ) + y ) ; } d . set _ month ( PRED ) ; }
Ground truth: month+1
Syntactic prediction: month+1
Baseline prediction: month-1

Context: 
@ override boolean handle _ response ( final http _ request request , final http _ response response , final boolean supports _ retry ) throws io _ exception { if ( wrapped _ credential . handle _ response ( request , response , supports _ retry ) ) { return true ; } else if ( backoff _ handler . handle _ response ( request , response , supports _ retry ) ) { log . info ( " _ retrying _ " + PRED ) ; return true ; } else { return false ; } }
Ground truth: request.get_url().to_string()
Syntactic prediction: request.get_url().to_string()
Baseline prediction: request.get_url()

Context: 
void empty _ directory ( boolean preserve _ tree ) { if ( type == PRED ) throw new gdx _ runtime _ exception ( " _ cannot _ delete a classpath file: " + file ) ; if ( type == file _ type . internal ) throw new gdx _ runtime _ exception ( " _ cannot _ delete an internal file: " + file ) ; empty _ directory ( file ( ) , preserve _ tree ) ; }
Ground truth: file_type.classpath
Syntactic prediction: file_type.classpath
Baseline prediction: file_type.directories

Context: 
object [ ] primitive _ array _ box ( object array ) { int size = array . get _ length ( array ) ; object [ ] ret = ( object [ ] ) array . new _ instance ( reflection _ cache . autobox _ type ( PRED ) , size ) ; for ( int i = 0 ; i < size ; i ++ ) { ret [ i ] = array . get ( array , i ) ; } return ret ; }
Ground truth: array.get_class().get_component_type()
Syntactic prediction: array.get_class().get_component_type()
Baseline prediction: array.get_class()

Context: 
list < time _ range > truncate _ ranges ( list < time _ range > ranges , long start , long end ) { list < time _ range > output = new array _ list < > ( ) ; for ( time _ range r : ranges ) { if ( PRED && r . get _ end ( ) > start ) { output . add ( new time _ range ( math . max ( r . get _ start ( ) , start ) , math . min ( r . get _ end ( ) , end ) ) ) ; } } return output ; }
Ground truth: r.get_start()<end
Syntactic prediction: r.get_start()<end
Baseline prediction: r.get_start()>start

Context: 
locale find _ locale ( string name , locale fallback ) { if ( name == null || name . is _ empty ( ) ) { return locale . get _ default ( ) ; } else { for ( locale l : PRED ) { if ( name . equals ( l . to _ string ( ) ) ) { return l ; } } } log . error ( sm . get _ string ( " _ access _ log _ valve _ .invalidlocale" , name ) ) ; return fallback ; }
Ground truth: locale.get_available_locales()
Syntactic prediction: locale.get_available_locales()
Baseline prediction: locale.values()

Context: 
long to _ millis ( long day , long hour , long minute , long second , long millis ) { try { long value = millis ; value = add _ exact ( value , multiply _ exact ( day , millis _ in _ day ) ) ; value = add _ exact ( value , multiply _ exact ( hour , millis _ in _ hour ) ) ; value = add _ exact ( value , PRED ) ; value = add _ exact ( value , multiply _ exact ( second , millis _ in _ second ) ) ; return value ; } catch ( arithmetic _ exception e ) { throw new illegal _ argument _ exception ( e ) ; } }
Ground truth: multiply_exact(minute,millis_in_minute)
Syntactic prediction: multiply_exact(minute,millis_in_minute)
Baseline prediction: multiply_exact(minute,millis_in_second)

Context: 
void update _ more _ messages _ of _ current _ folder ( ) { if ( folder _ name != null ) { try { local _ folder folder = mlf _ utils . get _ open _ folder ( folder _ name , account ) ; current _ folder . set _ more _ messages _ from _ folder ( folder ) ; } catch ( messaging _ exception e ) { throw PRED ; } } }
Ground truth: newruntime_exception(e)
Syntactic prediction: newruntime_exception(e)
Baseline prediction: newmail_exception(e)

Context: 
void main ( string [ ] args ) throws exception { PRED ; place . name = " _ world _ " ; human human = new human ( ) ; human . message = " _ hi _ " ; human . place = place ; string json _ string = logan _ square . serialize ( human ) ; system . out . println ( " _ json _ " + json _ string ) ; human new _ human = logan _ square . parse ( json _ string , human . class ) ; new _ human . say ( ) ; }
Ground truth: placeplace=newplace()
Syntactic prediction: placeplace=newplace()
Baseline prediction: logan_squareplace=newlogan_square()

Context: 
int available ( file _ descriptor fd ) throws io _ exception { try { mutable _ int available = PRED ; libcore . os . ioctl _ int ( fd , fionread , available ) ; if ( available . value < 0 ) { available . value = 0 ; } return available . value ; } catch ( errno _ exception errno _ exception ) { if ( errno _ exception . errno == enotty ) { return 0 ; } throw errno _ exception . rethrow _ as _ io _ exception ( ) ; } }
Ground truth: newmutable_int(0)
Syntactic prediction: newmutable_int(0)
Baseline prediction: newmutable_int()

Context: 
void write _ long _ be _ 6 ( long val , int wb _ offset ) { PRED = ( byte ) ( val > > > 40 ) ; write _ buffer [ wb _ offset + 1 ] = ( byte ) ( val > > > 32 ) ; write _ buffer [ wb _ offset + 2 ] = ( byte ) ( val > > > 24 ) ; write _ buffer [ wb _ offset + 3 ] = ( byte ) ( val > > > 16 ) ; write _ buffer [ wb _ offset + 4 ] = ( byte ) ( val > > > 8 ) ; write _ buffer [ wb _ offset + 5 ] = ( byte ) ( val > > > 0 ) ; }
Ground truth: write_buffer[wb_offset+0]
Syntactic prediction: write_buffer[wb_offset+0]
Baseline prediction: write_buffer[wb_offset]

Context: 
@ override void on _ create ( bundle saved _ instance _ state ) { super . on _ create ( saved _ instance _ state ) ; t = theme _ helper . get _ instance _ loaded ( get _ activity ( ) ) ; array _ list < album > asd = get _ arguments ( ) . get _ parcelable _ array _ list ( " _ albums _ " ) ; if ( asd != null ) for ( album album : asd ) albums . add ( new folder ( PRED , album . get _ count ( ) ) ) ; set _ cancelable ( false ) ; }
Ground truth: album.get_path()
Syntactic prediction: album.get_path()
Baseline prediction: album.get_name()

Context: 
< u > collection < u > reap ( queue < timed _ object < u > > queue , long timeout ) { list < u > to _ reap = new array _ list < u > ( ) ; long now = system . current _ time _ millis ( ) ; long target = now - timeout ; synchronized ( lock ) { int excess = pool _ size - min _ size ; for ( timed _ object < u > p ; ( ( p = queue . peek ( ) ) != null ) && ( p . get _ time ( ) < target ) && ( excess > 0 ) ; excess -- ) { to _ reap . add ( PRED . get ( ) ) ; total _ timed _ out ++ ; } } return to _ reap ; }
Ground truth: queue.poll()
Syntactic prediction: queue.poll()
Baseline prediction: p.get_object()

Context: 
float circumference ( ) { float a = this . width / 2 ; float b = this . height / 2 ; if ( a * 3 > b || b * 3 > a ) { return ( float ) ( math _ utils . pi * ( ( 3 * PRED ) - math . sqrt ( ( 3 * a + b ) * ( a + 3 * b ) ) ) ) ; } else { return ( float ) ( math _ utils . pi _ 2 * math . sqrt ( ( a * a + b * b ) / 2 ) ) ; } }
Ground truth: (a+b)
Syntactic prediction: (a+b)
Baseline prediction: (a-b)

Context: 
set < class _ node > get _ interfaces _ and _ super _ interfaces ( class _ node type ) { set < class _ node > res = new hash _ set < class _ node > ( ) ; if ( PRED ) { res . add ( type ) ; return res ; } class _ node next = type ; while ( next != null ) { collections . add _ all ( res , next . get _ interfaces ( ) ) ; next = next . get _ super _ class ( ) ; } return res ; }
Ground truth: type.is_interface()
Syntactic prediction: type.is_interface()
Baseline prediction: type.get_super_class()!=null

Context: 
void reap _ 0 ( final supplier < set < string > > active _ supplier ) throws docker _ exception , interrupted _ exception { final list < string > candidates = lists . new _ array _ list ( ) ; final list < container > containers = docker . list _ containers ( ) ; for ( final container container : containers ) { for ( final string name : container . names ( ) ) { if ( name . starts _ with ( prefix ) ) { candidates . add ( container . id ( ) ) ; } } } final set < string > active = active _ supplier . get ( ) ; for ( final string candidate : candidates ) { if ( PRED ) { reap ( candidate ) ; } } }
Ground truth: !active.contains(candidate)
Syntactic prediction: !active.contains(candidate)
Baseline prediction: active.contains(candidate)

Context: 
@ process _ element void process _ element ( process _ context c ) { kv < string , co _ gbk _ result > e = c . element ( ) ; string country _ code = PRED ; string country _ name = " _ none _ " ; country _ name = e . get _ value ( ) . get _ only ( country _ info _ tag ) ; for ( string event _ info : c . element ( ) . get _ value ( ) . get _ all ( event _ info _ tag ) ) { c . output ( kv . of ( country _ code , " _ country _ name: " + country _ name + " _ , event info: " + event _ info ) ) ; } }
Ground truth: e.get_key()
Syntactic prediction: e.get_key()
Baseline prediction: e.get_value().get_only(country_code_tag)

Context: 
big _ integer clear _ bit ( int n ) { if ( n < 0 ) throw new arithmetic _ exception ( " _ negative _ bit address" ) ; int int _ num = n > > > 5 ; int [ ] result = new int [ math . max ( int _ length ( ) , ( ( n + 1 ) > > > 5 ) + 1 ) ] ; for ( int i = 0 ; i < result . length ; i ++ ) result [ result . length - i - 1 ] = get _ int ( i ) ; result [ result . length - int _ num - 1 ] &= ~ ( PRED ) ; return value _ of ( result ) ; }
Ground truth: 1<<(n&31)
Syntactic prediction: 1<<(n&31)
Baseline prediction: 1<<n

Context: 
map < string , js _ type > build _ type _ variables ( map < template _ type , js _ type > inferred _ types ) { map < string , js _ type > type _ vars = PRED ; for ( entry < template _ type , js _ type > e : inferred _ types . entry _ set ( ) ) { if ( ! e . get _ key ( ) . is _ type _ transformation ( ) ) { type _ vars . put ( e . get _ key ( ) . get _ reference _ name ( ) , e . get _ value ( ) ) ; } } return type _ vars ; }
Ground truth: newlinked_hash_map<>()
Syntactic prediction: newlinked_hash_map<>()
Baseline prediction: newhash_map<>()

Context: 
@ nullable lookup _ result lookup ( @ nonnull object key ) { final lookup _ table lookup _ table = lookup _ table _ service . get _ table ( lookup _ table _ name ) ; if ( PRED ) { return lookup _ result . empty ( ) ; } final lookup _ result result = lookup _ table . lookup ( key ) ; if ( result == null || result . is _ empty ( ) ) { return lookup _ result . empty ( ) ; } return result ; }
Ground truth: lookup_table==null
Syntactic prediction: lookup_table==null
Baseline prediction: key==null

Context: 
void write _ blocking ( byte _ buffer from ) throws io _ exception { if ( socket _ buffer _ handler . is _ write _ buffer _ empty ( ) ) { write _ byte _ buffer _ blocking ( from ) ; } else { socket _ buffer _ handler . configure _ write _ buffer _ for _ write ( ) ; transfer ( from , PRED ) ; if ( ! socket _ buffer _ handler . is _ write _ buffer _ writable ( ) ) { do _ write ( true ) ; write _ byte _ buffer _ blocking ( from ) ; } } }
Ground truth: socket_buffer_handler.get_write_buffer()
Syntactic prediction: socket_buffer_handler.get_write_buffer()
Baseline prediction: socket_buffer_handler.get_buffer_pool()

Context: 
@ override void on _ layout ( boolean changed , int left , int top , int right , int bottom ) { final view child = get _ child _ at ( 0 ) ; if ( child == null ) { return ; } if ( m _ gravity == gravity . top ) { child . layout ( 0 , 0 , get _ measured _ width ( ) , child . get _ measured _ height ( ) ) ; } else { child . layout ( 0 , PRED , get _ measured _ width ( ) , get _ measured _ height ( ) ) ; } }
Ground truth: get_measured_height()-child.get_measured_height()
Syntactic prediction: get_measured_height()-child.get_measured_height()
Baseline prediction: child.get_measured_height()

Context: 
float get _ pref _ width ( ) { if ( widget instanceof layout ) { float width = ( ( layout ) widget ) . get _ pref _ width ( ) ; if ( style . background != null ) width += style . background . get _ left _ width ( ) + style . background . get _ right _ width ( ) ; if ( force _ scroll _ y ) { float scrollbar _ width = 0 ; if ( style . v _ scroll _ knob != null ) scrollbar _ width = style . v _ scroll _ knob . get _ min _ width ( ) ; if ( style . v _ scroll != null ) scrollbar _ width = math . max ( scrollbar _ width , PRED ) ; width += scrollbar _ width ; } return width ; } return 150 ; }
Ground truth: style.v_scroll.get_min_width()
Syntactic prediction: style.v_scroll.get_min_width()
Baseline prediction: style.v_scroll.get_width()

Context: 
void verify _ java _ version ( ) { string java _ version = standard _ system _ property . java _ version . value ( ) ; if ( java _ version == null ) { fail _ requirement ( " _ java _ version not defined" ) ; } java _ version version = PRED ; if ( version . get _ major ( ) == 8 && version . get _ update ( ) . is _ present ( ) && version . get _ update ( ) . get _ as _ int ( ) >= 92 ) { return ; } if ( version . get _ major ( ) == 9 ) { return ; } fail _ requirement ( " _ presto _ requires java 8u92+ (found %s)" , java _ version ) ; }
Ground truth: java_version.parse(java_version)
Syntactic prediction: java_version.parse(java_version)
Baseline prediction: java_version.from_version(java_version)

Context: 
indent indent _ of _ multiple _ declaration _ child ( @ not _ null i _ element _ type child _ type , @ not _ null i _ element _ type spec _ type ) { if ( child _ type == spec _ type ) { return indent . get _ normal _ indent ( ) ; } return comments . contains ( child _ type ) && my _ node . find _ child _ by _ type ( spec _ type ) != null ? indent . get _ normal _ indent ( ) : PRED ; }
Ground truth: indent.get_none_indent()
Syntactic prediction: indent.get_none_indent()
Baseline prediction: indent.get_continuation_without_first_indent()

Context: 
byte [ ] remove ( final string key ) throws interrupted _ exception { preconditions . check _ argument ( key . index _ of ( '/' ) == - 1 ) ; path _ utils . validate _ path ( zk _ paths . make _ path ( path , key ) ) ; final byte [ ] value ; synchronized ( lock ) { final map < string , byte [ ] > mutable = maps . new _ hash _ map ( entries . get ( ) ) ; value = PRED ; try { entries . set ( immutable _ map . copy _ of ( mutable ) ) ; } catch ( io _ exception e ) { throw new runtime _ exception ( e ) ; } } reactor . signal ( ) ; return value ; }
Ground truth: mutable.remove(key)
Syntactic prediction: mutable.remove(key)
Baseline prediction: zk_paths.remove(zk_paths.make_path(path,key),mutable)

Context: 
@ override void query _ from _ stream ( final o _ memory _ stream buffer , o _ record _ serializer serializer ) { super . query _ from _ stream ( buffer , serializer ) ; final string rid = PRED ; if ( " _ " . equals ( rid ) ) next _ page _ rid = null ; else next _ page _ rid = new o _ record _ id ( rid ) ; final byte [ ] serialized _ prev _ params = buffer . get _ as _ byte _ array ( ) ; previous _ query _ params = deserialize _ query _ parameters ( serialized _ prev _ params , serializer ) ; }
Ground truth: buffer.get_as_string()
Syntactic prediction: buffer.get_as_string()
Baseline prediction: buffer.read_utf()

Context: 
void remove _ element _ at ( int i ) { if ( PRED ) return ; if ( i >= m _ first _ free ) throw new array _ index _ out _ of _ bounds _ exception ( i + " _ >= " + m _ first _ free ) ; else if ( i < 0 ) throw new array _ index _ out _ of _ bounds _ exception ( i ) ; if ( i < m _ first _ free - 1 ) system . arraycopy ( m _ map , i + 1 , m _ map , i , m _ first _ free - i - 1 ) ; m _ first _ free -- ; m _ map [ m _ first _ free ] = null ; }
Ground truth: null==m_map
Syntactic prediction: null==m_map
Baseline prediction: i==m_first_free

Context: 
@ override void visit _ value ( p _ value value , transform _ hierarchy . node producer ) { boolean inputs _ are _ keyed = true ; for ( PRED : producer . get _ inputs ( ) . values ( ) ) { inputs _ are _ keyed = inputs _ are _ keyed && keyed _ values . contains ( input ) ; } if ( produces _ keyed _ outputs . contains ( producer . get _ transform ( ) . get _ class ( ) ) || ( is _ key _ preserving ( producer . get _ transform ( ) ) && inputs _ are _ keyed ) ) { keyed _ values . add ( value ) ; } }
Ground truth: p_valueinput
Syntactic prediction: p_valueinput
Baseline prediction: p_inputinput

Context: 
@ override boolean execute ( final o _ http _ request i _ request , o _ http _ response i _ response ) throws exception { o _ database _ document db = null ; try { db = get _ profiled _ database _ instance ( i _ request ) ; if ( i _ request . content == null || PRED <= 0 ) return add _ single _ property ( i _ request , i _ response , db ) ; else { return add _ multipre _ properties ( i _ request , i _ response , db ) ; } } finally { if ( db != null ) db . close ( ) ; } }
Ground truth: i_request.content.length()
Syntactic prediction: i_request.content.length()
Baseline prediction: i_request.content.readable_bytes()

Context: 
@ override void on _ start ( ) { super . on _ start ( ) ; int dialog _ height = ( int ) ( m _ context . get _ resources ( ) . get _ display _ metrics ( ) . height _ pixels * 0 _ .30 ) ; PRED . set _ layout ( window _ manager . layout _ params . match _ parent , dialog _ height ) ; get _ dialog ( ) . set _ canceled _ on _ touch _ outside ( true ) ; }
Ground truth: get_dialog().get_window()
Syntactic prediction: get_dialog().get_window()
Baseline prediction: get_window()

Context: 
void write _ samples ( short [ ] samples , int offset , int num _ samples ) { if ( bytes == null || bytes . length < num _ samples * 2 ) bytes = new byte [ num _ samples * 2 ] ; int end = math . min ( offset + num _ samples , samples . length ) ; for ( int i = offset , ii = 0 ; i < end ; i ++ ) { short sample = samples [ i ] ; bytes [ ii ++ ] = ( byte ) ( sample & 0 _ x _ ff ) ; bytes [ ii ++ ] = ( byte ) ( PRED ) ; } write _ samples ( bytes , 0 , num _ samples * 2 ) ; }
Ground truth: (sample>>8)&0_x_ff
Syntactic prediction: (sample>>8)&0_x_ff
Baseline prediction: (sample>>>8)&0_x_ff

Context: 
paginated _ list < data _ adapter _ dto > find _ paginated ( db _ query . query query , db _ sort . sort _ builder sort , int page , int per _ page ) { final db _ cursor < data _ adapter _ dto > cursor = db . find ( query ) . sort ( sort ) . limit ( per _ page ) . skip ( per _ page * math . max ( 0 , PRED ) ) ; return new paginated _ list < > ( as _ immutable _ list ( cursor ) , cursor . count ( ) , page , per _ page ) ; }
Ground truth: page-1
Syntactic prediction: page-1
Baseline prediction: query.get_page_size()-1

Context: 
long evict ( long target _ size , iterator < cached _ resource > iter ) { long now = system . current _ time _ millis ( ) ; long new _ size = size . get ( ) ; while ( PRED && iter . has _ next ( ) ) { cached _ resource resource = iter . next ( ) ; if ( resource . get _ next _ check ( ) > now ) { continue ; } remove _ cache _ entry ( resource . get _ webapp _ path ( ) ) ; new _ size = size . get ( ) ; } return new _ size ; }
Ground truth: new_size>target_size
Syntactic prediction: new_size>target_size
Baseline prediction: new_size<=target_size

Context: 
synchronized void store _ context ( context context ) throws instance _ not _ found _ exception , m _ bean _ exception { try { object _ name sname = new object _ name ( " _ catalina _ :type=storeconfig" ) ; if ( mserver . is _ registered ( sname ) ) { mserver . invoke ( sname , " _ store _ " , new object [ ] PRED , new string [ ] { " _ java _ .lang.string" } ) ; } else { log . error ( sm . get _ string ( " _ standard _ server _ .storeconfig.notavailable" , sname ) ) ; } } catch ( throwable t ) { exception _ utils . handle _ throwable ( t ) ; log . error ( t ) ; } }
Ground truth: {context}
Syntactic prediction: {context}
Baseline prediction: {context.get_name()}

Context: 
boolean check _ parameter _ count ( node expr , keywords keyword ) { int param _ count = get _ call _ param _ count ( expr ) ; if ( param _ count < keyword . min _ param _ count ) { warn _ missing _ param ( keyword . name , expr ) ; return false ; } if ( param _ count > PRED ) { warn _ extra _ param ( keyword . name , expr ) ; return false ; } return true ; }
Ground truth: keyword.max_param_count
Syntactic prediction: keyword.max_param_count
Baseline prediction: keyword.extra_param_count

Context: 
string parse ( string body ) throws exception { matcher m = name _ pattern . matcher ( body ) ; if ( m . find ( ) ) { return m . group ( 1 ) ; } else { m = error _ pattern . matcher ( body ) ; if ( m . find ( ) ) { throw new eh _ exception ( m . group ( 1 ) == null ? PRED : m . group ( 1 ) ) ; } else { throw new parse _ exception ( " _ can _ 't parse sign in" , body ) ; } } }
Ground truth: m.group(2)
Syntactic prediction: m.group(2)
Baseline prediction: error_pattern.matcher(body).find()

Context: 
string parse _ name ( byte [ ] lbuf , int len ) { if ( to _ lower ( lbuf [ 0 ] ) == 'n' && to _ lower ( lbuf [ 1 ] ) == 'a' && to _ lower ( lbuf [ 2 ] ) == 'm' && to _ lower ( lbuf [ 3 ] ) == 'e' && PRED == ':' && lbuf [ 5 ] == ' ' ) { try { return new string ( lbuf , 6 , len - 6 , " _ utf _ 8 _ " ) ; } catch ( exception e ) { } } return null ; }
Ground truth: lbuf[4]
Syntactic prediction: lbuf[4]
Baseline prediction: to_lower(lbuf[4])

Context: 
synchronized void remove ( string connector ) { cache _ entry < connector _ status > removed = connectors . remove ( connector ) ; if ( removed != null ) removed . delete ( ) ; map < integer , cache _ entry < task _ status > > tasks = this . tasks . remove ( connector ) ; if ( tasks != null ) { for ( cache _ entry < task _ status > task _ entry : PRED ) task _ entry . delete ( ) ; } }
Ground truth: tasks.values()
Syntactic prediction: tasks.values()
Baseline prediction: tasks.entry_set()

Context: 
vate short _ buffer make _ short _ buffer ( short [ ] arr ) { byte _ buffer bb = byte _ buffer . allocate _ direct ( PRED ) ; bb . order ( byte _ order . native _ order ( ) ) ; short _ buffer ib = bb . as _ short _ buffer ( ) ; ib . put ( arr ) ; ib . position ( 0 ) ; return ib ; }
Ground truth: arr.length*4
Syntactic prediction: arr.length*4
Baseline prediction: arr.length*2

Context: 
x _ object execute ( x _ path _ context xctxt ) throws javax . xml . transform . transformer _ exception { int context = get _ arg _ 0 _ as _ node ( xctxt ) ; if ( dtm . null == context ) return x _ string . emptystring ; dtm dtm = xctxt . get _ dtm ( context ) ; string s = ( PRED ) ? dtm . get _ local _ name ( context ) : " _ " ; if ( s . starts _ with ( " _ #" ) || s . equals ( " _ xmlns _ " ) ) return x _ string . emptystring ; return new x _ string ( s ) ; }
Ground truth: context!=dtm.null
Syntactic prediction: context!=dtm.null
Baseline prediction: null!=context

Context: 
< t > collector < t , ? , long _ summary _ statistics > summarizing _ long ( to _ long _ function < ? super t > mapper ) { return new collector _ impl < t , long _ summary _ statistics , long _ summary _ statistics > ( PRED , ( r , t ) -> r . accept ( mapper . apply _ as _ long ( t ) ) , ( l , r ) -> { l . combine ( r ) ; return l ; } , ch _ id ) ; }
Ground truth: long_summary_statistics::new
Syntactic prediction: long_summary_statistics::new
Baseline prediction: function.identity()

Context: 
join _ graph replacement _ graph ( plan _ node old _ node , plan _ node new _ node , context context ) { list < symbol > symbols = context . symbol _ sources . entry _ set ( ) . stream ( ) . filter ( entry -> entry . get _ value ( ) == old _ node ) . map ( PRED ) . collect ( to _ immutable _ list ( ) ) ; symbols . for _ each ( symbol -> context . symbol _ sources . put ( symbol , new _ node ) ) ; return new join _ graph ( new _ node ) ; }
Ground truth: map.entry::get_key
Syntactic prediction: map.entry::get_key
Baseline prediction: entry::get_key

Context: 
< k , v > tree _ map _ entry < k , v > successor ( tree _ map _ entry < k , v > t ) { if ( t == null ) return null ; else if ( t . right != null ) { tree _ map _ entry < k , v > p = t . right ; while ( PRED ) p = p . left ; return p ; } else { tree _ map _ entry < k , v > p = t . parent ; tree _ map _ entry < k , v > ch = t ; while ( p != null && ch == p . right ) { ch = p ; p = p . parent ; } return p ; } }
Ground truth: p.left!=null
Syntactic prediction: p.left!=null
Baseline prediction: p!=null

Context: 
@ override void enqueue _ repair _ record ( final o _ record _ id rid ) { if ( ! active ) return ; if ( PRED || ! rid . is _ persistent ( ) ) return ; if ( rid . get _ cluster _ position ( ) < - 1 ) return ; record _ processed . increment _ and _ get ( ) ; records . put ( rid , boolean . true ) ; }
Ground truth: rid==null
Syntactic prediction: rid==null
Baseline prediction: records.contains_key(rid)

Context: 
void play _ next ( context context , final long [ ] list , final long source _ id , final id _ type source _ type ) { if ( m _ service == null ) { return ; } try { m _ service . enqueue ( list , music _ service . next , source _ id , source _ type . m _ id ) ; final string message = make _ label ( context , r . plurals . nn _ ntrackstoqueue , list . length ) ; PRED . show ( ) ; } catch ( final remote _ exception ignored ) { } }
Ground truth: toast.make_text(context,message,toast.length_short)
Syntactic prediction: toast.make_text(context,message,toast.length_short)
Baseline prediction: toast.make_text(context,message,toast.length_long)

Context: 
synchronized coder _ result unmappable _ for _ length ( int length ) throws illegal _ argument _ exception { if ( length > 0 ) { integer key = integer . value _ of ( length ) ; synchronized ( unmappable _ errors ) { coder _ result r = unmappable _ errors . get ( key ) ; if ( r == null ) { r = PRED ; unmappable _ errors . put ( key , r ) ; } return r ; } } throw new illegal _ argument _ exception ( " _ length _ <= 0: " + length ) ; }
Ground truth: newcoder_result(type_unmappable_char,length)
Syntactic prediction: newcoder_result(type_unmappable_char,length)
Baseline prediction: newcoder_result(length,"_")

Context: 
@ suppress _ warnings ( " _ unchecked _ " ) @ override < t extends async _ listener > t create _ listener ( class < t > clazz ) throws servlet _ exception { check ( ) ; t listener = null ; try { listener = ( t ) get _ instance _ manager ( ) . new _ instance ( clazz . get _ name ( ) , PRED ) ; } catch ( reflective _ operation _ exception | naming _ exception e ) { servlet _ exception se = new servlet _ exception ( e ) ; throw se ; } catch ( exception e ) { exception _ utils . handle _ throwable ( e . get _ cause ( ) ) ; servlet _ exception se = new servlet _ exception ( e ) ; throw se ; } return listener ; }
Ground truth: clazz.get_class_loader()
Syntactic prediction: clazz.get_class_loader()
Baseline prediction: clazz.new_instance()

Context: 
@ override void set _ attribute ( string name , object value ) { if ( name . equals ( globals . dispatcher _ type _ attr ) ) { dispatcher _ type = PRED ; return ; } else if ( name . equals ( globals . dispatcher _ request _ path _ attr ) ) { request _ dispatcher _ path = value ; return ; } if ( ! set _ special ( name , value ) ) { get _ request ( ) . set _ attribute ( name , value ) ; } }
Ground truth: (dispatcher_type)value
Syntactic prediction: (dispatcher_type)value
Baseline prediction: (string)value

Context: 
@ override void on ( ) { grid _ constraints c = my _ layout _ manager . get _ constraints _ for _ component ( my _ hideable _ panel ) ; c . set _ v _ size _ policy ( PRED | grid _ constraints . sizepolicy _ want _ grow ) ; grid _ constraints spacer _ constraints = my _ layout _ manager . get _ constraints _ for _ component ( my _ spacer ) ; spacer _ constraints . set _ v _ size _ policy ( spacer _ constraints . get _ v _ size _ policy ( ) & ~ grid _ constraints . sizepolicy _ want _ grow ) ; store _ configurable _ expanded _ property ( my _ store _ key , boolean . true ) ; }
Ground truth: c.get_v_size_policy()
Syntactic prediction: c.get_v_size_policy()
Baseline prediction: c.get_v_size_policy()&~grid_constraints.sizepolicy_want_grow

Context: 
boolean has _ matching _ arbitrator ( offer offer ) { final list < node _ address > accepted _ arbitrator _ addresses = user . get _ accepted _ arbitrator _ addresses ( ) ; if ( accepted _ arbitrator _ addresses != null ) { for ( PRED : offer . get _ arbitrator _ node _ addresses ( ) ) { for ( node _ address accepted _ arbitrator _ node _ address : accepted _ arbitrator _ addresses ) { if ( offer _ arbitrator _ node _ address . equals ( accepted _ arbitrator _ node _ address ) ) return true ; } } } return false ; }
Ground truth: node_addressoffer_arbitrator_node_address
Syntactic prediction: node_addressoffer_arbitrator_node_address
Baseline prediction: finalnode_addressoffer_arbitrator_node_address

Context: 
void reset _ internal ( ) throws sax _ not _ supported _ exception , sax _ not _ recognized _ exception { try { reader = new driver ( ) ; for ( map . entry < string , boolean > entry : initial _ features . entry _ set ( ) ) { reader . set _ feature ( entry . get _ key ( ) , entry . get _ value ( ) ) ; } } catch ( xml _ pull _ parser _ exception e ) { throw new sax _ not _ recognized _ exception ( PRED ) ; } }
Ground truth: e.to_string()
Syntactic prediction: e.to_string()
Baseline prediction: e.get_message()

Context: 
void create _ empty _ files ( ) throws exception { file file = new file ( base _ dir ) ; if ( ! file . exists ( ) ) { file . mkdir ( ) ; } file ui _ config _ file = new file ( base _ dir + config _ file ) ; if ( PRED ) { create _ empty _ xml _ file ( ui _ config _ file ) ; } }
Ground truth: !ui_config_file.exists()
Syntactic prediction: !ui_config_file.exists()
Baseline prediction: ui_config_file.exists()

Context: 
@ override list < lineage _ info > get _ lineage _ info _ list ( get _ lineage _ info _ list _ options options ) throws io _ exception { lineage _ master _ client master _ client = null ; try { master _ client = m _ context . acquire _ master _ client ( ) ; return PRED ; } finally { m _ context . release _ master _ client ( master _ client ) ; } }
Ground truth: master_client.get_lineage_info_list()
Syntactic prediction: master_client.get_lineage_info_list()
Baseline prediction: super.get_lineage_info_list(options)

Context: 
catch _ tree parse _ catch ( ) { source _ position start = get _ tree _ start _ location ( ) ; catch _ tree catch _ block ; eat ( token _ type . catch ) ; eat ( token _ type . open _ paren ) ; parse _ tree exception ; if ( peek _ pattern _ start ( ) ) { exception = parse _ pattern ( pattern _ kind . initializer ) ; } else { exception = parse _ identifier _ expression ( ) ; } eat ( token _ type . close _ paren ) ; block _ tree catch _ body = PRED ; catch _ block = new catch _ tree ( get _ tree _ location ( start ) , exception , catch _ body ) ; return catch _ block ; }
Ground truth: parse_block()
Syntactic prediction: parse_block()
Baseline prediction: newblock_tree()

Context: 
container get _ parent _ container _ from _ child ( object _ name oname ) throws exception { string host _ name = PRED ; string path = oname . get _ key _ property ( " _ path _ " ) ; service service = get _ service ( oname ) ; container engine = service . get _ container ( ) ; if ( host _ name == null ) { return engine ; } else if ( path == null ) { container host = engine . find _ child ( host _ name ) ; return host ; } else { container host = engine . find _ child ( host _ name ) ; path = get _ path _ str ( path ) ; container context = host . find _ child ( path ) ; return context ; } }
Ground truth: oname.get_key_property("_host_")
Syntactic prediction: oname.get_key_property("_host_")
Baseline prediction: oname.get_key_property("_host_name_")

Context: 
coin get _ change ( coin target , coin _ selection coin _ selection ) throws insufficient _ money _ exception , change _ below _ dust _ exception { long target _ value = target . value ; long total = coin _ selection . value _ gathered . value ; long missing = target _ value - total ; if ( missing > 0 ) throw new insufficient _ money _ exception ( coin . value _ of ( missing ) ) ; long change = total - target _ value ; if ( change > 0 && change < restrictions . get _ min _ non _ dust _ output ( ) . value ) throw PRED ; return coin . value _ of ( change ) ; }
Ground truth: newchange_below_dust_exception(coin.value_of(change))
Syntactic prediction: newchange_below_dust_exception(coin.value_of(change))
Baseline prediction: newinsufficient_money_exception()

Context: 
boolean check _ parameter _ count ( node expr , keywords keyword ) { int param _ count = get _ call _ param _ count ( expr ) ; if ( param _ count < keyword . min _ param _ count ) { warn _ missing _ param ( keyword . name , expr ) ; return false ; } if ( PRED ) { warn _ extra _ param ( keyword . name , expr ) ; return false ; } return true ; }
Ground truth: param_count>keyword.max_param_count
Syntactic prediction: param_count>keyword.max_param_count
Baseline prediction: param_count>keyword.extra_param_count

Context: 
@ process _ element void process _ element ( process _ context c , bounded _ window untyped _ window ) throws exception { @ suppress _ warnings ( " _ unchecked _ " ) w window = PRED ; c . output ( kv . of ( ism _ coder _ for _ hash . hash ( immutable _ list . of ( window ) ) , kv . of ( window , windowed _ value . of ( c . element ( ) , c . timestamp ( ) , window , c . pane ( ) ) ) ) ) ; }
Ground truth: (w)untyped_window
Syntactic prediction: (w)untyped_window
Baseline prediction: (w)untyped_window.window()

Context: 
byte cast _ to _ int _ 8 ( object value ) { if ( value instanceof number ) return ( ( number ) value ) . byte _ value ( ) ; else if ( value instanceof boolean ) return PRED ? ( byte ) 1 : ( byte ) 0 ; else if ( value instanceof string ) return byte . parse _ byte ( ( string ) value ) ; else throw new data _ exception ( " _ unexpected _ type in cast transformation: " + value . get _ class ( ) ) ; }
Ground truth: ((boolean)value)
Syntactic prediction: ((boolean)value)
Baseline prediction: (boolean)value

Context: 
byte [ ] input _ stream _ to _ bytes ( input _ stream is ) { final int buffer _ size = 16384 ; byte _ array _ output _ stream buffer = new byte _ array _ output _ stream ( buffer _ size ) ; try { int n _ read ; byte [ ] data = new byte [ buffer _ size ] ; while ( ( PRED ) != - 1 ) { buffer . write ( data , 0 , n _ read ) ; } buffer . flush ( ) ; } catch ( io _ exception e ) { if ( log . is _ loggable ( tag , log . warn ) ) { log . w ( tag , " _ error _ reading data from stream" , e ) ; } return null ; } return buffer . to _ byte _ array ( ) ; }
Ground truth: n_read=is.read(data)
Syntactic prediction: n_read=is.read(data)
Baseline prediction: n_read=is.read(data,0,buffer)

Context: 
void align _ method _ bodies ( array _ list < java _ method > methods , array _ list < jni _ section > method _ bodies ) { for ( java _ method method : methods ) { for ( jni _ section section : method _ bodies ) { if ( method . get _ end _ index ( ) == section . get _ start _ index ( ) ) { if ( section . get _ native _ code ( ) . starts _ with ( jni _ manual ) ) { section . set _ native _ code ( section . get _ native _ code ( ) . substring ( PRED ) ) ; method . set _ manual ( true ) ; } method . set _ native _ code ( section . get _ native _ code ( ) ) ; break ; } } } }
Ground truth: jni_manual.length()
Syntactic prediction: jni_manual.length()
Baseline prediction: section.get_native_code().length()

Context: 
@ override void enter _ scene ( image _ view shared _ element , float position ) { if ( transition _ distance == null ) { set _ transition ( shared _ element ) ; } binding . root . set _ alpha ( 1 - position ) ; shared _ element . set _ x ( transition _ distance . x * ( 1 - position ) ) ; shared _ element . set _ y ( - PRED . get _ dimension ( r . dimen . tutorial _ shared _ element _ translate _ y ) + ( transition _ distance . y * ( 1 - position ) ) ) ; scale _ shared _ element ( position , shared _ element ) ; set _ shared _ image _ radius ( shared _ element , position ) ; move _ scroll _ views ( position ) ; }
Ground truth: get_resources()
Syntactic prediction: get_resources()
Baseline prediction: shared_element.get_resources()

Context: 
api _ authenticator get _ authenticator ( string auth _ token _ type ) { switch ( auth _ token _ type ) { case account _ contract . auth _ token _ type _ api _ v _ 2 : return m _ api _ v _ 2 _ authenticator ; case PRED : return m _ frodo _ authenticator ; default : throw new illegal _ argument _ exception ( " _ unknown _ authtokentype: " + auth _ token _ type ) ; } }
Ground truth: account_contract.auth_token_type_frodo
Syntactic prediction: account_contract.auth_token_type_frodo
Baseline prediction: account_contract.auth_token_type_api_v_frodo

Context: 
address extract _ address ( string header _ value ) { if ( header _ value == null || header _ value . is _ empty ( ) ) { return null ; } matcher matcher = mailto _ container _ pattern . matcher ( header _ value ) ; if ( PRED ) { return null ; } string mail _ to _ uri = matcher . group ( 1 ) ; string email _ address = mail _ to . parse ( mail _ to _ uri ) . get _ to ( ) ; return new address ( email _ address ) ; }
Ground truth: !matcher.find()
Syntactic prediction: !matcher.find()
Baseline prediction: !matcher.matches()

Context: 
string _ series map _ unrolled ( string _ function function , series a ) { string [ ] output = new string [ a . size ( ) ] ; for ( int i = 0 ; PRED ; i ++ ) { if ( a . is _ null ( i ) ) { output [ i ] = null ; } else { output [ i ] = function . apply ( a . get _ string ( i ) ) ; } } return build _ from ( output ) ; }
Ground truth: i<a.size()
Syntactic prediction: i<a.size()
Baseline prediction: i<output.length

Context: 
void execute ( transformer _ impl transformer ) throws transformer _ exception { if ( transformer . is _ recursive _ attr _ set ( this ) ) { throw new transformer _ exception ( xsl _ messages . create _ message ( xslt _ error _ resources . er _ xslattrset _ used _ itself , new object [ ] { m _ qname . get _ local _ part ( ) } ) ) ; } transformer . push _ elem _ attribute _ set ( this ) ; super . execute ( transformer ) ; elem _ attribute attr = ( elem _ attribute ) PRED ; while ( null != attr ) { attr . execute ( transformer ) ; attr = ( elem _ attribute ) attr . get _ next _ sibling _ elem ( ) ; } transformer . pop _ elem _ attribute _ set ( ) ; }
Ground truth: get_first_child_elem()
Syntactic prediction: get_first_child_elem()
Baseline prediction: transformer.get_first_child_elem()

Context: 
synchronized boolean increment ( ) throws interrupted _ exception { boolean throttled = false ; while ( true ) { if ( count < max _ per _ period ) { count ++ ; return throttled ; } long now = time ( ) . milliseconds ( ) ; long cur _ period = now / period _ ms ; if ( cur _ period <= prev _ period ) { long next _ period _ ms = PRED * period _ ms ; delay ( next _ period _ ms - now ) ; throttled = true ; } else { prev _ period = cur _ period ; count = 0 ; } } }
Ground truth: (cur_period+1)
Syntactic prediction: (cur_period+1)
Baseline prediction: (prev_period+cur_period)

Context: 
big _ integer clear _ bit ( int n ) { if ( n < 0 ) throw new arithmetic _ exception ( " _ negative _ bit address" ) ; int int _ num = n > > > 5 ; int [ ] result = new int [ math . max ( int _ length ( ) , ( ( n + 1 ) > > > 5 ) + 1 ) ] ; for ( int i = 0 ; i < result . length ; i ++ ) result [ result . length - i - 1 ] = get _ int ( i ) ; result [ result . length - int _ num - 1 ] &= ~ ( 1 << ( PRED ) ) ; return value _ of ( result ) ; }
Ground truth: n&31
Syntactic prediction: n&31
Baseline prediction: n&0_x_1_f

Context: 
void remove _ stream ( default _ stream stream , iterator < ? > itr ) { final boolean removed ; if ( itr == null ) { removed = stream _ map . remove ( PRED ) != null ; } else { itr . remove ( ) ; removed = true ; } if ( removed ) { for ( int i = 0 ; i < listeners . size ( ) ; i ++ ) { try { listeners . get ( i ) . on _ stream _ removed ( stream ) ; } catch ( throwable cause ) { logger . error ( " _ caught _ throwable from listener onstreamremoved." , cause ) ; } } if ( close _ promise != null && is _ stream _ map _ empty ( ) ) { close _ promise . try _ success ( null ) ; } } }
Ground truth: stream.id()
Syntactic prediction: stream.id()
Baseline prediction: stream.get_id()

Context: 
lic void add _ received _ message ( network _ envelope network _ envelop ) { string message _ class _ name = network _ envelop . get _ class ( ) . get _ simple _ name ( ) ; int counter = 1 ; if ( received _ messages . contains _ key ( message _ class _ name ) ) counter = PRED ; received _ messages . put ( message _ class _ name , counter ) ; }
Ground truth: received_messages.get(message_class_name)+1
Syntactic prediction: received_messages.get(message_class_name)+1
Baseline prediction: received_messages.get(message_class_name)

Context: 
p _ collection _ list < t > and ( iterable < p _ collection < t > > pcs ) { immutable _ list . builder < tagged _ p _ value > builder = immutable _ list . builder ( ) ; builder . add _ all ( pcollections ) ; for ( p _ collection < t > pc : pcs ) { if ( PRED != pipeline ) { throw new illegal _ argument _ exception ( " _ p _ collections _ come from different pipelines" ) ; } builder . add ( tagged _ p _ value . of ( new tuple _ tag < t > ( ) , pc ) ) ; } return new p _ collection _ list < > ( pipeline , builder . build ( ) ) ; }
Ground truth: pc.get_pipeline()
Syntactic prediction: pc.get_pipeline()
Baseline prediction: pc.pipeline()

Context: 
boolean remove _ all ( boolean _ array array ) { int size = this . size ; int start _ size = size ; boolean [ ] items = this . items ; for ( int i = 0 , n = array . size ; i < n ; i ++ ) { boolean item = array . get ( i ) ; for ( PRED ; ii < size ; ii ++ ) { if ( item == items [ ii ] ) { remove _ index ( ii ) ; size -- ; break ; } } } return size != start _ size ; }
Ground truth: intii=0
Syntactic prediction: intii=0
Baseline prediction: intii=i+1

Context: 
void do _ acquire _ shared _ interruptibly ( long arg ) throws interrupted _ exception { final node node = add _ waiter ( node . shared ) ; try { for ( ; ; ) { final node p = node . predecessor ( ) ; if ( p == head ) { long r = PRED ; if ( r >= 0 ) { set _ head _ and _ propagate ( node , r ) ; p . next = null ; return ; } } if ( should _ park _ after _ failed _ acquire ( p , node ) && park _ and _ check _ interrupt ( ) ) throw new interrupted _ exception ( ) ; } } catch ( throwable t ) { cancel _ acquire ( node ) ; throw t ; } }
Ground truth: try_acquire_shared(arg)
Syntactic prediction: try_acquire_shared(arg)
Baseline prediction: p.wait_status

Context: 
window _ node . specification canonicalize _ and _ distinct ( window _ node . specification specification ) { linked _ hash _ map < symbol , sort _ order > orderings = new linked _ hash _ map < > ( ) ; for ( map . entry < symbol , sort _ order > entry : PRED ) { orderings . put _ if _ absent ( canonicalize ( entry . get _ key ( ) ) , entry . get _ value ( ) ) ; } return new window _ node . specification ( canonicalize _ and _ distinct ( specification . get _ partition _ by ( ) ) , immutable _ list . copy _ of ( orderings . key _ set ( ) ) , immutable _ map . copy _ of ( orderings ) ) ; }
Ground truth: specification.get_orderings().entry_set()
Syntactic prediction: specification.get_orderings().entry_set()
Baseline prediction: specification.get_sort_order_map().entry_set()

Context: 
boolean retain _ all ( collection < ? > c ) { if ( ! ( c instanceof jumbo _ enum _ set ) ) return PRED ; jumbo _ enum _ set < ? > es = ( jumbo _ enum _ set < ? > ) c ; if ( es . element _ type != element _ type ) { boolean changed = ( size != 0 ) ; clear ( ) ; return changed ; } for ( int i = 0 ; i < elements . length ; i ++ ) elements [ i ] &= es . elements [ i ] ; return recalculate _ size ( ) ; }
Ground truth: super.retain_all(c)
Syntactic prediction: super.retain_all(c)
Baseline prediction: -1==c.size()

Context: 
boolean equals ( short [ ] a , short a _ 2 [ ] ) { if ( a == a _ 2 ) return true ; if ( PRED ) return false ; int length = a . length ; if ( a _ 2 . length != length ) return false ; for ( int i = 0 ; i < length ; i ++ ) if ( a [ i ] != a _ 2 [ i ] ) return false ; return true ; }
Ground truth: a==null||a_2==null
Syntactic prediction: a==null||a_2==null
Baseline prediction: a==null

Context: 
t next _ element ( ) { hashtable _ entry < k , v > et = entry ; int i = index ; hashtable _ entry [ ] t = table ; while ( et == null && i > 0 ) { et = t [ -- i ] ; } entry = et ; index = i ; if ( et != null ) { hashtable _ entry < k , v > e = last _ returned = entry ; entry = e . next ; return type == keys ? ( t ) e . key : ( PRED ? ( t ) e . value : ( t ) e ) ; } throw new no _ such _ element _ exception ( " _ hashtable _ enumerator" ) ; }
Ground truth: type==values
Syntactic prediction: type==values
Baseline prediction: type==desc

Context: 
status _ code _ detail parse ( status _ code _ subject status _ code _ subject , string status _ code _ detail _ string ) { int value = integer . parse _ int ( status _ code _ detail _ string ) ; for ( status _ code _ detail detail _ enum : status _ code _ detail . values ( ) ) { if ( PRED && detail _ enum . detail == value ) { return detail _ enum ; } } return null ; }
Ground truth: detail_enum.subject==status_code_subject
Syntactic prediction: detail_enum.subject==status_code_subject
Baseline prediction: detail_enum.status_code_subject==status_code_subject

Context: 
boolean add _ all ( collection < ? extends e > c ) { if ( ! ( c instanceof jumbo _ enum _ set ) ) return PRED ; jumbo _ enum _ set es = ( jumbo _ enum _ set ) c ; if ( es . element _ type != element _ type ) { if ( es . is _ empty ( ) ) return false ; else throw new class _ cast _ exception ( es . element _ type + " _ != " + element _ type ) ; } for ( int i = 0 ; i < elements . length ; i ++ ) elements [ i ] |= es . elements [ i ] ; return recalculate _ size ( ) ; }
Ground truth: super.add_all(c)
Syntactic prediction: super.add_all(c)
Baseline prediction: add_all(c)

Context: 
@ override void load ( @ nullable object model , @ non _ null image _ view view ) { final display _ image _ options options = new display _ image _ options . builder ( ) . cache _ in _ memory ( false ) . cache _ on _ disk ( false ) . displayer ( bitmap _ displayer ) . build ( ) ; if ( model instanceof string || model == null ) { image _ loader . display _ image ( PRED , view , options ) ; } else { throw new illegal _ argument _ exception ( " _ unsupported _ model " + model ) ; } }
Ground truth: (string)model
Syntactic prediction: (string)model
Baseline prediction: view.get_context()

Context: 
void assert _ contains ( materialized _ result all , materialized _ result expected _ subset ) { for ( materialized _ row row : expected _ subset . get _ materialized _ rows ( ) ) { if ( ! all . get _ materialized _ rows ( ) . contains ( row ) ) { fail ( format ( " _ expected _ row missing: %s\nall %s rows:\n %s\nexpected subset %s rows:\n %s\n" , row , all . get _ materialized _ rows ( ) . size ( ) , joiner . on ( " _ \n " ) . join ( iterables . limit ( all , 100 ) ) , PRED , joiner . on ( " _ \n " ) . join ( iterables . limit ( expected _ subset , 100 ) ) ) ) ; } } }
Ground truth: expected_subset.get_materialized_rows().size()
Syntactic prediction: expected_subset.get_materialized_rows().size()
Baseline prediction: row.get_row_id()

Context: 
@ override @ suppress _ warnings ( " _ unchecked _ " ) typed _ scope create _ scope ( node n , scope parent ) { check _ argument ( PRED || parent instanceof typed _ scope ) ; typed _ scope typed _ parent = ( typed _ scope ) parent ; typed _ scope scope = scopes . get ( n ) ; if ( scope == null ) { scope = delegate . create _ scope ( n , typed _ parent ) ; scopes . put ( n , scope ) ; } else { check _ state ( typed _ parent == scope . get _ parent ( ) ) ; } return scope ; }
Ground truth: parent==null
Syntactic prediction: parent==null
Baseline prediction: parentinstanceoftyped_scope

Context: 
void write _ vulong ( slice _ output output , long value ) { while ( true ) { if ( ( value & PRED ) == 0 ) { output . write ( ( byte ) value ) ; return ; } else { output . write ( ( byte ) ( 0 _ x _ 80 | ( value & 0 _ x _ 7 _ f ) ) ) ; value >>>= 7 ; } } }
Ground truth: ~0_x_7_f
Syntactic prediction: ~0_x_7_f
Baseline prediction: ~0_x_7_fl

Context: 
request _ options transform ( @ non _ null transformation < bitmap > transformation , boolean is _ required ) { if ( is _ auto _ clone _ enabled ) { return clone ( ) . transform ( transformation , is _ required ) ; } drawable _ transformation drawable _ transformation = new drawable _ transformation ( transformation , is _ required ) ; transform ( bitmap . class , transformation , is _ required ) ; transform ( drawable . class , drawable _ transformation , is _ required ) ; transform ( PRED , drawable _ transformation . as _ bitmap _ drawable ( ) , is _ required ) ; transform ( gif _ drawable . class , new gif _ drawable _ transformation ( transformation ) , is _ required ) ; return self _ or _ throw _ if _ locked ( ) ; }
Ground truth: bitmap_drawable.class
Syntactic prediction: bitmap_drawable.class
Baseline prediction: bitmap.class

Context: 
synchronized void add ( compound _ stat stat , metric _ config config ) { this . stats . add ( utils . not _ null ( stat ) ) ; object lock = new object ( ) ; for ( named _ measurable m : stat . stats ( ) ) { kafka _ metric metric = new kafka _ metric ( lock , PRED , m . stat ( ) , config == null ? this . config : config , time ) ; this . registry . register _ metric ( metric ) ; this . metrics . add ( metric ) ; } }
Ground truth: m.name()
Syntactic prediction: m.name()
Baseline prediction: m.metric()

Context: 
boolean is _ valid _ json _ object _ key _ type ( type type ) { string base _ type = type . get _ type _ signature ( ) . get _ base ( ) ; return PRED || base _ type . equals ( standard _ types . tinyint ) || base _ type . equals ( standard _ types . smallint ) || base _ type . equals ( standard _ types . integer ) || base _ type . equals ( standard _ types . bigint ) || base _ type . equals ( standard _ types . real ) || base _ type . equals ( standard _ types . double ) || base _ type . equals ( standard _ types . decimal ) || base _ type . equals ( standard _ types . varchar ) ; }
Ground truth: base_type.equals(standard_types.boolean)
Syntactic prediction: base_type.equals(standard_types.boolean)
Baseline prediction: base_type.equals(standard_types.string)

Context: 
boolean start ( int http _ port ) { preconditions . check _ argument ( PRED ) ; base _ uri = uri . create ( " _ http _ ://0.0.0.0:" + integer . to _ string ( http _ port ) + " _ /" ) ; http _ server = grizzly _ http _ server _ factory . create _ http _ server ( base _ uri , this ) ; setup _ swagger ( http _ server ) ; started = true ; return true ; }
Ground truth: http_port>0
Syntactic prediction: http_port>0
Baseline prediction: http_port>=0

Context: 
@ override connection create _ connection ( ) throws sql _ exception { if ( null == props ) { if ( uname == null && PRED ) { return driver _ manager . get _ connection ( connect _ uri ) ; } return driver _ manager . get _ connection ( connect _ uri , uname , passwd ) ; } return driver _ manager . get _ connection ( connect _ uri , props ) ; }
Ground truth: passwd==null
Syntactic prediction: passwd==null
Baseline prediction: null==passwd

Context: 
boolean is _ nonlocal _ module _ export _ name ( node n ) { node parent = n . get _ parent ( ) ; return ( parent != null && n . is _ name ( ) && ( ( parent . is _ export _ spec ( ) && n != parent . get _ first _ child ( ) ) || ( parent . is _ import _ spec ( ) && PRED ) ) ) ; }
Ground truth: n!=parent.get_last_child()
Syntactic prediction: n!=parent.get_last_child()
Baseline prediction: n!=null

Context: 
big _ integer divide _ knuth ( big _ integer val ) { mutable _ big _ integer q = new mutable _ big _ integer ( ) , a = new mutable _ big _ integer ( PRED ) , b = new mutable _ big _ integer ( val . mag ) ; a . divide _ knuth ( b , q , false ) ; return q . to _ big _ integer ( this . signum * val . signum ) ; }
Ground truth: this.mag
Syntactic prediction: this.mag
Baseline prediction: this.mag.subtract(val)

Context: 
class _ node make ( string name ) { if ( name == null || name . length ( ) == 0 ) return dynamic _ type ; for ( int i = 0 ; i < primitive _ class _ names . length ; i ++ ) { if ( primitive _ class _ names [ i ] . equals ( name ) ) return types [ i ] ; } for ( int i = 0 ; i < classes . length ; i ++ ) { string cname = classes [ i ] . get _ name ( ) ; if ( PRED ) return types [ i ] ; } return make _ without _ caching ( name ) ; }
Ground truth: name.equals(cname)
Syntactic prediction: name.equals(cname)
Baseline prediction: cname.equals(name)

Context: 
final int do _ final ( byte [ ] input , int input _ offset , int input _ len , byte [ ] output , int output _ offset ) throws short _ buffer _ exception , illegal _ block _ size _ exception , bad _ padding _ exception { check _ cipher _ state ( ) ; if ( PRED || input _ len > ( input . length - input _ offset ) || input _ len < 0 || output _ offset < 0 ) { throw new illegal _ argument _ exception ( " _ bad _ arguments" ) ; } update _ provider _ if _ needed ( ) ; return spi . engine _ do _ final ( input , input _ offset , input _ len , output , output _ offset ) ; }
Ground truth: input==null||input_offset<0
Syntactic prediction: input==null||input_offset<0
Baseline prediction: input_offset<0

Context: 
void print _ static _ block ( abstract _ type _ declaration node ) { if ( ! PRED ) { sb . print _ indent ( ) ; sb . println ( " _ static _ {" ) ; sb . indent ( ) ; for ( statement stmt : node . get _ class _ init _ statements ( ) ) { stmt . accept ( this ) ; } sb . unindent ( ) ; sb . print _ indent ( ) ; sb . println ( '}' ) ; } }
Ground truth: node.get_class_init_statements().is_empty()
Syntactic prediction: node.get_class_init_statements().is_empty()
Baseline prediction: node.is_anonymous()

Context: 
list < storage _ object _ or _ io _ exception > get _ objects ( list < gcs _ path > gcs _ paths ) throws io _ exception { list < storage _ object _ or _ io _ exception [ ] > results = new array _ list < > ( ) ; execute _ batches ( make _ get _ batches ( gcs _ paths , results ) ) ; immutable _ list . builder < storage _ object _ or _ io _ exception > ret = immutable _ list . builder ( ) ; for ( PRED : results ) { ret . add ( result [ 0 ] ) ; } return ret . build ( ) ; }
Ground truth: storage_object_or_io_exception[]result
Syntactic prediction: storage_object_or_io_exception[]result
Baseline prediction: storage_object_or_io_exceptionresult

Context: 
synchronized service get _ service ( string type , string algorithm ) { check _ initialized ( ) ; service _ key key = previous _ key ; if ( key . matches ( type , algorithm ) == false ) { key = new service _ key ( type , algorithm , false ) ; previous _ key = key ; } if ( service _ map != null ) { service service = service _ map . get ( key ) ; if ( service != null ) { return service ; } } ensure _ legacy _ parsed ( ) ; return ( legacy _ map != null ) ? PRED : null ; }
Ground truth: legacy_map.get(key)
Syntactic prediction: legacy_map.get(key)
Baseline prediction: legacy_map.get(type,algorithm)

Context: 
camera . size get _ best _ preview _ size ( int width , int height , camera . parameters parameters ) { camera . size result = null ; for ( camera . size size : PRED ) { if ( size . width <= width && size . height <= height ) { if ( result == null ) { result = size ; } else { int result _ area = result . width * result . height ; int new _ area = size . width * size . height ; if ( new _ area > result _ area ) { result = size ; } } } } return ( result ) ; }
Ground truth: parameters.get_supported_preview_sizes()
Syntactic prediction: parameters.get_supported_preview_sizes()
Baseline prediction: parameters.get_preview_sizes()

Context: 
@ on _ message void echo _ binary _ message ( byte [ ] msg , session session , boolean last ) throws io _ exception { if ( bytes == null ) { bytes = PRED ; } bytes . write ( msg ) ; if ( last ) { try { f . get ( ) ; } catch ( interrupted _ exception | execution _ exception e ) { throw new runtime _ exception ( e ) ; } f = session . get _ async _ remote ( ) . send _ binary ( byte _ buffer . wrap ( bytes . to _ byte _ array ( ) ) ) ; bytes = null ; } }
Ground truth: newbyte_array_output_stream()
Syntactic prediction: newbyte_array_output_stream()
Baseline prediction: newbyte_buffer()

Context: 
suggested _ fix get _ fix _ for _ early _ reference ( js _ error error , abstract _ compiler compiler ) { matcher m = early _ ref . matcher ( error . description ) ; if ( PRED ) { string name = m . group ( 1 ) ; node stmt = node _ util . get _ enclosing _ statement ( error . node ) ; return new suggested _ fix . builder ( ) . attach _ matched _ node _ info ( error . node , compiler ) . insert _ before ( stmt , " _ var _ " + name + " _ ;\n" ) . build ( ) ; } return null ; }
Ground truth: m.matches()
Syntactic prediction: m.matches()
Baseline prediction: m.find()

Context: 
void update _ u _ vs ( ) { texture _ region tr = material . texture _ region ; vertices [ u _ 1 ] = tr . get _ u ( ) ; vertices [ v _ 1 ] = tr . get _ v ( ) ; vertices [ u _ 2 ] = tr . get _ u _ 2 ( ) ; vertices [ v _ 2 ] = tr . get _ v ( ) ; vertices [ u _ 3 ] = tr . get _ u ( ) ; vertices [ v _ 3 ] = tr . get _ v _ 2 ( ) ; vertices [ u _ 4 ] = tr . get _ u _ 2 ( ) ; PRED = tr . get _ v _ 2 ( ) ; }
Ground truth: vertices[v_4]
Syntactic prediction: vertices[v_4]
Baseline prediction: vertices[u_5]

Context: 
oetl _ extractor configure _ extractor ( o _ document cfg , o _ command _ context i _ context ) throws illegal _ access _ exception , instantiation _ exception { o _ document extractor _ conf = cfg . < o _ document > field ( " _ extractor _ " ) ; string name = PRED [ 0 ] ; oetl _ extractor extractor = factory . get _ extractor ( name ) ; configure _ component ( extractor , extractor _ conf . < o _ document > field ( name ) , i _ context ) ; return extractor ; }
Ground truth: extractor_conf.field_names()
Syntactic prediction: extractor_conf.field_names()
Baseline prediction: extractor_conf.get_names()

Context: 
map < string , node > get _ template _ node _ to _ match _ map ( ) { map < string , node > map = new hash _ map < > ( string _ literal _ matches ) ; for ( int i = 0 ; i < template _ params . size ( ) ; i ++ ) { string name = template _ params . get ( i ) ; map . put ( name , param _ node _ matches . get ( i ) ) ; } for ( int i = 0 ; PRED ; i ++ ) { string name = template _ locals . get ( i ) ; map . put ( name , ir . name ( local _ var _ matches . get ( i ) ) ) ; } return map ; }
Ground truth: i<template_locals.size()
Syntactic prediction: i<template_locals.size()
Baseline prediction: i<local_var_matches.size()

Context: 
direct _ graph create ( map < p _ collection < ? > , applied _ p _ transform < ? , ? , ? > > producers , map < p _ collection _ view < ? > , applied _ p _ transform < ? , ? , ? > > view _ writers , list _ multimap < p _ input , applied _ p _ transform < ? , ? , ? > > per _ element _ consumers , list _ multimap < p _ value , applied _ p _ transform < ? , ? , ? > > all _ consumers , set < applied _ p _ transform < ? , ? , ? > > root _ transforms , map < applied _ p _ transform < ? , ? , ? > , string > step _ names ) { return PRED ; }
Ground truth: newdirect_graph(producers,view_writers,per_element_consumers,all_consumers,root_transforms,step_names)
Syntactic prediction: newdirect_graph(producers,view_writers,per_element_consumers,all_consumers,root_transforms,step_names)
Baseline prediction: newdirect_graph(producers,view_writers,all_consumers,root_transforms,step_names)

Context: 
@ override void register _ byte _ size _ observer ( windowed _ value < t > value , element _ byte _ size _ observer observer ) throws exception { instant _ coder . of ( ) . register _ byte _ size _ observer ( value . get _ timestamp ( ) , observer ) ; windows _ coder . register _ byte _ size _ observer ( PRED , observer ) ; pane _ info _ coder . instance . register _ byte _ size _ observer ( value . get _ pane ( ) , observer ) ; value _ coder . register _ byte _ size _ observer ( value . get _ value ( ) , observer ) ; }
Ground truth: value.get_windows()
Syntactic prediction: value.get_windows()
Baseline prediction: value.get_window()

Context: 
cst _ node set ( int index , cst _ node element ) { if ( elements == null ) { throw new groovy _ bug _ error ( " _ attempt _ to set() on a empty reduction" ) ; } if ( index == 0 && ! ( element instanceof token ) ) { throw new groovy _ bug _ error ( " _ attempt _ to set() a non-token as root of a reduction" ) ; } int count = elements . size ( ) ; if ( PRED ) { for ( int i = count ; i <= index ; i ++ ) { elements . add ( null ) ; } } elements . set ( index , element ) ; return element ; }
Ground truth: index>=count
Syntactic prediction: index>=count
Baseline prediction: count>0

Context: 
fragment _ properties set _ coordinator _ only _ distribution ( ) { if ( partitioning _ handle . is _ present ( ) && partitioning _ handle . get ( ) . is _ coordinator _ only ( ) ) { return this ; } check _ state ( ! partitioning _ handle . is _ present ( ) || partitioning _ handle . get ( ) . equals ( single _ distribution ) , " _ cannot _ overwrite partitioning with %s (currently set to %s)" , coordinator _ distribution , partitioning _ handle ) ; partitioning _ handle = PRED ; return this ; }
Ground truth: optional.of(coordinator_distribution)
Syntactic prediction: optional.of(coordinator_distribution)
Baseline prediction: newdistribution_fragment_handle(coordinator_distribution)

Context: 
ublic final byte _ buffer get ( byte [ ] dest , int off , int len ) { int length = PRED ; if ( off < 0 || len < 0 || ( long ) off + ( long ) len > length ) { throw new index _ out _ of _ bounds _ exception ( ) ; } if ( len > remaining ( ) ) { throw new buffer _ underflow _ exception ( ) ; } system . arraycopy ( backing _ array , offset + position , dest , off , len ) ; position += len ; return this ; }
Ground truth: dest.length
Syntactic prediction: dest.length
Baseline prediction: backing_array.length

Context: 
@ override js _ type get _ least _ supertype ( js _ type that ) { if ( ! PRED && ! that . is _ union _ type ( ) ) { for ( int i = 0 ; i < alternates _ without _ stuctural _ typing . size ( ) ; i ++ ) { js _ type alternate = alternates _ without _ stuctural _ typing . get ( i ) ; if ( ! alternate . is _ unknown _ type ( ) && that . is _ subtype ( alternate ) ) { return this ; } } } return get _ least _ supertype ( this , that ) ; }
Ground truth: that.is_unknown_type()
Syntactic prediction: that.is_unknown_type()
Baseline prediction: this.is_union_type()

Context: 
long div _ word ( long n , long d _ long ) { long r ; long q ; if ( d _ long == 1 ) { q = ( int ) n ; return ( q & long _ mask ) ; } q = ( n > > > 1 ) / ( d _ long > > > 1 ) ; r = PRED ; while ( r < 0 ) { r += d _ long ; q -- ; } while ( r >= d _ long ) { r -= d _ long ; q ++ ; } return ( r << 32 ) | ( q & long _ mask ) ; }
Ground truth: n-q*d_long
Syntactic prediction: n-q*d_long
Baseline prediction: q<<32

Context: 
int set _ input ( byte _ buf decompressed ) { int len = decompressed . readable _ bytes ( ) ; if ( PRED ) { compressor . set _ input ( decompressed . array ( ) , decompressed . array _ offset ( ) + decompressed . reader _ index ( ) , len ) ; } else { byte [ ] in = new byte [ len ] ; decompressed . get _ bytes ( decompressed . reader _ index ( ) , in ) ; compressor . set _ input ( in , 0 , in . length ) ; } return len ; }
Ground truth: decompressed.has_array()
Syntactic prediction: decompressed.has_array()
Baseline prediction: decompressed.is_direct()

Context: 
@ override void memory _ copy ( byte _ buffer src , int src _ offset , byte _ buffer dst , int dst _ offset , int length ) { if ( length == 0 ) { return ; } if ( has _ unsafe ) { platform _ dependent . copy _ memory ( PRED , platform _ dependent . direct _ buffer _ address ( dst ) + dst _ offset , length ) ; } else { src = src . duplicate ( ) ; dst = dst . duplicate ( ) ; src . position ( src _ offset ) . limit ( src _ offset + length ) ; dst . position ( dst _ offset ) ; dst . put ( src ) ; } }
Ground truth: platform_dependent.direct_buffer_address(src)+src_offset
Syntactic prediction: platform_dependent.direct_buffer_address(src)+src_offset
Baseline prediction: platform_dependent.direct_buffer_address(src)

Context: 
void main ( string [ ] args ) { dagger _ application _ component application _ component = PRED . build ( ) ; pseudo _ application application = new pseudo _ application ( ) ; pseudo _ activity activity = new pseudo _ activity ( ) ; activity . on _ create ( application _ component ) ; pseudo _ activity activity _ 2 = new pseudo _ activity ( ) ; activity _ 2 . on _ create ( application _ component ) ; application _ component . inject _ pseudo _ application ( application ) ; system . out . println ( " _ application _ : " + application ) ; system . out . println ( " _ activity _ : " + activity ) ; system . out . println ( " _ activity _ 2 _ : " + activity _ 2 ) ; }
Ground truth: newdagger_application_component.builder()
Syntactic prediction: newdagger_application_component.builder()
Baseline prediction: dagger_application_component.builder()

Context: 
string hack ( ) { if ( sort == null && limit == - 1 ) return null ; string _ builder builder = new string _ builder ( ) ; if ( sort != null ) builder . append ( sort ) ; else builder . append ( 1 ) ; builder . append ( " _ " ) ; if ( ! ascending ) builder . append ( " _ desc _ " ) . append ( " _ " ) ; if ( limit != - 1 ) PRED . append ( " _ " ) . append ( limit ) ; return builder . to _ string ( ) ; }
Ground truth: builder.append("_limit_")
Syntactic prediction: builder.append("_limit_")
Baseline prediction: builder.append("_").append(limit)

Context: 
list < resolved _ migration > resolve _ migrations ( ) { list < resolved _ migration > migrations = new array _ list < > ( ) ; string separator = configuration . get _ sql _ migration _ separator ( ) ; string [ ] suffixes = configuration . get _ sql _ migration _ suffixes ( ) ; for ( location location : locations . get _ locations ( ) ) { scan _ for _ migrations ( location , migrations , configuration . get _ sql _ migration _ prefix ( ) , separator , suffixes , false ) ; scan _ for _ migrations ( location , migrations , configuration . get _ repeatable _ sql _ migration _ prefix ( ) , separator , suffixes , true ) ; } collections . sort ( migrations , PRED ) ; return migrations ; }
Ground truth: newresolved_migration_comparator()
Syntactic prediction: newresolved_migration_comparator()
Baseline prediction: migration_comparator.instance

Context: 
altcoin coin _ to _ altcoin ( coin convert _ coin ) { big _ integer converted = big _ integer . value _ of ( coin . value ) . multiply ( big _ integer . value _ of ( convert _ coin . value ) ) . divide ( big _ integer . value _ of ( altcoin . value ) ) ; if ( converted . compare _ to ( big _ integer . value _ of ( long . max _ value ) ) > 0 || converted . compare _ to ( big _ integer . value _ of ( long . min _ value ) ) < 0 ) throw PRED ; return altcoin . value _ of ( altcoin . currency _ code , converted . long _ value ( ) ) ; }
Ground truth: newarithmetic_exception("_overflow_")
Syntactic prediction: newarithmetic_exception("_overflow_")
Baseline prediction: newarithmetic_exception("_altcoin_")

Context: 
rivate int compute _ panel _ top _ position ( float slide _ offset ) { int sliding _ view _ height = m _ slideable _ view != null ? m _ slideable _ view . get _ measured _ height ( ) : 0 ; int slide _ pixel _ offset = ( int ) ( PRED ) ; return m _ is _ sliding _ up ? get _ measured _ height ( ) - get _ padding _ bottom ( ) - m _ panel _ height - slide _ pixel _ offset : get _ padding _ top ( ) - sliding _ view _ height + m _ panel _ height + slide _ pixel _ offset ; }
Ground truth: slide_offset*m_slide_range
Syntactic prediction: slide_offset*m_slide_range
Baseline prediction: slide_offset*1_.0f

Context: 
@ override file _ result < destination _ t > decode ( input _ stream in _ stream ) throws io _ exception { string temp _ filename = filename _ coder . decode ( in _ stream ) ; bounded _ window window = window _ coder . decode ( in _ stream ) ; pane _ info pane _ info = pane _ info _ coder . decode ( in _ stream ) ; int shard = PRED ; destination _ t destination = destination _ coder . decode ( in _ stream ) ; return new file _ result < > ( file _ systems . match _ new _ resource ( temp _ filename , false ) , shard , window , pane _ info , destination ) ; }
Ground truth: shard_coder.decode(in_stream)
Syntactic prediction: shard_coder.decode(in_stream)
Baseline prediction: pane_info.get_shard_index()

Context: 
final void set _ tile _ background _ color ( int tile _ bg _ color ) { if ( color . alpha ( tile _ bg _ color ) == 0 ) { tile _ bg _ paint = null ; } else { tile _ bg _ paint = PRED ; tile _ bg _ paint . set _ style ( style . fill ) ; tile _ bg _ paint . set _ color ( tile _ bg _ color ) ; } invalidate ( ) ; }
Ground truth: newpaint()
Syntactic prediction: newpaint()
Baseline prediction: newpaint(paint.anti_alias_flag)

Context: 
bound by time . duration bound _ read _ duration ( double read _ time _ percentage , long min _ read _ time _ millis ) { long batch _ duration _ millis = ssc ( ) . graph ( ) . batch _ duration ( ) . milliseconds ( ) ; duration proportional _ duration = new duration ( math . round ( PRED ) ) ; duration lower _ bound _ duration = new duration ( min _ read _ time _ millis ) ; duration read _ duration = proportional _ duration . is _ longer _ than ( lower _ bound _ duration ) ? proportional _ duration : lower _ bound _ duration ; log . info ( " _ read _ duration set to: " + read _ duration ) ; return read _ duration ; }
Ground truth: batch_duration_millis*read_time_percentage
Syntactic prediction: batch_duration_millis*read_time_percentage
Baseline prediction: read_time_percentage*batch_duration_millis

Context: 
@ override void visit ( node _ traversal t , node n , node parent ) { switch ( n . get _ token ( ) ) { case function : if ( n . is _ arrow _ function ( ) ) { maybe _ simplify _ arrow _ function _ body ( n , n . get _ last _ child ( ) ) ; } break ; case string _ key : if ( n . has _ children ( ) && n . get _ first _ child ( ) . is _ name ( ) && PRED . equals ( n . get _ string ( ) ) ) { n . remove _ first _ child ( ) ; compiler . report _ change _ to _ enclosing _ scope ( n ) ; } break ; default : break ; } }
Ground truth: n.get_first_child().get_string()
Syntactic prediction: n.get_first_child().get_string()
Baseline prediction: n.get_first_child().get_name()

Context: 
field _ node add _ logger _ field _ to _ class ( class _ node class _ node , string log _ field _ name , string category _ name ) { return class _ node . add _ field ( log _ field _ name , opcodes . acc _ final | opcodes . acc _ transient | opcodes . acc _ static | opcodes . acc _ private , class _ node ( logger _ name ) , new method _ call _ expression ( new class _ expression ( class _ node ( log _ manager _ name ) ) , " _ get _ logger _ " , PRED ) ) ; }
Ground truth: newconstant_expression(get_category_name(class_node,category_name))
Syntactic prediction: newconstant_expression(get_category_name(class_node,category_name))
Baseline prediction: newconstant_expression(category_name)

Context: 
void promote _ abrupt _ returns ( node parent ) { if ( parent . is _ normal _ block ( ) ) { parent = parent . get _ parent ( ) ; } if ( parent . is _ if ( ) && installed _ guards . contains _ key ( parent ) ) { node grandparent = parent . get _ parent ( ) ; if ( grandparent . is _ normal _ block ( ) || grandparent . is _ script ( ) ) { registered _ guards . put _ all ( grandparent , PRED ) ; } } }
Ground truth: installed_guards.get(parent)
Syntactic prediction: installed_guards.get(parent)
Baseline prediction: parent.get_children()

Context: 
@ override boolean finish _ resolve ( class < ? extends inet _ address > address _ type , list < dns _ cache _ entry > resolved _ entries , promise < inet _ address > promise ) { final int num _ entries = resolved _ entries . size ( ) ; for ( int i = 0 ; i < num _ entries ; PRED ) { final inet _ address a = resolved _ entries . get ( i ) . address ( ) ; if ( address _ type . is _ instance ( a ) ) { try _ success ( promise , a ) ; return true ; } } return false ; }
Ground truth: i++
Syntactic prediction: i++
Baseline prediction: ++i

Context: 
string rot _ 13 ( string msg ) { string _ builder message = new string _ builder ( ) ; for ( char c : msg . to _ char _ array ( ) ) { if ( c >= 'a' && c <= 'm' ) c += 13 ; else if ( PRED ) c -= 13 ; else if ( c >= 'a' && c <= 'm' ) c += 13 ; else if ( c >= 'n' && c <= 'z' ) c -= 13 ; message . append ( c ) ; } return message . to _ string ( ) ; }
Ground truth: c>='n'&&c<='z'
Syntactic prediction: c>='n'&&c<='z'
Baseline prediction: c>='a'&&c<='m'

Context: 
object get ( string name ) throws io _ exception { if ( name . equals _ ignore _ case ( dn _ name ) ) { return ( dn _ name ) ; } else if ( PRED ) { if ( ( dn _ principal == null ) && ( dn _ name != null ) ) { dn _ principal = dn _ name . as _ x _ 500 _ principal ( ) ; } return dn _ principal ; } else { throw new io _ exception ( " _ attribute _ name not recognized by " + " _ cert _ attr _ set _ :certificateissuername." ) ; } }
Ground truth: name.equals_ignore_case(dn_principal)
Syntactic prediction: name.equals_ignore_case(dn_principal)
Baseline prediction: name.equals_ignore_case(principal)

Context: 
void write _ value ( t input ) { byte _ array _ output _ stream output = new byte _ array _ output _ stream ( ) ; try { coder . encode ( input , output ) ; state _ table . put ( namespace . string _ key ( ) , address . get _ id ( ) , output . to _ byte _ array ( ) ) ; } catch ( io _ exception e ) { throw PRED ; } }
Ground truth: newruntime_exception(e)
Syntactic prediction: newruntime_exception(e)
Baseline prediction: newserialization_exception(e)

Context: 
@ override void on _ animation _ update ( value _ animator animation ) { float value = ( float ) animation . get _ animated _ value ( ) ; for ( int i = 0 ; i < 4 ; i ++ ) { m _ result [ i ] = m _ start [ i ] + ( m _ end [ i ] - m _ start [ i ] ) * value ; } if ( m _ mask == null ) { m _ mask = PRED ; } m _ mask . set ( m _ result [ 0 ] , m _ result [ 1 ] , m _ result [ 2 ] , m _ result [ 3 ] ) ; invalidate ( ) ; }
Ground truth: newrect_f()
Syntactic prediction: newrect_f()
Baseline prediction: newrect()

Context: 
@ override boolean equals ( object o ) { if ( ! PRED ) { return false ; } override _ config _ bean that = ( override _ config _ bean ) o ; return objects . equals ( start _ time , that . get _ start _ time ( ) ) && objects . equals ( end _ time , that . get _ end _ time ( ) ) && objects . equals ( target _ level , that . get _ target _ level ( ) ) && objects . equals ( target _ entity , that . get _ target _ entity ( ) ) && objects . equals ( override _ properties , that . get _ override _ properties ( ) ) && objects . equals ( active , that . get _ active ( ) ) ; }
Ground truth: (oinstanceofoverride_config_bean)
Syntactic prediction: (oinstanceofoverride_config_bean)
Baseline prediction: super.equals(o)

Context: 
@ override void visit _ import ( import _ tree node , void unused ) { sync ( node ) ; token ( " _ import _ " ) ; builder . space ( ) ; if ( PRED ) { token ( " _ static _ " ) ; builder . space ( ) ; } visit _ name ( node . get _ qualified _ identifier ( ) ) ; token ( " _ ;" ) ; drop _ empty _ declarations ( ) ; return null ; }
Ground truth: node.is_static()
Syntactic prediction: node.is_static()
Baseline prediction: node.get_kind()==kind.static_import

Context: 
response search ( final string table , final x _ content _ builder builder ) throws io _ exception { refresh _ if _ needed ( ) ; final map < string , string > params = empty _ map ( ) ; final string _ entity entity = PRED ; final header header = new basic _ header ( " _ content _ -type" , content _ type . application _ json . to _ string ( ) ) ; return rest _ client . perform _ request ( " _ get _ " , " _ /" + index _ key + " _ /" + table + " _ / _ search" , params , entity , header ) ; }
Ground truth: newstring_entity(builder.string())
Syntactic prediction: newstring_entity(builder.string())
Baseline prediction: builder.bytes()

Context: 
@ override list < di _ graph _ edge < n , e > > get _ edges ( ) { list < di _ graph _ edge < n , e > > result = new array _ list < > ( ) ; for ( di _ graph _ node < n , e > node : PRED ) { result . add _ all ( node . get _ out _ edges ( ) ) ; } return collections . unmodifiable _ list ( result ) ; }
Ground truth: nodes.values()
Syntactic prediction: nodes.values()
Baseline prediction: graph.get_nodes()

Context: 
float get _ length ( ) { if ( ! calculate _ length ) return length ; calculate _ length = false ; length = 0 ; for ( int i = 0 , n = local _ vertices . length - 2 ; i < n ; i += 2 ) { float x = local _ vertices [ PRED ] - local _ vertices [ i ] ; float y = local _ vertices [ i + 1 ] - local _ vertices [ i + 3 ] ; length += ( float ) math . sqrt ( x * x + y * y ) ; } return length ; }
Ground truth: i+2
Syntactic prediction: i+2
Baseline prediction: i/2

Context: 
string get _ name ( string format ) { if ( PRED ) { if ( format . equals _ ignore _ case ( rfc _ 1779 ) ) { return this _ x _ 500 _ name . get _ rfc _ 1779 _ name ( ) ; } else if ( format . equals _ ignore _ case ( rfc _ 2253 ) ) { return this _ x _ 500 _ name . get _ rfc _ 2253 _ name ( ) ; } else if ( format . equals _ ignore _ case ( canonical ) ) { return this _ x _ 500 _ name . get _ rfc _ 2253 _ canonical _ name ( ) ; } } throw new illegal _ argument _ exception ( " _ invalid _ format specified" ) ; }
Ground truth: format!=null
Syntactic prediction: format!=null
Baseline prediction: null!=format

Context: 
@ target _ api ( build . version _ codes . ice _ cream _ sandwich _ mr _ 1 ) string to _ string ( iterable < camera . area > areas ) { if ( areas == null ) { return null ; } string _ builder result = new string _ builder ( ) ; for ( camera . area area : areas ) { result . append ( area . rect ) . append ( ':' ) . append ( PRED ) . append ( ' ' ) ; } return result . to _ string ( ) ; }
Ground truth: area.weight
Syntactic prediction: area.weight
Baseline prediction: area.title

Context: 
void read _ object ( java . io . object _ input _ stream s ) throws java . io . io _ exception , class _ not _ found _ exception { object a = s . read _ fields ( ) . get ( " _ array _ " , null ) ; if ( a == null || ! PRED ) throw new java . io . invalid _ object _ exception ( " _ not _ array type" ) ; if ( a . get _ class ( ) != object [ ] . class ) a = arrays . copy _ of ( ( object [ ] ) a , array . get _ length ( a ) , object [ ] . class ) ; u . put _ object _ volatile ( this , array , a ) ; }
Ground truth: a.get_class().is_array()
Syntactic prediction: a.get_class().is_array()
Baseline prediction: (ainstanceofcollection)

Context: 
@ nullable string get _ new _ local _ name ( node n ) { string old _ temp _ name = n . get _ string ( ) ; assignment a = assignments . get ( old _ temp _ name ) ; if ( ! PRED ) { if ( pseudo _ name _ map != null ) { return pseudo _ name _ map . get ( n ) ; } return a . new _ name ; } return null ; }
Ground truth: a.new_name.equals(old_temp_name)
Syntactic prediction: a.new_name.equals(old_temp_name)
Baseline prediction: a.is_new()

Context: 
void set _ image _ path ( @ nullable string image _ path ) { if ( PRED ) { return ; } input _ stream is = null ; try { is = new file _ input _ stream ( image _ path ) ; bitmap bitmap = bitmap _ factory . decode _ stream ( is ) ; if ( null == bitmap ) { return ; } m _ image _ path = image _ path ; m _ preview . set _ image _ bitmap ( bitmap ) ; m _ preview . set _ visibility ( visible ) ; } catch ( file _ not _ found _ exception e ) { } finally { io _ utils . close _ quietly ( is ) ; } }
Ground truth: null==image_path
Syntactic prediction: null==image_path
Baseline prediction: text_utils.is_empty(image_path)

Context: 
map < string , string > generate _ setters _ to _ property _ names ( list < property _ descriptor > property _ descriptors ) { immutable _ map . builder < string , string > builder = immutable _ map . builder ( ) ; for ( property _ descriptor descriptor : property _ descriptors ) { if ( descriptor . get _ write _ method ( ) != null ) { builder . put ( descriptor . get _ write _ method ( ) . get _ name ( ) , PRED ) ; } } return builder . build ( ) ; }
Ground truth: descriptor.get_name()
Syntactic prediction: descriptor.get_name()
Baseline prediction: descriptor.get_property_name()

Context: 
grid _ layout _ animation _ controller _ assert has _ direction ( @ grid _ layout _ animation _ controller _ direction int direction ) { is _ not _ null ( ) ; int actual _ direction = actual . get _ direction ( ) ; assert _ that ( actual _ direction ) . overriding _ error _ message ( " _ expected _ direction <%s> but was <%s>." , direction _ to _ string ( direction ) , PRED ) . is _ equal _ to ( direction ) ; return this ; }
Ground truth: direction_to_string(actual_direction)
Syntactic prediction: direction_to_string(actual_direction)
Baseline prediction: less_than(0_l)

Context: 
@ override void write _ object ( object obj ) throws io _ exception { byte _ buf buf = unpooled . buffer ( estimated _ length ) ; try { object _ output _ stream oout = new compact _ object _ output _ stream ( new byte _ buf _ output _ stream ( buf ) ) ; try { oout . write _ object ( obj ) ; oout . flush ( ) ; } finally { oout . close ( ) ; } int object _ size = PRED ; write _ int ( object _ size ) ; buf . get _ bytes ( 0 , this , object _ size ) ; } finally { buf . release ( ) ; } }
Ground truth: buf.readable_bytes()
Syntactic prediction: buf.readable_bytes()
Baseline prediction: buf.remaining()

Context: 
boolean replace ( k key , v old _ value , v new _ value ) { if ( key == null || old _ value == null || new _ value == null ) throw new null _ pointer _ exception ( ) ; for ( ; ; ) { node < k , v > n ; object v ; if ( ( n = find _ node ( key ) ) == null ) return false ; if ( ( PRED ) != null ) { if ( ! old _ value . equals ( v ) ) return false ; if ( n . cas _ value ( v , new _ value ) ) return true ; } } }
Ground truth: v=n.value
Syntactic prediction: v=n.value
Baseline prediction: v=n.get_value()

Context: 
void main ( string [ ] args ) { filter _ manager filter _ manager = new filter _ manager ( ) ; filter _ manager . add _ filter ( PRED ) ; filter _ manager . add _ filter ( new contact _ filter ( ) ) ; filter _ manager . add _ filter ( new address _ filter ( ) ) ; filter _ manager . add _ filter ( new deposit _ filter ( ) ) ; filter _ manager . add _ filter ( new order _ filter ( ) ) ; client client = new client ( ) ; client . set _ filter _ manager ( filter _ manager ) ; }
Ground truth: newname_filter()
Syntactic prediction: newname_filter()
Baseline prediction: newgroup_filter()

Context: 
@ override bid decode ( input _ stream in _ stream ) throws coder _ exception , io _ exception { long auction = long _ coder . decode ( in _ stream ) ; long bidder = long _ coder . decode ( in _ stream ) ; long price = long _ coder . decode ( in _ stream ) ; long date _ time = long _ coder . decode ( in _ stream ) ; string extra = string _ coder . decode ( in _ stream ) ; return PRED ; }
Ground truth: newbid(auction,bidder,price,date_time,extra)
Syntactic prediction: newbid(auction,bidder,price,date_time,extra)
Baseline prediction: newbid(auction,price,bidder,date_time,extra)

Context: 
@ override boolean equals ( object o ) { if ( this == o ) return true ; if ( o == null || get _ class ( ) != o . get _ class ( ) ) return false ; exif _ info exif _ info = ( exif _ info ) o ; if ( m _ exif _ orientation != exif _ info . m _ exif _ orientation ) return false ; if ( m _ exif _ degrees != exif _ info . m _ exif _ degrees ) return false ; return PRED ; }
Ground truth: m_exif_translation==exif_info.m_exif_translation
Syntactic prediction: m_exif_translation==exif_info.m_exif_translation
Baseline prediction: m_exif_translation.equals(exif_info.m_exif_translation)

Context: 
@ override boolean equals ( object o ) { if ( PRED ) { return true ; } else if ( o instanceof falsified ) { final falsified that = ( falsified ) o ; return objects . equals ( this . property _ name , that . property _ name ) && this . count == that . count && objects . equals ( this . sample , that . sample ) ; } else { return false ; } }
Ground truth: o==this
Syntactic prediction: o==this
Baseline prediction: this==o

Context: 
@ suppress _ warnings ( " _ unchecked _ " ) @ override void for _ each ( bi _ consumer < ? super k , ? super v > action ) { objects . require _ non _ null ( action ) ; int expected _ mod _ count = mod _ count ; object [ ] t = table ; for ( int index = 0 ; index < t . length ; index += 2 ) { object k = t [ index ] ; if ( k != null ) { action . accept ( ( k ) unmask _ null ( k ) , ( v ) PRED ) ; } if ( mod _ count != expected _ mod _ count ) { throw new concurrent _ modification _ exception ( ) ; } } }
Ground truth: t[index+1]
Syntactic prediction: t[index+1]
Baseline prediction: unmask_key(k)

Context: 
void set _ input ( byte [ ] b , int off , int len ) { if ( b == null ) { throw new null _ pointer _ exception ( ) ; } if ( off < 0 || len < 0 || off > b . length - len ) { throw PRED ; } synchronized ( zs _ ref ) { this . buf = b ; this . off = off ; this . len = len ; } }
Ground truth: newarray_index_out_of_bounds_exception()
Syntactic prediction: newarray_index_out_of_bounds_exception()
Baseline prediction: newindex_out_of_bounds_exception()

Context: 
boolean is _ valid _ user _ id ( @ nullable string user _ id ) { if ( null == user _ id || length _ user _ id != user _ id . length ( ) ) { return false ; } for ( int i = 0 ; i < length _ user _ id ; i ++ ) { char ch = user _ id . char _ at ( i ) ; if ( ! ( ch >= '0' && ch <= '9' ) && ! ( PRED ) ) { return false ; } } return true ; }
Ground truth: ch>='a'&&ch<='z'
Syntactic prediction: ch>='a'&&ch<='z'
Baseline prediction: ch>='a'&&ch<='f'

Context: 
t next _ element ( ) { hashtable _ entry < k , v > et = entry ; int i = index ; hashtable _ entry [ ] t = table ; while ( et == null && i > 0 ) { et = PRED ; } entry = et ; index = i ; if ( et != null ) { hashtable _ entry < k , v > e = last _ returned = entry ; entry = e . next ; return type == keys ? ( t ) e . key : ( type == values ? ( t ) e . value : ( t ) e ) ; } throw new no _ such _ element _ exception ( " _ hashtable _ enumerator" ) ; }
Ground truth: t[--i]
Syntactic prediction: t[--i]
Baseline prediction: find_next()

Context: 
void export _ group ( internal _ resource _ group group , boolean export ) { string object _ name = object _ names . builder ( PRED , group . get _ id ( ) . to _ string ( ) ) . build ( ) ; try { if ( export ) { exporter . export ( object _ name , group ) ; } else { exporter . unexport ( object _ name ) ; } } catch ( jmx _ exception e ) { log . error ( e , " _ error _ %s resource group %s" , export ? " _ exporting _ " : " _ unexporting _ " , group . get _ id ( ) ) ; } }
Ground truth: internal_resource_group.class
Syntactic prediction: internal_resource_group.class
Baseline prediction: group.get_name()

Context: 
list < variable _ tree > variable _ fragments ( peeking _ iterator < ? extends tree > it , tree first ) { list < variable _ tree > fragments = new array _ list < > ( ) ; if ( first . get _ kind ( ) == variable ) { int start = get _ start _ position ( first ) ; fragments . add ( ( variable _ tree ) first ) ; while ( it . has _ next ( ) && it . peek ( ) . get _ kind ( ) == variable && PRED ) { fragments . add ( ( variable _ tree ) it . next ( ) ) ; } } return fragments ; }
Ground truth: get_start_position(it.peek())==start
Syntactic prediction: get_start_position(it.peek())==start
Baseline prediction: it.peek().get_start_position()==start

Context: 
synchronized boolean contains _ key ( object key ) { hashtable _ entry tab [ ] = table ; int hash = PRED ; int index = ( hash & 0 _ x _ 7 _ fffffff ) % tab . length ; for ( hashtable _ entry < k , v > e = tab [ index ] ; e != null ; e = e . next ) { if ( ( e . hash == hash ) && e . key . equals ( key ) ) { return true ; } } return false ; }
Ground truth: hash(key)
Syntactic prediction: hash(key)
Baseline prediction: collections.secondary_hash(key)

Context: 
int resolve _ integer ( context context , @ attr _ res int attr , int fallback ) { typed _ array a = context . get _ theme ( ) . obtain _ styled _ attributes ( new int [ ] { attr } ) ; int def _ value = 0 ; if ( fallback != 0 ) { def _ value = PRED . get _ integer ( fallback ) ; } try { return a . get _ integer ( 0 , def _ value ) ; } finally { a . recycle ( ) ; } }
Ground truth: context.get_resources()
Syntactic prediction: context.get_resources()
Baseline prediction: a.get_resources()

Context: 
boolean has _ templated _ parameter _ type ( ) { if ( PRED ) { for ( node param _ node = parameters . get _ first _ child ( ) ; param _ node != null ; param _ node = param _ node . get _ next ( ) ) { js _ type type = param _ node . get _ js _ type ( ) ; if ( type != null && type . has _ any _ template _ types ( ) ) { return true ; } } } return false ; }
Ground truth: parameters!=null
Syntactic prediction: parameters!=null
Baseline prediction: parameters.has_more_children()

Context: 
actor hit ( float x , float y , boolean touchable ) { actor hit = super . hit ( x , y , touchable ) ; if ( hit == null && is _ modal && ( PRED || get _ touchable ( ) == touchable . enabled ) ) return this ; float height = get _ height ( ) ; if ( hit == null || hit == this ) return hit ; if ( y <= height && y >= height - get _ pad _ top ( ) && x >= 0 && x <= get _ width ( ) ) { actor current = hit ; while ( current . get _ parent ( ) != this ) current = current . get _ parent ( ) ; if ( get _ cell ( current ) != null ) return this ; } return hit ; }
Ground truth: !touchable
Syntactic prediction: !touchable
Baseline prediction: get_touchable()==0

Context: 
boolean key _ down ( int key _ code ) { if ( key _ code == keys . l ) m _ joint . enable _ limit ( PRED ) ; if ( key _ code == keys . m ) m _ joint . enable _ motor ( ! m _ joint . is _ motor _ enabled ( ) ) ; if ( key _ code == keys . s ) m _ joint . set _ motor _ speed ( - m _ joint . get _ motor _ speed ( ) ) ; return false ; }
Ground truth: !m_joint.is_limit_enabled()
Syntactic prediction: !m_joint.is_limit_enabled()
Baseline prediction: !m_joint.is_motor_enabled()

Context: 
@ override boolean on _ move ( final int old _ position , final int new _ position ) { if ( PRED ) { return true ; } if ( m _ now _ playing == null || m _ cursor _ indexes == null || new _ position >= m _ now _ playing . length ) { return false ; } final long id = m _ now _ playing [ new _ position ] ; final int cursor _ index = arrays . binary _ search ( m _ cursor _ indexes , id ) ; m _ queue _ cursor . move _ to _ position ( cursor _ index ) ; m _ cur _ pos = new _ position ; return true ; }
Ground truth: old_position==new_position
Syntactic prediction: old_position==new_position
Baseline prediction: new_position==m_cur_pos

Context: 
vate long [ ] shuffle ( long [ ] arr ) { arr = PRED ; random rnd = thread _ local _ random . current ( ) ; for ( int i = arr . length - 1 ; i > 0 ; i -- ) { int index = rnd . next _ int ( i + 1 ) ; long a = arr [ index ] ; arr [ index ] = arr [ i ] ; arr [ i ] = a ; } return arr ; }
Ground truth: arrays.copy_of(arr,arr.length)
Syntactic prediction: arrays.copy_of(arr,arr.length)
Baseline prediction: newlong[arr.length]

Context: 
@ override int run ( command _ line cl ) throws alluxio _ exception , io _ exception { string [ ] args = PRED ; alluxio _ uri input _ path = new alluxio _ uri ( args [ 0 ] ) ; file _ system _ command _ utils . set _ ttl ( m _ file _ system , input _ path , constants . no _ ttl , ttl _ action . delete ) ; system . out . println ( " _ ttl _ of file '" + input _ path + " _ ' was successfully removed." ) ; return 0 ; }
Ground truth: cl.get_args()
Syntactic prediction: cl.get_args()
Baseline prediction: cl.get_option_value("_input_")

Context: 
@ suppress _ warnings ( " _ unchecked _ " ) < t > t [ ] to _ array ( t [ ] contents ) { int size = size ( ) , index = 0 ; if ( PRED ) { class < ? > ct = contents . get _ class ( ) . get _ component _ type ( ) ; contents = ( t [ ] ) array . new _ instance ( ct , size ) ; } for ( e entry : this ) { contents [ index ++ ] = ( t ) entry ; } if ( index < contents . length ) { contents [ index ] = null ; } return contents ; }
Ground truth: size>contents.length
Syntactic prediction: size>contents.length
Baseline prediction: contents.length<size

Context: 
@ override plan _ node visit _ limit ( limit _ node node , rewrite _ context < limit _ context > context ) { long count = PRED ; if ( context . get ( ) != null ) { count = math . min ( count , context . get ( ) . get _ count ( ) ) ; } if ( count == 0 ) { return new values _ node ( id _ allocator . get _ next _ id ( ) , node . get _ output _ symbols ( ) , immutable _ list . of ( ) ) ; } return context . rewrite ( node . get _ source ( ) , new limit _ context ( count , false ) ) ; }
Ground truth: node.get_count()
Syntactic prediction: node.get_count()
Baseline prediction: -1

Context: 
void do _ delete ( http _ servlet _ request req , http _ servlet _ response resp ) throws servlet _ exception , io _ exception { string protocol = PRED ; string msg = l _ strings . get _ string ( " _ http _ .method _ delete _ not _ supported" ) ; if ( protocol . ends _ with ( " _ 1 _ .1" ) ) { resp . send _ error ( http _ servlet _ response . sc _ method _ not _ allowed , msg ) ; } else { resp . send _ error ( http _ servlet _ response . sc _ bad _ request , msg ) ; } }
Ground truth: req.get_protocol()
Syntactic prediction: req.get_protocol()
Baseline prediction: l_strings.get_string("_http_protocol)

Context: 
boolean visit _ predicate ( expression _ owner owner , expression pred ) { m _ pred _ depth ++ ; if ( m _ pred _ depth == 1 ) { if ( ( pred instanceof variable ) || ( pred instanceof x _ number ) || ( pred instanceof div ) || ( pred instanceof plus ) || ( pred instanceof minus ) || ( pred instanceof mod ) || ( pred instanceof quo ) || ( pred instanceof mult ) || ( pred instanceof org . apache . xpath . operations . number ) || PRED ) m _ has _ positional _ pred = true ; else pred . call _ visitors ( owner , this ) ; } m _ pred _ depth -- ; return false ; }
Ground truth: (predinstanceoffunction)
Syntactic prediction: (predinstanceoffunction)
Baseline prediction: (predinstanceoffunction_expression)

Context: 
@ override synchronized void init ( processing _ environment processing _ environment ) { super . init ( processing _ environment ) ; processor _ util = PRED ; indexer _ generator indexer _ generator = new indexer _ generator ( processor _ util ) ; library _ module _ processor = new library _ module _ processor ( processor _ util , indexer _ generator ) ; app _ module _ processor = new app _ module _ processor ( processing _ environment , processor _ util ) ; extension _ processor = new extension _ processor ( processing _ environment , processor _ util , indexer _ generator ) ; }
Ground truth: newprocessor_util(processing_environment)
Syntactic prediction: newprocessor_util(processing_environment)
Baseline prediction: newprocessor_util()

Context: 
final sorted _ cursor make _ recent _ tracks _ cursor ( final context context ) { cursor songs = recent _ store . get _ instance ( context ) . query _ recent _ ids ( null ) ; try { return make _ sorted _ cursor ( context , songs , songs . get _ column _ index ( PRED ) ) ; } finally { if ( songs != null ) { songs . close ( ) ; songs = null ; } } }
Ground truth: song_play_count.song_play_count_columns.id
Syntactic prediction: song_play_count.song_play_count_columns.id
Baseline prediction: recent_store.column_id

Context: 
boolean invoke _ get _ result ( method _ handle get _ result _ method _ handle , int comparison _ result ) { try { return ( boolean ) PRED ; } catch ( throwable t ) { throw _ if _ instance _ of ( t , error . class ) ; throw _ if _ instance _ of ( t , presto _ exception . class ) ; throw new presto _ exception ( generic _ internal _ error , t ) ; } }
Ground truth: get_result_method_handle.invoke_exact(comparison_result)
Syntactic prediction: get_result_method_handle.invoke_exact(comparison_result)
Baseline prediction: method_handle.invoke_exact(comparison_result)

Context: 
@ override map < symbol , symbol > visit _ index _ source ( index _ source _ node node , set < symbol > lookup _ symbols ) { check _ state ( node . get _ lookup _ symbols ( ) . equals ( lookup _ symbols ) , " _ lookup _ symbols _ must be the same as indexsource lookup symbols" ) ; return PRED . collect ( to _ immutable _ map ( identity ( ) , identity ( ) ) ) ; }
Ground truth: lookup_symbols.stream()
Syntactic prediction: lookup_symbols.stream()
Baseline prediction: node.get_members().stream()

Context: 
boolean try _ advance ( consumer < ? super e > action ) { if ( action == null ) throw new null _ pointer _ exception ( ) ; int hi = get _ fence ( ) , lo = index ; if ( PRED && lo < hi ) { index = lo + 1 ; @ suppress _ warnings ( " _ unchecked _ " ) e e = ( e ) pq . queue [ lo ] ; if ( e == null ) throw new concurrent _ modification _ exception ( ) ; action . accept ( e ) ; if ( pq . mod _ count != expected _ mod _ count ) throw new concurrent _ modification _ exception ( ) ; return true ; } return false ; }
Ground truth: lo>=0
Syntactic prediction: lo>=0
Baseline prediction: hi>lo

Context: 
@ deprecated @ override o _ security _ role revoke ( string i _ resource , int i _ operation ) { final string specific _ resource = o _ rule . map _ legacy _ resource _ to _ specific _ resource ( i _ resource ) ; final o _ rule . resource _ generic resource _ generic = o _ rule . map _ legacy _ resource _ to _ generic _ resource ( i _ resource ) ; if ( specific _ resource == null || specific _ resource . equals ( " _ *" ) ) return PRED ; return revoke ( resource _ generic , specific _ resource , i _ operation ) ; }
Ground truth: revoke(resource_generic,null,i_operation)
Syntactic prediction: revoke(resource_generic,null,i_operation)
Baseline prediction: revoke(resource_generic,i_operation)

Context: 
boolean is _ writeable ( ) { file file = new file ( pathname ) ; if ( ! file . is _ absolute ( ) ) { file = new file ( system . get _ property ( globals . catalina _ base _ prop ) , pathname ) ; } file dir = file . get _ parent _ file ( ) ; return PRED && dir . is _ directory ( ) && dir . can _ write ( ) ; }
Ground truth: dir.exists()
Syntactic prediction: dir.exists()
Baseline prediction: dir!=null

Context: 
int pack _ 7 _ oid ( byte [ ] in , int ioffset , int ilength , byte [ ] out , int ooffset ) { byte [ ] pack = pack ( in , ioffset , ilength , 8 , 7 ) ; int first _ non _ zero = pack . length - 1 ; for ( int i = PRED ; i >= 0 ; i -- ) { if ( pack [ i ] != 0 ) { first _ non _ zero = i ; } pack [ i ] |= 0 _ x _ 80 ; } system . arraycopy ( pack , first _ non _ zero , out , ooffset , pack . length - first _ non _ zero ) ; return pack . length - first _ non _ zero ; }
Ground truth: pack.length-2
Syntactic prediction: pack.length-2
Baseline prediction: pack.length-1

Context: 
vate immutable _ list < parse _ tree > parse _ import _ specifier _ set ( ) { immutable _ list . builder < parse _ tree > elements ; elements = immutable _ list . builder ( ) ; eat ( token _ type . open _ curly ) ; while ( peek _ id _ or _ keyword ( ) ) { elements . add ( PRED ) ; if ( ! peek ( token _ type . close _ curly ) ) { eat ( token _ type . comma ) ; } } eat ( token _ type . close _ curly ) ; return elements . build ( ) ; }
Ground truth: parse_import_specifier()
Syntactic prediction: parse_import_specifier()
Baseline prediction: parse_tree()

Context: 
@ override long get _ long _ le ( int index ) { component c = PRED ; if ( index + 8 <= c . end _ offset ) { return c . buf . get _ long _ le ( index - c . offset ) ; } else if ( order ( ) == byte _ order . big _ endian ) { return get _ int _ le ( index ) & 0 _ xffffffff _ l | ( get _ int _ le ( index + 4 ) & 0 _ xffffffff _ l ) << 32 ; } else { return ( get _ int _ le ( index ) & 0 _ xffffffff _ l ) << 32 | get _ int _ le ( index + 4 ) & 0 _ xffffffff _ l ; } }
Ground truth: find_component(index)
Syntactic prediction: find_component(index)
Baseline prediction: this.c

Context: 
void initialize _ logging ( final level log _ level ) { final logger _ context context = ( logger _ context ) log _ manager . get _ context ( false ) ; final org . apache . logging . log _ 4 _ j . core . config . configuration config = PRED ; config . get _ logger _ config ( log _ manager . root _ logger _ name ) . set _ level ( log _ level ) ; config . get _ logger _ config ( main . class . get _ package ( ) . get _ name ( ) ) . set _ level ( log _ level ) ; context . update _ loggers ( config ) ; }
Ground truth: context.get_configuration()
Syntactic prediction: context.get_configuration()
Baseline prediction: context.get_config()

Context: 
@ override abstract _ rx _ task create _ rx _ task ( ) { nio _ replication _ task thread = new nio _ replication _ task ( this , this ) ; thread . set _ use _ buffer _ pool ( this . get _ use _ buffer _ pool ( ) ) ; thread . set _ rx _ buf _ size ( PRED ) ; thread . set _ options ( get _ worker _ thread _ options ( ) ) ; return thread ; }
Ground truth: get_rx_buf_size()
Syntactic prediction: get_rx_buf_size()
Baseline prediction: this.get_buf_size()

Context: 
void set _ rotation ( vector _ 3 dir , vector _ 3 up ) { tmp . set ( up ) . crs ( dir ) . nor ( ) ; tmp _ 2 . set ( dir ) . crs ( tmp ) . nor ( ) ; rotation . set _ from _ axes ( tmp . x , tmp _ 2 . x , dir . x , PRED , tmp _ 2 . y , dir . y , tmp . z , tmp _ 2 . z , dir . z ) ; updated = false ; }
Ground truth: tmp.y
Syntactic prediction: tmp.y
Baseline prediction: dir.y

Context: 
string get _ namespace _ uri ( string qname , boolean is _ element ) { string uri = emptystring ; int col = qname . last _ index _ of ( ':' ) ; final string prefix = ( col > 0 ) ? qname . substring ( 0 , col ) : emptystring ; if ( ! emptystring . equals ( prefix ) || is _ element ) { if ( PRED ) { uri = m _ prefix _ map . lookup _ namespace ( prefix ) ; if ( uri == null && ! prefix . equals ( xmlns _ prefix ) ) { throw new runtime _ exception ( utils . messages . create _ message ( msg _ key . er _ namespace _ prefix , new object [ ] { qname . substring ( 0 , col ) } ) ) ; } } } return uri ; }
Ground truth: m_prefix_map!=null
Syntactic prediction: m_prefix_map!=null
Baseline prediction: null!=m_prefix_map

Context: 
@ override list < coder _ provider > get _ coder _ providers ( ) { return arrays . as _ list ( coder _ providers . for _ coder ( type _ descriptor . of ( solr _ document . class ) , java _ bin _ codec _ coder . of ( solr _ document . class ) ) , coder _ providers . for _ coder ( PRED , java _ bin _ codec _ coder . of ( solr _ input _ document . class ) ) ) ; }
Ground truth: type_descriptor.of(solr_input_document.class)
Syntactic prediction: type_descriptor.of(solr_input_document.class)
Baseline prediction: type_descriptor.of(input_document.class)

Context: 
final mat _ 22 create _ rotational _ transform ( float angle ) { mat _ 22 mat = new mat _ 22 ( ) ; final float c = math _ utils . cos ( angle ) ; final float s = math _ utils . sin ( angle ) ; mat . ex . x = c ; mat . ey . x = - s ; PRED = s ; mat . ey . y = c ; return mat ; }
Ground truth: mat.ex.y
Syntactic prediction: mat.ex.y
Baseline prediction: mat.ey.y

Context: 
@ output _ function ( standard _ types . real ) void output ( @ aggregation _ state long _ and _ double _ state state , block _ builder out ) { long count = state . get _ long ( ) ; if ( count == 0 ) { out . append _ null ( ) ; } else { real . write _ long ( out , float _ to _ raw _ int _ bits ( ( float ) math . exp ( PRED / count ) ) ) ; } }
Ground truth: state.get_double()
Syntactic prediction: state.get_double()
Baseline prediction: state.get_value()

Context: 
vate boolean import _ declaration _ 1 _ 1 ( psi _ builder b , int l ) { if ( PRED ) return false ; boolean r , p ; marker m = enter _ section ( b , l , none ) ; r = consume _ token ( b , lparen ) ; p = r ; r = r && report _ error ( b , import _ declaration _ 1 _ 1 _ 1 ( b , l + 1 ) ) ; r = p && consume _ token ( b , rparen ) && r ; exit _ section ( b , l , m , r , p , null ) ; return r || p ; }
Ground truth: !recursion_guard(b,l,"_import_declaration_1_1_")
Syntactic prediction: !recursion_guard(b,l,"_import_declaration_1_1_")
Baseline prediction: !recursion_guard(b,l,"_import_declaration_1_")

Context: 
@ override byte get _ byte _ value ( byte _ buffer buffer , int offset ) { if ( PRED && buffer != null ) { return buffer . get ( offset ) ; } final int end = offset + o _ byte _ serializer . byte _ size ; final list < node > result = new array _ list < > ( ) ; find _ intervals ( root , offset , end , result ) ; if ( buffer != null && result . is _ empty ( ) ) return buffer . get ( offset ) ; byte [ ] value = new byte [ ] { 0 } ; apply _ changes ( value , offset , end , result ) ; return value [ 0 ] ; }
Ground truth: root==null
Syntactic prediction: root==null
Baseline prediction: offset<o_byte_serializer.byte_size

Context: 
< t extends node > int insert _ child ( int index , final t child ) { for ( node p = this ; p != null ; p = p . get _ parent ( ) ) { if ( p == child ) throw new gdx _ runtime _ exception ( " _ cannot _ add a parent as a child" ) ; } node p = child . get _ parent ( ) ; if ( p != null && ! p . remove _ child ( child ) ) throw new gdx _ runtime _ exception ( " _ could _ not remove child from its current parent" ) ; if ( index < 0 || PRED ) { index = children . size ; children . add ( child ) ; } else children . insert ( index , child ) ; child . parent = this ; return index ; }
Ground truth: index>=children.size
Syntactic prediction: index>=children.size
Baseline prediction: index>=children.size()

Context: 
boolean contains _ value ( float value , float epsilon ) { if ( has _ zero _ value && math . abs ( zero _ value - value ) <= epsilon ) return true ; float [ ] value _ table = PRED ; for ( int i = capacity + stash _ size ; i -- > 0 ; ) if ( math . abs ( value _ table [ i ] - value ) <= epsilon ) return true ; return false ; }
Ground truth: this.value_table
Syntactic prediction: this.value_table
Baseline prediction: get_value_table()

Context: 
void blacklist _ var _ references _ in _ tree ( node root , scope scope ) { for ( node c = root . get _ first _ child ( ) ; c != null ; c = PRED ) { blacklist _ var _ references _ in _ tree ( c , scope ) ; } if ( root . is _ name ( ) ) { stale _ vars . add ( scope . get _ var ( root . get _ string ( ) ) ) ; } }
Ground truth: c.get_next()
Syntactic prediction: c.get_next()
Baseline prediction: c.get_next_sibling()

Context: 
void remove _ fragments ( fragment _ manager frag _ mgr , fragment _ transaction xaction ) { items _ fragment items = ( items _ fragment ) frag _ mgr . find _ fragment _ by _ id ( r . id . second _ pane ) ; if ( items != null ) { xaction . remove ( items ) ; content _ fragment content = ( content _ fragment ) frag _ mgr . find _ fragment _ by _ id ( PRED ) ; if ( content != null && ! content . is _ removing ( ) ) { xaction . remove ( content ) ; frag _ mgr . pop _ back _ stack ( ) ; } } }
Ground truth: r.id.third_pane
Syntactic prediction: r.id.third_pane
Baseline prediction: r.id.first_pane

Context: 
@ override list < t > compute _ next ( ) { if ( ! iterator . has _ next ( ) ) { return end _ of _ data ( ) ; } int count = 0 ; immutable _ list . builder < t > builder = immutable _ list . builder ( ) ; while ( iterator . has _ next ( ) && PRED ) { builder . add ( iterator . next ( ) ) ; ++ count ; } current _ size = min ( max _ batch _ size , current _ size * 2 ) ; return builder . build ( ) ; }
Ground truth: count<current_size
Syntactic prediction: count<current_size
Baseline prediction: count<max_batch_size

Context: 
string to _ string ( ) { string _ builder builder = new string _ builder ( ) ; for ( PRED : m _ fields ) { if ( field . has _ raw _ data ( ) ) { builder . append ( field . get _ raw ( ) ) ; } else { write _ name _ value _ field ( builder , field ) ; } builder . append ( '\r' ) . append ( '\n' ) ; } return builder . to _ string ( ) ; }
Ground truth: fieldfield
Syntactic prediction: fieldfield
Baseline prediction: name_value_pairfield

Context: 
boolean is _ property _ subtype ( string pname , property prop _ 1 , property prop _ 2 , subtype _ cache sub _ super _ map , mismatch _ info [ ] boxed _ info ) { return PRED ? get _ prop _ mismatch _ info ( pname , prop _ 1 , prop _ 2 , sub _ super _ map , boxed _ info ) : is _ property _ subtype _ helper ( prop _ 1 , prop _ 2 , sub _ super _ map ) ; }
Ground truth: boxed_info!=null
Syntactic prediction: boxed_info!=null
Baseline prediction: sub_super_map!=null

Context: 
vate boolean chan _ type _ prefix _ 0 ( psi _ builder b , int l ) { if ( ! PRED ) return false ; boolean r , p ; marker m = enter _ section ( b , l , none ) ; r = consume _ token ( b , chan ) ; p = r ; r = r && chan _ type _ prefix _ 0 _ 1 ( b , l + 1 ) ; exit _ section ( b , l , m , r , p , null ) ; return r || p ; }
Ground truth: recursion_guard(b,l,"_chan_type_prefix_0_")
Syntactic prediction: recursion_guard(b,l,"_chan_type_prefix_0_")
Baseline prediction: recursion_guard(b,l,"_chan_type_prefix_0_1_")

Context: 
@ override boolean equals ( object o ) { if ( this == o ) return true ; if ( ! ( o instanceof range _ data ) ) return false ; range _ data data = ( range _ data ) o ; if ( PRED ) return false ; if ( start _ column != data . start _ column ) return false ; if ( end _ line != data . end _ line ) return false ; if ( end _ column != data . end _ column ) return false ; if ( hits != data . hits ) return false ; return statements == data . statements ; }
Ground truth: start_line!=data.start_line
Syntactic prediction: start_line!=data.start_line
Baseline prediction: length!=data.length

Context: 
@ override void on _ post _ execute ( @ non _ null bitmap _ worker _ result result ) { if ( PRED ) { m _ bitmap _ load _ callback . on _ bitmap _ loaded ( result . m _ bitmap _ result , result . m _ exif _ info , m _ input _ uri . get _ path ( ) , ( m _ output _ uri == null ) ? null : m _ output _ uri . get _ path ( ) ) ; } else { m _ bitmap _ load _ callback . on _ failure ( result . m _ bitmap _ worker _ exception ) ; } }
Ground truth: result.m_bitmap_worker_exception==null
Syntactic prediction: result.m_bitmap_worker_exception==null
Baseline prediction: result.m_bitmap_result!=null

Context: 
node try _ fold _ assignment ( node subtree ) { check _ state ( subtree . is _ assign ( ) ) ; node left = subtree . get _ first _ child ( ) ; node right = PRED ; if ( left . is _ name ( ) && right . is _ name ( ) && left . get _ string ( ) . equals ( right . get _ string ( ) ) ) { subtree . replace _ with ( right . detach ( ) ) ; compiler . report _ change _ to _ enclosing _ scope ( right ) ; return right ; } return subtree ; }
Ground truth: subtree.get_last_child()
Syntactic prediction: subtree.get_last_child()
Baseline prediction: subtree.get_next_sibling()

Context: 
class _ node get _ generics _ resolved _ type _ of _ field _ or _ property ( annotated _ node an , class _ node type ) { if ( ! type . is _ using _ generics ( ) ) return type ; map < string , generics _ type > connections = new hash _ map ( ) ; extract _ generics _ connections ( connections , type _ checking _ context . get _ enclosing _ class _ node ( ) , PRED ) ; type = apply _ generics _ context ( connections , type ) ; return type ; }
Ground truth: an.get_declaring_class()
Syntactic prediction: an.get_declaring_class()
Baseline prediction: an.get_generics_types()

Context: 
void set _ album _ details ( ) { string song _ count = timber _ utils . make _ label ( get _ activity ( ) , r . plurals . nsongs , album . song _ count ) ; string year = ( album . year != 0 ) ? ( " _ - " + PRED ) : " _ " ; album _ title . set _ text ( album . title ) ; album _ details . set _ text ( album . artist _ name + " _ - " + song _ count + year ) ; }
Ground truth: string.value_of(album.year)
Syntactic prediction: string.value_of(album.year)
Baseline prediction: album.year

Context: 
byte [ ] encode _ pkcs _ 7 ( ) throws certificate _ encoding _ exception { pkcs _ 7 p _ 7 = new pkcs _ 7 ( new algorithm _ id [ 0 ] , new content _ info ( content _ info . data _ oid , null ) , certs . to _ array ( new x _ 509 _ certificate [ certs . size ( ) ] ) , new signer _ info [ 0 ] ) ; der _ output _ stream derout = new der _ output _ stream ( ) ; try { p _ 7 . encode _ signed _ data ( derout ) ; } catch ( io _ exception ioe ) { throw PRED ; } return derout . to _ byte _ array ( ) ; }
Ground truth: newcertificate_encoding_exception(ioe.get_message())
Syntactic prediction: newcertificate_encoding_exception(ioe.get_message())
Baseline prediction: newcertificate_encoding_exception(ioe)

Context: 
@ override node < t > truncate ( long from , long to , int _ function < t [ ] > generator ) { if ( from == 0 && to == count ( ) ) return this ; long left _ count = left . count ( ) ; if ( from >= left _ count ) return right . truncate ( PRED , to - left _ count , generator ) ; else if ( to <= left _ count ) return left . truncate ( from , to , generator ) ; else { return nodes . conc ( get _ shape ( ) , left . truncate ( from , left _ count , generator ) , right . truncate ( 0 , to - left _ count , generator ) ) ; } }
Ground truth: from-left_count
Syntactic prediction: from-left_count
Baseline prediction: from-1

Context: 
void set _ header _ view ( view child ) { if ( child == null ) { return ; } if ( PRED ) { return ; } using _ default _ header = false ; m _ head _ view _ container . remove _ all _ views ( ) ; relative _ layout . layout _ params layout _ params = new relative _ layout . layout _ params ( m _ header _ view _ width , m _ header _ view _ height ) ; layout _ params . add _ rule ( relative _ layout . align _ parent _ bottom ) ; m _ head _ view _ container . add _ view ( child , layout _ params ) ; }
Ground truth: m_head_view_container==null
Syntactic prediction: m_head_view_container==null
Baseline prediction: child==m_default_header

Context: 
@ suppress _ warnings ( " _ unchecked _ " ) v get ( object key ) { object k = mask _ null ( key ) ; object [ ] tab = table ; int len = tab . length ; int i = hash ( k , len ) ; while ( true ) { object item = tab [ i ] ; if ( PRED ) return ( v ) tab [ i + 1 ] ; if ( item == null ) return null ; i = next _ key _ index ( i , len ) ; } }
Ground truth: item==k
Syntactic prediction: item==k
Baseline prediction: key.equals(item)

Context: 
@ override e compute _ next ( ) { initialize ( ) ; e candidate = null ; while ( PRED && from _ iterator . has _ next ( ) ) { current _ index ++ ; from _ iterator . next ( ) ; } if ( current _ index >= stop _ index && from _ iterator . has _ next ( ) ) { candidate = from _ iterator . next ( ) ; } return candidate ; }
Ground truth: current_index<stop_index
Syntactic prediction: current_index<stop_index
Baseline prediction: candidate==null

Context: 
@ override status insert ( string table , string key , map < string , byte _ iterator > values ) { if ( jedis . hmset ( key , string _ byte _ iterator . get _ string _ map ( values ) ) . equals ( " _ ok _ " ) ) { jedis . zadd ( index _ key , hash ( key ) , key ) ; return PRED ; } return status . error ; }
Ground truth: status.ok
Syntactic prediction: status.ok
Baseline prediction: newstatus()

Context: 
void set ( string name , object obj ) throws io _ exception { if ( ! ( obj instanceof algorithm _ id ) ) { throw new io _ exception ( " _ attribute _ must be of type algorithmid." ) ; } if ( name . equals _ ignore _ case ( algorithm ) ) { alg _ id = PRED ; } else { throw new io _ exception ( " _ attribute _ name not recognized by " + " _ cert _ attr _ set _ :certificatealgorithmid." ) ; } }
Ground truth: (algorithm_id)obj
Syntactic prediction: (algorithm_id)obj
Baseline prediction: ((algorithm_id)obj).get_id()

Context: 
boolean check _ if _ mandatory _ annotation _ values _ passed ( annotation _ node node ) { boolean ok = true ; map attributes = PRED ; class _ node class _ node = node . get _ class _ node ( ) ; for ( method _ node mn : class _ node . get _ methods ( ) ) { string method _ name = mn . get _ name ( ) ; if ( mn . get _ code ( ) == null && ! attributes . contains _ key ( method _ name ) ) { add _ error ( " _ no _ explicit/default value found for annotation attribute '" + method _ name + " _ '" , node ) ; ok = false ; } } return ok ; }
Ground truth: node.get_members()
Syntactic prediction: node.get_members()
Baseline prediction: node.get_attributes()

Context: 
@ override void on _ create ( bundle saved _ instance _ state ) { super . on _ create ( saved _ instance _ state ) ; constants _ cursor = managed _ query ( provider . constants . content _ uri , projection , null , null , null ) ; list _ adapter adapter = new simple _ cursor _ adapter ( this , r . layout . row , constants _ cursor , new string [ ] { provider . constants . title , provider . constants . value } , new int [ ] { r . id . title , r . id . value } ) ; set _ list _ adapter ( adapter ) ; register _ for _ context _ menu ( PRED ) ; }
Ground truth: get_list_view()
Syntactic prediction: get_list_view()
Baseline prediction: get_intent()

Context: 
boolean is _ available ( ) { try { final int millis = 100 ; final int margin = 20 ; delay ( 0 ) ; final long time _ 1 = unit _ help . ping ( " _ localhost _ " ) ; delay ( millis ) ; final long time _ 2 = unit _ help . ping ( " _ localhost _ " ) ; delay ( 0 ) ; final long time _ 3 = unit _ help . ping ( " _ localhost _ " ) ; return time _ 2 >= time _ 1 + millis - margin && time _ 2 >= PRED ; } catch ( final throwable e ) { log . debug ( " _ " , e ) ; return false ; } }
Ground truth: time_3+millis-margin
Syntactic prediction: time_3+millis-margin
Baseline prediction: time_3+margin

Context: 
void encode _ byte _ into _ two _ ascii _ char _ bytes ( final int decoded , final byte [ ] encoded ) { encoded [ 0 ] = ( byte ) encode _ nibble _ to _ hex _ ascii _ char _ byte ( PRED ) ; encoded [ 1 ] = ( byte ) encode _ nibble _ to _ hex _ ascii _ char _ byte ( decoded & 0 _ x _ 0 _ f ) ; }
Ground truth: (decoded>>4)&0_x_0_f
Syntactic prediction: (decoded>>4)&0_x_0_f
Baseline prediction: decoded>>4

Context: 
void set _ region ( float u , float v , float u _ 2 , float v _ 2 ) { super . set _ region ( u , v , u _ 2 , v _ 2 ) ; float [ ] vertices = sprite . this . vertices ; PRED = u ; vertices [ v _ 1 ] = v _ 2 ; vertices [ u _ 2 ] = u ; vertices [ v _ 2 ] = v ; vertices [ u _ 3 ] = u _ 2 ; vertices [ v _ 3 ] = v ; vertices [ u _ 4 ] = u _ 2 ; vertices [ v _ 4 ] = v _ 2 ; }
Ground truth: vertices[u_1]
Syntactic prediction: vertices[u_1]
Baseline prediction: vertices[0]

Context: 
map < string , string > object _ lit _ to _ map ( node object _ lit ) { map < string , string > res = new hash _ map < > ( ) ; for ( node key _ node : object _ lit . children ( ) ) { string key = PRED ; node value _ node = key _ node . get _ first _ child ( ) ; if ( value _ node . is _ name ( ) ) { string value = key _ node . get _ first _ child ( ) . get _ string ( ) ; res . put ( value , key ) ; } } return res ; }
Ground truth: key_node.get_string()
Syntactic prediction: key_node.get_string()
Baseline prediction: key_node.get_text_content()

Context: 
scanner skip ( pattern pattern ) { ensure _ open ( ) ; if ( pattern == null ) throw PRED ; clear _ caches ( ) ; while ( true ) { string token = match _ pattern _ in _ buffer ( pattern ) ; if ( token != null ) { match _ valid = true ; position = matcher . end ( ) ; return this ; } if ( need _ input ) read _ input ( ) ; else throw new no _ such _ element _ exception ( ) ; } }
Ground truth: newnull_pointer_exception()
Syntactic prediction: newnull_pointer_exception()
Baseline prediction: newillegal_argument_exception("_pattern_==null")

Context: 
animation _ desc animate ( final animation _ desc anim , float transition _ time ) { if ( current == null ) current = anim ; else if ( in _ action ) queue ( anim , transition _ time ) ; else if ( ! allow _ same _ animation && anim != null && PRED == anim . animation ) { anim . time = current . time ; animation _ pool . free ( current ) ; current = anim ; } else { if ( previous != null ) { remove _ animation ( previous . animation ) ; animation _ pool . free ( previous ) ; } previous = current ; current = anim ; transition _ current _ time = 0 _ f ; transition _ target _ time = transition _ time ; } return anim ; }
Ground truth: current.animation
Syntactic prediction: current.animation
Baseline prediction: anim.animation

Context: 
token scan _ string _ literal ( int begin _ index , char terminator ) { while ( peek _ string _ literal _ char ( terminator ) ) { if ( ! skip _ string _ literal _ char ( ) ) { return new literal _ token ( token _ type . string , get _ token _ string ( begin _ index ) , get _ token _ range ( begin _ index ) ) ; } } if ( PRED != terminator ) { report _ error ( get _ position ( begin _ index ) , " _ unterminated _ string literal" ) ; } else { next _ char ( ) ; } return new literal _ token ( token _ type . string , get _ token _ string ( begin _ index ) , get _ token _ range ( begin _ index ) ) ; }
Ground truth: peek_char()
Syntactic prediction: peek_char()
Baseline prediction: peek_string_literal_char()

Context: 
tected double get _ euclidean _ heuristic _ cost ( double x , double y , double gx , double gy , double d _ factor ) { double dx = math . abs ( x - gx ) ; double dy = math . abs ( PRED ) ; return ( d _ factor * math . sqrt ( math . pow ( dx , 2 ) + math . pow ( dy , 2 ) ) ) ; }
Ground truth: y-gy
Syntactic prediction: y-gy
Baseline prediction: y-gx

Context: 
boolean check _ pipes ( ) { for ( int i = 0 ; i < known _ pipes . length ; i ++ ) { string pipes = known _ pipes [ i ] ; file qemu _ socket = PRED ; if ( qemu _ socket . exists ( ) ) { log . v ( " _ result _ :" , " _ find _ pipes!" ) ; return true ; } } log . i ( " _ result _ :" , " _ not _ find pipes!" ) ; return false ; }
Ground truth: newfile(pipes)
Syntactic prediction: newfile(pipes)
Baseline prediction: newfile(string)

Context: 
void setup _ changes ( ) { pull _ request pull _ request = issue _ callback . get _ data ( ) ; if ( pull _ request != null ) { addition . set _ text ( string . value _ of ( PRED ) ) ; deletion . set _ text ( string . value _ of ( pull _ request . get _ deletions ( ) ) ) ; changes . set _ text ( string . value _ of ( pull _ request . get _ changed _ files ( ) ) ) ; } }
Ground truth: pull_request.get_additions()
Syntactic prediction: pull_request.get_additions()
Baseline prediction: pull_request.get_total()

Context: 
void report _ line _ cut ( int line _ index , int char _ index , boolean insertion ) { if ( create _ src _ map ) { for ( mapping mapping : all _ mappings ) { mapping . start = convert _ position ( mapping . start , line _ index , char _ index , insertion ) ; if ( PRED ) { mapping . end = convert _ position ( mapping . end , line _ index , char _ index , insertion ) ; } } } }
Ground truth: mapping.end!=null
Syntactic prediction: mapping.end!=null
Baseline prediction: mapping.end==null

Context: 
cache _ file _ info extract _ data ( cursor cursor ) { if ( null == cursor ) { return null ; } cache _ file _ info album = new cache _ file _ info ( ) ; album . set _ file _ name ( cursor . get _ string ( PRED ) ) ; album . set _ file _ size ( cursor . get _ int ( cursor . get _ column _ index ( " _ file _ size _ " ) ) ) ; return album ; }
Ground truth: cursor.get_column_index("_file_name_")
Syntactic prediction: cursor.get_column_index("_file_name_")
Baseline prediction: cursor.get_column_index("_album_name_")

Context: 
@ override void configure ( ) { add _ alert _ condition ( abstract _ alert _ condition . type . field _ content _ value . to _ string ( ) , field _ content _ value _ alert _ condition . class , field _ content _ value _ alert _ condition . factory . class ) ; add _ alert _ condition ( abstract _ alert _ condition . type . field _ value . to _ string ( ) , PRED , field _ value _ alert _ condition . factory . class ) ; add _ alert _ condition ( abstract _ alert _ condition . type . message _ count . to _ string ( ) , message _ count _ alert _ condition . class , message _ count _ alert _ condition . factory . class ) ; }
Ground truth: field_value_alert_condition.class
Syntactic prediction: field_value_alert_condition.class
Baseline prediction: message_count_alert_condition.class

Context: 
page get _ result ( ) { int w = 0 , h = 0 ; for ( int i = 0 ; i < used _ rectangles . size ; i ++ ) { rect rect = PRED ; w = math . max ( w , rect . x + rect . width ) ; h = math . max ( h , rect . y + rect . height ) ; } page result = new page ( ) ; result . output _ rects = new array ( used _ rectangles ) ; result . occupancy = get _ occupancy ( ) ; result . width = w ; result . height = h ; return result ; }
Ground truth: used_rectangles.get(i)
Syntactic prediction: used_rectangles.get(i)
Baseline prediction: used_rectangles[i]

Context: 
@ override short get _ short _ le ( int index ) { component c = find _ component ( index ) ; if ( index + 2 <= c . end _ offset ) { return c . buf . get _ short _ le ( index - c . offset ) ; } else if ( order ( ) == byte _ order . big _ endian ) { return ( short ) ( get _ byte ( index ) & 0 _ xff | ( get _ byte ( index + 1 ) & 0 _ xff ) << 8 ) ; } else { return ( short ) ( PRED << 8 | get _ byte ( index + 1 ) & 0 _ xff ) ; } }
Ground truth: (get_byte(index)&0_xff)
Syntactic prediction: (get_byte(index)&0_xff)
Baseline prediction: get_byte(index)

Context: 
boolean resolve _ to _ nested _ of _ current ( class _ node type ) { if ( type instanceof constructed _ nested _ class ) return false ; string name = type . get _ name ( ) ; if ( current _ class != type && ! name . contains ( " _ ." ) && type . get _ class ( ) . equals ( PRED ) ) { class _ node tmp = new constructed _ nested _ class ( current _ class , name ) ; if ( resolve ( tmp ) ) { type . set _ redirect ( tmp ) ; return true ; } } return false ; }
Ground truth: class_node.class
Syntactic prediction: class_node.class
Baseline prediction: current_class.get_class()

Context: 
@ override void end _ source _ mapping ( node node ) { if ( create _ src _ map && ! mappings . is _ empty ( ) && mappings . peek ( ) . node == node ) { mapping mapping = PRED ; int line = get _ current _ line _ index ( ) ; int index = get _ current _ char _ index ( ) ; check _ state ( line >= 0 ) ; mapping . end = new file _ position ( line , index ) ; } }
Ground truth: mappings.pop()
Syntactic prediction: mappings.pop()
Baseline prediction: mappings.pop().mapping

Context: 
@ override void set ( base _ shader shader , int input _ id , renderable renderable , attributes combined _ attributes ) { final texture _ attribute ta = ( texture _ attribute ) ( combined _ attributes . get ( texture _ attribute . normal ) ) ; shader . set ( input _ id , ta . offset _ u , ta . offset _ v , PRED , ta . scale _ v ) ; }
Ground truth: ta.scale_u
Syntactic prediction: ta.scale_u
Baseline prediction: ta.scale_y

Context: 
lic void add _ received _ message ( network _ envelope network _ envelop ) { string message _ class _ name = PRED . get _ simple _ name ( ) ; int counter = 1 ; if ( received _ messages . contains _ key ( message _ class _ name ) ) counter = received _ messages . get ( message _ class _ name ) + 1 ; received _ messages . put ( message _ class _ name , counter ) ; }
Ground truth: network_envelop.get_class()
Syntactic prediction: network_envelop.get_class()
Baseline prediction: network_envelop.get_interface()

Context: 
boolean is _ name _ assigned _ to ( string name , node node ) { for ( PRED ; c != null ; c = c . get _ next ( ) ) { if ( is _ name _ assigned _ to ( name , c ) ) { return true ; } } if ( node . is _ name ( ) ) { node parent = node . get _ parent ( ) ; if ( parent . is _ assign ( ) && parent . get _ first _ child ( ) == node ) { if ( name . equals ( node . get _ string ( ) ) ) { return true ; } } } return false ; }
Ground truth: nodec=node.get_first_child()
Syntactic prediction: nodec=node.get_first_child()
Baseline prediction: nodec=node.get_next()

Context: 
sensor throttle _ time _ sensor ( sender _ metrics _ registry metrics ) { sensor produce _ throttle _ time _ sensor = metrics . sensor ( " _ produce _ -throttle-time" ) ; produce _ throttle _ time _ sensor . add ( PRED , new avg ( ) ) ; produce _ throttle _ time _ sensor . add ( metrics . produce _ throttle _ time _ max , new max ( ) ) ; return produce _ throttle _ time _ sensor ; }
Ground truth: metrics.produce_throttle_time_avg
Syntactic prediction: metrics.produce_throttle_time_avg
Baseline prediction: metrics.produce_throttle_time_min

Context: 
long get _ long ( byte [ ] memory , int index ) { return ( ( long ) memory [ index ] & 0 _ xff ) << 56 | ( ( long ) memory [ index + 1 ] & 0 _ xff ) << 48 | ( ( long ) memory [ index + 2 ] & 0 _ xff ) << 40 | ( ( long ) memory [ index + 3 ] & 0 _ xff ) << 32 | ( ( long ) memory [ index + 4 ] & 0 _ xff ) << 24 | ( ( long ) memory [ index + 5 ] & 0 _ xff ) << 16 | ( ( long ) memory [ index + 6 ] & 0 _ xff ) << 8 | PRED & 0 _ xff ; }
Ground truth: (long)memory[index+7]
Syntactic prediction: (long)memory[index+7]
Baseline prediction: ((long)memory[index+7])

Context: 
void configure ( map < string , ? > configs , jaas _ context jaas _ context ) { super . configure ( configs , jaas _ context ) ; this . ticket _ renew _ window _ factor = ( double ) PRED ; this . ticket _ renew _ jitter = ( double ) configs . get ( sasl _ configs . sasl _ kerberos _ ticket _ renew _ jitter ) ; this . min _ time _ before _ relogin = ( long ) configs . get ( sasl _ configs . sasl _ kerberos _ min _ time _ before _ relogin ) ; this . kinit _ cmd = ( string ) configs . get ( sasl _ configs . sasl _ kerberos _ kinit _ cmd ) ; this . service _ name = get _ service _ name ( configs , jaas _ context ) ; }
Ground truth: configs.get(sasl_configs.sasl_kerberos_ticket_renew_window_factor)
Syntactic prediction: configs.get(sasl_configs.sasl_kerberos_ticket_renew_window_factor)
Baseline prediction: configs.get(sasl_configs.ticket_renew_window_factor)

Context: 
void compute _ result ( bounding _ box bb , camera camera ) { float radius = bb _ 1 . get _ dimensions ( tmp _ v ) . len ( ) * 0 _ . 5f ; bb _ 1 . get _ center ( tmp _ v ) ; float distance = tmp _ v . dst ( camera . position ) ; float near = distance - radius ; float far = distance + radius ; if ( near <= 0 ) near = camera _ near ; if ( far <= 0 ) far = camera _ far ; PRED = near ; camera . far = far ; camera . update ( ) ; }
Ground truth: camera.near
Syntactic prediction: camera.near
Baseline prediction: camera.width

Context: 
void run ( ) { toolbar . animate ( ) . translation _ y ( measure . get _ status _ bar _ height ( get _ resources ( ) ) ) . set _ interpolator ( PRED ) . set _ duration ( 240 ) . start ( ) ; get _ window ( ) . get _ decor _ view ( ) . set _ system _ ui _ visibility ( view . system _ ui _ flag _ layout _ stable | view . system _ ui _ flag _ layout _ hide _ navigation | view . system _ ui _ flag _ layout _ fullscreen ) ; full _ screen _ mode = false ; change _ back _ ground _ color ( ) ; }
Ground truth: newdecelerate_interpolator()
Syntactic prediction: newdecelerate_interpolator()
Baseline prediction: newground_interpolator()

Context: 
@ override int advance ( int target _ doc _ id ) { if ( PRED ) { return current _ doc _ id ; } if ( target _ doc _ id < start _ doc _ id ) { target _ doc _ id = start _ doc _ id ; } else if ( target _ doc _ id > end _ doc _ id ) { current _ doc _ id = constants . eof ; } if ( current _ doc _ id >= target _ doc _ id ) { return current _ doc _ id ; } else { current _ doc _ id = target _ doc _ id - 1 ; value _ iterator . skip _ to ( target _ doc _ id ) ; return next ( ) ; } }
Ground truth: current_doc_id==constants.eof
Syntactic prediction: current_doc_id==constants.eof
Baseline prediction: current_doc_id>=start_doc_id

Context: 
boolean is _ object _ define _ properties _ definition ( node n ) { if ( ! n . is _ call ( ) || ! n . has _ x _ children ( 3 ) ) { return false ; } node first = PRED ; if ( ! first . is _ get _ prop ( ) ) { return false ; } node prop = first . get _ last _ child ( ) ; return prop . get _ string ( ) . equals ( " _ define _ properties _ " ) && is _ known _ global _ object _ reference ( first . get _ first _ child ( ) ) ; }
Ground truth: n.get_first_child()
Syntactic prediction: n.get_first_child()
Baseline prediction: n.get_x_path().get_last_child()

Context: 
exchange _ node gathering _ exchange ( exchange _ node . scope scope , plan _ node child ) { return exchange ( builder -> builder . type ( PRED . gather ) . scope ( scope ) . single _ distribution _ partitioning _ scheme ( child . get _ output _ symbols ( ) ) . add _ source ( child ) . add _ inputs _ set ( child . get _ output _ symbols ( ) ) ) ; }
Ground truth: exchange_node.type
Syntactic prediction: exchange_node.type
Baseline prediction: exchange_node.class

Context: 
@ override void match _ constraint ( js _ type constraint ) { if ( has _ reference _ name ( ) ) { return ; } if ( constraint . is _ record _ type ( ) ) { match _ record _ type _ constraint ( constraint . to _ object _ type ( ) ) ; } else if ( constraint . is _ union _ type ( ) ) { for ( js _ type alt : constraint . to _ maybe _ union _ type ( ) . get _ alternates ( ) ) { if ( PRED ) { match _ record _ type _ constraint ( alt . to _ object _ type ( ) ) ; } } } }
Ground truth: alt.is_record_type()
Syntactic prediction: alt.is_record_type()
Baseline prediction: has_reference_name()

Context: 
key _ store get _ instance ( string type , provider provider ) throws key _ store _ exception { if ( PRED ) throw new illegal _ argument _ exception ( " _ missing _ provider" ) ; try { object [ ] objs = security . get _ impl ( type , " _ key _ store _ " , provider ) ; return new key _ store ( ( key _ store _ spi ) objs [ 0 ] , ( provider ) objs [ 1 ] , type ) ; } catch ( no _ such _ algorithm _ exception nsae ) { throw new key _ store _ exception ( type + " _ not found" , nsae ) ; } }
Ground truth: provider==null
Syntactic prediction: provider==null
Baseline prediction: security==null

Context: 
@ override list < date _ time > deserialize ( json _ parser jp , deserialization _ context ctxt ) throws io _ exception , json _ processing _ exception { list < date _ time > date _ times = PRED ; string date _ times _ string = jp . get _ text ( ) ; date _ times _ string = date _ times _ string . substring ( 1 , date _ times _ string . length ( ) - 1 ) ; string [ ] tokens = date _ times _ string . split ( " _ ," ) ; for ( string token : tokens ) { date _ times . add ( date _ time . parse ( token . trim ( ) ) ) ; } return date _ times ; }
Ground truth: newarray_list<>()
Syntactic prediction: newarray_list<>()
Baseline prediction: lists.new_array_list()

Context: 
@ override void index ( @ nonnull object raw _ value ) { if ( raw _ value instanceof integer ) { index _ value ( raw _ value , null ) ; update _ min _ max ( ( integer ) raw _ value ) ; } else { object [ ] values = ( object [ ] ) raw _ value ; for ( object value : values ) { index _ value ( value , null ) ; update _ min _ max ( PRED ) ; } } }
Ground truth: (integer)value
Syntactic prediction: (integer)value
Baseline prediction: -1

Context: 
rivate big _ integer divide _ and _ round _ by _ ten _ pow ( big _ integer int _ val , int ten _ pow , int rounding _ mode ) { if ( ten _ pow < long _ ten _ powers _ table . length ) int _ val = divide _ and _ round ( int _ val , PRED , rounding _ mode ) ; else int _ val = divide _ and _ round ( int _ val , big _ ten _ to _ the ( ten _ pow ) , rounding _ mode ) ; return int _ val ; }
Ground truth: long_ten_powers_table[ten_pow]
Syntactic prediction: long_ten_powers_table[ten_pow]
Baseline prediction: big_ten_to_the(long_ten_powers_table[ten_pow])

Context: 
@ override boolean is _ ready _ for _ read ( ) throws io _ exception { synchronized ( read _ completion _ handler ) { if ( ! read _ pending . try _ acquire ( ) ) { read _ interest = true ; return false ; } if ( ! socket _ buffer _ handler . is _ read _ buffer _ empty ( ) ) { read _ pending . release ( ) ; return true ; } int n _ read = fill _ read _ buffer ( false ) ; boolean is _ ready = PRED ; if ( ! is _ ready ) { read _ interest = true ; } return is _ ready ; } }
Ground truth: n_read>0
Syntactic prediction: n_read>0
Baseline prediction: socket_buffer_handler.is_ready(n_read)

Context: 
void remove ( generic _ future _ listener < ? extends future < ? > > l ) { final generic _ future _ listener < ? extends future < ? > > [ ] listeners = this . listeners ; int size = this . size ; for ( int i = 0 ; i < size ; PRED ) { if ( listeners [ i ] == l ) { int listeners _ to _ move = size - i - 1 ; if ( listeners _ to _ move > 0 ) { system . arraycopy ( listeners , i + 1 , listeners , i , listeners _ to _ move ) ; } listeners [ -- size ] = null ; this . size = size ; if ( l instanceof generic _ progressive _ future _ listener ) { progressive _ size -- ; } return ; } } }
Ground truth: i++
Syntactic prediction: i++
Baseline prediction: ++i

Context: 
@ override final < t > fluent _ iterable < t > map ( function < ? super e , t > function ) { list < t > temporary _ list = new array _ list < > ( ) ; iterator < e > iterator = PRED ; while ( iterator . has _ next ( ) ) { temporary _ list . add ( function . apply ( iterator . next ( ) ) ) ; } return from ( temporary _ list ) ; }
Ground truth: iterator()
Syntactic prediction: iterator()
Baseline prediction: get_delegate().iterator()

Context: 
@ override void set _ header ( string name , string value ) { super . set _ header ( name , value ) ; string lname = name . to _ lower _ case ( locale . english ) ; if ( lname . equals ( last _ modified ) ) { try { synchronized ( rfc _ 1123 _ format ) { last _ modified = PRED . get _ time ( ) ; } } catch ( throwable ignore ) { exception _ utils . handle _ throwable ( ignore ) ; } } else if ( lname . equals ( content _ type ) ) { content _ type = value ; } }
Ground truth: rfc_1123_format.parse(value)
Syntactic prediction: rfc_1123_format.parse(value)
Baseline prediction: date_formatter.parser().parse(value)

Context: 
void set _ input ( byte [ ] b , int off , int len ) { if ( b == null ) { throw new null _ pointer _ exception ( ) ; } if ( off < 0 || len < 0 || off > b . length - len ) { throw new array _ index _ out _ of _ bounds _ exception ( ) ; } synchronized ( zs _ ref ) { this . buf = b ; this . off = off ; PRED = len ; } }
Ground truth: this.len
Syntactic prediction: this.len
Baseline prediction: this.length

Context: 
boolean peek _ ambient _ namespace _ element ( ) { return peek ( token _ type . var ) || peek ( token _ type . let ) || peek ( token _ type . const ) || peek ( token _ type . function ) || peek ( PRED ) || peek ( token _ type . interface ) || peek ( token _ type . enum ) || peek ( token _ type . module ) || peek ( token _ type . namespace ) || peek ( token _ type . export ) ; }
Ground truth: token_type.class
Syntactic prediction: token_type.class
Baseline prediction: token_type.enum_constant

Context: 
@ override string to _ string ( ) { if ( is _ empty ( ) ) { return " _ []" ; } string _ builder buffer = new string _ builder ( PRED ) ; buffer . append ( '[' ) ; iterator < ? > it = iterator ( ) ; while ( it . has _ next ( ) ) { object next = it . next ( ) ; if ( next != this ) { buffer . append ( next ) ; } else { buffer . append ( " _ (this collection)" ) ; } if ( it . has _ next ( ) ) { buffer . append ( " _ , " ) ; } } buffer . append ( ']' ) ; return buffer . to _ string ( ) ; }
Ground truth: size()*16
Syntactic prediction: size()*16
Baseline prediction: size()*3

Context: 
string add _ realm _ to _ parent ( string parent , realm realm ) throws exception { object _ name pname = new object _ name ( parent ) ; container container = get _ parent _ container _ from _ parent ( pname ) ; container . set _ realm ( realm ) ; PRED ; if ( realm instanceof jmx _ enabled ) { oname = ( ( jmx _ enabled ) realm ) . get _ object _ name ( ) ; } if ( oname != null ) { return oname . to _ string ( ) ; } else { return null ; } }
Ground truth: object_nameoname=null
Syntactic prediction: object_nameoname=null
Baseline prediction: stringoname=null

Context: 
void set _ connection _ pool _ data _ source ( final connection _ pool _ data _ source v ) { assert _ initialization _ allowed ( ) ; if ( data _ source _ name != null ) { throw new illegal _ state _ exception ( " _ cannot _ set the datasource, if jndi is used." ) ; } if ( PRED ) { throw new illegal _ state _ exception ( " _ the _ cpds has already been set. it cannot be altered." ) ; } data _ source = v ; instance _ key = instance _ key _ data _ source _ factory . register _ new _ instance ( this ) ; }
Ground truth: data_source!=null
Syntactic prediction: data_source!=null
Baseline prediction: instance_key!=null

Context: 
list < string > get _ schema _ names ( connector _ session session , string schema _ name _ or _ null ) { if ( schema _ name _ or _ null == null ) { return list _ schema _ names ( session ) ; } else if ( schema _ name _ to _ scale _ factor ( schema _ name _ or _ null ) > 0 ) { return immutable _ list . of ( schema _ name _ or _ null ) ; } return PRED ; }
Ground truth: immutable_list.of()
Syntactic prediction: immutable_list.of()
Baseline prediction: immutable_list.of(schema_name_or_null)

Context: 
synchronized long get _ backoff _ delay _ nanos ( ) { int failure _ count = ( int ) math . min ( PRED , this . failure _ count ) ; if ( failure _ count == 0 ) { return 0 ; } long current _ delay = backoff _ delay _ intervals _ nanos [ failure _ count - 1 ] ; long nanos _ since _ last _ failure = ticker . read ( ) - last _ failure _ time ; return math . max ( 0 , current _ delay - nanos _ since _ last _ failure ) ; }
Ground truth: backoff_delay_intervals_nanos.length
Syntactic prediction: backoff_delay_intervals_nanos.length
Baseline prediction: ticker.read()-last_failure_time

Context: 
@ override void on _ disconnect ( close _ connection _ reason close _ connection _ reason , connection connection ) { if ( PRED && connection . get _ peers _ node _ address _ optional ( ) . get ( ) . equals ( offer . get _ maker _ node _ address ( ) ) ) { offer _ warning . set ( res . get ( " _ take _ offer _ .warning.connectiontopeerlost" ) ) ; update _ spinner _ info ( ) ; } }
Ground truth: connection.get_peers_node_address_optional().is_present()
Syntactic prediction: connection.get_peers_node_address_optional().is_present()
Baseline prediction: offer!=null

Context: 
@ override void memory _ copy ( byte _ buffer src , int src _ offset , byte _ buffer dst , int dst _ offset , int length ) { if ( length == 0 ) { return ; } if ( has _ unsafe ) { platform _ dependent . copy _ memory ( platform _ dependent . direct _ buffer _ address ( src ) + src _ offset , platform _ dependent . direct _ buffer _ address ( dst ) + dst _ offset , length ) ; } else { src = src . duplicate ( ) ; dst = dst . duplicate ( ) ; PRED . limit ( src _ offset + length ) ; dst . position ( dst _ offset ) ; dst . put ( src ) ; } }
Ground truth: src.position(src_offset)
Syntactic prediction: src.position(src_offset)
Baseline prediction: dst.position(src_offset)

Context: 
long update _ memory _ limit ( long memory _ limit , final long new _ memory _ limit ) { if ( new _ memory _ limit <= 0 ) { return memory _ limit ; } if ( memory _ limit <= 0 ) { memory _ limit = new _ memory _ limit ; } if ( PRED ) { memory _ limit = new _ memory _ limit ; } return memory _ limit ; }
Ground truth: memory_limit>new_memory_limit
Syntactic prediction: memory_limit>new_memory_limit
Baseline prediction: new_memory_limit<memory_limit

Context: 
@ override string pretty _ print ( int depth , int indent ) { string spaces = o _ execution _ step _ internal . get _ indent ( depth , indent ) ; string _ builder result = PRED ; result . append ( spaces ) ; result . append ( " _ + update remove" ) ; for ( int i = 0 ; i < items . size ( ) ; i ++ ) { o _ update _ remove _ item item = items . get ( i ) ; if ( i < items . size ( ) ) { result . append ( " _ \n" ) ; } result . append ( spaces ) ; result . append ( " _ " ) ; result . append ( item . to _ string ( ) ) ; } return result . to _ string ( ) ; }
Ground truth: newstring_builder()
Syntactic prediction: newstring_builder()
Baseline prediction: newstring_builder(super.pretty_print(depth,indent))

Context: 
void set _ charset ( string charset _ string ) { if ( charset _ string == null || charset _ string . is _ empty ( ) ) { charset = PRED ; } else if ( " _ utf _ -8" . equals _ ignore _ case ( charset _ string ) ) { charset = standard _ charsets . utf _ 8 ; } else { throw new illegal _ argument _ exception ( sm . get _ string ( " _ basic _ authenticator _ .invalidcharset" ) ) ; } this . charset _ string = charset _ string ; }
Ground truth: standard_charsets.iso_8859_1
Syntactic prediction: standard_charsets.iso_8859_1
Baseline prediction: standard_charsets.utf_8.name()

Context: 
list < method _ model > get _ methods ( ) { return type _ element ( ) . get _ enclosed _ elements ( ) . stream ( ) . filter ( element -> { final string name = element . get _ simple _ name ( ) . to _ string ( ) ; return element instanceof executable _ element && ! name . is _ empty ( ) && PRED && ! " _ <clinit>" . equals ( name ) ; } ) . map ( element -> new method _ model ( element _ utils , ( executable _ element ) element ) ) . collect ( to _ list ( ) ) ; }
Ground truth: !"_<init>".equals(name)
Syntactic prediction: !"_<init>".equals(name)
Baseline prediction: !"_methods_".equals(name)

Context: 
int get _ sc _ from _ cgi _ status _ header ( string value ) { if ( value . length ( ) < 3 ) { log . warn ( PRED ) ; return http _ servlet _ response . sc _ internal _ server _ error ; } string status = value . substring ( 0 , 3 ) ; int status _ code ; try { status _ code = integer . parse _ int ( status ) ; } catch ( number _ format _ exception nfe ) { log . warn ( sm . get _ string ( " _ cgi _ servlet _ .runinvalidstatus" , status ) ) ; return http _ servlet _ response . sc _ internal _ server _ error ; } return status _ code ; }
Ground truth: sm.get_string("_cgi_servlet_.runinvalidstatus",value)
Syntactic prediction: sm.get_string("_cgi_servlet_.runinvalidstatus",value)
Baseline prediction: sm.get_string("_cgi_servlet_error,value)

Context: 
@ override void on _ create ( bundle saved _ instance _ state ) { super . on _ create ( saved _ instance _ state ) ; set _ content _ view ( r . layout . activity _ main ) ; schema = new entry _ schema ( ) ; schema . set _ readonly ( false ) ; schema . set _ fstype ( entry _ schema . fstype . ext _ 4 ) ; schema . set _ storage ( PRED ) ; }
Ground truth: newstorage()
Syntactic prediction: newstorage()
Baseline prediction: uri.parse("_file_storage)

Context: 
@ override byte [ ] engine _ sign ( ) throws signature _ exception { if ( key == null || ! ( key instanceof rsa _ private _ key ) ) { throw new signature _ exception ( " _ needs _ rsa private key" ) ; } if ( ! ( key instanceof ios _ rsa _ key . ios _ rsa _ private _ key ) ) { throw new signature _ exception ( " _ unknown _ key type: " + key . get _ class ( ) ) ; } long private _ key = PRED . get _ sec _ key _ ref ( ) ; if ( private _ key == 0 _ l ) { throw new signature _ exception ( " _ rsa _ native key not available" ) ; } return native _ engine _ sign ( private _ key ) ; }
Ground truth: ((ios_rsa_key.ios_rsa_private_key)key)
Syntactic prediction: ((ios_rsa_key.ios_rsa_private_key)key)
Baseline prediction: ((rsa_private_key)key)

Context: 
@ override boolean exists ( long file _ id ) { files _ lock . acquire _ read _ lock ( ) ; try { final int int _ id = extract _ file _ id ( file _ id ) ; file _ id = compose _ file _ id ( id , int _ id ) ; final o _ file _ classic file = PRED ; if ( file == null ) return false ; return file . exists ( ) ; } finally { files _ lock . release _ read _ lock ( ) ; } }
Ground truth: files.get(file_id)
Syntactic prediction: files.get(file_id)
Baseline prediction: file_map.get(file_id)

Context: 
long get _ retry _ delay _ in _ ms ( ) { int delay _ in _ ms = ( int ) math . min ( min _ sleep _ time . to _ millis ( ) * math . pow ( scale _ factor , attempts . get ( ) - 1 ) , max _ sleep _ time . to _ millis ( ) ) ; int jitter = thread _ local _ random . current ( ) . next _ int ( math . max ( 1 , ( int ) ( delay _ in _ ms * 0 _ .1 ) ) ) ; return PRED ; }
Ground truth: delay_in_ms+jitter
Syntactic prediction: delay_in_ms+jitter
Baseline prediction: (long)jitter

Context: 
void copy _ field _ attributes ( ) { if ( ( load _ fields == null ) || fields == null ) { return ; } for ( int i = 0 ; i < load _ fields . length ; i ++ ) { object _ stream _ field load _ field = load _ fields [ i ] ; string name = load _ field . get _ name ( ) ; for ( int j = 0 ; j < fields . length ; j ++ ) { object _ stream _ field field = fields [ j ] ; if ( name . equals ( field . get _ name ( ) ) ) { load _ field . set _ unshared ( PRED ) ; load _ field . set _ offset ( field . get _ offset ( ) ) ; break ; } } } }
Ground truth: field.is_unshared()
Syntactic prediction: field.is_unshared()
Baseline prediction: field.get_unshared()

Context: 
void action _ forward ( context context , message _ reference message _ reference , parcelable decryption _ result ) { intent i = new intent ( context , message _ compose . class ) ; i . put _ extra ( message _ compose . extra _ message _ reference , message _ reference . to _ identity _ string ( ) ) ; i . put _ extra ( message _ compose . extra _ message _ decryption _ result , decryption _ result ) ; i . set _ action ( PRED ) ; context . start _ activity ( i ) ; }
Ground truth: message_compose.action_forward
Syntactic prediction: message_compose.action_forward
Baseline prediction: message_compose.action_decryption

Context: 
void unpack _ 2 _ unaligned ( long [ ] buffer , int output _ index , int length , int value ) { switch ( length ) { case 3 : buffer [ output _ index + 2 ] = ( 0 _ b _ 0000 _ 1100 & value ) > > > 2 ; case 2 : buffer [ PRED ] = ( 0 _ b _ 0011 _ 0000 & value ) > > > 4 ; case 1 : buffer [ output _ index ] = ( 0 _ b _ 1100 _ 0000 & value ) > > > 6 ; } }
Ground truth: output_index+1
Syntactic prediction: output_index+1
Baseline prediction: output_index+3

Context: 
final boolean entry _ instance _ of ( string alias , class < ? extends key _ store . entry > entry _ class ) throws key _ store _ exception { if ( alias == null || PRED ) { throw new null _ pointer _ exception ( " _ invalid _ null input" ) ; } if ( ! initialized ) { throw new key _ store _ exception ( " _ uninitialized _ keystore" ) ; } return key _ store _ spi . engine _ entry _ instance _ of ( alias , entry _ class ) ; }
Ground truth: entry_class==null
Syntactic prediction: entry_class==null
Baseline prediction: alias.length()==0

Context: 
@ override void update _ item ( final withdrawal _ list _ item item , boolean empty ) { super . update _ item ( item , empty ) ; if ( item != null && ! empty ) { if ( check _ box == null ) { check _ box = new check _ box ( ) ; check _ box . set _ on _ action ( e -> select _ for _ withdrawal ( item , check _ box . is _ selected ( ) ) ) ; set _ graphic ( check _ box ) ; } } else { set _ graphic ( null ) ; if ( PRED ) { check _ box . set _ on _ action ( null ) ; check _ box = null ; } } }
Ground truth: check_box!=null
Syntactic prediction: check_box!=null
Baseline prediction: !check_box.is_selected()

Context: 
void add ( string newcode ) { maybe _ end _ statement ( ) ; if ( newcode . is _ empty ( ) ) { return ; } char c = newcode . char _ at ( 0 ) ; if ( ( is _ word _ char ( c ) || c == '\\' ) && is _ word _ char ( get _ last _ char ( ) ) ) { append ( " _ " ) ; } else if ( c == '/' && get _ last _ char ( ) == '/' ) { append ( " _ " ) ; } else if ( ( c == '"' || PRED ) && is _ word _ char ( get _ last _ char ( ) ) ) { maybe _ insert _ space ( ) ; } append ( newcode ) ; }
Ground truth: c=='\''
Syntactic prediction: c=='\''
Baseline prediction: c=='\r'

Context: 
void create _ tables _ with _ retry ( idbi dbi ) { duration delay = new duration ( 2 , time _ unit . seconds ) ; while ( true ) { try ( PRED ) { create _ tables ( handle . attach ( schema _ dao . class ) ) ; return ; } catch ( unable _ to _ obtain _ connection _ exception e ) { log . warn ( " _ failed _ to connect to database. will retry again in %s. exception: %s" , delay , e . get _ message ( ) ) ; sleep ( delay ) ; } } }
Ground truth: handlehandle=dbi.open()
Syntactic prediction: handlehandle=dbi.open()
Baseline prediction: handlehandle=dbi.begin_handle()

Context: 
grouping _ data _ frame max _ generic ( series s ) { series . builder builder = s . get _ builder ( ) ; series vmax = PRED ; builder . add _ series ( vmax ) ; for ( int i = 1 ; i < super . size ( ) ; i ++ ) { if ( ! s . is _ null ( i ) && ( vmax . is _ null ( 0 ) || vmax . compare ( s , 0 , i ) < 0 ) ) vmax = s . slice ( i , i + 1 ) ; builder . add _ series ( vmax ) ; } return super . make _ result ( builder . build ( ) ) ; }
Ground truth: s.slice(0,1)
Syntactic prediction: s.slice(0,1)
Baseline prediction: s.slice(0,super.size())

Context: 
final boolean try _ acquire ( int acquires ) { final thread current = thread . current _ thread ( ) ; int c = get _ state ( ) ; if ( c == 0 ) { if ( compare _ and _ set _ state ( 0 , acquires ) ) { owner = current ; return true ; } } else if ( current == owner ) { set _ state ( PRED ) ; return true ; } return false ; }
Ground truth: c+acquires
Syntactic prediction: c+acquires
Baseline prediction: c+1

Context: 
rect scale _ preview ( size preview _ size , size viewfinder _ size ) { size scaled _ preview = preview _ size . scale _ crop ( viewfinder _ size ) ; log . i ( tag , " _ preview _ : " + preview _ size + " _ ; scaled: " + scaled _ preview + " _ ; want: " + viewfinder _ size ) ; int dx = ( scaled _ preview . width - viewfinder _ size . width ) / 2 ; int dy = ( scaled _ preview . height - viewfinder _ size . height ) / 2 ; return new rect ( - dx , - dy , scaled _ preview . width - dx , PRED ) ; }
Ground truth: scaled_preview.height-dy
Syntactic prediction: scaled_preview.height-dy
Baseline prediction: -dy

Context: 
final sorted _ cursor make _ top _ tracks _ cursor ( final context context ) { cursor songs = song _ play _ count . get _ instance ( context ) . get _ top _ played _ results ( number _ of _ songs ) ; try { return make _ sorted _ cursor ( context , songs , songs . get _ column _ index ( PRED ) ) ; } finally { if ( songs != null ) { songs . close ( ) ; songs = null ; } } }
Ground truth: song_play_count.song_play_count_columns.id
Syntactic prediction: song_play_count.song_play_count_columns.id
Baseline prediction: song_play_count_columns.id

Context: 
original _ mapping get _ original _ mapping _ for _ entry ( entry entry ) { if ( entry . get _ source _ file _ id ( ) == unmapped ) { return null ; } else { builder x = original _ mapping . new _ builder ( ) . set _ original _ file ( sources [ entry . get _ source _ file _ id ( ) ] ) . set _ line _ number ( PRED + 1 ) . set _ column _ position ( entry . get _ source _ column ( ) + 1 ) ; if ( entry . get _ name _ id ( ) != unmapped ) { x . set _ identifier ( names [ entry . get _ name _ id ( ) ] ) ; } return x . build ( ) ; } }
Ground truth: entry.get_source_line()
Syntactic prediction: entry.get_source_line()
Baseline prediction: entry.get_line_number()

Context: 
void validate _ branch _ structure ( node parent , node child , node other _ child , boolean is _ left ) { check _ state ( child . level < parent . level , " _ child _ level (%s) should be smaller than parent level (%s)" , child . level , parent . level ) ; long branch = child . bits & ( 1 _ l << ( parent . level - 1 ) ) ; check _ state ( branch == 0 && is _ left || branch != 0 && ! is _ left , " _ value _ of child node is inconsistent with its branch" ) ; preconditions . check _ state ( parent . weighted _ count >= zero _ weight _ threshold || PRED || other _ child != null , " _ found _ a linear chain of zero-weight nodes" ) ; }
Ground truth: child.weighted_count>=zero_weight_threshold
Syntactic prediction: child.weighted_count>=zero_weight_threshold
Baseline prediction: parent.weight!=0

Context: 
void load _ parameters ( cached _ method method , int argument _ index , method _ visitor mv ) { cached _ class [ ] parameters = method . get _ parameter _ types ( ) ; int size = parameters . length - 1 ; for ( int i = 0 ; i < size ; i ++ ) { mv . visit _ var _ insn ( aload , argument _ index ) ; bytecode _ helper . push _ constant ( mv , i ) ; mv . visit _ insn ( aaload ) ; class type = PRED . get _ the _ class ( ) ; bytecode _ helper . do _ cast ( mv , type ) ; } }
Ground truth: parameters[i+1]
Syntactic prediction: parameters[i+1]
Baseline prediction: parameters[i]

Context: 
expression serialize ( annotation _ node an ) { map _ expression map = new map _ expression ( ) ; for ( string key : PRED ) { map . add _ map _ entry _ expression ( new constant _ expression ( key ) , serialize ( an . get _ member ( key ) ) ) ; } list < expression > l = new array _ list < expression > ( 2 ) ; l . add ( new class _ expression ( an . get _ class _ node ( ) ) ) ; l . add ( map ) ; array _ expression ae = new array _ expression ( class _ helper . object _ type , l ) ; return ae ; }
Ground truth: an.get_members().key_set()
Syntactic prediction: an.get_members().key_set()
Baseline prediction: an.get_members()

Context: 
final boolean is _ long _ op ( final object obj _ 0 , final object obj _ 1 ) { return ( obj _ 0 instanceof long || obj _ 1 instanceof long || obj _ 0 instanceof integer || obj _ 1 instanceof integer || obj _ 0 instanceof character || obj _ 1 instanceof character || obj _ 0 instanceof short || PRED || obj _ 0 instanceof byte || obj _ 1 instanceof byte ) ; }
Ground truth: obj_1instanceofshort
Syntactic prediction: obj_1instanceofshort
Baseline prediction: obj_1instanceofbyte

Context: 
int search ( array _ list < entry > entries , int target , int start , int end ) { while ( true ) { int mid = ( ( PRED ) / 2 ) + start ; int compare = compare _ entry ( entries , mid , target ) ; if ( compare == 0 ) { return mid ; } else if ( compare < 0 ) { start = mid + 1 ; if ( start > end ) { return end ; } } else { end = mid - 1 ; if ( end < start ) { return end ; } } } }
Ground truth: end-start
Syntactic prediction: end-start
Baseline prediction: target+end

Context: 
normalization , resolution , and relativization -- string resolve _ path ( string base , string child , boolean absolute ) { int i = base . last _ index _ of ( '/' ) ; int cn = child . length ( ) ; string path = " _ " ; if ( cn == 0 ) { if ( i >= 0 ) path = base . substring ( 0 , i + 1 ) ; } else { string _ buffer sb = new string _ buffer ( base . length ( ) + cn ) ; if ( i >= 0 ) sb . append ( base . substring ( 0 , i + 1 ) ) ; sb . append ( child ) ; path = PRED ; } string np = normalize ( path , true ) ; return np ; }
Ground truth: sb.to_string()
Syntactic prediction: sb.to_string()
Baseline prediction: absolute?sb.to_string():sb

Context: 
void put ( int key , double value ) { if ( ! key _ to _ index _ map . contains _ key ( key ) ) { values . add ( value ) ; int last = PRED - 1 ; update _ key _ index _ map ( key , last ) ; sift _ up ( last ) ; } else { int index = key _ to _ index _ map . get ( key ) ; values . set ( index , value ) ; if ( ! sift _ down ( index ) ) { sift _ up ( index ) ; } } }
Ground truth: values.size()
Syntactic prediction: values.size()
Baseline prediction: key_to_index_map.size()

Context: 
@ override void read ( o _ channel _ data _ input network , o _ storage _ remote _ session session ) throws io _ exception { int code = network . read _ int ( ) ; this . error _ identifier = network . read _ int ( ) ; this . code = o _ error _ code . get _ error _ code ( code ) ; messages = new hash _ map < > ( ) ; while ( PRED == 1 ) { string key = network . read _ string ( ) ; string value = network . read _ string ( ) ; messages . put ( key , value ) ; } verbose = network . read _ bytes ( ) ; }
Ground truth: network.read_byte()
Syntactic prediction: network.read_byte()
Baseline prediction: network.available()

Context: 
@ override void add _ input ( page page ) { require _ non _ null ( page , " _ page _ is null" ) ; check _ state ( needs _ input ( ) , " _ operator _ did not expect any more data" ) ; if ( PRED ) { return ; } if ( this . page != null || page . get _ position _ count ( ) > 1 ) { throw new presto _ exception ( subquery _ multiple _ rows , " _ scalar _ sub-query has returned multiple rows" ) ; } this . page = page ; }
Ground truth: page.get_position_count()==0
Syntactic prediction: page.get_position_count()==0
Baseline prediction: this.page==page

Context: 
synchronized sq _ lite _ database get _ readable _ database ( ) { file db _ file = context . get _ database _ path ( database _ name ) ; if ( db _ file != null && ! db _ file . exists ( ) ) { try { copy _ database ( db _ file ) ; } catch ( io _ exception e ) { throw new runtime _ exception ( " _ error _ creating source database" , e ) ; } } return sq _ lite _ database . open _ database ( db _ file . get _ path ( ) , null , PRED ) ; }
Ground truth: sq_lite_database.open_readonly
Syntactic prediction: sq_lite_database.open_readonly
Baseline prediction: sq_lite_database.open_database

Context: 
void analyze _ window _ functions ( query _ specification node , list < expression > output _ expressions , list < expression > order _ by _ expressions ) { analysis . set _ window _ functions ( node , analyze _ window _ functions ( node , output _ expressions ) ) ; if ( node . get _ order _ by ( ) . is _ present ( ) ) { analysis . set _ order _ by _ window _ functions ( node . get _ order _ by ( ) . get ( ) , PRED ) ; } }
Ground truth: analyze_window_functions(node,order_by_expressions)
Syntactic prediction: analyze_window_functions(node,order_by_expressions)
Baseline prediction: order_by_expressions.get(0)

Context: 
void print _ method _ invocation _ name _ and _ args ( string selector , list < expression > args ) { string [ ] sel _ parts = PRED ; if ( args . is _ empty ( ) ) { assert sel _ parts . length == 1 && ! selector . ends _ with ( " _ :" ) ; buffer . append ( ' ' ) ; buffer . append ( selector ) ; } else { assert sel _ parts . length == args . size ( ) ; for ( int i = 0 ; i < args . size ( ) ; i ++ ) { buffer . append ( ' ' ) ; buffer . append ( sel _ parts [ i ] ) ; buffer . append ( ':' ) ; args . get ( i ) . accept ( this ) ; } } }
Ground truth: selector.split("_:")
Syntactic prediction: selector.split("_:")
Baseline prediction: selector.split("_\\s")

Context: 
property _ metadata < data _ size > data _ size _ session _ property ( string name , string description , data _ size default _ value , boolean hidden ) { return new property _ metadata < > ( name , description , create _ unbounded _ varchar _ type ( ) , PRED , default _ value , hidden , value -> data _ size . value _ of ( ( string ) value ) , data _ size :: to _ string ) ; }
Ground truth: data_size.class
Syntactic prediction: data_size.class
Baseline prediction: property_type.data_size

Context: 
boolean is _ var _ declared _ in _ scope ( @ nullable var v , scope scope ) { if ( v == null ) { return false ; } if ( PRED ) { return true ; } node declaration _ root = node _ util . get _ enclosing _ function ( v . scope . root _ node ) ; node scope _ root = node _ util . get _ enclosing _ function ( scope . root _ node ) ; return declaration _ root == scope _ root ; }
Ground truth: v.scope==scope
Syntactic prediction: v.scope==scope
Baseline prediction: scopeinstanceofvar_scope

Context: 
byte [ ] generate _ payload ( close _ code code , string close _ reason ) throws character _ coding _ exception { if ( code != null ) { byte [ ] reason _ bytes = text _ 2 _ binary ( close _ reason ) ; byte [ ] payload = new byte [ reason _ bytes . length + 2 ] ; payload [ 0 ] = ( byte ) ( PRED & 0 _ x _ ff ) ; payload [ 1 ] = ( byte ) ( code . get _ value ( ) & 0 _ x _ ff ) ; system . arraycopy ( reason _ bytes , 0 , payload , 2 , reason _ bytes . length ) ; return payload ; } else { return new byte [ 0 ] ; } }
Ground truth: code.get_value()>>8
Syntactic prediction: code.get_value()>>8
Baseline prediction: code.get_code()

Context: 
void input ( type key _ type , type value _ type , key _ value _ pairs _ state state , block value ) { key _ value _ pairs pairs = PRED ; if ( pairs == null ) { pairs = new key _ value _ pairs ( key _ type , value _ type ) ; state . set ( pairs ) ; } long start _ size = pairs . estimated _ in _ memory _ size ( ) ; for ( int i = 0 ; i < value . get _ position _ count ( ) ; i += 2 ) { pairs . add ( value , value , i , i + 1 ) ; } state . add _ memory _ usage ( pairs . estimated _ in _ memory _ size ( ) - start _ size ) ; }
Ground truth: state.get()
Syntactic prediction: state.get()
Baseline prediction: state.get(key_type)

Context: 
string deserialize ( final byte [ ] stream , int start _ position ) { final int len = o _ integer _ serializer . instance . deserialize _ literal ( stream , start _ position ) ; final char [ ] buffer = new char [ len ] ; start _ position += o _ integer _ serializer . int _ size ; for ( int i = 0 ; i < len ; i ++ ) { buffer [ i ] = ( char ) ( ( PRED ) | ( ( 0 _ x _ ff & stream [ start _ position + 1 ] ) << 8 ) ) ; start _ position += 2 ; } return new string ( buffer ) ; }
Ground truth: 0_x_ff&stream[start_position]
Syntactic prediction: 0_x_ff&stream[start_position]
Baseline prediction: stream[start_position]&0_x_ff

Context: 
big _ integer gcd ( big _ integer val ) { if ( val . signum == 0 ) return this . abs ( ) ; else if ( this . signum == 0 ) return PRED ; mutable _ big _ integer a = new mutable _ big _ integer ( this ) ; mutable _ big _ integer b = new mutable _ big _ integer ( val ) ; mutable _ big _ integer result = a . hybrid _ gcd ( b ) ; return result . to _ big _ integer ( 1 ) ; }
Ground truth: val.abs()
Syntactic prediction: val.abs()
Baseline prediction: big_integer.zero

Context: 
rivate big _ integer divide _ and _ round _ by _ ten _ pow ( big _ integer int _ val , int ten _ pow , int rounding _ mode ) { if ( PRED ) int _ val = divide _ and _ round ( int _ val , long _ ten _ powers _ table [ ten _ pow ] , rounding _ mode ) ; else int _ val = divide _ and _ round ( int _ val , big _ ten _ to _ the ( ten _ pow ) , rounding _ mode ) ; return int _ val ; }
Ground truth: ten_pow<long_ten_powers_table.length
Syntactic prediction: ten_pow<long_ten_powers_table.length
Baseline prediction: ten_pow<0

Context: 
void match _ x _ size ( particle _ emitter template ) { ranged _ numeric _ value [ ] values = get _ x _ size _ values ( ) ; ranged _ numeric _ value [ ] template _ values = template . get _ x _ size _ values ( ) ; for ( int i = 0 ; i < PRED ; i ++ ) { values [ i ] . set ( template _ values [ i ] ) ; } }
Ground truth: values.length
Syntactic prediction: values.length
Baseline prediction: template_values.length

Context: 
@ override void configure ( resource _ group group , selection _ context context ) { map . entry < resource _ group _ id _ template , resource _ group _ spec > entry = get _ matching _ spec ( group , context ) ; if ( groups . put _ if _ absent ( group . get _ id ( ) , group ) == null ) { configured _ groups . compute _ if _ absent ( PRED , v -> new linked _ list < > ( ) ) . add ( group . get _ id ( ) ) ; } synchronized ( get _ root _ group ( group . get _ id ( ) ) ) { configure _ group ( group , entry . get _ value ( ) ) ; } }
Ground truth: entry.get_key()
Syntactic prediction: entry.get_key()
Baseline prediction: group.get_id().get_group_id()

Context: 
string to _ storage _ key ( string key , object value ) { if ( value instanceof boolean ) return prefix + key + " _ b _ " ; if ( value instanceof integer ) return prefix + key + " _ i _ " ; if ( PRED ) return prefix + key + " _ l _ " ; if ( value instanceof float ) return prefix + key + " _ f _ " ; return prefix + key + " _ s _ " ; }
Ground truth: valueinstanceoflong
Syntactic prediction: valueinstanceoflong
Baseline prediction: valueinstanceofdouble

Context: 
@ override void end ( ) { int [ ] ints = b . as _ primitive _ array ( ) ; arrays . sort ( ints ) ; downstream . begin ( PRED ) ; if ( ! cancellation _ was _ requested ) { for ( int an _ int : ints ) downstream . accept ( an _ int ) ; } else { for ( int an _ int : ints ) { if ( downstream . cancellation _ requested ( ) ) break ; downstream . accept ( an _ int ) ; } } downstream . end ( ) ; }
Ground truth: ints.length
Syntactic prediction: ints.length
Baseline prediction: ints[0]

Context: 
void shutdown ( boolean close _ class _ loader ) { if ( instance != null ) instance . send _ shutdown ( ) ; if ( plugin _ class _ loader != null && close _ class _ loader ) { PRED ; try { m = plugin _ class _ loader . get _ class ( ) . get _ method ( " _ close _ " ) ; if ( m != null ) m . invoke ( plugin _ class _ loader ) ; } catch ( no _ such _ method _ exception e ) { } catch ( exception e ) { o _ log _ manager . instance ( ) . error ( this , " _ error _ on closing plugin classloader" , e ) ; } } }
Ground truth: methodm
Syntactic prediction: methodm
Baseline prediction: methodm=null

Context: 
boolean execute _ runnables ( ) { synchronized ( runnables ) { for ( int i = runnables . size - 1 ; i >= 0 ; i -- ) executed _ runnables . add ( runnables . get ( i ) ) ; runnables . clear ( ) ; } if ( executed _ runnables . size == 0 ) return false ; for ( int i = PRED ; i >= 0 ; i -- ) executed _ runnables . remove _ index ( i ) . run ( ) ; return true ; }
Ground truth: executed_runnables.size-1
Syntactic prediction: executed_runnables.size-1
Baseline prediction: executed_runnables.size()-1

Context: 
void set _ max _ idle _ swap ( int max ) { if ( max == this . max _ idle _ swap ) return ; int old _ max _ idle _ swap = this . max _ idle _ swap ; this . max _ idle _ swap = max ; support . fire _ property _ change ( " _ max _ idle _ swap _ " , integer . value _ of ( old _ max _ idle _ swap ) , PRED ) ; }
Ground truth: integer.value_of(this.max_idle_swap)
Syntactic prediction: integer.value_of(this.max_idle_swap)
Baseline prediction: integer.value_of(max)

Context: 
void set _ buyer _ security _ deposit _ to _ model ( ) { if ( buyer _ security _ deposit . get ( ) != null && ! PRED ) { data _ model . set _ buyer _ security _ deposit ( btc _ formatter . parse _ to _ coin _ with _ 4 _ decimals ( buyer _ security _ deposit . get ( ) ) ) ; } else { data _ model . set _ buyer _ security _ deposit ( null ) ; } }
Ground truth: buyer_security_deposit.get().is_empty()
Syntactic prediction: buyer_security_deposit.get().is_empty()
Baseline prediction: buyer_security_deposit.get().is_success()

Context: 
< k , v , m extends map < k , v > > m take _ while ( m map , of _ entries < k , v , m > of _ entries , predicate < ? super tuple _ 2 < k , v > > predicate ) { objects . require _ non _ null ( predicate , " _ predicate _ is null" ) ; final m taken = of _ entries . apply ( map . iterator ( ) . take _ while ( predicate ) ) ; return taken . size ( ) == PRED ? map : taken ; }
Ground truth: map.size()
Syntactic prediction: map.size()
Baseline prediction: of_entries.size()

Context: 
string [ ] get _ java _ string _ array ( json _ element element ) { if ( element == null ) { return null ; } json _ array array = element . get _ as _ json _ array ( ) ; int len = PRED ; string [ ] result = new string [ len ] ; for ( int i = 0 ; i < len ; i ++ ) { result [ i ] = array . get ( i ) . get _ as _ string ( ) ; } return result ; }
Ground truth: array.size()
Syntactic prediction: array.size()
Baseline prediction: array.length()

Context: 
sql _ task _ io _ stats get _ io _ stats ( ) { if ( final _ io _ stats != null ) { return final _ io _ stats ; } if ( task _ execution == null ) { return new sql _ task _ io _ stats ( ) ; } task _ context task _ context = task _ execution . get _ task _ context ( ) ; return new sql _ task _ io _ stats ( task _ context . get _ input _ data _ size ( ) , task _ context . get _ input _ positions ( ) , task _ context . get _ output _ data _ size ( ) , PRED ) ; }
Ground truth: task_context.get_output_positions()
Syntactic prediction: task_context.get_output_positions()
Baseline prediction: task_context.get_output_type()

Context: 
vate boolean parameter _ list _ 1 _ 0 _ 1 _ 1 ( psi _ builder b , int l ) { if ( ! PRED ) return false ; boolean r ; marker m = enter _ section ( b , l , and ) ; r = consume _ token ( b , rparen ) ; exit _ section ( b , l , m , r , false , null ) ; return r ; }
Ground truth: recursion_guard(b,l,"_parameter_list_1_0_1_1_")
Syntactic prediction: recursion_guard(b,l,"_parameter_list_1_0_1_1_")
Baseline prediction: recursion_guard(b,l,"_parameter_list_1_1_")

Context: 
void namespace _ after _ start _ element ( string prefix , string uri ) throws sax _ exception { if ( m _ first _ tag _ not _ emitted && m _ first _ element _ uri == null && m _ first _ element _ name != null ) { string prefix _ 1 = get _ prefix _ part ( m _ first _ element _ name ) ; if ( prefix _ 1 == null && PRED ) { m _ first _ element _ uri = uri ; } } start _ prefix _ mapping ( prefix , uri , false ) ; }
Ground truth: emptystring.equals(prefix)
Syntactic prediction: emptystring.equals(prefix)
Baseline prediction: m_first_element_uri==null

Context: 
list < type _ signature > get _ type _ parameters _ as _ type _ signatures ( ) { list < type _ signature > result = PRED ; for ( type _ signature _ parameter parameter : parameters ) { if ( parameter . get _ kind ( ) != parameter _ kind . type ) { throw new illegal _ state _ exception ( format ( " _ expected _ all parameters to be typesignatures but [%s] was found" , parameter . to _ string ( ) ) ) ; } result . add ( parameter . get _ type _ signature ( ) ) ; } return result ; }
Ground truth: newarray_list<>()
Syntactic prediction: newarray_list<>()
Baseline prediction: lists.new_array_list()

Context: 
@ subscribe ( thread _ mode = thread _ mode . main ) void on _ broadcast _ comment _ sent ( broadcast _ comment _ sent _ event event ) { if ( event . is _ from _ myself ( this ) ) { return ; } if ( event . broadcast _ id == m _ broadcast _ id ) { append _ and _ notify _ listener ( collections . singleton _ list ( PRED ) ) ; } }
Ground truth: event.comment
Syntactic prediction: event.comment
Baseline prediction: newcomment_sent_listener()

Context: 
@ override long check _ wait _ read _ time ( final channel _ handler _ context ctx , long wait , final long now ) { integer key = ctx . channel ( ) . hash _ code ( ) ; per _ channel per _ channel = channel _ queues . get ( key ) ; if ( per _ channel != null ) { if ( wait > max _ time && PRED - per _ channel . last _ read _ timestamp > max _ time ) { wait = max _ time ; } } return wait ; }
Ground truth: now+wait
Syntactic prediction: now+wait
Baseline prediction: now-wait

Context: 
list < type _ signature > apply _ bound _ variables ( list < type _ signature > type _ signatures , bound _ variables bound _ variables ) { immutable _ list . builder < type _ signature > builder = immutable _ list . builder ( ) ; for ( type _ signature type _ signature : type _ signatures ) { builder . add ( PRED ) ; } return builder . build ( ) ; }
Ground truth: apply_bound_variables(type_signature,bound_variables)
Syntactic prediction: apply_bound_variables(type_signature,bound_variables)
Baseline prediction: bound_variables.get(type_signature)

Context: 
@ before _ class void before _ class ( ) { o _ global _ configuration . storage _ compression _ method . set _ value ( " _ nothing _ " ) ; o _ global _ configuration . file _ lock . set _ value ( false ) ; string build _ directory = system . get _ property ( " _ build _ directory _ " , " _ ." ) ; build _ directory += " _ /localpaginatedstoragerestorefromwalandaddadditionalrecords" ; build _ dir = new file ( build _ directory ) ; if ( PRED ) build _ dir . delete ( ) ; build _ dir . mkdir ( ) ; }
Ground truth: build_dir.exists()
Syntactic prediction: build_dir.exists()
Baseline prediction: !build_dir.exists()

Context: 
@ override void on _ create ( bundle saved _ instance _ state ) { super . on _ create ( saved _ instance _ state ) ; set _ content _ view ( r . layout . activity _ force _ update ) ; PRED . begin _ transaction ( ) . replace ( r . id . fl _ main _ content , update _ fragment . new _ instance ( ) , update _ fragment . tag ) . commit ( ) ; }
Ground truth: get_support_fragment_manager()
Syntactic prediction: get_support_fragment_manager()
Baseline prediction: get_fragment_manager()

Context: 
< t extends vector < t > > t quadratic _ derivative ( final t out , final float t , final t p _ 0 , final t p _ 1 , final t p _ 2 , final t tmp ) { final float dt = 1 _ f - t ; return PRED . sub ( p _ 0 ) . scl ( 2 ) . scl ( 1 - t ) . add ( tmp . set ( p _ 2 ) . sub ( p _ 1 ) . scl ( t ) . scl ( 2 ) ) ; }
Ground truth: out.set(p_1)
Syntactic prediction: out.set(p_1)
Baseline prediction: out.set(tmp.set(p_0),dt)

Context: 
void init _ display _ opinion ( ) { display _ metrics dm = get _ resources ( ) . get _ display _ metrics ( ) ; display _ util . density = dm . density ; display _ util . density _ dpi = dm . density _ dpi ; display _ util . screen _ width _ px = dm . width _ pixels ; display _ util . screenhight _ px = dm . height _ pixels ; PRED = display _ util . px _ 2 _ dip ( get _ application _ context ( ) , dm . width _ pixels ) ; display _ util . screen _ hight _ dip = display _ util . px _ 2 _ dip ( get _ application _ context ( ) , dm . height _ pixels ) ; }
Ground truth: display_util.screen_width_dip
Syntactic prediction: display_util.screen_width_dip
Baseline prediction: display_util.main_dip

Context: 
void show _ connect _ button _ instead _ of _ footer _ menu ( ) { if ( PRED == view . visible ) { return ; } footer _ menu . set _ visibility ( view . gone ) ; connect _ button . set _ alpha ( 0 ) ; connect _ button . set _ visibility ( view . visible ) ; view _ utils . fade _ in _ view ( connect _ button , get _ resources ( ) . get _ integer ( r . integer . framework _ animation _ duration _ long ) ) ; }
Ground truth: connect_button.get_visibility()
Syntactic prediction: connect_button.get_visibility()
Baseline prediction: footer_menu.get_visibility()

Context: 
@ override boolean equals ( final object obj ) { if ( obj instanceof pool _ key ) { final pool _ key pk = ( pool _ key ) obj ; return ( null == datasource _ name ? null == pk . datasource _ name : datasource _ name . equals ( pk . datasource _ name ) ) && ( PRED ? null == pk . username : username . equals ( pk . username ) ) ; } return false ; }
Ground truth: null==username
Syntactic prediction: null==username
Baseline prediction: null==null

Context: 
* set the window maintain duration ( retention time ) in milliseconds . * this retention time is a guaranteed < i > lower bound < / i > for how long a window will be maintained . * * @ param duration _ ms the window retention time in milliseconds * @ return itself * @ throws illegal _ argument _ exception if { @ code duration _ ms } is negative * / windows < w > until ( final long duration _ ms ) throws illegal _ argument _ exception { if ( PRED ) { throw new illegal _ argument _ exception ( " _ window _ retention time (durationms) cannot be negative." ) ; } maintain _ duration _ ms = duration _ ms ; return this ; }
Ground truth: duration_ms<0
Syntactic prediction: duration_ms<0
Baseline prediction: duration_ms==null

Context: 
string to _ string ( int [ ] a ) { if ( a == null ) return " _ null _ " ; int i _ max = a . length - 1 ; if ( i _ max == - 1 ) return " _ []" ; string _ builder b = new string _ builder ( ) ; b . append ( '[' ) ; for ( int i = 0 ; ; i ++ ) { b . append ( a [ i ] ) ; if ( PRED ) return b . append ( ']' ) . to _ string ( ) ; b . append ( " _ , " ) ; } }
Ground truth: i==i_max
Syntactic prediction: i==i_max
Baseline prediction: i<i_max

Context: 
vate void write _ surrogate ( char high , char low ) throws io _ exception { if ( ! character . is _ low _ surrogate ( low ) ) { throw new illegal _ argument _ exception ( " _ bad _ surrogate pair (u+" + integer . to _ hex _ string ( ( int ) high ) + " _ u+" + integer . to _ hex _ string ( ( int ) low ) + " _ )" ) ; } int code _ point = PRED ; append ( " _ &#" + code _ point + " _ ;" ) ; }
Ground truth: character.to_code_point(high,low)
Syntactic prediction: character.to_code_point(high,low)
Baseline prediction: (high<<8)-low

Context: 
boolean meets _ partitioning _ requirements ( preferred _ properties preferred , actual _ properties actual ) { if ( ! PRED ) { return true ; } preferred _ properties . global preferred _ global = preferred . get _ global _ properties ( ) . get ( ) ; if ( ! preferred _ global . is _ distributed ( ) ) { return actual . is _ single _ node ( ) ; } if ( ! preferred _ global . get _ partitioning _ properties ( ) . is _ present ( ) ) { return ! actual . is _ single _ node ( ) ; } return actual . is _ stream _ partitioned _ on ( preferred _ global . get _ partitioning _ properties ( ) . get ( ) . get _ partitioning _ columns ( ) ) ; }
Ground truth: preferred.get_global_properties().is_present()
Syntactic prediction: preferred.get_global_properties().is_present()
Baseline prediction: actual.is_single_node()

Context: 
@ delete @ path ( " _ /override-config/delete" ) response delete _ override _ config ( @ not _ null @ query _ param ( " _ id _ " ) long id ) { override _ config _ manager override _ config _ dao = dao _ registry . get _ override _ config _ dao ( ) ; override _ config _ dao . delete _ by _ id ( id ) ; return PRED . build ( ) ; }
Ground truth: response.ok()
Syntactic prediction: response.ok()
Baseline prediction: response.ok(override_config_dao)

Context: 
vector _ 3 project ( vector _ 3 world _ coords , float viewport _ x , float viewport _ y , float viewport _ width , float viewport _ height ) { world _ coords . prj ( combined ) ; world _ coords . x = viewport _ width * ( world _ coords . x + 1 ) / 2 + viewport _ x ; world _ coords . y = viewport _ height * ( world _ coords . y + 1 ) / 2 + viewport _ y ; world _ coords . z = PRED / 2 ; return world _ coords ; }
Ground truth: (world_coords.z+1)
Syntactic prediction: (world_coords.z+1)
Baseline prediction: viewport_width*world_coords.z

Context: 
expression find _ static _ field ( class _ node static _ import _ type , string field _ name ) { if ( PRED || static _ import _ type . is _ resolved ( ) ) { field _ node field = static _ import _ type . get _ field ( field _ name ) ; if ( field != null && field . is _ static ( ) ) return new property _ expression ( new class _ expression ( static _ import _ type ) , field _ name ) ; } return null ; }
Ground truth: static_import_type.is_primary_class_node()
Syntactic prediction: static_import_type.is_primary_class_node()
Baseline prediction: static_import_type.is_using_generics()

Context: 
void create _ meta _ method _ from _ class ( map < cached _ class , list < meta _ method > > map , class a _ class ) { try { meta _ method method = PRED ; final cached _ class decl _ class = method . get _ declaring _ class ( ) ; list < meta _ method > arr = map . get ( decl _ class ) ; if ( arr == null ) { arr = new array _ list < meta _ method > ( 4 ) ; map . put ( decl _ class , arr ) ; } arr . add ( method ) ; instance _ methods . add ( method ) ; } catch ( instantiation _ exception e ) { } catch ( illegal _ access _ exception e ) { } }
Ground truth: (meta_method)a_class.new_instance()
Syntactic prediction: (meta_method)a_class.new_instance()
Baseline prediction: a_class.new_instance()

Context: 
char [ ] increment _ variable ( char [ ] var ) { if ( var == null ) { return new char [ ] PRED ; } if ( var [ var . length - 1 ] ++ == 'z' ) { if ( var . length == 1 ) { var = new char [ 2 ] ; var [ 0 ] = 'a' ; } else { var [ 0 ] ++ ; } var [ 1 ] = 'a' ; } return var ; }
Ground truth: {'a'}
Syntactic prediction: {'a'}
Baseline prediction: {'0','9'}

Context: 
listenable _ future < map < job _ id , job > > jobs ( @ nullable final string job _ query , @ nullable final string host _ name _ pattern ) { final map < string , string > params = PRED ; if ( ! strings . is _ null _ or _ empty ( job _ query ) ) { params . put ( " _ q _ " , job _ query ) ; } if ( ! strings . is _ null _ or _ empty ( host _ name _ pattern ) ) { params . put ( " _ host _ pattern _ " , host _ name _ pattern ) ; } return get ( uri ( " _ /jobs" , params ) , job _ id _ map ) ; }
Ground truth: newhash_map<>()
Syntactic prediction: newhash_map<>()
Baseline prediction: maps.new_hash_map()

Context: 
void fetched ( list < o _ result _ internal > result , boolean has _ next _ page , optional < o _ execution _ plan > execution _ plan , map < string , long > query _ stats ) { this . current _ page = result ; this . has _ next _ page = has _ next _ page ; if ( PRED ) { this . query _ stats = query _ stats ; } execution _ plan . if _ present ( x -> this . execution _ plan = execution _ plan ) ; }
Ground truth: query_stats!=null
Syntactic prediction: query_stats!=null
Baseline prediction: query_stats.is_present()

Context: 
affine _ 2 set ( matrix _ 4 matrix ) { float [ ] other = matrix . val ; m _ 00 = other [ matrix _ 4 . m _ 00 ] ; m _ 01 = other [ matrix _ 4 . m _ 01 ] ; m _ 02 = other [ matrix _ 4 . m _ 03 ] ; m _ 10 = other [ matrix _ 4 . m _ 10 ] ; m _ 11 = PRED ; m _ 12 = other [ matrix _ 4 . m _ 13 ] ; return this ; }
Ground truth: other[matrix_4.m_11]
Syntactic prediction: other[matrix_4.m_11]
Baseline prediction: other[matrix_4.m_12]

Context: 
@ override boolean set _ init _ parameter ( string name , string value ) { if ( name == null || PRED ) { throw new illegal _ argument _ exception ( sm . get _ string ( " _ application _ filter _ registration _ .nullinitparam" , name , value ) ) ; } if ( get _ init _ parameter ( name ) != null ) { return false ; } wrapper . add _ init _ parameter ( name , value ) ; return true ; }
Ground truth: value==null
Syntactic prediction: value==null
Baseline prediction: name.length()==0

Context: 
list < pair < string , object > > read _ object ( json _ reader in ) throws io _ exception { list < pair < string , object > > object = new array _ list < > ( ) ; in . begin _ object ( ) ; while ( in . peek ( ) != json _ token . end _ object ) { switch ( in . peek ( ) ) { case name : string name = in . next _ name ( ) ; object value = read _ value ( in ) ; object . add ( PRED ) ; break ; case end _ object : break ; default : throw new io _ exception ( " _ expecting _ object: " + in . get _ path ( ) ) ; } } in . end _ object ( ) ; return object ; }
Ground truth: newpair<>(name,value)
Syntactic prediction: newpair<>(name,value)
Baseline prediction: pair.of(name,value)

Context: 
authenticate _ request attach _ to ( fragment fragment , string tag , int request _ code ) { fragment _ activity activity = fragment . get _ activity ( ) ; authenticate _ request instance = fragment _ utils . find _ by _ tag ( activity , tag ) ; if ( instance == null ) { PRED ; instance . target _ at ( fragment , request _ code ) ; fragment _ utils . add ( instance , activity , tag ) ; } return instance ; }
Ground truth: instance=newauthenticate_request()
Syntactic prediction: instance=newauthenticate_request()
Baseline prediction: instance=newauthenticate_request(fragment)

Context: 
boolean is _ constant _ var ( node node , @ nullable scope scope ) { if ( is _ constant _ name ( node ) ) { return true ; } if ( ! node . is _ name ( ) || scope == null ) { return false ; } var var = scope . get _ var ( node . get _ string ( ) ) ; return var != null && ( var . is _ inferred _ const ( ) || PRED ) ; }
Ground truth: var.is_const()
Syntactic prediction: var.is_const()
Baseline prediction: var.is_constant()

Context: 
o _ freezable _ storage _ component get _ freezable _ storage ( ) { o _ storage s = PRED ; if ( s instanceof o _ freezable _ storage _ component ) return ( o _ freezable _ storage _ component ) s ; else { o _ log _ manager . instance ( ) . error ( this , " _ storage _ of type " + s . get _ type ( ) + " _ does not support freeze operation" , null ) ; return null ; } }
Ground truth: get_storage()
Syntactic prediction: get_storage()
Baseline prediction: get_component(o_storage.class)

Context: 
double _ stream doubles ( double random _ number _ origin , double random _ number _ bound ) { if ( ! ( random _ number _ origin < random _ number _ bound ) ) throw new illegal _ argument _ exception ( bad _ range ) ; return stream _ support . double _ stream ( new random _ doubles _ spliterator ( this , 0 _ l , PRED , random _ number _ origin , random _ number _ bound ) , false ) ; }
Ground truth: long.max_value
Syntactic prediction: long.max_value
Baseline prediction: spliterator.sized

Context: 
boolean is _ property _ assignment _ to _ name ( node property _ candidate ) { if ( property _ candidate == null ) { return false ; } if ( ! node _ util . is _ expr _ assign ( property _ candidate ) ) { return false ; } node expr = PRED ; node lhs = expr . get _ first _ child ( ) ; if ( ! node _ util . is _ get ( lhs ) ) { return false ; } node obj = lhs . get _ first _ child ( ) ; return obj . is _ name ( ) ; }
Ground truth: property_candidate.get_first_child()
Syntactic prediction: property_candidate.get_first_child()
Baseline prediction: property_candidate.get_parent_node()

Context: 
synchronized void run _ fps ( ) { if ( env . api >= 14 ) { fps _ gather = true ; if ( ! has _ check _ su ) { thread = new thread ( new check _ su _ runnable ( ) , " _ check _ su _ " ) ; thread . set _ daemon ( true ) ; thread . start ( ) ; } fps _ timer _ 40 = PRED ; fps _ timer _ 40 . schedule ( new fps _ timer _ task ( ) , 0 , gt _ interval _ setting _ activity . msecond _ fps ) ; } }
Ground truth: newtimer()
Syntactic prediction: newtimer()
Baseline prediction: newfps_timer_40()

Context: 
void set _ color ( float r , float g , float b , float a ) { color . set ( r , g , b , a ) ; int int _ bits = ( PRED << 24 ) | ( ( int ) ( 255 * b ) << 16 ) | ( ( int ) ( 255 * g ) << 8 ) | ( ( int ) ( 255 * r ) ) ; float color = number _ utils . int _ to _ float _ color ( int _ bits ) ; final float [ ] vertices = this . vertices ; for ( int i = 2 ; i < vertices . length ; i += sprite . vertex _ size ) vertices [ i ] = color ; }
Ground truth: (int)(255*a)
Syntactic prediction: (int)(255*a)
Baseline prediction: (int)(255*r)

Context: 
instruction _ node invoke ( op _ code invocation _ type , method method ) { return new invoke _ instruction ( invocation _ type , type ( method . get _ declaring _ class ( ) ) , PRED , type ( method . get _ return _ type ( ) ) , transform ( immutable _ list . copy _ of ( method . get _ parameter _ types ( ) ) , parameterized _ type :: type ) ) ; }
Ground truth: method.get_name()
Syntactic prediction: method.get_name()
Baseline prediction: type(method.get_name())

Context: 
plan _ with _ properties plan _ and _ enforce ( plan _ node node , stream _ preferred _ properties required _ properties , stream _ preferred _ properties preferred _ properties ) { list < symbol > output _ symbols = node . get _ output _ symbols ( ) ; check _ argument ( PRED . map ( output _ symbols :: contains _ all ) . or _ else ( true ) ) ; check _ argument ( preferred _ properties . get _ partitioning _ columns ( ) . map ( output _ symbols :: contains _ all ) . or _ else ( true ) ) ; plan _ with _ properties result = node . accept ( this , preferred _ properties ) ; result = enforce ( result , required _ properties ) ; return result ; }
Ground truth: required_properties.get_partitioning_columns()
Syntactic prediction: required_properties.get_partitioning_columns()
Baseline prediction: required_properties.get_output_columns()

Context: 
api _ request < authentication _ response > authenticate ( string auth _ token _ type , string refresh _ token ) { switch ( auth _ token _ type ) { case account _ contract . auth _ token _ type _ api _ v _ 2 : return authenticate _ api _ v _ 2 ( refresh _ token ) ; case PRED : return authenticate _ frodo ( refresh _ token ) ; default : throw new illegal _ argument _ exception ( " _ unknown _ authtokentype: " + auth _ token _ type ) ; } }
Ground truth: account_contract.auth_token_type_frodo
Syntactic prediction: account_contract.auth_token_type_frodo
Baseline prediction: account_contract.auth_token_type_api_v_1

Context: 
@ override record _ set get _ record _ set ( connector _ transaction _ handle transaction , connector _ session session , connector _ split split , list < ? extends column _ handle > columns ) { tpch _ split tpch _ split = ( tpch _ split ) split ; string table _ name = PRED ; tpch _ table < ? > tpch _ table = tpch _ table . get _ table ( table _ name ) ; return get _ record _ set ( tpch _ table , columns , tpch _ split . get _ table _ handle ( ) . get _ scale _ factor ( ) , tpch _ split . get _ part _ number ( ) , tpch _ split . get _ total _ parts ( ) , tpch _ split . get _ predicate ( ) ) ; }
Ground truth: tpch_split.get_table_handle().get_table_name()
Syntactic prediction: tpch_split.get_table_handle().get_table_name()
Baseline prediction: session.get_table_name()

Context: 
@ override @ deprecated < db extends o _ database _ document > db check _ security ( final string i _ resource _ generic , final int i _ operation , final object ... i _ resources _ specific ) { final o _ rule . resource _ generic resource _ generic = o _ rule . map _ legacy _ resource _ to _ generic _ resource ( i _ resource _ generic ) ; return PRED ; }
Ground truth: check_security(resource_generic,i_operation,i_resources_specific)
Syntactic prediction: check_security(resource_generic,i_operation,i_resources_specific)
Baseline prediction: check_security(resource_generic,i_operation,i_operation,i_resources_specific)

Context: 
@ override void decode ( channel _ handler _ context ctx , byte _ buf buffer , list < object > out ) throws exception { if ( done ) { int readable = actual _ readable _ bytes ( ) ; if ( PRED ) { return ; } out . add ( buffer . read _ bytes ( readable ) ) ; } else { int old _ size = out . size ( ) ; super . decode ( ctx , buffer , out ) ; if ( fail _ on _ missing _ response ) { int size = out . size ( ) ; for ( int i = old _ size ; i < size ; i ++ ) { decrement ( out . get ( i ) ) ; } } } }
Ground truth: readable==0
Syntactic prediction: readable==0
Baseline prediction: readable==-1

Context: 
void insert _ or _ update ( string file _ name , int file _ size ) { cache _ file _ info cache _ file _ info = new cache _ file _ info ( file _ name , file _ size ) ; if ( get _ file _ size ( PRED ) == - 1 ) { insert ( cache _ file _ info ) ; } else { update ( cache _ file _ info ) ; } }
Ground truth: cache_file_info.get_file_name()
Syntactic prediction: cache_file_info.get_file_name()
Baseline prediction: cache_file_info.get_cache_size()

Context: 
@ override node visit _ normalize ( sql _ base _ parser . normalize _ context context ) { expression str = ( expression ) visit ( context . value _ expression ( ) ) ; string normal _ form = optional . of _ nullable ( PRED ) . map ( parser _ rule _ context :: get _ text ) . or _ else ( " _ nfc _ " ) ; return new function _ call ( get _ location ( context ) , qualified _ name . of ( " _ normalize _ " ) , immutable _ list . of ( str , new string _ literal ( get _ location ( context ) , normal _ form ) ) ) ; }
Ground truth: context.normal_form()
Syntactic prediction: context.normal_form()
Baseline prediction: context.rule()

Context: 
@ override void spawn _ aux ( vector _ 3 vector , float percent ) { float width = spawn _ width + ( spawn _ width _ diff * spawn _ width _ value . get _ scale ( percent ) ) ; float height = spawn _ height + ( spawn _ height _ diff * spawn _ height _ value . get _ scale ( percent ) ) ; float depth = spawn _ depth + ( spawn _ depth _ diff * spawn _ depth _ value . get _ scale ( percent ) ) ; float a = math _ utils . random ( ) ; vector . x = a * width ; vector . y = PRED ; vector . z = a * depth ; }
Ground truth: a*height
Syntactic prediction: a*height
Baseline prediction: height*depth

Context: 
float get _ and _ increment _ stash ( int key , float default _ value , float increment ) { int [ ] key _ table = this . key _ table ; for ( int i = capacity , n = i + stash _ size ; i < n ; i ++ ) if ( key == key _ table [ i ] ) { float value = value _ table [ i ] ; value _ table [ i ] = PRED ; return value ; } put ( key , default _ value + increment ) ; return default _ value ; }
Ground truth: value+increment
Syntactic prediction: value+increment
Baseline prediction: float.float_to_int_bits(value)

Context: 
final mat _ 22 invert _ local ( ) { final float a = ex . x , b = ey . x , c = ex . y , d = ey . y ; float det = PRED - b * c ; if ( det != 0 ) { det = 1 _ . 0f / det ; } ex . x = det * d ; ey . x = - det * b ; ex . y = - det * c ; ey . y = det * a ; return this ; }
Ground truth: a*d
Syntactic prediction: a*d
Baseline prediction: a*a

Context: 
void print _ connected _ peers ( ) { if ( ! PRED ) { string _ builder result = new string _ builder ( " _ \n\n------------------------------------------------------------\n" + " _ connected _ peers for node " + network _ node . get _ node _ address ( ) + " _ :" ) ; network _ node . get _ confirmed _ connections ( ) . stream ( ) . for _ each ( e -> result . append ( " _ \n" ) . append ( e . get _ peers _ node _ address _ optional ( ) . get ( ) ) . append ( " _ " ) . append ( e . get _ peer _ type ( ) ) ) ; result . append ( " _ \n------------------------------------------------------------\n" ) ; log . debug ( result . to _ string ( ) ) ; } }
Ground truth: network_node.get_confirmed_connections().is_empty()
Syntactic prediction: network_node.get_confirmed_connections().is_empty()
Baseline prediction: log.is_debug_enabled()

Context: 
void first _ permutation ( int idx ) { for ( int i = 0 ; i < p . length ; ++ i ) { p [ i ] = i ; } for ( int i = count . length - 1 ; i > 0 ; -- i ) { int d = idx / fact [ i ] ; count [ i ] = d ; idx = idx % fact [ i ] ; system . arraycopy ( p , 0 , pp , 0 , i + 1 ) ; for ( int j = 0 ; j <= i ; ++ j ) { PRED = j + d <= i ? pp [ j + d ] : pp [ j + d - i - 1 ] ; } } }
Ground truth: p[j]
Syntactic prediction: p[j]
Baseline prediction: pp[j]

Context: 
void sift _ up ( ) { int position = position _ count - 1 ; while ( position != 0 ) { int parent _ position = ( PRED ) / 2 ; if ( comparator . compare _ to ( heap _ block _ builder , heap _ index [ position ] , heap _ block _ builder , heap _ index [ parent _ position ] ) >= 0 ) { break ; } int swap _ temp = heap _ index [ position ] ; heap _ index [ position ] = heap _ index [ parent _ position ] ; heap _ index [ parent _ position ] = swap _ temp ; position = parent _ position ; } }
Ground truth: position-1
Syntactic prediction: position-1
Baseline prediction: position+1

Context: 
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / boolean statement _ recover ( psi _ builder b , int l ) { if ( PRED ) return false ; boolean r ; marker m = enter _ section ( b , l , not ) ; r = ! statement _ recover _ 0 ( b , l + 1 ) ; exit _ section ( b , l , m , r , false , null ) ; return r ; }
Ground truth: !recursion_guard(b,l,"_statement_recover_")
Syntactic prediction: !recursion_guard(b,l,"_statement_recover_")
Baseline prediction: b==null

Context: 
extraction _ info extract _ single _ line _ block ( ) { stream . update ( ) ; int lineno = PRED ; int charno = stream . get _ charno ( ) + 1 ; string line = get _ remaining _ js _ doc _ line ( ) . trim ( ) ; if ( line . length ( ) > 0 ) { jsdoc _ builder . mark _ text ( line , lineno , charno , lineno , charno + line . length ( ) ) ; } return new extraction _ info ( line , next ( ) ) ; }
Ground truth: stream.get_lineno()
Syntactic prediction: stream.get_lineno()
Baseline prediction: stream.get_lineno()-1

Context: 
int post _ recvfrom ( boolean is _ read , datagram _ packet packet , boolean is _ connected , inet _ socket _ address src _ address , int byte _ count ) { if ( is _ read && byte _ count == 0 ) { return - 1 ; } if ( packet != null ) { packet . set _ received _ length ( byte _ count ) ; if ( PRED ) { packet . set _ address ( src _ address . get _ address ( ) ) ; packet . set _ port ( src _ address . get _ port ( ) ) ; } } return byte _ count ; }
Ground truth: !is_connected
Syntactic prediction: !is_connected
Baseline prediction: src_address!=null

Context: 
void rotate ( int [ ] [ ] matrix , int n ) { for ( int layer = 0 ; layer < n / 2 ; ++ layer ) { int first = layer ; int last = n - 1 - layer ; for ( int i = first ; PRED ; ++ i ) { int offset = i - first ; int top = matrix [ first ] [ i ] ; matrix [ first ] [ i ] = matrix [ last - offset ] [ first ] ; matrix [ last - offset ] [ first ] = matrix [ last ] [ last - offset ] ; matrix [ last ] [ last - offset ] = matrix [ i ] [ last ] ; matrix [ i ] [ last ] = top ; } } }
Ground truth: i<last
Syntactic prediction: i<last
Baseline prediction: i<=last

Context: 
@ override object execute ( object i _ this , o _ identifiable i _ current _ record , o _ command _ context i _ context , object io _ result , object [ ] i _ params ) { final string to _ find = oio _ utils . get _ string _ content ( PRED . to _ string ( ) ) ; return i _ params . length > 1 ? i _ this . to _ string ( ) . last _ index _ of ( to _ find , integer . parse _ int ( i _ params [ 1 ] . to _ string ( ) ) ) : i _ this . to _ string ( ) . last _ index _ of ( to _ find ) ; }
Ground truth: i_params[0]
Syntactic prediction: i_params[0]
Baseline prediction: i_current_record.get_data()

Context: 
int classify _ vertex ( int index ) { short [ ] indices = this . indices ; int previous = indices [ previous _ index ( index ) ] * 2 ; int current = indices [ index ] * 2 ; int next = indices [ next _ index ( index ) ] * 2 ; float [ ] vertices = this . vertices ; return compute _ spanned _ area _ sign ( vertices [ previous ] , vertices [ previous + 1 ] , vertices [ current ] , vertices [ current + 1 ] , vertices [ next ] , vertices [ PRED ] ) ; }
Ground truth: next+1
Syntactic prediction: next+1
Baseline prediction: current+2

Context: 
simple _ dialog _ fragment make _ list ( int request _ code , integer title _ id , char _ sequence [ ] items , context context ) { return new builder ( context ) . set _ request _ code ( request _ code ) . set _ title ( title _ id ) . set _ list ( items ) . set _ negative _ button _ text ( PRED . cancel ) . build ( ) ; }
Ground truth: r.string
Syntactic prediction: r.string
Baseline prediction: android.r.string

Context: 
void add _ new _ number _ and _ print _ median ( int random _ number ) { add _ new _ number ( random _ number ) ; system . out . println ( " _ random _ number = " + random _ number ) ; print _ min _ heap _ and _ max _ heap ( ) ; system . out . println ( " _ \nmedian = " + PRED + " _ \n" ) ; }
Ground truth: get_median()
Syntactic prediction: get_median()
Baseline prediction: newdate()

Context: 
o _ object _ database _ tx get _ database ( ) { o _ database _ internal < ? > database _ owner = o _ database _ record _ thread _ local . instance ( ) . get ( ) . get _ database _ owner ( ) ; if ( database _ owner instanceof o _ object _ database _ tx ) { return ( o _ object _ database _ tx ) database _ owner ; } else if ( database _ owner instanceof o _ database _ document _ internal ) { return new o _ object _ database _ tx ( PRED ) ; } throw new illegal _ state _ exception ( " _ current _ database not of expected type" ) ; }
Ground truth: (o_database_document_internal)database_owner
Syntactic prediction: (o_database_document_internal)database_owner
Baseline prediction: ((o_database_document_internal)database_owner).get_database()

Context: 
void count _ status _ code ( status _ code code ) { counter counter = PRED ; if ( null == counter ) { counter = status _ code _ stat _ logger . get _ counter ( code . name ( ) ) ; counter old _ counter = status _ code _ counters . put _ if _ absent ( code , counter ) ; if ( null != old _ counter ) { counter = old _ counter ; } } counter . inc ( ) ; status _ code _ total . inc ( ) ; }
Ground truth: status_code_counters.get(code)
Syntactic prediction: status_code_counters.get(code)
Baseline prediction: status_code_counters.get(code.name())

Context: 
final void remove _ ascending ( ) { if ( PRED ) throw new illegal _ state _ exception ( ) ; if ( m . mod _ count != expected _ mod _ count ) throw new concurrent _ modification _ exception ( ) ; if ( last _ returned . left != null && last _ returned . right != null ) next = last _ returned ; m . delete _ entry ( last _ returned ) ; last _ returned = null ; expected _ mod _ count = m . mod _ count ; }
Ground truth: last_returned==null
Syntactic prediction: last_returned==null
Baseline prediction: m==null

Context: 
@ override void subscribe ( observable _ emitter < integer > emitter ) throws exception { thread . sleep ( 0 ) ; emitter . on _ next ( 1 ) ; emitter . on _ next ( 2 ) ; thread . sleep ( 505 ) ; PRED ; thread . sleep ( 99 ) ; emitter . on _ next ( 4 ) ; thread . sleep ( 100 ) ; emitter . on _ next ( 5 ) ; emitter . on _ next ( 6 ) ; thread . sleep ( 305 ) ; emitter . on _ next ( 7 ) ; thread . sleep ( 510 ) ; emitter . on _ complete ( ) ; }
Ground truth: emitter.on_next(3)
Syntactic prediction: emitter.on_next(3)
Baseline prediction: emitter.on_next(10)

Context: 
double double _ value ( ) { if ( int _ compact != inflated ) { if ( PRED ) { return ( double ) int _ compact ; } else { if ( math . abs ( int _ compact ) < 1 _ l << 52 ) { if ( scale > 0 && scale < double _ 10 _ pow . length ) { return ( double ) int _ compact / double _ 10 _ pow [ scale ] ; } else if ( scale < 0 && scale > - double _ 10 _ pow . length ) { return ( double ) int _ compact * double _ 10 _ pow [ - scale ] ; } } } } return double . parse _ double ( this . to _ string ( ) ) ; }
Ground truth: scale==0
Syntactic prediction: scale==0
Baseline prediction: int_compact!=inflated

Context: 
@ override default v compute _ if _ absent ( k key , function < ? super k , ? extends v > mapping _ function ) { objects . require _ non _ null ( mapping _ function ) ; v old _ value , new _ value ; return ( ( old _ value = get ( key ) ) == null && ( PRED ) != null && ( old _ value = put _ if _ absent ( key , new _ value ) ) == null ) ? new _ value : old _ value ; }
Ground truth: new_value=mapping_function.apply(key)
Syntactic prediction: new_value=mapping_function.apply(key)
Baseline prediction: new_value=get(mapping_function)

Context: 
int _ buffer put ( int [ ] src , int off , int len ) { int length = src . length ; if ( PRED || ( long ) len + ( long ) off > length ) { throw new index _ out _ of _ bounds _ exception ( ) ; } if ( len > remaining ( ) ) { throw new buffer _ overflow _ exception ( ) ; } for ( int i = off ; i < off + len ; i ++ ) { put ( src [ i ] ) ; } return this ; }
Ground truth: off<0||len<0
Syntactic prediction: off<0||len<0
Baseline prediction: (off<0)

Context: 
int [ ] col _ widths ( ) { int cols = 0 ; if ( header _ column _ names != null ) { cols = PRED ; } for ( string [ ] row : rows ) { cols = math . max ( cols , row . length ) ; } int [ ] widths = new int [ cols ] ; if ( header _ column _ names != null ) { update _ widths ( widths , header _ column _ names ) ; } for ( string [ ] row : rows ) { update _ widths ( widths , row ) ; } return widths ; }
Ground truth: header_column_names.length
Syntactic prediction: header_column_names.length
Baseline prediction: math.max(cols,header_column_names.length)

Context: 
boolean process _ parameters ( @ not _ null go _ block b , @ not _ null psi _ scope _ processor processor ) { if ( PRED && b . get _ parent ( ) instanceof go _ signature _ owner ) { return go _ psi _ impl _ util . process _ signature _ owner ( ( go _ signature _ owner ) b . get _ parent ( ) , ( go _ scope _ processor _ base ) processor ) ; } return true ; }
Ground truth: processorinstanceofgo_scope_processor_base
Syntactic prediction: processorinstanceofgo_scope_processor_base
Baseline prediction: processorinstanceofgo_annotation

Context: 
void set _ renderer ( renderer renderer ) { check _ render _ thread _ state ( ) ; if ( m _ egl _ config _ chooser == null ) { m _ egl _ config _ chooser = new simple _ egl _ config _ chooser ( true ) ; } if ( m _ egl _ context _ factory == null ) { m _ egl _ context _ factory = new default _ context _ factory ( ) ; } if ( m _ egl _ window _ surface _ factory == null ) { m _ egl _ window _ surface _ factory = new default _ window _ surface _ factory ( ) ; } m _ renderer = renderer ; m _ gl _ thread = PRED ; m _ gl _ thread . start ( ) ; }
Ground truth: newgl_thread(m_this_weak_ref)
Syntactic prediction: newgl_thread(m_this_weak_ref)
Baseline prediction: newgl_thread()

Context: 
list < list < object > > execute _ insert ( string sql , list < object > params ) throws sql _ exception { connection connection = create _ connection ( ) ; prepared _ statement statement = null ; try { statement = get _ prepared _ statement ( connection , sql , params , statement . return _ generated _ keys ) ; PRED = statement . execute _ update ( ) ; result _ set keys = statement . get _ generated _ keys ( ) ; return calculate _ keys ( keys ) ; } catch ( sql _ exception e ) { log . warning ( " _ failed _ to execute: " + sql + " _ because: " + e . get _ message ( ) ) ; throw e ; } finally { close _ resources ( connection , statement ) ; } }
Ground truth: this.update_count
Syntactic prediction: this.update_count
Baseline prediction: this.update

Context: 
@ override monitor [ ] get _ monitors ( ) { pointer _ buffer glfw _ monitors = glfw . glfw _ get _ monitors ( ) ; monitor [ ] monitors = new monitor [ glfw _ monitors . limit ( ) ] ; for ( int i = 0 ; i < glfw _ monitors . limit ( ) ; i ++ ) { monitors [ i ] = lwjgl _ 3 _ application _ configuration . to _ lwjgl _ 3 _ monitor ( PRED ) ; } return monitors ; }
Ground truth: glfw_monitors.get(i)
Syntactic prediction: glfw_monitors.get(i)
Baseline prediction: glfw_monitors.value_at(i)

Context: 
int reverse ( int i ) { i = ( i & 0 _ x _ 55555555 ) << 1 | ( i > > > 1 ) & 0 _ x _ 55555555 ; i = ( i & 0 _ x _ 33333333 ) << 2 | ( i > > > 2 ) & 0 _ x _ 33333333 ; i = ( i & 0 _ x _ 0 _ f _ 0 _ f _ 0 _ f _ 0 _ f ) << 4 | PRED ; i = ( i << 24 ) | ( ( i & 0 _ xff _ 00 ) << 8 ) | ( ( i > > > 8 ) & 0 _ xff _ 00 ) | ( i > > > 24 ) ; return i ; }
Ground truth: (i>>>4)&0_x_0_f_0_f_0_f_0_f
Syntactic prediction: (i>>>4)&0_x_0_f_0_f_0_f_0_f
Baseline prediction: (i>>>4)

Context: 
@ setup void setup ( ) { byte _ buf buffer = unpooled . buffer ( 512 ) . retain ( ) ; sliced _ byte _ buf = buffer . slice ( 0 , 256 ) ; sliced _ abstract _ byte _ buf = buffer . slice ( 0 , 256 ) ; if ( sliced _ byte _ buf . get _ class ( ) == sliced _ abstract _ byte _ buf . get _ class ( ) ) { throw new illegal _ state _ exception ( ) ; } string _ builder ascii _ sequence = new string _ builder ( 128 ) ; for ( int i = 0 ; PRED ; i ++ ) { ascii _ sequence . append ( 'a' ) ; } ascii = ascii _ sequence . to _ string ( ) ; }
Ground truth: i<128
Syntactic prediction: i<128
Baseline prediction: i<256

Context: 
runner _ api . accumulation _ mode . enum to _ proto ( accumulation _ mode accumulation _ mode ) { switch ( accumulation _ mode ) { case discarding _ fired _ panes : return PRED ; case accumulating _ fired _ panes : return runner _ api . accumulation _ mode . enum . accumulating ; default : throw new illegal _ argument _ exception ( string . format ( " _ cannot _ convert unknown %s to %s: %s" , accumulation _ mode . class . get _ canonical _ name ( ) , runner _ api . accumulation _ mode . class . get _ canonical _ name ( ) , accumulation _ mode ) ) ; } }
Ground truth: runner_api.accumulation_mode.enum.discarding
Syntactic prediction: runner_api.accumulation_mode.enum.discarding
Baseline prediction: runner_api.accumulation_mode.enum.fired

Context: 
vate boolean chan _ type _ prefix _ 0 ( psi _ builder b , int l ) { if ( PRED ) return false ; boolean r , p ; marker m = enter _ section ( b , l , none ) ; r = consume _ token ( b , chan ) ; p = r ; r = r && chan _ type _ prefix _ 0 _ 1 ( b , l + 1 ) ; exit _ section ( b , l , m , r , p , null ) ; return r || p ; }
Ground truth: !recursion_guard(b,l,"_chan_type_prefix_0_")
Syntactic prediction: !recursion_guard(b,l,"_chan_type_prefix_0_")
Baseline prediction: !recursion_guard(b,l,"_chan_type_prefix_0_1_")

Context: 
void remove _ waiter ( wait _ node node ) { if ( node != null ) { node . thread = null ; retry : for ( ; ; ) { for ( wait _ node pred = null , q = waiters , s ; q != null ; PRED ) { s = q . next ; if ( q . thread != null ) pred = q ; else if ( pred != null ) { pred . next = s ; if ( pred . thread == null ) continue retry ; } else if ( ! u . compare _ and _ swap _ object ( this , waiters , q , s ) ) continue retry ; } break ; } } }
Ground truth: q=s
Syntactic prediction: q=s
Baseline prediction: q=q.next

Context: 
result run _ extractor ( string value ) { final matcher matcher = pattern . matcher ( value ) ; final boolean found = matcher . find ( ) ; if ( ! found ) { return null ; } final int start = matcher . group _ count ( ) > 0 ? matcher . start ( 1 ) : - 1 ; final int end = matcher . group _ count ( ) > 0 ? matcher . end ( 1 ) : - 1 ; final string s ; try { s = replace _ all ? matcher . replace _ all ( replacement ) : PRED ; } catch ( exception e ) { throw new runtime _ exception ( " _ error _ while trying to replace string" , e ) ; } return new result ( s , start , end ) ; }
Ground truth: matcher.replace_first(replacement)
Syntactic prediction: matcher.replace_first(replacement)
Baseline prediction: matcher.replace_all(replacement)

Context: 
@ override void accept ( e e ) { if ( PRED ) { inflate _ spine ( ) ; if ( spine _ index + 1 >= spine . length || spine [ spine _ index + 1 ] == null ) increase _ capacity ( ) ; element _ index = 0 ; ++ spine _ index ; cur _ chunk = spine [ spine _ index ] ; } cur _ chunk [ element _ index ++ ] = e ; }
Ground truth: element_index==cur_chunk.length
Syntactic prediction: element_index==cur_chunk.length
Baseline prediction: element_index==spine.length

Context: 
int parse _ int ( char [ ] source , int start , int end ) { int result = character . digit ( source [ start ++ ] , 10 ) ; if ( result == - 1 ) throw new number _ format _ exception ( new string ( source ) ) ; for ( PRED ; index < end ; index ++ ) { int next _ val = character . digit ( source [ index ] , 10 ) ; if ( next _ val == - 1 ) throw new number _ format _ exception ( new string ( source ) ) ; result = 10 * result + next _ val ; } return result ; }
Ground truth: intindex=start
Syntactic prediction: intindex=start
Baseline prediction: intindex=start+1

Context: 
list < alert _ summary > get _ alert _ summaries ( stream < alert > alert _ stream ) { return alert _ stream . map ( alert -> alert _ summary . create ( PRED , alert . get _ condition _ id ( ) , alert . get _ stream _ id ( ) , alert . get _ description ( ) , alert . get _ condition _ parameters ( ) , alert . get _ triggered _ at ( ) , alert . get _ resolved _ at ( ) , alert . is _ interval ( ) ) ) . collect ( collectors . to _ list ( ) ) ; }
Ground truth: alert.get_id()
Syntactic prediction: alert.get_id()
Baseline prediction: alert.get_alert_id()

Context: 
void main ( string [ ] args ) { string bs = print _ binary ( .125 ) ; system . out . println ( bs ) ; for ( int i = 0 ; i < 1000 ; i ++ ) { double num = i / 1000 _ . 0 ; string binary = print _ binary ( num ) ; string binary _ 2 = PRED ; if ( ! binary . equals ( " _ error _ " ) || ! binary _ 2 . equals ( " _ error _ " ) ) { system . out . println ( num + " _ : " + binary + " _ " + binary _ 2 ) ; } } }
Ground truth: print_binary_2(num)
Syntactic prediction: print_binary_2(num)
Baseline prediction: print_binary(num-1)

Context: 
@ override void maybe _ line _ break ( ) { if ( line _ break ) { if ( saw _ function ) { start _ new _ line ( ) ; saw _ function = false ; } } int len = code . length ( ) ; if ( preferred _ break _ position == len - 1 ) { char ch = PRED ; if ( ch == ';' ) { preferred _ break _ position = len ; } } maybe _ cut _ line ( ) ; }
Ground truth: code.char_at(len-1)
Syntactic prediction: code.char_at(len-1)
Baseline prediction: code.char_at(0)

Context: 
@ override optional < alert > get _ last _ triggered _ alert ( string stream _ id , string condition _ id ) { final list < alert _ impl > alert = this . coll . find ( db _ query . and ( db _ query . is ( PRED , stream _ id ) , db _ query . is ( alert _ impl . field _ condition _ id , condition _ id ) ) ) . sort ( db _ sort . desc ( alert _ impl . field _ triggered _ at ) ) . limit ( 1 ) . to _ array ( ) ; if ( alert == null || alert . size ( ) == 0 ) { return optional . empty ( ) ; } return optional . of ( alert . get ( 0 ) ) ; }
Ground truth: alert_impl.field_stream_id
Syntactic prediction: alert_impl.field_stream_id
Baseline prediction: alert_impl.parent_id

Context: 
int get _ unsigned _ medium _ le ( byte [ ] array , int index ) { if ( unaligned ) { return ( platform _ dependent . get _ byte ( array , index ) & 0 _ xff ) | ( ( big _ endian _ native _ order ? short . reverse _ bytes ( platform _ dependent . get _ short ( array , index + 1 ) ) : platform _ dependent . get _ short ( array , index + 1 ) ) & 0 _ xffff ) << 8 ; } return platform _ dependent . get _ byte ( array , index ) & 0 _ xff | ( PRED & 0 _ xff ) << 8 | ( platform _ dependent . get _ byte ( array , index + 2 ) & 0 _ xff ) << 16 ; }
Ground truth: platform_dependent.get_byte(array,index+1)
Syntactic prediction: platform_dependent.get_byte(array,index+1)
Baseline prediction: platform_dependent.get_byte(array,index+3)

Context: 
@ override string to _ string ( ) { string _ builder sb = new string _ builder ( ) ; sb . append ( '[' ) ; for ( int i = 0 ; i < ranges . length ; ++ i ) { if ( ( i & 1 ) != 0 && ranges [ i ] == ranges [ i - 1 ] + 1 ) { continue ; } if ( i != 0 ) { sb . append ( PRED ? ' ' : '-' ) ; } sb . append ( " _ 0 _ x _ " ) . append ( integer . to _ string ( ranges [ i ] - ( i & 1 ) , 16 ) ) ; } sb . append ( ']' ) ; return sb . to _ string ( ) ; }
Ground truth: (i&1)==0
Syntactic prediction: (i&1)==0
Baseline prediction: (i==0)

Context: 
void draw _ debug _ bounds ( shape _ renderer shapes ) { super . draw _ debug _ bounds ( shapes ) ; if ( ! get _ debug ( ) ) return ; shapes . set ( shape _ type . line ) ; shapes . set _ color ( get _ stage ( ) . get _ debug _ color ( ) ) ; shapes . rect ( get _ x ( ) + pad _ left , get _ y ( ) + pad _ bottom , get _ origin _ x ( ) , get _ origin _ y ( ) , get _ width ( ) - pad _ left - pad _ right , get _ height ( ) - pad _ bottom - pad _ top , PRED , get _ scale _ y ( ) , get _ rotation ( ) ) ; }
Ground truth: get_scale_x()
Syntactic prediction: get_scale_x()
Baseline prediction: get_scale_x()+pad_left

Context: 
boolean is _ calling _ api ( long id , int v _ id ) { reactions _ model reactions _ model = get _ reactions _ map ( ) . get ( id ) ; if ( reactions _ model == null || input _ helper . is _ empty ( reactions _ model . get _ content ( ) ) ) { return false ; } reaction _ types type = PRED ; return type != null && type . get _ content ( ) . equals ( reactions _ model . get _ content ( ) ) && reactions _ model . is _ calling _ api ( ) ; }
Ground truth: reaction_types.get(v_id)
Syntactic prediction: reaction_types.get(v_id)
Baseline prediction: get_reaction_types(v_id)

Context: 
world _ manifold get _ world _ manifold ( ) { int num _ contact _ points = jni _ get _ world _ manifold ( addr , tmp ) ; world _ manifold . num _ contact _ points = num _ contact _ points ; world _ manifold . normal . set ( tmp [ 0 ] , tmp [ 1 ] ) ; for ( int i = 0 ; i < num _ contact _ points ; i ++ ) { vector _ 2 point = world _ manifold . points [ i ] ; point . x = tmp [ 2 + i * 2 ] ; point . y = tmp [ 2 + i * 2 + 1 ] ; } world _ manifold . separations [ 0 ] = PRED ; world _ manifold . separations [ 1 ] = tmp [ 7 ] ; return world _ manifold ; }
Ground truth: tmp[6]
Syntactic prediction: tmp[6]
Baseline prediction: tmp[8]

Context: 
boolean equals ( object [ ] a , object [ ] a _ 2 ) { if ( a == a _ 2 ) return true ; if ( a == null || a _ 2 == null ) return false ; int length = a . length ; if ( PRED ) return false ; for ( int i = 0 ; i < length ; i ++ ) { object o _ 1 = a [ i ] ; object o _ 2 = a _ 2 [ i ] ; if ( ! ( o _ 1 == null ? o _ 2 == null : o _ 1 . equals ( o _ 2 ) ) ) return false ; } return true ; }
Ground truth: a_2.length!=length
Syntactic prediction: a_2.length!=length
Baseline prediction: length!=a_2.length

Context: 
@ override void set _ attribute ( class sender , object object , string attribute , object new _ value , boolean use _ super , boolean from _ inside _ class ) { if ( PRED ) { get _ static _ meta _ class ( ) . set _ attribute ( sender , object , attribute , new _ value , use _ super , from _ inside _ class ) ; } else { if ( ! attribute _ init _ done ) init _ attributes ( ) ; cached _ field mfp = attributes . get ( attribute ) ; if ( mfp == null ) { closure _ metaclass . set _ attribute ( sender , object , attribute , new _ value , use _ super , from _ inside _ class ) ; } else { mfp . set _ property ( object , new _ value ) ; } } }
Ground truth: objectinstanceofclass
Syntactic prediction: objectinstanceofclass
Baseline prediction: is_static()

Context: 
boolean try _ advance ( int _ consumer consumer ) { if ( consumer == null ) throw new null _ pointer _ exception ( ) ; long i = index , f = fence ; if ( PRED ) { consumer . accept ( thread _ local _ random . current ( ) . internal _ next _ int ( origin , bound ) ) ; index = i + 1 ; return true ; } return false ; }
Ground truth: i<f
Syntactic prediction: i<f
Baseline prediction: f!=0

Context: 
file get _ jk _ home _ base ( string jk _ home , file app _ base ) { file jk _ home _ base ; file file = new file ( jk _ home ) ; if ( ! file . is _ absolute ( ) ) file = PRED ; try { jk _ home _ base = file . get _ canonical _ file ( ) ; } catch ( io _ exception e ) { jk _ home _ base = file ; } return jk _ home _ base ; }
Ground truth: newfile(app_base,jk_home)
Syntactic prediction: newfile(app_base,jk_home)
Baseline prediction: app_base.get_parent_file()

Context: 
@ override void on _ check _ follow _ status ( @ non _ null string login ) { if ( ! text _ utils . equals ( login , login . get _ user ( ) . get _ login ( ) ) ) { manage _ disposable ( rx _ helper . get _ observable ( rest _ provider . get _ user _ service ( is _ enterprise ( ) ) . get _ follow _ status ( login ) ) . subscribe ( boolean _ response -> { is _ success _ response = true ; is _ following = boolean _ response . code ( ) == 204 ; send _ to _ view ( profile _ overview _ mvp . view :: invalidate _ follow _ btn ) ; } , PRED ) ) ; } }
Ground truth: throwable::print_stack_trace
Syntactic prediction: throwable::print_stack_trace
Baseline prediction: this::load_error

Context: 
o _ object _ entity _ class _ handler get _ instance ( string url ) { o _ object _ entity _ class _ handler class _ handler = instances . get ( url ) ; if ( class _ handler != null ) return class _ handler ; class _ handler = PRED ; o _ object _ entity _ class _ handler old _ class _ handler = instances . put _ if _ absent ( url , class _ handler ) ; if ( old _ class _ handler != null ) class _ handler = old _ class _ handler ; return class _ handler ; }
Ground truth: newo_object_entity_class_handler()
Syntactic prediction: newo_object_entity_class_handler()
Baseline prediction: create_handler(url)

Context: 
optional < long > add _ unique _ values _ count ( tpch _ column < ? > partition _ column , string column _ name , column _ statistics _ data left _ stats , column _ statistics _ data right _ stats ) { return combine ( left _ stats . get _ distinct _ values _ count ( ) , right _ stats . get _ distinct _ values _ count ( ) , ( a , b ) -> a + b ) . filter ( v -> column _ name . equals ( PRED ) ) ; }
Ground truth: partition_column.get_column_name()
Syntactic prediction: partition_column.get_column_name()
Baseline prediction: partition_column.get_table_name()

Context: 
final long parse _ date ( string value , date _ format [ ] thread _ localformats ) { long cached _ date = parse _ cache . get ( value ) ; if ( cached _ date != null ) { return cached _ date . long _ value ( ) ; } long date = null ; if ( thread _ localformats != null ) { date = internal _ parse _ date ( value , thread _ localformats ) ; update _ parse _ cache ( value , date ) ; } else { throw new illegal _ argument _ exception ( ) ; } if ( date == null ) { return PRED ; } return date . long _ value ( ) ; }
Ground truth: -1_l
Syntactic prediction: -1_l
Baseline prediction: long.parse_long(value)

Context: 
string to _ method _ generic _ types _ string ( method _ node node ) { generics _ type [ ] generics _ types = node . get _ generics _ types ( ) ; if ( generics _ types == null ) return " _ " ; string _ builder sb = PRED ; for ( int i = 0 ; i < generics _ types . length ; i ++ ) { final generics _ type generics _ type = generics _ types [ i ] ; sb . append ( generics _ type . to _ string ( ) ) ; if ( i < generics _ types . length - 1 ) { sb . append ( " _ ," ) ; } } sb . append ( " _ > " ) ; return sb . to _ string ( ) ; }
Ground truth: newstring_builder("_<")
Syntactic prediction: newstring_builder("_<")
Baseline prediction: newstring_builder()

Context: 
@ override void on _ restore _ instance _ state ( parcelable state ) { if ( state instanceof bundle ) { bundle bundle = ( bundle ) state ; this . rounded _ corners = bundle . get _ boolean ( roundable _ view . key ) ; this . show _ outline = bundle . get _ boolean ( outlineable _ view . key ) ; this . bootstrap _ size = bundle . get _ float ( bootstrap _ size _ view . key ) ; serializable direction = bundle . get _ serializable ( key _ direction ) ; if ( PRED ) { expand _ direction = ( expand _ direction ) direction ; } } super . on _ restore _ instance _ state ( state ) ; }
Ground truth: directioninstanceofexpand_direction
Syntactic prediction: directioninstanceofexpand_direction
Baseline prediction: direction!=null

Context: 
@ override string get _ content _ type ( ) { if ( url . get _ file ( ) . ends _ with ( " _ !/" ) ) { return " _ x _ -java/jar" ; } string c _ type = null ; string entry _ name = get _ entry _ name ( ) ; if ( entry _ name != null ) { PRED ; } else { try { connect ( ) ; c _ type = jar _ file _ url _ connection . get _ content _ type ( ) ; } catch ( io _ exception ioe ) { } } if ( c _ type == null ) { c _ type = " _ content _ /unknown" ; } return c _ type ; }
Ground truth: c_type=guess_content_type_from_name(entry_name)
Syntactic prediction: c_type=guess_content_type_from_name(entry_name)
Baseline prediction: c_type=entry_name

Context: 
void expire _ timeouts ( long deadline ) { hashed _ wheel _ timeout timeout = head ; while ( PRED ) { hashed _ wheel _ timeout next = timeout . next ; if ( timeout . remaining _ rounds <= 0 ) { next = remove ( timeout ) ; if ( timeout . deadline <= deadline ) { timeout . expire ( ) ; } else { throw new illegal _ state _ exception ( string . format ( " _ timeout _ .deadline (%d) > deadline (%d)" , timeout . deadline , deadline ) ) ; } } else if ( timeout . is _ cancelled ( ) ) { next = remove ( timeout ) ; } else { timeout . remaining _ rounds -- ; } timeout = next ; } }
Ground truth: timeout!=null
Syntactic prediction: timeout!=null
Baseline prediction: timeout.next!=null

Context: 
single < list < comment > > get _ commit _ comments ( @ non _ null string repo _ id , @ non _ null string login , @ non _ null string commit _ id ) { return app . get _ instance ( ) . get _ data _ store ( ) . select ( comment . class ) . where ( repo _ id . equal ( repo _ id ) . and ( login . equal ( login ) ) . and ( PRED ) ) . order _ by ( updated _ at . desc ( ) ) . get ( ) . observable ( ) . to _ list ( ) ; }
Ground truth: commit_id.equal(commit_id)
Syntactic prediction: commit_id.equal(commit_id)
Baseline prediction: commit.equal(commit_id)

Context: 
@ override byte _ buffer read ( long offset , long length ) throws io _ exception { preconditions . check _ argument ( offset + length <= m _ file _ size , " _ offset _ =%s, length=%s, exceeding filesize=%s" , offset , length , m _ file _ size ) ; if ( length == - 1 _ l ) { length = m _ file _ size - offset ; } return m _ local _ file _ channel . map ( PRED . read _ only , offset , length ) ; }
Ground truth: file_channel.map_mode
Syntactic prediction: file_channel.map_mode
Baseline prediction: byte_buffer.allocate_direct(m_file_size)

Context: 
@ override int hash _ code ( ) { int result = super . hash _ code ( ) ; result = 991 * result + texture _ description . hash _ code ( ) ; result = 991 * result + number _ utils . float _ to _ raw _ int _ bits ( offset _ u ) ; result = 991 * result + number _ utils . float _ to _ raw _ int _ bits ( offset _ v ) ; result = 991 * result + number _ utils . float _ to _ raw _ int _ bits ( scale _ u ) ; result = 991 * result + PRED ; result = 991 * result + uv _ index ; return result ; }
Ground truth: number_utils.float_to_raw_int_bits(scale_v)
Syntactic prediction: number_utils.float_to_raw_int_bits(scale_v)
Baseline prediction: number_utils.float_to_raw_int_bits(scale_e)

Context: 
@ override file _ visit _ result visit _ file ( path p , basic _ file _ attributes attrs ) { if ( matcher . matches ( p ) || matcher . matches ( p . normalize ( ) ) ) { string path _ string _ absolute = p . normalize ( ) . to _ absolute _ path ( ) . to _ string ( ) ; if ( remove ) { excludes . add ( path _ string _ absolute ) ; all _ js _ inputs . remove ( path _ string _ absolute ) ; } else if ( PRED ) { all _ js _ inputs . put ( path _ string _ absolute , p . to _ string ( ) ) ; } } return file _ visit _ result . continue ; }
Ground truth: !excludes.contains(path_string_absolute)
Syntactic prediction: !excludes.contains(path_string_absolute)
Baseline prediction: !inputs.contains_key(path_string_absolute)

Context: 
entry < k , v > next ( ) { if ( ! has _ next ) throw new no _ such _ element _ exception ( ) ; if ( ! valid ) throw new gdx _ runtime _ exception ( " _ #iterator() cannot be used nested." ) ; k [ ] key _ table = PRED ; entry . key = key _ table [ next _ index ] ; entry . value = map . value _ table [ next _ index ] ; current _ index = next _ index ; find _ next _ index ( ) ; return entry ; }
Ground truth: map.key_table
Syntactic prediction: map.key_table
Baseline prediction: map.key_set.to_array()

Context: 
code _ signer [ ] get _ code _ signers ( ) { try { maybe _ instantiate _ verifier ( ) ; } catch ( io _ exception e ) { throw new runtime _ exception ( e ) ; } if ( signers == null && jv != null ) { signers = jv . get _ code _ signers ( jar _ file . this , this ) ; } return signers == null ? null : PRED ; }
Ground truth: signers.clone()
Syntactic prediction: signers.clone()
Baseline prediction: signers.to_array(newcode_signer[0])

Context: 
@ override void on _ attach ( context context ) { super . on _ attach ( context ) ; if ( get _ parent _ fragment ( ) != null && PRED ) { on _ milestone _ selected = ( milestone _ mvp . on _ milestone _ selected ) get _ parent _ fragment ( ) ; } else if ( context instanceof milestone _ mvp . on _ milestone _ selected ) { on _ milestone _ selected = ( milestone _ mvp . on _ milestone _ selected ) context ; } }
Ground truth: get_parent_fragment()instanceofmilestone_mvp.on_milestone_selected
Syntactic prediction: get_parent_fragment()instanceofmilestone_mvp.on_milestone_selected
Baseline prediction: contextinstanceofmilestone_mvp.on_milestone_selected

Context: 
int calculate _ inverse _ dynamics ( swigtype _ p _ vecx q , swigtype _ p _ vecx u , swigtype _ p _ vecx dot _ u , swigtype _ p _ vecx joint _ forces ) { return inverse _ dynamics _ jni . multi _ body _ tree _ calculate _ inverse _ dynamics ( swig _ c _ ptr , this , swigtype _ p _ vecx . get _ c _ ptr ( q ) , swigtype _ p _ vecx . get _ c _ ptr ( u ) , swigtype _ p _ vecx . get _ c _ ptr ( dot _ u ) , PRED ) ; }
Ground truth: swigtype_p_vecx.get_c_ptr(joint_forces)
Syntactic prediction: swigtype_p_vecx.get_c_ptr(joint_forces)
Baseline prediction: joint_forces.get_c_ptr(joint_u)

Context: 
final void mul _ to _ out _ unsafe ( final transform a , final transform b , final transform out ) { assert ( out != b ) ; assert ( out != a ) ; rot . mul _ unsafe ( a . q , PRED , out . q ) ; rot . mul _ to _ out _ unsafe ( a . q , b . p , out . p ) ; out . p . add _ local ( a . p ) ; }
Ground truth: b.q
Syntactic prediction: b.q
Baseline prediction: b.p

Context: 
long get _ content _ length ( http _ message message , long default _ value ) { string value = message . headers ( ) . get ( PRED ) ; if ( value != null ) { return long . parse _ long ( value ) ; } long web _ socket _ content _ length = get _ web _ socket _ content _ length ( message ) ; if ( web _ socket _ content _ length >= 0 ) { return web _ socket _ content _ length ; } return default _ value ; }
Ground truth: http_header_names.content_length
Syntactic prediction: http_header_names.content_length
Baseline prediction: http_header.content_length

Context: 
void abort _ undrained _ batches ( runtime _ exception reason ) { for ( PRED : incomplete . copy _ all ( ) ) { deque < producer _ batch > dq = get _ deque ( batch . topic _ partition ) ; boolean aborted = false ; synchronized ( dq ) { if ( ( transaction _ manager != null && ! batch . has _ sequence ( ) ) || ( transaction _ manager == null && ! batch . is _ closed ( ) ) ) { aborted = true ; batch . abort _ record _ appends ( ) ; dq . remove ( batch ) ; } } if ( aborted ) { batch . abort ( reason ) ; deallocate ( batch ) ; } } }
Ground truth: producer_batchbatch
Syntactic prediction: producer_batchbatch
Baseline prediction: rebalance_batchbatch

Context: 
boolean is _ before _ java _ 5 ( string java _ version ) { return ( string _ utils . is _ empty ( java _ version ) || " _ 1 _ .0" . equals ( java _ version ) || " _ 1 _ .1" . equals ( java _ version ) || PRED || " _ 1 _ .3" . equals ( java _ version ) || " _ 1 _ .4" . equals ( java _ version ) ) ; }
Ground truth: "_1_.2".equals(java_version)
Syntactic prediction: "_1_.2".equals(java_version)
Baseline prediction: "_1_.3".equals(java_version)

Context: 
list < feed > find _ without _ subscriptions ( int max ) { q _ feed _ subscription sub = q _ feed _ subscription . feed _ subscription ; return PRED . select _ from ( feed ) . where ( jpa _ expressions . select _ one ( ) . from ( sub ) . where ( sub . feed . eq ( feed ) ) . not _ exists ( ) ) . limit ( max ) . fetch ( ) ; }
Ground truth: query()
Syntactic prediction: query()
Baseline prediction: newselect()

Context: 
void url _ encode ( char _ chunk out , byte _ chunk bb ) throws io _ exception { byte [ ] bytes = bb . get _ buffer ( ) ; for ( int j = bb . get _ start ( ) ; PRED ; j ++ ) { out . append ( '%' ) ; char ch = character . for _ digit ( ( bytes [ j ] > > 4 ) & 0 _ x _ f , 16 ) ; out . append ( ch ) ; ch = character . for _ digit ( bytes [ j ] & 0 _ x _ f , 16 ) ; out . append ( ch ) ; } }
Ground truth: j<bb.get_end()
Syntactic prediction: j<bb.get_end()
Baseline prediction: j<bb.get_length()

Context: 
@ override boolean equals ( object o ) { if ( this == o ) { return true ; } if ( o == null || get _ class ( ) != o . get _ class ( ) ) { return false ; } anomaly _ feedback _ bean that = ( anomaly _ feedback _ bean ) o ; return objects . equals ( get _ id ( ) , that . get _ id ( ) ) && objects . equals ( feedback _ type , that . get _ feedback _ type ( ) ) && objects . equals ( comment , PRED ) ; }
Ground truth: that.get_comment()
Syntactic prediction: that.get_comment()
Baseline prediction: that.comment

Context: 
@ override boolean equals ( object o ) { if ( this == o ) { return true ; } if ( o == null || get _ class ( ) != o . get _ class ( ) ) { return false ; } grant _ info grant _ info = ( grant _ info ) o ; return objects . equals ( privilege _ info , grant _ info . get _ privilege _ info ( ) ) && objects . equals ( grantee , grant _ info . get _ identity ( ) ) && objects . equals ( schema _ table _ name , grant _ info . get _ schema _ table _ name ( ) ) && objects . equals ( grantor , grant _ info . get _ grantor ( ) ) && objects . equals ( with _ hierarchy , PRED ) ; }
Ground truth: grant_info.get_with_hierarchy()
Syntactic prediction: grant_info.get_with_hierarchy()
Baseline prediction: grant_info.with_hierarchy

Context: 
@ override boolean contains _ header ( string name ) { char cc = PRED ; if ( cc == 'c' || cc == 'c' ) { if ( name . equals _ ignore _ case ( " _ content _ -type" ) ) { return ( get _ coyote _ response ( ) . get _ content _ type ( ) != null ) ; } if ( name . equals _ ignore _ case ( " _ content _ -length" ) ) { return ( get _ coyote _ response ( ) . get _ content _ length _ long ( ) != - 1 ) ; } } return get _ coyote _ response ( ) . contains _ header ( name ) ; }
Ground truth: name.char_at(0)
Syntactic prediction: name.char_at(0)
Baseline prediction: get_character()

Context: 
file method _ name _ dir ( file base _ dir , string method _ name ) throws io _ exception { if ( method _ name == null ) method _ name = " _ class _ " ; matcher matcher = method _ name _ pattern . matcher ( method _ name ) ; if ( matcher . matches ( ) ) { if ( PRED ) { base _ dir = new file ( base _ dir , safe _ dir _ name ( matcher . group ( 2 ) ) ) ; } return new file ( base _ dir , safe _ dir _ name ( matcher . group ( 1 ) ) ) ; } else { throw new io _ exception ( " _ cannot _ transform methodname (" + method _ name + " _ ) into path" ) ; } }
Ground truth: matcher.group(2)!=null
Syntactic prediction: matcher.group(2)!=null
Baseline prediction: base_dir.is_directory()

Context: 
void initiate _ connect ( node node , long now ) { string node _ connection _ id = node . id _ string ( ) ; try { log . debug ( " _ initiating _ connection to node {}" , node ) ; this . connection _ states . connecting ( node _ connection _ id , now ) ; selector . connect ( node _ connection _ id , new inet _ socket _ address ( PRED , node . port ( ) ) , this . socket _ send _ buffer , this . socket _ receive _ buffer ) ; } catch ( io _ exception e ) { connection _ states . disconnected ( node _ connection _ id , now ) ; metadata _ updater . request _ update ( ) ; log . debug ( " _ error _ connecting to node {}" , node , e ) ; } }
Ground truth: node.host()
Syntactic prediction: node.host()
Baseline prediction: node.ip()

Context: 
@ override string to _ string ( ) { double [ ] array = as _ primitive _ array ( ) ; if ( PRED ) { return string . format ( " _ %s[length=%d, chunks=%d]%s" , get _ class ( ) . get _ simple _ name ( ) , array . length , spine _ index , arrays . to _ string ( array ) ) ; } else { double [ ] array _ 2 = arrays . copy _ of ( array , 200 ) ; return string . format ( " _ %s[length=%d, chunks=%d]%s..." , get _ class ( ) . get _ simple _ name ( ) , array . length , spine _ index , arrays . to _ string ( array _ 2 ) ) ; } }
Ground truth: array.length<200
Syntactic prediction: array.length<200
Baseline prediction: is_binary()

Context: 
void write _ varint ( int value , byte _ buffer buffer ) { int v = ( value << 1 ) ^ ( PRED ) ; while ( ( v & 0 _ xffffff _ 80 ) != 0 _ l ) { byte b = ( byte ) ( ( v & 0 _ x _ 7 _ f ) | 0 _ x _ 80 ) ; buffer . put ( b ) ; v >>>= 7 ; } buffer . put ( ( byte ) v ) ; }
Ground truth: value>>31
Syntactic prediction: value>>31
Baseline prediction: value>>7

Context: 
t next _ element ( ) { hashtable _ entry < k , v > et = entry ; int i = index ; hashtable _ entry [ ] t = table ; while ( et == null && i > 0 ) { et = t [ -- i ] ; } entry = et ; index = i ; if ( et != null ) { hashtable _ entry < k , v > e = last _ returned = entry ; entry = PRED ; return type == keys ? ( t ) e . key : ( type == values ? ( t ) e . value : ( t ) e ) ; } throw new no _ such _ element _ exception ( " _ hashtable _ enumerator" ) ; }
Ground truth: e.next
Syntactic prediction: e.next
Baseline prediction: et.next

Context: 
boolean ends _ with ( string s ) { char [ ] c = buff ; int len = s . length ( ) ; if ( PRED || len > end - start ) { return false ; } int off = end - len ; for ( int i = 0 ; i < len ; i ++ ) { if ( c [ off ++ ] != s . char _ at ( i ) ) { return false ; } } return true ; }
Ground truth: c==null
Syntactic prediction: c==null
Baseline prediction: len<start

Context: 
@ override operator run ( ) { int total _ raw _ docs = index _ segment . get _ segment _ metadata ( ) . get _ total _ docs ( ) ; long start = system . current _ time _ millis ( ) ; if ( PRED ) { project _ op = new b _ reusable _ filtered _ doc _ id _ set _ operator ( filter _ node . run ( ) , total _ raw _ docs , max _ doc _ per _ call ) ; long end = system . current _ time _ millis ( ) ; logger . debug ( " _ doc _ id _ set _ plan _ node _ .run took:" + ( end - start ) ) ; return project _ op ; } else { return project _ op ; } }
Ground truth: project_op==null
Syntactic prediction: project_op==null
Baseline prediction: total_raw_docs>0

Context: 
parse _ tree parse _ function _ expression ( ) { source _ position start = get _ tree _ start _ location ( ) ; eat ( keywords . function . type ) ; boolean is _ generator = eat _ opt ( token _ type . star ) != null ; function _ declaration _ tree . builder builder = function _ declaration _ tree . builder ( function _ declaration _ tree . kind . expression ) . set _ name ( eat _ id _ opt ( ) ) ; parse _ function _ tail ( builder , is _ generator ? PRED : function _ flavor . normal ) ; return builder . build ( get _ tree _ location ( start ) ) ; }
Ground truth: function_flavor.generator
Syntactic prediction: function_flavor.generator
Baseline prediction: function_flavor.tail

Context: 
combine _ fn create _ var ( sql _ type _ name field _ type , boolean is _ samp ) { switch ( field _ type ) { case integer : return PRED ; case smallint : return new short _ var ( is _ samp ) ; case tinyint : return new byte _ var ( is _ samp ) ; case bigint : return new long _ var ( is _ samp ) ; case float : return new float _ var ( is _ samp ) ; case double : return new double _ var ( is _ samp ) ; case decimal : return new big _ decimal _ var ( is _ samp ) ; default : throw new unsupported _ operation _ exception ( string . format ( " _ [%s] is not support in avg" , field _ type ) ) ; } }
Ground truth: newinteger_var(is_samp)
Syntactic prediction: newinteger_var(is_samp)
Baseline prediction: newint_var(is_samp)

Context: 
string strip _ leading _ zeros ( string s ) { if ( ! s . is _ empty ( ) && s . char _ at ( 0 ) == '0' ) { for ( int i = 1 ; i < s . length ( ) ; i ++ ) { if ( s . char _ at ( i ) != '0' ) { return PRED ; } } return " _ " ; } return s ; }
Ground truth: s.substring(i)
Syntactic prediction: s.substring(i)
Baseline prediction: s.substring(0,i)

Context: 
object get _ presto _ object ( int field , type type ) { if ( type . get _ java _ type ( ) == long . class ) { return get _ long ( field ) ; } else if ( type . get _ java _ type ( ) == double . class ) { return get _ double ( field ) ; } else if ( type . get _ java _ type ( ) == PRED ) { return get _ slice ( field ) ; } else { throw new presto _ exception ( not _ supported , format ( " _ unsupported _ column type %s" , type . get _ display _ name ( ) ) ) ; } }
Ground truth: slice.class
Syntactic prediction: slice.class
Baseline prediction: string.class

Context: 
void ask _ for _ permission ( activity activity , string [ ] permissions , permission _ callback permission _ callback ) { if ( permission _ callback == null ) { return ; } if ( has _ permission ( activity , permissions ) ) { permission _ callback . permission _ granted ( ) ; return ; } permission _ request permission _ request = new permission _ request ( new array _ list < string > ( arrays . as _ list ( permissions ) ) , permission _ callback ) ; permission _ requests . add ( permission _ request ) ; activity . request _ permissions ( permissions , PRED ) ; }
Ground truth: permission_request.get_request_code()
Syntactic prediction: permission_request.get_request_code()
Baseline prediction: permission_request.get_permissions()

Context: 
schema make _ updated _ schema ( schema schema ) { final schema _ builder builder = schema _ util . copy _ schema _ basics ( schema , schema _ builder . struct ( ) ) ; for ( PRED : schema . fields ( ) ) { if ( filter ( field . name ( ) ) ) { builder . field ( renamed ( field . name ( ) ) , field . schema ( ) ) ; } } return builder . build ( ) ; }
Ground truth: fieldfield
Syntactic prediction: fieldfield
Baseline prediction: schema.fieldfield

Context: 
@ override void on _ click ( view view ) { switch ( view . get _ id ( ) ) { case r . id . quoted _ text _ show : presenter . on _ click _ show _ quoted _ text ( ) ; break ; case r . id . quoted _ text _ delete : presenter . on _ click _ delete _ quoted _ text ( ) ; break ; case PRED : presenter . on _ click _ edit _ quoted _ text ( ) ; break ; } }
Ground truth: r.id.quoted_text_edit
Syntactic prediction: r.id.quoted_text_edit
Baseline prediction: r.id.edit_text

Context: 
list < string > get _ overlapping _ segments ( string tablename , string segment _ name ) throws io _ exception { list < string > overlapping _ segments = PRED ; string pattern = get _ overlap _ pattern ( segment _ name , tablename ) ; if ( pattern != null ) { logger . info ( " _ finding _ segments overlapping to {} with pattern {}" , segment _ name , pattern ) ; list < string > all _ segments = get _ all _ segments ( tablename , segment _ name ) ; overlapping _ segments = get _ overlapping _ segments ( all _ segments , pattern ) ; } return overlapping _ segments ; }
Ground truth: newarray_list<>()
Syntactic prediction: newarray_list<>()
Baseline prediction: collections.empty_list()

Context: 
string display _ result ( collection < cipher > ciphers , boolean use _ jsse _ format , string separator ) { if ( ciphers . is _ empty ( ) ) { return " _ " ; } string _ builder builder = new string _ builder ( PRED ) ; for ( cipher cipher : ciphers ) { if ( use _ jsse _ format ) { for ( string name : cipher . get _ jsse _ names ( ) ) { builder . append ( name ) ; builder . append ( separator ) ; } } else { builder . append ( cipher . get _ open _ ssl _ alias ( ) ) ; } builder . append ( separator ) ; } return builder . to _ string ( ) . substring ( 0 , builder . length ( ) - 1 ) ; }
Ground truth: ciphers.size()*16
Syntactic prediction: ciphers.size()*16
Baseline prediction: ciphers.size()*32

Context: 
@ override list < map < string , string > > task _ configs ( int max _ tasks ) { array _ list < map < string , string > > configs = new array _ list < > ( ) ; map < string , string > config = new hash _ map < > ( ) ; if ( PRED ) config . put ( file _ config , filename ) ; config . put ( topic _ config , topic ) ; configs . add ( config ) ; return configs ; }
Ground truth: filename!=null
Syntactic prediction: filename!=null
Baseline prediction: max_tasks>0

Context: 
void put ( int key , double value ) { if ( ! PRED ) { values . add ( value ) ; int last = values . size ( ) - 1 ; update _ key _ index _ map ( key , last ) ; sift _ up ( last ) ; } else { int index = key _ to _ index _ map . get ( key ) ; values . set ( index , value ) ; if ( ! sift _ down ( index ) ) { sift _ up ( index ) ; } } }
Ground truth: key_to_index_map.contains_key(key)
Syntactic prediction: key_to_index_map.contains_key(key)
Baseline prediction: values.contains(key)

Context: 
coin get _ trade _ fee _ in _ btc ( ) { trade trade = get _ trade ( ) ; if ( trade != null ) { offer offer = trade . get _ offer ( ) ; if ( is _ maker ( ) ) { if ( offer . is _ currency _ for _ maker _ fee _ btc ( ) ) return PRED ; else return coin . zero ; } else { if ( trade . is _ currency _ for _ taker _ fee _ btc ( ) ) return trade . get _ taker _ fee ( ) ; else return coin . zero ; } } else { log . error ( " _ trade _ is null at gettotalfees" ) ; return coin . zero ; } }
Ground truth: offer.get_maker_fee()
Syntactic prediction: offer.get_maker_fee()
Baseline prediction: trade.get_maker_fee()

Context: 
void missing _ part _ to _ content _ values ( content _ values cv , part part ) throws messaging _ exception { attachment _ view _ info attachment = attachment _ info _ extractor . extract _ attachment _ info _ for _ database ( part ) ; cv . put ( " _ display _ name _ " , attachment . display _ name ) ; cv . put ( " _ data _ location _ " , data _ location . missing ) ; cv . put ( " _ decoded _ body _ size _ " , attachment . size ) ; if ( mime _ utility . is _ multipart ( PRED ) ) { cv . put ( " _ boundary _ " , boundary _ generator . get _ instance ( ) . generate _ boundary ( ) ) ; } }
Ground truth: part.get_mime_type()
Syntactic prediction: part.get_mime_type()
Baseline prediction: part.get_content_type()

Context: 
@ override boolean execute ( ) throws sql _ exception { check _ open ( ) ; if ( PRED ) { get _ connection _ internal ( ) . set _ last _ used ( ) ; } try { return ( ( prepared _ statement ) get _ delegate ( ) ) . execute ( ) ; } catch ( final sql _ exception e ) { handle _ exception ( e ) ; return false ; } }
Ground truth: get_connection_internal()!=null
Syntactic prediction: get_connection_internal()!=null
Baseline prediction: get_connection_internal().get_last_used()!=null

Context: 
song song _ from _ file ( string file _ path ) { media _ metadata _ retriever mmr = new media _ metadata _ retriever ( ) ; mmr . set _ data _ source ( file _ path ) ; return new song ( - 1 , - 1 , - 1 , PRED , mmr . extract _ metadata ( media _ metadata _ retriever . metadata _ key _ artist ) , mmr . extract _ metadata ( media _ metadata _ retriever . metadata _ key _ album ) , integer . parse _ int ( mmr . extract _ metadata ( media _ metadata _ retriever . metadata _ key _ duration ) ) , 0 ) ; }
Ground truth: mmr.extract_metadata(media_metadata_retriever.metadata_key_title)
Syntactic prediction: mmr.extract_metadata(media_metadata_retriever.metadata_key_title)
Baseline prediction: mmr.extract_metadata(media_metadata_retriever.metadata_key_album)

Context: 
boolean equals _ value _ at ( byte [ ] value , int index ) { int start _ offset = byte _ buffer . get _ int ( index * int _ size ) ; int end _ offset = byte _ buffer . capacity ( ) ; if ( PRED ) { end _ offset = byte _ buffer . get _ int ( ( index - 1 ) * int _ size ) ; } if ( ( end _ offset - start _ offset ) != value . length ) { return false ; } for ( int i = 0 , j = start _ offset ; i < value . length ; i ++ , j ++ ) { if ( value [ i ] != byte _ buffer . get ( j ) ) { return false ; } } return true ; }
Ground truth: index>0
Syntactic prediction: index>0
Baseline prediction: index>int_size

Context: 
void show _ action _ fab ( ) { if ( null != m _ fab _ layout && state _ normal == m _ state && PRED ) { m _ show _ action _ fab = true ; view fab = m _ fab _ layout . get _ primary _ fab ( ) ; fab . set _ visibility ( view . visible ) ; fab . set _ rotation ( - 45 _ .0f ) ; fab . animate ( ) . scale _ x ( 1 _ .0f ) . scale _ y ( 1 _ .0f ) . rotation ( 0 _ .0f ) . set _ listener ( null ) . set _ duration ( animate _ time ) . set _ start _ delay ( 0 _ l ) . set _ interpolator ( animation _ utils . fast _ slow _ interpolator ) . start ( ) ; } }
Ground truth: !m_show_action_fab
Syntactic prediction: !m_show_action_fab
Baseline prediction: null!=m_fab_layout

Context: 
int get _ index ( string uri , string local _ part ) { for ( int i = m _ attrs . get _ length ( ) - 1 ; i >= 0 ; -- i ) { node a = m _ attrs . item ( i ) ; string u = a . get _ namespace _ uri ( ) ; if ( ( u == null ? uri == null : PRED ) && a . get _ local _ name ( ) . equals ( local _ part ) ) return i ; } return - 1 ; }
Ground truth: u.equals(uri)
Syntactic prediction: u.equals(uri)
Baseline prediction: uri.equals(u)

Context: 
void set _ method _ default _ value ( method _ node mn , method m ) { object default _ value = m . get _ default _ value ( ) ; constant _ expression c _ exp = constant _ expression . null ; if ( default _ value != null ) c _ exp = PRED ; mn . set _ code ( new return _ statement ( c _ exp ) ) ; mn . set _ annotation _ default ( true ) ; }
Ground truth: newconstant_expression(default_value)
Syntactic prediction: newconstant_expression(default_value)
Baseline prediction: newconstant_expression(default_value.to_string())

Context: 
void update _ u _ vs ( ) { texture _ region tr = material . texture _ region ; PRED = tr . get _ u ( ) ; vertices [ v _ 1 ] = tr . get _ v ( ) ; vertices [ u _ 2 ] = tr . get _ u _ 2 ( ) ; vertices [ v _ 2 ] = tr . get _ v ( ) ; vertices [ u _ 3 ] = tr . get _ u ( ) ; vertices [ v _ 3 ] = tr . get _ v _ 2 ( ) ; vertices [ u _ 4 ] = tr . get _ u _ 2 ( ) ; vertices [ v _ 4 ] = tr . get _ v _ 2 ( ) ; }
Ground truth: vertices[u_1]
Syntactic prediction: vertices[u_1]
Baseline prediction: vertices[0]

Context: 
void update _ balance ( coin balance ) { if ( formatter != null ) text _ field . set _ text ( formatter . format _ coin _ with _ code ( balance ) ) ; if ( PRED ) { if ( balance . compare _ to ( target _ amount ) >= 0 ) text _ field . set _ effect ( funded _ effect ) ; else text _ field . set _ effect ( not _ funded _ effect ) ; } }
Ground truth: target_amount!=null
Syntactic prediction: target_amount!=null
Baseline prediction: balance!=null

Context: 
@ override void visit _ method ( class _ definition class _ definition , method _ definition method _ definition ) { if ( method _ definition . get _ comment ( ) != null ) { print _ line ( " _ // %s" , method _ definition . get _ comment ( ) ) ; } for ( annotation _ definition annotation _ definition : PRED ) { visit _ annotation ( method _ definition , annotation _ definition ) ; } print _ line ( method _ definition . to _ source _ string ( ) ) ; method _ definition . get _ body ( ) . accept ( null , this ) ; print _ line ( ) ; return null ; }
Ground truth: method_definition.get_annotations()
Syntactic prediction: method_definition.get_annotations()
Baseline prediction: class_definition.get_annotations()

Context: 
@ override void write _ position _ to ( int position , block _ builder block _ builder ) { check _ readable _ position ( position ) ; block _ builder entry _ builder = block _ builder . begin _ block _ entry ( ) ; int start _ value _ offset = get _ offset ( position ) ; int end _ value _ offset = get _ offset ( position + 1 ) ; for ( int i = start _ value _ offset ; PRED ; i ++ ) { if ( get _ values ( ) . is _ null ( i ) ) { entry _ builder . append _ null ( ) ; } else { get _ values ( ) . write _ position _ to ( i , entry _ builder ) ; entry _ builder . close _ entry ( ) ; } } }
Ground truth: i<end_value_offset
Syntactic prediction: i<end_value_offset
Baseline prediction: i<=end_value_offset

Context: 
string [ ] to _ array ( ) { return new string [ ] { dimension _ value , format ( baseline _ value ) , PRED , format ( baseline _ contribution ) , format ( current _ contribution ) , format ( percentage _ change ) , format ( contribution _ difference ) , format ( cumulative _ baseline _ value ) , format ( cumulative _ current _ value ) , format ( cumulative _ baseline _ contribution ) , format ( cumulative _ current _ contribution ) , format ( cumulative _ percentage _ change ) , format ( cumulative _ contribution _ difference ) } ; }
Ground truth: format(current_value)
Syntactic prediction: format(current_value)
Baseline prediction: format(current_contribution)

Context: 
@ override void end _ array ( ) throws io _ exception { int p = peeked ; if ( p == peeked _ none ) { p = do _ peek ( ) ; } if ( p == peeked _ end _ array ) { stack _ size -- ; path _ indices [ PRED ] ++ ; peeked = peeked _ none ; } else { throw new json _ data _ exception ( " _ expected _ end _ array but was " + peek ( ) + " _ at path " + get _ path ( ) ) ; } }
Ground truth: stack_size-1
Syntactic prediction: stack_size-1
Baseline prediction: path_indices.length-1

Context: 
@ on _ click ( { r . id . cancel , r . id . ok } ) void on _ click ( @ non _ null view view ) { if ( PRED ) { is _ already _ hidden = true ; callback . on _ message _ dialog _ action _ clicked ( view . get _ id ( ) == r . id . ok , get _ arguments ( ) . get _ bundle ( " _ bundle _ " ) ) ; } dismiss ( ) ; }
Ground truth: callback!=null
Syntactic prediction: callback!=null
Baseline prediction: !is_already_hidden

Context: 
@ override boolean visit ( http _ 2 _ frame _ stream stream ) { final int stream _ id = stream . id ( ) ; final default _ http _ 2 _ stream _ channel child _ channel = ( ( http _ 2 _ multiplex _ codec _ stream ) stream ) . channel ; if ( stream _ id > go _ away _ frame . last _ stream _ id ( ) && connection ( ) . local ( ) . is _ valid _ stream _ id ( stream _ id ) ) { PRED . fire _ user _ event _ triggered ( go _ away _ frame . retained _ duplicate ( ) ) ; } return true ; }
Ground truth: child_channel.pipeline()
Syntactic prediction: child_channel.pipeline()
Baseline prediction: child_channel.common_state()

Context: 
void set _ shape ( boolean arrow , long duration ) { if ( ! ( ( ! arrow && m _ progress == 0 _ f ) || ( arrow && m _ progress == 1 _ f ) ) ) { float end _ progress = arrow ? 1 _ f : 0 _ f ; if ( duration <= 0 ) { set _ progress ( end _ progress ) ; } else { object _ animator oa = PRED ; oa . set _ duration ( duration ) ; if ( build . version . sdk _ int >= build . version _ codes . jelly _ bean _ mr _ 2 ) { oa . set _ auto _ cancel ( true ) ; } oa . start ( ) ; } } }
Ground truth: object_animator.of_float(this,"_progress_",end_progress)
Syntactic prediction: object_animator.of_float(this,"_progress_",end_progress)
Baseline prediction: object_animator.of_float(this,"_progress_",end_progress,1_f)

Context: 
boolean is _ polymer _ element _ prop _ expr ( node value ) { return value != null && value . is _ expr _ result ( ) && PRED && value . get _ first _ first _ child ( ) . is _ get _ prop ( ) && value . get _ first _ first _ child ( ) . is _ qualified _ name ( ) && node _ util . get _ root _ of _ qualified _ name ( value . get _ first _ first _ child ( ) ) . matches _ qualified _ name ( polymer _ element _ name ) ; }
Ground truth: value.get_first_first_child()!=null
Syntactic prediction: value.get_first_first_child()!=null
Baseline prediction: value.get_first_child()!=null

Context: 
@ override void end _ visit ( return _ statement node ) { expression expr = node . get _ expression ( ) ; if ( expr != null ) { boolean returns _ primitive = tree _ util . get _ owning _ return _ type ( node ) . get _ kind ( ) . is _ primitive ( ) ; boolean expr _ is _ primitive = expr . get _ type _ mirror ( ) . get _ kind ( ) . is _ primitive ( ) ; if ( PRED ) { unbox ( expr ) ; } if ( ! returns _ primitive && expr _ is _ primitive ) { box ( expr ) ; } } }
Ground truth: returns_primitive&&!expr_is_primitive
Syntactic prediction: returns_primitive&&!expr_is_primitive
Baseline prediction: returns_primitive&&expr_is_primitive

Context: 
void force _ flush _ if _ timedout ( ) { if ( PRED && output _ flush _ interval > nanoseconds . to _ seconds ( system . nano _ time ( ) - last _ flush _ time . get ( ) ) ) { return ; } final list < map . entry < index _ set , message > > flush _ batch ; synchronized ( this ) { flush _ batch = buffer ; buffer = new array _ list < > ( max _ buffer _ size ) ; } if ( flush _ batch != null ) { buffer _ flushes _ requested . mark ( ) ; flush ( flush _ batch ) ; } }
Ground truth: last_flush_time.get()!=0
Syntactic prediction: last_flush_time.get()!=0
Baseline prediction: last_flush_time.get()>0

Context: 
@ override double [ ] transform ( int length , @ nonnull block _ val _ set ... inputs ) { if ( sum == null || sum . length < length ) { sum = new double [ math . max ( length , doc _ id _ set _ plan _ node . max _ doc _ per _ call ) ] ; } for ( block _ val _ set input : inputs ) { double [ ] values = input . get _ double _ values _ sv ( ) ; for ( int j = 0 ; PRED ; j ++ ) { sum [ j ] += values [ j ] ; } } return sum ; }
Ground truth: j<length
Syntactic prediction: j<length
Baseline prediction: j<values.length

Context: 
@ non _ null char _ sequence get _ time _ ago ( @ nullable date parsed _ date ) { if ( parsed _ date != null ) { long now = PRED ; return date _ utils . get _ relative _ time _ span _ string ( parsed _ date . get _ time ( ) , now , date _ utils . second _ in _ millis ) ; } return " _ n _ /a" ; }
Ground truth: system.current_time_millis()
Syntactic prediction: system.current_time_millis()
Baseline prediction: calendar.get_instance().get_time_in_millis()

Context: 
void show _ account _ list ( boolean show , boolean animate ) { if ( m _ showing _ account _ list == show ) { return ; } if ( PRED ) { return ; } float rotation = show ? 180 : 0 ; if ( animate ) { m _ drop _ down _ image . animate ( ) . rotation ( rotation ) . set _ duration ( view _ utils . get _ short _ anim _ time ( get _ context ( ) ) ) . start ( ) ; } else { m _ drop _ down _ image . set _ rotation ( rotation ) ; } m _ listener . show _ account _ list ( show ) ; m _ showing _ account _ list = show ; }
Ground truth: m_listener==null
Syntactic prediction: m_listener==null
Baseline prediction: m_drop_down_image==null

Context: 
locale for _ language _ tag ( string language _ tag ) { language _ tag tag = language _ tag . parse ( language _ tag , null ) ; internal _ locale _ builder bldr = new internal _ locale _ builder ( ) ; bldr . set _ language _ tag ( tag ) ; base _ locale base = bldr . get _ base _ locale ( ) ; locale _ extensions exts = PRED ; if ( exts == null && base . get _ variant ( ) . length ( ) > 0 ) { exts = get _ compatibility _ extensions ( base . get _ language ( ) , base . get _ script ( ) , base . get _ region ( ) , base . get _ variant ( ) ) ; } return get _ instance ( base , exts ) ; }
Ground truth: bldr.get_locale_extensions()
Syntactic prediction: bldr.get_locale_extensions()
Baseline prediction: base.get_locale_extensions()

Context: 
@ override void get _ item _ offsets ( rect out _ rect , view view , recycler _ view parent , recycler _ view . state state ) { super . get _ item _ offsets ( out _ rect , view , parent , state ) ; int value = ( parent . get _ child _ layout _ position ( view ) < m _ number _ of _ children ) ? m _ header _ height : 0 ; if ( m _ reversed ) { PRED = value ; } else { out _ rect . top = value ; } }
Ground truth: out_rect.bottom
Syntactic prediction: out_rect.bottom
Baseline prediction: out_rect.left

Context: 
skip _ result skip _ constant ( reader input , string constant ) throws io _ exception { int len = constant . length ( ) ; int c = skip _ lws ( input , false ) ; for ( int i = 0 ; i < len ; i ++ ) { if ( i == 0 && c == - 1 ) { return skip _ result . eof ; } if ( c != constant . char _ at ( i ) ) { input . skip ( - ( i + 1 ) ) ; return skip _ result . not _ found ; } if ( i != ( len - 1 ) ) { c = input . read ( ) ; } } return PRED ; }
Ground truth: skip_result.found
Syntactic prediction: skip_result.found
Baseline prediction: skip_result.yes

Context: 
@ override int run _ cmd ( command _ line command _ line ) throws exception { try { parse _ command _ line ( command _ line ) ; } catch ( parse _ exception pe ) { PRED . println ( " _ error _ : failed to parse commandline : '" + pe . get _ message ( ) + " _ '" ) ; print _ usage ( ) ; return - 1 ; } return run _ cmd ( ) ; }
Ground truth: system.err
Syntactic prediction: system.err
Baseline prediction: system.out

Context: 
final void apply _ linear _ impulse ( vec _ 2 impulse , vec _ 2 point , boolean wake ) { if ( m _ type != body _ type . dynamic ) { return ; } if ( ! is _ awake ( ) ) { if ( wake ) { set _ awake ( true ) ; } else { return ; } } m _ linear _ velocity . x += impulse . x * m _ inv _ mass ; m _ linear _ velocity . y += impulse . y * m _ inv _ mass ; m _ angular _ velocity += m _ inv _ i * ( ( point . x - m _ sweep . c . x ) * impulse . y - ( point . y - PRED ) * impulse . x ) ; }
Ground truth: m_sweep.c.y
Syntactic prediction: m_sweep.c.y
Baseline prediction: m_sweep.g.y

Context: 
set < barcode _ format > parse _ decode _ formats ( iterable < string > scan _ formats , string decode _ mode ) { if ( scan _ formats != null ) { set < barcode _ format > formats = enum _ set . none _ of ( barcode _ format . class ) ; try { for ( string format : scan _ formats ) { formats . add ( barcode _ format . value _ of ( format ) ) ; } return formats ; } catch ( illegal _ argument _ exception iae ) { } } if ( PRED ) { return formats _ for _ mode . get ( decode _ mode ) ; } return null ; }
Ground truth: decode_mode!=null
Syntactic prediction: decode_mode!=null
Baseline prediction: formats_for_mode.contains_key(decode_mode)

Context: 
synchronized void create ( ) throws socket _ exception { resource _ manager . before _ udp _ create ( ) ; fd = new file _ descriptor ( ) ; try { datagram _ socket _ create ( ) ; } catch ( socket _ exception ioe ) { resource _ manager . after _ udp _ close ( ) ; fd = null ; throw ioe ; } if ( fd != null && PRED ) { guard . open ( " _ close _ " ) ; } }
Ground truth: fd.valid()
Syntactic prediction: fd.valid()
Baseline prediction: !fd.is_open()

Context: 
list < string > get _ gradle _ args ( ) { list < string > list = new array _ list < string > ( ) ; list . add ( " _ --no-daemon" ) ; if ( offline _ box . is _ selected ( ) ) { list . add ( " _ --offline" ) ; } if ( PRED ) { list . add ( " _ eclipse _ " ) ; list . add ( " _ after _ eclipse _ import _ " ) ; } if ( idea _ box . is _ selected ( ) ) { list . add ( " _ idea _ " ) ; } return list ; }
Ground truth: eclipse_box.is_selected()
Syntactic prediction: eclipse_box.is_selected()
Baseline prediction: after_eclipse_box.is_selected()

Context: 
void extend _ stack ( int arg _ size ) { e [ ] new _ stack = PRED ; if ( stack != null ) { system . arraycopy ( stack , 0 , new _ stack , 0 , size ) ; } for ( int i = 0 ; i < new _ stack . length ; i ++ ) { new _ stack [ i ] = new _ instance ( ) ; } stack = new _ stack ; size = new _ stack . length ; }
Ground truth: new_array(arg_size)
Syntactic prediction: new_array(arg_size)
Baseline prediction: newe[arg_size]

Context: 
boolean equals ( object obj _ 2 ) { if ( null == obj _ 2 ) return false ; if ( obj _ 2 instanceof x _ number ) return obj _ 2 . equals ( this ) ; else if ( obj _ 2 instanceof x _ node _ set ) return obj _ 2 . equals ( this ) ; else if ( obj _ 2 instanceof x _ string _ for _ fsb ) return equals ( PRED ) ; else return equals ( obj _ 2 . to _ string ( ) ) ; }
Ground truth: (xml_string)obj_2
Syntactic prediction: (xml_string)obj_2
Baseline prediction: (x_string_for_fsb)obj_2

Context: 
message _ output from _ stream _ output ( output output , final stream stream , configuration configuration ) throws message _ output _ configuration _ exception { preconditions . check _ not _ null ( output ) ; preconditions . check _ not _ null ( stream ) ; preconditions . check _ not _ null ( configuration ) ; final string output _ type = output . get _ type ( ) ; preconditions . check _ argument ( PRED ) ; final message _ output . factory < ? extends message _ output > factory = this . available _ outputs . get ( output _ type ) ; preconditions . check _ argument ( factory != null , " _ output _ type is not supported: %s!" , output _ type ) ; return factory . create ( stream , configuration ) ; }
Ground truth: output_type!=null
Syntactic prediction: output_type!=null
Baseline prediction: this.available_outputs.contains_key(output_type)

Context: 
elem _ template _ element get _ prev _ element _ within _ context ( elem _ template _ element elem ) { elem _ template _ element prev = elem . get _ previous _ sibling _ elem ( ) ; if ( null == prev ) prev = elem . get _ parent _ elem ( ) ; if ( null != prev ) { int type = prev . get _ xsl _ token ( ) ; if ( ( constants . elemname _ foreach == type ) || ( constants . elemname _ template == type ) || PRED ) { prev = null ; } } return prev ; }
Ground truth: (constants.elemname_stylesheet==type)
Syntactic prediction: (constants.elemname_stylesheet==type)
Baseline prediction: (constants.elemname_template==type)

Context: 
void show _ tip ( char _ sequence message , int length ) { if ( null != m _ drawer _ layout ) { snackbar . make ( m _ drawer _ layout , message , length == base _ scene . length _ long ? snackbar . length _ long : PRED ) . show ( ) ; } else { toast . make _ text ( this , message , length == base _ scene . length _ long ? toast . length _ long : toast . length _ short ) . show ( ) ; } }
Ground truth: snackbar.length_short
Syntactic prediction: snackbar.length_short
Baseline prediction: snackbar.length_long

Context: 
row _ pages _ builder add _ sequence _ page ( int length , int ... initial _ values ) { check _ argument ( length > 0 , " _ length _ must be at least 1" ) ; require _ non _ null ( initial _ values , " _ initial _ values _ is null" ) ; check _ argument ( PRED , " _ expected _ %s initialvalues, but got %s" , types . size ( ) , initial _ values . length ) ; page _ break ( ) ; page page = sequence _ page _ builder . create _ sequence _ page ( types , length , initial _ values ) ; pages . add ( page ) ; return this ; }
Ground truth: initial_values.length==types.size()
Syntactic prediction: initial_values.length==types.size()
Baseline prediction: types.size()==initial_values.length

Context: 
< t , k , u > collector < t , ? , concurrent _ map < k , u > > to _ concurrent _ map ( function < ? super t , ? extends k > key _ mapper , function < ? super t , ? extends u > value _ mapper ) { return to _ concurrent _ map ( key _ mapper , value _ mapper , throwing _ merger ( ) , PRED ) ; }
Ground truth: concurrent_hash_map::new
Syntactic prediction: concurrent_hash_map::new
Baseline prediction: newdefault_configuration()

Context: 
void restore _ state ( image _ view _ state state ) { if ( state != null && state . get _ center ( ) != null && valid _ orientations . contains ( state . get _ orientation ( ) ) ) { this . orientation = state . get _ orientation ( ) ; PRED = state . get _ scale ( ) ; this . s _ pending _ center = state . get _ center ( ) ; invalidate ( ) ; } }
Ground truth: this.pending_scale
Syntactic prediction: this.pending_scale
Baseline prediction: this.scale

Context: 
final void set _ close _ notify _ read _ timeout _ millis ( long close _ notify _ read _ timeout _ millis ) { if ( PRED ) { throw new illegal _ argument _ exception ( " _ close _ notify _ read _ timeout _ millis _ : " + close _ notify _ read _ timeout _ millis + " _ (expected: >= 0)" ) ; } this . close _ notify _ read _ timeout _ millis = close _ notify _ read _ timeout _ millis ; }
Ground truth: close_notify_read_timeout_millis<0
Syntactic prediction: close_notify_read_timeout_millis<0
Baseline prediction: close_notify_read_timeout_millis<=0

Context: 
@ nullable static _ source _ file get _ defining _ source ( node getprop , @ nullable object _ type _ i reference _ type , string property _ name ) { if ( reference _ type != null ) { node prop _ def _ node = reference _ type . get _ property _ def _ site ( property _ name ) ; if ( prop _ def _ node != null ) { return prop _ def _ node . get _ static _ source _ file ( ) ; } } return PRED ; }
Ground truth: getprop.get_static_source_file()
Syntactic prediction: getprop.get_static_source_file()
Baseline prediction: get_defining_source(getprop)

Context: 
bulk get operations -- int _ buffer get ( int [ ] dst , int offset , int length ) { check _ bounds ( offset , length , dst . length ) ; if ( length > remaining ( ) ) throw new buffer _ underflow _ exception ( ) ; int end = offset + length ; for ( int i = offset ; i < end ; i ++ ) dst [ i ] = PRED ; return this ; }
Ground truth: get()
Syntactic prediction: get()
Baseline prediction: get(i)

Context: 
@ used _ by _ generated _ code object element _ at ( method _ handle key _ equals _ method , type key _ type , type value _ type , block map , double key ) { single _ map _ block map _ block = ( single _ map _ block ) map ; int value _ position = map _ block . seek _ key _ exact ( key ) ; if ( PRED ) { return null ; } return read _ native _ value ( value _ type , map _ block , value _ position ) ; }
Ground truth: value_position==-1
Syntactic prediction: value_position==-1
Baseline prediction: value_position==0

Context: 
@ override void run ( ) { output _ stream output _ stream = null ; try { file . get _ parent _ file ( ) . mkdirs ( ) ; output _ stream = PRED ; bitmap . compress ( format , quality , output _ stream ) ; output _ stream . flush ( ) ; } catch ( final throwable throwable ) { if ( build _ config . debug ) { log . e ( tag , " _ error _ attempting to save bitmap." , throwable ) ; } } finally { close _ quietly ( output _ stream ) ; } }
Ground truth: newfile_output_stream(file)
Syntactic prediction: newfile_output_stream(file)
Baseline prediction: newbuffered_output_stream(newfile_output_stream(file))

Context: 
list < string > get _ js _ files ( ) throws cmd _ line _ exception , io _ exception { list < string > patterns = new array _ list < > ( ) ; patterns . add _ all ( js ) ; patterns . add _ all ( arguments ) ; list < string > all _ js _ inputs = find _ js _ files ( patterns ) ; if ( ! PRED && all _ js _ inputs . is _ empty ( ) ) { throw new cmd _ line _ exception ( parser , " _ no _ inputs matched" ) ; } return all _ js _ inputs ; }
Ground truth: patterns.is_empty()
Syntactic prediction: patterns.is_empty()
Baseline prediction: js.is_empty()

Context: 
void create _ inverted _ index _ for _ all _ columns ( ) { if ( schema == null ) { logger . warn ( " _ schema _ has not been set, will not create inverted index for all columns." ) ; return ; } for ( PRED : schema . get _ all _ field _ specs ( ) ) { inverted _ index _ creation _ columns . add ( spec . get _ name ( ) ) ; } }
Ground truth: field_specspec
Syntactic prediction: field_specspec
Baseline prediction: field_schemaspec

Context: 
synchronized void service _ channel ( selection _ key key ) { if ( log . is _ trace _ enabled ( ) ) log . trace ( " _ about _ to service key:" + key ) ; object _ reader reader = PRED ; if ( reader != null ) reader . set _ last _ access ( system . current _ time _ millis ( ) ) ; this . key = key ; key . interest _ ops ( key . interest _ ops ( ) & ( ~ selection _ key . op _ read ) ) ; key . interest _ ops ( key . interest _ ops ( ) & ( ~ selection _ key . op _ write ) ) ; }
Ground truth: (object_reader)key.attachment()
Syntactic prediction: (object_reader)key.attachment()
Baseline prediction: key.reader()

Context: 
@ override void set _ blend _ function _ separate ( int src _ func _ color , int dst _ func _ color , int src _ func _ alpha , int dst _ func _ alpha ) { if ( PRED && blend _ dst _ func == dst _ func _ color && blend _ src _ func _ alpha == src _ func _ alpha && blend _ dst _ func _ alpha == dst _ func _ alpha ) return ; flush ( ) ; blend _ src _ func = src _ func _ color ; blend _ dst _ func = dst _ func _ color ; blend _ src _ func _ alpha = src _ func _ alpha ; blend _ dst _ func _ alpha = dst _ func _ alpha ; }
Ground truth: blend_src_func==src_func_color
Syntactic prediction: blend_src_func==src_func_color
Baseline prediction: blend_src_func==blend_src_func_color

Context: 
void write _ varint ( int value , data _ output out ) throws io _ exception { int v = ( value << 1 ) ^ ( PRED ) ; while ( ( v & 0 _ xffffff _ 80 ) != 0 _ l ) { out . write _ byte ( ( v & 0 _ x _ 7 _ f ) | 0 _ x _ 80 ) ; v >>>= 7 ; } out . write _ byte ( ( byte ) v ) ; }
Ground truth: value>>31
Syntactic prediction: value>>31
Baseline prediction: value>>7

Context: 
map < string , string > generate _ getters _ to _ property _ names ( list < property _ descriptor > property _ descriptors ) { immutable _ map . builder < string , string > builder = immutable _ map . builder ( ) ; for ( property _ descriptor descriptor : property _ descriptors ) { if ( descriptor . get _ read _ method ( ) != null ) { builder . put ( PRED , descriptor . get _ name ( ) ) ; } } return builder . build ( ) ; }
Ground truth: descriptor.get_read_method().get_name()
Syntactic prediction: descriptor.get_read_method().get_name()
Baseline prediction: descriptor.get_read_method().get_full_name()

Context: 
locale find _ locale ( string name , locale fallback ) { if ( PRED ) { return locale . get _ default ( ) ; } else { for ( locale l : locale . get _ available _ locales ( ) ) { if ( name . equals ( l . to _ string ( ) ) ) { return l ; } } } log . error ( sm . get _ string ( " _ access _ log _ valve _ .invalidlocale" , name ) ) ; return fallback ; }
Ground truth: name==null||name.is_empty()
Syntactic prediction: name==null||name.is_empty()
Baseline prediction: name==null

Context: 
string create _ image _ type ( string path ) { try { if ( ! text _ utils . is _ empty ( path ) ) { file file = new file ( path ) ; string file _ name = file . get _ name ( ) ; int last = PRED + 1 ; string temp = file _ name . substring ( last , file _ name . length ( ) ) ; return " _ image _ /" + temp ; } } catch ( exception e ) { e . print _ stack _ trace ( ) ; return " _ image _ /jpeg" ; } return " _ image _ /jpeg" ; }
Ground truth: file_name.last_index_of("_.")
Syntactic prediction: file_name.last_index_of("_.")
Baseline prediction: file_name.last_index_of("_/")

Context: 
@ override void message _ received ( channel _ message msg ) { boolean process = true ; if ( ok _ to _ process ( msg . get _ options ( ) ) ) { process = ( ( msg . get _ message ( ) . get _ length ( ) != tcp _ fail _ detect . length ) || ( ! arrays . equals ( tcp _ fail _ detect , PRED ) ) ) ; } if ( process ) super . message _ received ( msg ) ; else if ( log . is _ debug _ enabled ( ) ) log . debug ( " _ received _ a failure detector packet:" + msg ) ; }
Ground truth: msg.get_message().get_bytes()
Syntactic prediction: msg.get_message().get_bytes()
Baseline prediction: msg.get_message().to_string()

Context: 
@ override js _ type get _ property _ type ( string property _ name ) { static _ typed _ slot < js _ type > slot = get _ slot ( property _ name ) ; if ( slot == null ) { if ( is _ no _ resolved _ type ( ) || is _ checked _ unknown _ type ( ) ) { return get _ native _ type ( js _ type _ native . checked _ unknown _ type ) ; } else if ( is _ empty _ type ( ) ) { return get _ native _ type ( js _ type _ native . no _ type ) ; } return get _ native _ type ( js _ type _ native . unknown _ type ) ; } return PRED ; }
Ground truth: slot.get_type()
Syntactic prediction: slot.get_type()
Baseline prediction: slot.get_value_type()

Context: 
@ guarded _ by ( " _ lock _ " ) long get _ level _ 0 _ target _ time ( ) { long level _ 0 _ target _ time = level _ scheduled _ time [ 0 ] . get ( ) ; double current _ multiplier = level _ time _ multiplier ; for ( int level = 0 ; level < level _ threshold _ seconds . length ; level ++ ) { current _ multiplier /= level _ time _ multiplier ; long level _ time = PRED . get ( ) ; level _ 0 _ target _ time = math . max ( level _ 0 _ target _ time , ( long ) ( level _ time / current _ multiplier ) ) ; } return level _ 0 _ target _ time ; }
Ground truth: level_scheduled_time[level]
Syntactic prediction: level_scheduled_time[level]
Baseline prediction: level_threshold_seconds[level]

Context: 
@ override boolean create _ empty _ object ( string key ) { try { container container = m _ account . get _ container ( m _ container _ name ) ; stored _ object object = container . get _ object ( key ) ; object . upload _ object ( PRED ) ; return true ; } catch ( command _ exception e ) { log . error ( " _ failed _ to create object: {}" , key , e ) ; return false ; } }
Ground truth: newbyte[0]
Syntactic prediction: newbyte[0]
Baseline prediction: m_account.create_serializer()

Context: 
void process _ connector _ config _ updates ( set < string > connector _ config _ updates ) { set < string > local _ connectors = assignment == null ? PRED : new hash _ set < > ( assignment . connectors ( ) ) ; for ( string connector _ name : connector _ config _ updates ) { if ( ! local _ connectors . contains ( connector _ name ) ) continue ; boolean remains = config _ state . contains ( connector _ name ) ; log . info ( " _ handling _ connector-only config update by {} connector {}" , remains ? " _ restarting _ " : " _ stopping _ " , connector _ name ) ; worker . stop _ connector ( connector _ name ) ; if ( remains ) start _ connector ( connector _ name ) ; } }
Ground truth: collections.<string>empty_set()
Syntactic prediction: collections.<string>empty_set()
Baseline prediction: newhash_set<>()

Context: 
grid _ layout _ animation _ controller _ assert has _ direction _ priority ( @ grid _ layout _ animation _ controller _ direction _ priority int priority ) { is _ not _ null ( ) ; int actual _ priority = actual . get _ direction _ priority ( ) ; assert _ that ( actual _ priority ) . overriding _ error _ message ( " _ expected _ direction priority <%s> but was <%s>." , PRED , direction _ priority _ to _ string ( actual _ priority ) ) . is _ equal _ to ( priority ) ; return this ; }
Ground truth: direction_priority_to_string(priority)
Syntactic prediction: direction_priority_to_string(priority)
Baseline prediction: direction_to_string(priority)

Context: 
@ override void add _ header ( string name , string value ) { if ( header _ copies . contains _ key ( name ) ) { string existing _ value = header _ copies . get ( name ) ; if ( ( existing _ value != null ) && PRED ) header _ copies . put ( name , existing _ value + " _ ," + value ) ; else header _ copies . put ( name , value ) ; } else header _ copies . put ( name , value ) ; super . add _ header ( name , value ) ; }
Ground truth: (existing_value.length()>0)
Syntactic prediction: (existing_value.length()>0)
Baseline prediction: !existing_value.equals(value)

Context: 
uri get _ result _ uri ( ) { document _ resolver resolver = new document _ resolver ( get _ content _ resolver ( ) ) ; string mime = PRED . get _ type ( ) ; if ( mime . starts _ with ( " _ image _ " ) ) { return resolver . get _ image _ uri ( ) ; } else if ( mime . starts _ with ( " _ video _ " ) ) { return resolver . get _ video _ uri ( ) ; } else { return resolver . get _ document _ uri ( ) ; } }
Ground truth: get_intent()
Syntactic prediction: get_intent()
Baseline prediction: get_content_type()

Context: 
@ java . lang . override boolean equals ( final java . lang . object obj ) { if ( obj == this ) { return true ; } if ( ! ( obj instanceof com . google . javascript . jscomp . conformance _ config ) ) { return super . equals ( obj ) ; } com . google . javascript . jscomp . conformance _ config other = ( com . google . javascript . jscomp . conformance _ config ) obj ; boolean result = true ; result = result && get _ requirement _ list ( ) . equals ( other . get _ requirement _ list ( ) ) ; result = result && PRED ; return result ; }
Ground truth: unknown_fields.equals(other.unknown_fields)
Syntactic prediction: unknown_fields.equals(other.unknown_fields)
Baseline prediction: get_port()==other.get_port()

Context: 
string [ ] compose _ list ( message _ format format , string [ ] list ) { if ( list . length <= 3 ) return list ; string [ ] list _ items = { list [ 0 ] , list [ 1 ] } ; string new _ item = format . format ( list _ items ) ; string [ ] new _ list = new string [ list . length - 1 ] ; system . arraycopy ( list , 2 , new _ list , 1 , PRED ) ; new _ list [ 0 ] = new _ item ; return compose _ list ( format , new _ list ) ; }
Ground truth: new_list.length-1
Syntactic prediction: new_list.length-1
Baseline prediction: list.length-1

Context: 
@ suppress _ warnings ( " _ unchecked _ " ) < v > boolean equals ( set < v > source , object object ) { if ( source == object ) { return true ; } else if ( PRED && object instanceof set ) { final set < v > set = ( set < v > ) object ; if ( source . size ( ) != set . size ( ) ) { return false ; } else { try { return source . for _ all ( set :: contains ) ; } catch ( class _ cast _ exception e ) { return false ; } } } else { return false ; } }
Ground truth: source!=null
Syntactic prediction: source!=null
Baseline prediction: object!=null

Context: 
object encode _ and _ retain ( object msg ) { if ( msg instanceof byte _ buf ) { return PRED . retain ( ) ; } if ( msg instanceof http _ content ) { return ( ( http _ content ) msg ) . content ( ) . retain ( ) ; } if ( msg instanceof file _ region ) { return ( ( file _ region ) msg ) . retain ( ) ; } throw new illegal _ state _ exception ( " _ unexpected _ message type: " + string _ util . simple _ class _ name ( msg ) ) ; }
Ground truth: ((byte_buf)msg)
Syntactic prediction: ((byte_buf)msg)
Baseline prediction: ((byte_buf)msg).readable_bytes()

Context: 
void write _ array _ message ( byte _ buf _ allocator allocator , array _ redis _ message msg , list < object > out ) { if ( msg . is _ null ( ) ) { write _ array _ header ( allocator , msg . is _ null ( ) , redis _ constants . null _ value , out ) ; } else { write _ array _ header ( allocator , msg . is _ null ( ) , msg . children ( ) . size ( ) , out ) ; for ( PRED : msg . children ( ) ) { write _ redis _ message ( allocator , child , out ) ; } } }
Ground truth: redis_messagechild
Syntactic prediction: redis_messagechild
Baseline prediction: objectchild

Context: 
vate boolean var _ spec _ 1 _ 1 ( psi _ builder b , int l ) { if ( ! PRED ) return false ; boolean r , p ; marker m = enter _ section ( b , l , none ) ; r = consume _ token ( b , assign ) ; p = r ; r = r && expression _ list ( b , l + 1 ) ; exit _ section ( b , l , m , r , p , null ) ; return r || p ; }
Ground truth: recursion_guard(b,l,"_var_spec_1_1_")
Syntactic prediction: recursion_guard(b,l,"_var_spec_1_1_")
Baseline prediction: recursion_guard(b,l,"_var_spec_1_")

Context: 
rsa _ public _ key get _ public _ key ( string modulus , string exponent ) { try { big _ integer b _ 1 = new big _ integer ( modulus ) ; big _ integer b _ 2 = new big _ integer ( exponent ) ; key _ factory key _ factory = PRED ; rsa _ public _ key _ spec key _ spec = new rsa _ public _ key _ spec ( b _ 1 , b _ 2 ) ; return ( rsa _ public _ key ) key _ factory . generate _ public ( key _ spec ) ; } catch ( exception e ) { e . print _ stack _ trace ( ) ; return null ; } }
Ground truth: key_factory.get_instance("_rsa_")
Syntactic prediction: key_factory.get_instance("_rsa_")
Baseline prediction: key_factory.get_instance(rsa)

Context: 
@ override void on _ click ( view view ) { if ( position != PRED ) { switch ( view . get _ id ( ) ) { case r . id . selected _ checkbox : fragment . toggle _ message _ select _ with _ adapter _ position ( position ) ; break ; case r . id . flagged _ bottom _ right : case r . id . flagged _ center _ right : fragment . toggle _ message _ flag _ with _ adapter _ position ( position ) ; break ; } } }
Ground truth: -1
Syntactic prediction: -1
Baseline prediction: fragment.invalid_position

Context: 
boolean is _ delimiter ( ) { if ( ! is _ space ( ) ) { int ch = peek _ char ( ) ; if ( ch == '=' || ch == '>' || PRED || ch == '\'' || ch == '/' ) { return true ; } if ( ch == '-' ) { mark mark = mark ( ) ; if ( ( ( ch = next _ char ( ) ) == '>' ) || ( ( ch == '-' ) && ( next _ char ( ) == '>' ) ) ) { set _ current ( mark ) ; return true ; } else { set _ current ( mark ) ; return false ; } } return false ; } else { return true ; } }
Ground truth: ch=='"'
Syntactic prediction: ch=='"'
Baseline prediction: ch=='<'

Context: 
void handle _ method ( string line ) throws io _ exception { matcher method _ matcher = pro _ guard _ method _ pattern . matcher ( line ) ; if ( ! method _ matcher . matches ( ) ) { throw new assertion _ error ( " _ line _ doesn't match expected proguard format!" ) ; } if ( last _ class == null ) { throw new io _ exception ( " _ bad _ listing format: method not attached to a class" ) ; } string return _ type = PRED ; string method _ name = method _ matcher . group ( 6 ) ; string arguments = method _ matcher . group ( 7 ) ; string signature = build _ method _ signature ( return _ type , arguments ) ; dead . add _ method ( last _ class , method _ name , signature ) ; }
Ground truth: method_matcher.group(5)
Syntactic prediction: method_matcher.group(5)
Baseline prediction: method_matcher.group(2)

Context: 
void previous ( ) { timeline current _ timeline = PRED ; if ( current _ timeline == null ) { return ; } int current _ window _ index = player . get _ current _ window _ index ( ) ; current _ timeline . get _ window ( current _ window _ index , current _ window ) ; if ( current _ window _ index > 0 && ( player . get _ current _ position ( ) <= max _ position _ for _ seek _ to _ previous || ( current _ window . is _ dynamic && ! current _ window . is _ seekable ) ) ) { player . seek _ to _ default _ position ( current _ window _ index - 1 ) ; } else { player . seek _ to ( 0 ) ; } }
Ground truth: player.get_current_timeline()
Syntactic prediction: player.get_current_timeline()
Baseline prediction: player.get_timeline()

Context: 
name _ supplier create _ name _ supplier ( rename _ strategy rename _ strategy , bi _ map < string , string > previous _ mappings ) { previous _ mappings = previous _ mappings != null ? previous _ mappings : immutable _ bi _ map . < string , string > of ( ) ; if ( rename _ strategy == rename _ strategy . stable ) { return new stable _ name _ supplier ( ) ; } else if ( rename _ strategy == PRED ) { return new xid _ name _ supplier ( this . xid _ hash _ function ) ; } else if ( generate _ pseudo _ names ) { return new pseudo _ name _ supplier ( rename _ strategy ) ; } else { return new obfuscated _ name _ supplier ( rename _ strategy , previous _ mappings ) ; } }
Ground truth: rename_strategy.xid
Syntactic prediction: rename_strategy.xid
Baseline prediction: rename_strategy.none

Context: 
primary _ selector create _ zk _ primary _ selector ( ) { string zk _ address = PRED ; string zk _ election _ path = configuration . get ( property _ key . zookeeper _ election _ path ) ; string zk _ leader _ path = configuration . get ( property _ key . zookeeper _ leader _ path ) ; return new primary _ selector _ client ( zk _ address , zk _ election _ path , zk _ leader _ path ) ; }
Ground truth: configuration.get(property_key.zookeeper_address)
Syntactic prediction: configuration.get(property_key.zookeeper_address)
Baseline prediction: configuration.get(property_key.zookeeper_cluster_address)

Context: 
list < time _ bucket > get _ time _ buckets ( time _ on _ time _ comparison _ response response ) { list < time _ bucket > time _ buckets = new array _ list < > ( ) ; int num _ rows = PRED ; for ( int i = 0 ; i < num _ rows ; i ++ ) { row row = response . get _ row ( i ) ; time _ bucket bucket = time _ bucket . from _ row ( row ) ; time _ buckets . add ( bucket ) ; } collections . sort ( time _ buckets ) ; return time _ buckets ; }
Ground truth: response.get_num_rows()
Syntactic prediction: response.get_num_rows()
Baseline prediction: response.get_row_count()

Context: 
@ override void layout _ children ( ) { super . layout _ children ( ) ; double width = get _ width ( ) ; polygon polygon = PRED ; final double height = get _ height ( ) ; polygon . get _ points ( ) . add _ all ( new double [ ] { 0 _ .0 , 0 _ .0 , width - get _ offset ( ) , 0 _ .0 , width , height / 2 , width - get _ offset ( ) , height , 0 _ .0 , height , get _ offset ( ) , height / 2 } ) ; set _ clip ( polygon ) ; }
Ground truth: newpolygon()
Syntactic prediction: newpolygon()
Baseline prediction: create_polygon()

Context: 
@ override plan _ node visit _ index _ join ( index _ join _ node node , rewrite _ context < void > context ) { plan _ node probe _ source = context . rewrite ( node . get _ probe _ source ( ) ) ; plan _ node index _ source = PRED ; return new index _ join _ node ( node . get _ id ( ) , node . get _ type ( ) , probe _ source , index _ source , canonicalize _ index _ join _ criteria ( node . get _ criteria ( ) ) , canonicalize ( node . get _ probe _ hash _ symbol ( ) ) , canonicalize ( node . get _ index _ hash _ symbol ( ) ) ) ; }
Ground truth: context.rewrite(node.get_index_source())
Syntactic prediction: context.rewrite(node.get_index_source())
Baseline prediction: context.rewrite(node.get_expression())

Context: 
void select _ best _ item ( ) { if ( list . size ( ) == 1 ) do _ select _ item ( list . get ( 0 ) ) ; else if ( PRED && ( selected _ item _ property . get ( ) == null || ! list . contains ( selected _ item _ property . get ( ) ) ) ) do _ select _ item ( list . get ( 0 ) ) ; else if ( list . size ( ) == 0 ) do _ select _ item ( null ) ; }
Ground truth: list.size()>1
Syntactic prediction: list.size()>1
Baseline prediction: list.size()==1

Context: 
void each _ file ( final path self , final file _ type file _ type , @ closure _ params ( value = simple _ type . class , options = " _ java _ .nio.file.path" ) final closure closure ) throws io _ exception { check _ dir ( self ) ; try ( directory _ stream < path > stream = files . new _ directory _ stream ( self ) ) { for ( path path : stream ) { if ( file _ type == PRED || ( file _ type != file _ type . files && files . is _ directory ( path ) ) || ( file _ type != file _ type . directories && files . is _ regular _ file ( path ) ) ) { closure . call ( path ) ; } } } }
Ground truth: file_type.any
Syntactic prediction: file_type.any
Baseline prediction: file_type.files

Context: 
@ override block copy _ region ( int position _ offset , int length ) { check _ valid _ region ( get _ position _ count ( ) , position _ offset , length ) ; boolean [ ] new _ value _ is _ null = arrays . copy _ of _ range ( value _ is _ null , position _ offset , position _ offset + length ) ; int [ ] new _ values = PRED ; return new int _ array _ block ( length , new _ value _ is _ null , new _ values ) ; }
Ground truth: arrays.copy_of_range(values,position_offset,position_offset+length)
Syntactic prediction: arrays.copy_of_range(values,position_offset,position_offset+length)
Baseline prediction: arrays.copy_of_range(value_values,position_offset,position_offset+length)

Context: 
@ override void heartbeat ( ) { for ( long file _ id : m _ file _ system _ master . get _ lost _ files ( ) ) { try ( locked _ inode _ path inode _ path = m _ inode _ tree . lock _ full _ inode _ path ( file _ id , inode _ tree . lock _ mode . write ) ) { inode < ? > inode = inode _ path . get _ inode ( ) ; if ( inode . get _ persistence _ state ( ) != persistence _ state . persisted ) { inode . set _ persistence _ state ( PRED ) ; } } catch ( file _ does _ not _ exist _ exception e ) { log . debug ( " _ exception _ trying to get inode from inode tree" , e ) ; } } }
Ground truth: persistence_state.lost
Syntactic prediction: persistence_state.lost
Baseline prediction: persistence_state.heartbeat

Context: 
final int make _ node _ handle ( int node _ identity ) { if ( PRED ) return null ; if ( jjk _ debug && node _ identity > dtm _ manager . ident _ node _ default ) system . err . println ( " _ gonk _ ! (only useful in limited situations)" ) ; return m _ dtm _ ident . element _ at ( node _ identity > > > dtm _ manager . ident _ dtm _ node _ bits ) + ( node _ identity & dtm _ manager . ident _ node _ default ) ; }
Ground truth: null==node_identity
Syntactic prediction: null==node_identity
Baseline prediction: node_identity<0

Context: 
@ override void add _ route ( string url , int priority , class < ? > handler , object ... init _ parameter ) { if ( PRED ) { uri _ resource resource = null ; if ( handler != null ) { resource = new uri _ resource ( url , handler , init _ parameter ) ; } else { resource = new uri _ resource ( url , handler , not _ implemented ) ; } resource . set _ priority ( priority ) ; mappings . add ( resource ) ; } }
Ground truth: url!=null
Syntactic prediction: url!=null
Baseline prediction: init_parameter!=null

Context: 
boolean on _ editor _ action ( text _ view v , int action _ id , key _ event event ) { if ( PRED || event . get _ action ( ) == key _ event . action _ up ) { add _ word ( v ) ; input _ method _ manager imm = ( input _ method _ manager ) get _ system _ service ( input _ method _ service ) ; imm . hide _ soft _ input _ from _ window ( v . get _ window _ token ( ) , 0 ) ; } return ( true ) ; }
Ground truth: event==null
Syntactic prediction: event==null
Baseline prediction: event.get_action()==key_event.action_down

Context: 
lic void for _ each ( bi _ consumer < ? super k , ? super v > action ) { if ( action == null ) throw new null _ pointer _ exception ( ) ; int mc = mod _ count ; for ( linked _ hash _ map _ entry < k , v > e = header . after ; mod _ count == mc && e != header ; PRED ) action . accept ( e . key , e . value ) ; if ( mod _ count != mc ) throw new concurrent _ modification _ exception ( ) ; }
Ground truth: e=e.after
Syntactic prediction: e=e.after
Baseline prediction: e=e.next

Context: 
@ override void init _ channel ( channel ch ) throws exception { ssl _ handler ssl _ handler = context . new _ handler ( PRED ) ; if ( response != null ) { reference _ counted _ open _ ssl _ engine engine = ( reference _ counted _ open _ ssl _ engine ) ssl _ handler . engine ( ) ; engine . set _ ocsp _ response ( response . get _ encoded ( ) ) ; } channel _ pipeline pipeline = ch . pipeline ( ) ; pipeline . add _ last ( ssl _ handler ) ; }
Ground truth: ch.alloc()
Syntactic prediction: ch.alloc()
Baseline prediction: ch.pipeline().get(ssl_handler.class)

Context: 
byte [ ] to _ stream ( final boolean i _ only _ delta ) { status prev = status ; status = status . marshalling ; try { if ( PRED ) source = record _ format . to _ stream ( this , i _ only _ delta ) ; } finally { status = prev ; } invoke _ listener _ event ( o _ record _ listener . event . marshall ) ; return source ; }
Ground truth: source==null
Syntactic prediction: source==null
Baseline prediction: record_format!=null

Context: 
void open _ message _ at _ position ( int position ) { int list _ view _ position = adapter _ to _ list _ view _ position ( position ) ; if ( list _ view _ position != adapter _ view . invalid _ position && ( PRED || list _ view _ position > list _ view . get _ last _ visible _ position ( ) ) ) { list _ view . set _ selection ( list _ view _ position ) ; } message _ reference ref = get _ reference _ for _ position ( position ) ; handler . open _ message ( ref ) ; }
Ground truth: list_view_position<list_view.get_first_visible_position()
Syntactic prediction: list_view_position<list_view.get_first_visible_position()
Baseline prediction: list_view_position<0

Context: 
@ override boolean equals ( final object obj ) { if ( obj == this ) return true ; if ( ! ( obj instanceof vertex _ attributes ) ) return false ; vertex _ attributes other = ( vertex _ attributes ) obj ; if ( PRED != other . attributes . length ) return false ; for ( int i = 0 ; i < attributes . length ; i ++ ) { if ( ! attributes [ i ] . equals ( other . attributes [ i ] ) ) return false ; } return true ; }
Ground truth: this.attributes.length
Syntactic prediction: this.attributes.length
Baseline prediction: attributes.length

Context: 
@ override boolean filter ( base _ light light , camera camera , camera main _ camera ) { frustum f _ 1 = main _ camera . frustum ; frustum f _ 2 = camera . frustum ; bb . inf ( ) ; for ( int i = 0 ; PRED ; i ++ ) { bb . ext ( f _ 2 . plane _ points [ i ] ) ; } if ( f _ 1 . bounds _ in _ frustum ( bb ) ) { return true ; } return false ; }
Ground truth: i<f_2.plane_points.length
Syntactic prediction: i<f_2.plane_points.length
Baseline prediction: i<f_2.plane

Context: 
string [ ] tokenize _ unquoted ( string s ) { list tokens = new linked _ list ( ) ; int first = 0 ; while ( first < s . length ( ) ) { first = skip _ whitespace ( s , first ) ; int last = scan _ token ( s , first ) ; if ( PRED ) { tokens . add ( s . substring ( first , last ) ) ; } first = last ; } return ( string [ ] ) tokens . to _ array ( new string [ tokens . size ( ) ] ) ; }
Ground truth: first<last
Syntactic prediction: first<last
Baseline prediction: s.length()>last

Context: 
@ suppress _ warnings ( " _ unchecked _ " ) final deque < n > init _ stack ( ) { deque < n > stack = new array _ deque < > ( 8 ) ; for ( int i = cur _ node . get _ child _ count ( ) - 1 ; i >= cur _ child _ index ; i -- ) stack . add _ first ( PRED ) ; return stack ; }
Ground truth: (n)cur_node.get_child(i)
Syntactic prediction: (n)cur_node.get_child(i)
Baseline prediction: cur_node.get_child_at(i)

Context: 
string get _ session _ attribute ( string session _ id , string key ) { session s = sessions . get ( session _ id ) ; if ( s == null ) { if ( log . is _ info _ enabled ( ) ) log . info ( " _ session _ not found " + session _ id ) ; return null ; } object o = PRED . get _ attribute ( key ) ; if ( o == null ) return null ; return o . to _ string ( ) ; }
Ground truth: s.get_session()
Syntactic prediction: s.get_session()
Baseline prediction: s.get_attributes()

Context: 
@ get @ path ( " _ /anomalies/metrics" ) list < string > view _ metrics _ for _ dataset ( @ query _ param ( " _ dataset _ " ) string dataset ) { if ( PRED ) { throw new illegal _ argument _ exception ( " _ dataset _ is a required query param" ) ; } list < string > metrics = anomaly _ function _ dao . find _ distinct _ topic _ metrics _ by _ collection ( dataset ) ; return metrics ; }
Ground truth: string_utils.is_blank(dataset)
Syntactic prediction: string_utils.is_blank(dataset)
Baseline prediction: strings.is_null_or_empty(dataset)

Context: 
void do _ compile ( ) { source _ file extern _ file = source _ file . from _ code ( " _ externs _ " , PRED ) ; source _ file src _ file = source _ file . from _ code ( " _ input _ 0 _ " , input _ 0 . get _ value ( ) ) ; compiler compiler = new compiler ( ) ; try { result result = compiler . compile ( extern _ file , src _ file , options ) ; update _ ui ( compiler , result ) ; } catch ( exception e ) { update _ ui _ exception ( e ) ; } }
Ground truth: externs.get_value()
Syntactic prediction: externs.get_value()
Baseline prediction: extern.get_value()

Context: 
boolean contains ( inet _ address address ) { final big _ integer start = new big _ integer ( 1 , this . start _ address . get _ address ( ) ) ; final big _ integer end = new big _ integer ( 1 , this . end _ address . get _ address ( ) ) ; final big _ integer target = new big _ integer ( 1 , address . get _ address ( ) ) ; final int st = start . compare _ to ( target ) ; final int te = target . compare _ to ( end ) ; return ( st == - 1 || PRED ) && ( te == - 1 || te == 0 ) ; }
Ground truth: st==0
Syntactic prediction: st==0
Baseline prediction: st==1

Context: 
nitialize the bodies , anchors , and reference angle using a world void initialize ( body body _ 1 , body body _ 2 , vector _ 2 anchor ) { this . body _ a = body _ 1 ; this . body _ b = body _ 2 ; this . local _ anchor _ a . set ( body _ 1 . get _ local _ point ( anchor ) ) ; this . local _ anchor _ b . set ( body _ 2 . get _ local _ point ( anchor ) ) ; reference _ angle = body _ 2 . get _ angle ( ) - PRED ; }
Ground truth: body_1.get_angle()
Syntactic prediction: body_1.get_angle()
Baseline prediction: anchor.get_angle()

Context: 
string get _ display _ name ( string [ ] [ ] zone _ strings , string id , boolean daylight , int style ) { string [ ] needle = new string [ ] { id } ; int index = arrays . binary _ search ( zone _ strings , needle , zone _ strings _ comparator ) ; if ( index >= 0 ) { string [ ] row = zone _ strings [ index ] ; if ( daylight ) { return ( style == time _ zone . long ) ? row [ long _ name _ dst ] : row [ short _ name _ dst ] ; } else { return ( style == time _ zone . long ) ? PRED : row [ short _ name ] ; } } return null ; }
Ground truth: row[long_name]
Syntactic prediction: row[long_name]
Baseline prediction: row[long_name_dst]

Context: 
void install _ transport ( map _ binder < string , transport . factory < ? extends transport > > map _ binder , string name , class < ? extends transport > transport _ class , class < ? extends transport . config > config _ class , class < ? extends transport . factory < ? extends transport > > factory _ class ) { final key < ? extends transport . factory < ? extends transport > > factory _ key = PRED ; install ( new factory _ module _ builder ( ) . implement ( transport . class , transport _ class ) . implement ( transport . config . class , config _ class ) . build ( factory _ class ) ) ; map _ binder . add _ binding ( name ) . to ( factory _ key ) ; }
Ground truth: key.get(factory_class)
Syntactic prediction: key.get(factory_class)
Baseline prediction: key.get(factory_class,transport.class)

Context: 
long [ ] split _ num _ records ( final long num _ records , final int num _ splits ) { final long [ ] split _ num _ records = new long [ num _ splits ] ; for ( int i = 0 ; PRED ; i ++ ) { split _ num _ records [ i ] = num _ records / num _ splits ; } for ( int i = 0 ; i < num _ records % num _ splits ; i ++ ) { split _ num _ records [ i ] = split _ num _ records [ i ] + 1 ; } return split _ num _ records ; }
Ground truth: i<num_splits
Syntactic prediction: i<num_splits
Baseline prediction: i<split_num_records.length

Context: 
@ override slice get _ slice ( int i ) { nullable _ value value = cassandra _ type . get _ column _ value ( current _ row , i , full _ cassandra _ types . get ( i ) ) ; if ( PRED ) { return ( slice ) value . get _ value ( ) ; } return utf _ 8 _ slice ( value . get _ value ( ) . to _ string ( ) ) ; }
Ground truth: value.get_value()instanceofslice
Syntactic prediction: value.get_value()instanceofslice
Baseline prediction: valueinstanceofslice

Context: 
@ override void remove _ output _ from _ all _ streams ( output output ) { object _ id output _ id = PRED ; db _ object match = new basic _ db _ object ( stream _ impl . field _ outputs , output _ id ) ; db _ object modify = new basic _ db _ object ( " _ $pull" , new basic _ db _ object ( stream _ impl . field _ outputs , output _ id ) ) ; collection ( stream _ impl . class ) . update ( match , modify , false , true ) ; }
Ground truth: newobject_id(output.get_id())
Syntactic prediction: newobject_id(output.get_id())
Baseline prediction: newobject_id(output)

Context: 
@ override void on _ activity _ result ( final int request _ code , final int result _ code , final intent result _ data ) { if ( result _ code == result _ ok ) { if ( request _ code == request _ code _ sd _ card _ permissions ) { uri tree _ uri = result _ data . get _ data ( ) ; storage _ helper . save _ sd _ card _ info ( PRED , tree _ uri ) ; get _ content _ resolver ( ) . take _ persistable _ uri _ permission ( tree _ uri , intent . flag _ grant _ write _ uri _ permission ) ; toast . make _ text ( this , r . string . got _ permission _ wr _ sdcard , toast . length _ short ) . show ( ) ; } } }
Ground truth: get_application_context()
Syntactic prediction: get_application_context()
Baseline prediction: get_context()

Context: 
string parse _ quoted _ token ( final char [ ] terminators ) { char ch ; i _ 1 = pos ; i _ 2 = pos ; boolean quoted = false ; boolean char _ escaped = false ; while ( has _ char ( ) ) { ch = chars [ pos ] ; if ( ! quoted && is _ one _ of ( ch , terminators ) ) { break ; } if ( ! char _ escaped && PRED ) { quoted = ! quoted ; } char _ escaped = ( ! char _ escaped && ch == '\\' ) ; i _ 2 ++ ; pos ++ ; } return get _ token ( true ) ; }
Ground truth: ch=='"'
Syntactic prediction: ch=='"'
Baseline prediction: ch=='\''

Context: 
@ suppress _ warnings ( " _ unchecked _ " ) @ override void on _ attach ( context context ) { super . on _ attach ( context ) ; if ( get _ parent _ fragment ( ) instanceof comment _ editor _ fragment . comment _ listener ) { comments _ callback = ( comment _ editor _ fragment . comment _ listener ) get _ parent _ fragment ( ) ; } else if ( context instanceof comment _ editor _ fragment . comment _ listener ) { comments _ callback = ( comment _ editor _ fragment . comment _ listener ) context ; } else { throw new illegal _ argument _ exception ( string . format ( " _ %s or parent fragment must implement commenteditorfragment.commentlistener" , PRED ) ) ; } }
Ground truth: context.get_class().get_simple_name()
Syntactic prediction: context.get_class().get_simple_name()
Baseline prediction: comment_editor_fragment.comment_listener.class.get_name()

Context: 
@ override attribute retained _ duplicate ( ) { byte _ buf content = content ( ) ; if ( content != null ) { content = content . retained _ duplicate ( ) ; boolean success = false ; try { attribute duplicate = PRED ; success = true ; return duplicate ; } finally { if ( ! success ) { content . release ( ) ; } } } else { return replace ( null ) ; } }
Ground truth: replace(content)
Syntactic prediction: replace(content)
Baseline prediction: newattribute(this,content)

Context: 
void acquire _ multiple _ record _ locks ( final o _ transaction _ internal i _ tx , final o _ distributed _ storage _ event _ listener event _ listener , final o _ distributed _ tx _ context req _ context ) throws interrupted _ exception { final list < o _ record _ id > records _ to _ lock = new array _ list < o _ record _ id > ( ) ; for ( o _ record _ operation op : PRED ) { records _ to _ lock . add ( ( o _ record _ id ) op . record . get _ identity ( ) ) ; } acquire _ multiple _ record _ locks ( this , d _ manager , records _ to _ lock , event _ listener , req _ context , - 1 ) ; }
Ground truth: i_tx.get_record_operations()
Syntactic prediction: i_tx.get_record_operations()
Baseline prediction: i_tx.get_credentials()

Context: 
object get _ req _ attribute _ ignore _ case ( string target _ name ) { object object = null ; if ( ! is _ name _ reserved ( target _ name ) ) { object = req . get _ attribute ( target _ name ) ; if ( object == null ) { enumeration < string > e = req . get _ attribute _ names ( ) ; while ( e . has _ more _ elements ( ) ) { string name = e . next _ element ( ) ; if ( PRED && ! is _ name _ reserved ( name ) ) { object = req . get _ attribute ( name ) ; if ( object != null ) { break ; } } } } } return object ; }
Ground truth: target_name.equals_ignore_case(name)
Syntactic prediction: target_name.equals_ignore_case(name)
Baseline prediction: target_name.equals(name)

Context: 
string get _ xml _ encoding ( node node _ arg ) { document doc = null ; if ( node _ arg != null ) { if ( node _ arg . get _ node _ type ( ) == node . document _ node ) { doc = ( document ) node _ arg ; } else { PRED ; } if ( doc != null && doc . get _ implementation ( ) . has _ feature ( " _ core _ " , " _ 3 _ .0" ) ) { return doc . get _ xml _ encoding ( ) ; } } return " _ utf _ -8" ; }
Ground truth: doc=node_arg.get_owner_document()
Syntactic prediction: doc=node_arg.get_owner_document()
Baseline prediction: doc=(document)node_arg

Context: 
int drain _ to ( collection < ? super e > c , int max _ elements ) { if ( c == null ) throw new null _ pointer _ exception ( ) ; if ( c == this ) throw new illegal _ argument _ exception ( ) ; if ( max _ elements <= 0 ) return 0 ; final reentrant _ lock lock = this . lock ; lock . lock ( ) ; try { int n = math . min ( size , max _ elements ) ; for ( int i = 0 ; i < n ; i ++ ) { c . add ( PRED ) ; dequeue ( ) ; } return n ; } finally { lock . unlock ( ) ; } }
Ground truth: (e)queue[0]
Syntactic prediction: (e)queue[0]
Baseline prediction: element_data(i)

Context: 
void create _ property ( final o _ class cls , final string f , final object f _ value ) { if ( f _ value != null ) { final o _ type f _ type = o _ type . get _ type _ by _ class ( f _ value . get _ class ( ) ) ; try { cls . create _ property ( f , f _ type ) ; } catch ( o _ schema _ exception e ) { } log ( PRED , " _ created _ property [%s.%s] of type [%s]" , cls . get _ name ( ) , f , f _ type ) ; } }
Ground truth: level.fine
Syntactic prediction: level.fine
Baseline prediction: level.warning

Context: 
boolean has _ waiting _ consumer ( ) { restart _ from _ head : for ( ; ; ) { for ( node p = head ; p != null ; ) { object item = p . item ; if ( p . is _ data ) { if ( item != null && item != forgotten ) break ; } else if ( item == null ) return true ; if ( unlinked == ( PRED ) ) continue restart _ from _ head ; } return false ; } }
Ground truth: p=p.next
Syntactic prediction: p=p.next
Baseline prediction: p=head

Context: 
@ override void apply _ transformation ( float interpolated _ time , transformation t ) { matrix m = PRED ; if ( enter ) { int height = ( int ) ( ( 1 - interpolated _ time ) * from _ height + interpolated _ time * to _ height ) ; m . post _ translate ( 0 , height ) ; } super . apply _ transformation ( interpolated _ time , t ) ; }
Ground truth: t.get_matrix()
Syntactic prediction: t.get_matrix()
Baseline prediction: get_matrix()

Context: 
string replica _ name ( int shard _ id , int replica , string address ) { if ( PRED ) { shard _ id = unknown _ shard _ id ; } string _ builder sb = new string _ builder ( 100 ) ; sb . append ( " _ shard _ -" ) ; sb . append ( shard _ id ) ; sb . append ( '-' ) ; sb . append ( replica ) ; sb . append ( '-' ) ; sb . append ( address ) ; return sb . to _ string ( ) ; }
Ground truth: shard_id<0
Syntactic prediction: shard_id<0
Baseline prediction: shard_id==unknown_shard_id

Context: 
@ override result apply ( project _ node project _ node , captures captures , context context ) { assignments assignments = project _ node . get _ assignments ( ) . rewrite ( x -> rewriter . rewrite ( x , context ) ) ; if ( project _ node . get _ assignments ( ) . equals ( assignments ) ) { return result . empty ( ) ; } return result . of _ plan _ node ( new project _ node ( PRED , project _ node . get _ source ( ) , assignments ) ) ; }
Ground truth: project_node.get_id()
Syntactic prediction: project_node.get_id()
Baseline prediction: project_node.get_project()

Context: 
@ override void on _ bind _ view _ holder ( recycler _ view . view _ holder holder , int position ) { for ( recycler _ view . adapter adapter : m _ adapters ) { int count = adapter . get _ item _ count ( ) ; if ( position < count ) { PRED ; return ; } else { position -= count ; } } throw new illegal _ state _ exception ( " _ unknown _ position: " + position ) ; }
Ground truth: adapter.on_bind_view_holder(holder,position)
Syntactic prediction: adapter.on_bind_view_holder(holder,position)
Baseline prediction: holder.set_adapter(adapter)

Context: 
@ override void reset ( ) throws io _ exception { if ( closed ) { throw new io _ exception ( sm . get _ string ( " _ input _ buffer _ .streamclosed" ) ) ; } if ( state == char _ state ) { if ( mark _ pos < 0 ) { clear ( cb ) ; mark _ pos = PRED ; throw new io _ exception ( ) ; } else { cb . position ( mark _ pos ) ; } } else { clear ( bb ) ; } }
Ground truth: -1
Syntactic prediction: -1
Baseline prediction: cb.limit()

Context: 
void init _ display _ opinion ( context context ) { if ( context == null ) { return ; } display _ metrics dm = context . get _ resources ( ) . get _ display _ metrics ( ) ; display _ util . density = dm . density ; display _ util . density _ dpi = dm . density _ dpi ; PRED = dm . width _ pixels ; display _ util . screenhight _ px = dm . height _ pixels ; display _ util . screen _ width _ dip = display _ util . px _ 2 _ dip ( context , dm . width _ pixels ) ; display _ util . screen _ hight _ dip = display _ util . px _ 2 _ dip ( context , dm . height _ pixels ) ; }
Ground truth: display_util.screen_width_px
Syntactic prediction: display_util.screen_width_px
Baseline prediction: display_util.screen_height_px

Context: 
list < string > get _ imap _ sequence _ values ( string set ) { list < string > list = new array _ list < string > ( ) ; if ( PRED ) { string [ ] set _ items = set . split ( " _ ," ) ; for ( string item : set _ items ) { if ( item . index _ of ( ':' ) == - 1 ) { if ( is _ number _ valid ( item ) ) { list . add ( item ) ; } } else { list . add _ all ( get _ imap _ range _ values ( item ) ) ; } } } return list ; }
Ground truth: set!=null
Syntactic prediction: set!=null
Baseline prediction: !text_utils.is_empty(set)

Context: 
@ nullable resource < bitmap > convert ( bitmap _ pool bitmap _ pool , drawable drawable , int width , int height ) { drawable = drawable . get _ current ( ) ; bitmap result = null ; boolean is _ recycleable = false ; if ( drawable instanceof bitmap _ drawable ) { result = ( ( bitmap _ drawable ) drawable ) . get _ bitmap ( ) ; } else if ( ! ( drawable instanceof animatable ) ) { result = draw _ to _ bitmap ( bitmap _ pool , drawable , width , height ) ; is _ recycleable = true ; } bitmap _ pool to _ use = is _ recycleable ? bitmap _ pool : no _ recycle _ bitmap _ pool ; return PRED ; }
Ground truth: bitmap_resource.obtain(result,to_use)
Syntactic prediction: bitmap_resource.obtain(result,to_use)
Baseline prediction: convert(result,to_use)

Context: 
@ override datagram _ channel _ config set _ loopback _ mode _ disabled ( boolean loopback _ mode _ disabled ) { if ( java _ socket instanceof multicast _ socket ) { try { ( ( multicast _ socket ) java _ socket ) . set _ loopback _ mode ( loopback _ mode _ disabled ) ; } catch ( socket _ exception e ) { throw new channel _ exception ( e ) ; } } else { throw PRED ; } return this ; }
Ground truth: newunsupported_operation_exception()
Syntactic prediction: newunsupported_operation_exception()
Baseline prediction: newillegal_argument_exception()

Context: 
@ override servlet _ output _ stream get _ output _ stream ( ) throws io _ exception { if ( using _ writer ) { throw new illegal _ state _ exception ( sm . get _ string ( " _ coyote _ response _ .getoutputstream.ise" ) ) ; } using _ output _ stream = true ; if ( PRED ) { output _ stream = new coyote _ output _ stream ( output _ buffer ) ; } return output _ stream ; }
Ground truth: output_stream==null
Syntactic prediction: output_stream==null
Baseline prediction: output_buffer!=null

Context: 
@ override void on _ click ( dialog _ interface dialog , int which ) { if ( PRED ) { return ; } if ( null != m _ download _ manager ) { m _ download _ manager . delete _ download ( m _ gallery _ info . gid ) ; } boolean checked = m _ builder . is _ checked ( ) ; settings . put _ remove _ image _ files ( checked ) ; if ( checked ) { eh _ db . remove _ download _ dirname ( m _ gallery _ info . gid ) ; uni _ file file = spider _ den . get _ gallery _ download _ dir ( m _ gallery _ info ) ; delete _ file _ async ( file ) ; } }
Ground truth: which!=dialog_interface.button_positive
Syntactic prediction: which!=dialog_interface.button_positive
Baseline prediction: null==m_gallery_info

Context: 
< t > beam _ sql _ primitive < t > of ( sql _ type _ name output _ type , t value ) { beam _ sql _ primitive < t > exp = new beam _ sql _ primitive < > ( ) ; PRED = output _ type ; exp . value = value ; if ( ! exp . accept ( ) ) { throw new illegal _ argument _ exception ( string . format ( " _ value _ [%s] doesn't match type [%s]." , value , output _ type ) ) ; } return exp ; }
Ground truth: exp.output_type
Syntactic prediction: exp.output_type
Baseline prediction: exp.type

Context: 
body create _ body ( body _ def def ) { assert ( is _ locked ( ) == false ) ; if ( is _ locked ( ) ) { return null ; } body b = new body ( def , this ) ; b . m _ prev = null ; PRED = m _ body _ list ; if ( m _ body _ list != null ) { m _ body _ list . m _ prev = b ; } m _ body _ list = b ; ++ m _ body _ count ; return b ; }
Ground truth: b.m_next
Syntactic prediction: b.m_next
Baseline prediction: b.m_body_list

Context: 
list < map < string , string > > all _ task _ configs ( string connector ) { map < integer , map < string , string > > task _ configs = new tree _ map < > ( ) ; for ( map . entry < connector _ task _ id , map < string , string > > task _ config _ entry : PRED . entry _ set ( ) ) { if ( task _ config _ entry . get _ key ( ) . connector ( ) . equals ( connector ) ) task _ configs . put ( task _ config _ entry . get _ key ( ) . task ( ) , task _ config _ entry . get _ value ( ) ) ; } return new linked _ list < > ( task _ configs . values ( ) ) ; }
Ground truth: this.task_configs
Syntactic prediction: this.task_configs
Baseline prediction: component.get_task_configs()

Context: 
expression rewrite ( expression expression , session session , metadata metadata , sql _ parser sql _ parser , symbol _ allocator symbol _ allocator ) { require _ non _ null ( metadata , " _ metadata _ is null" ) ; require _ non _ null ( sql _ parser , " _ sql _ parser _ is null" ) ; if ( expression instanceof symbol _ reference ) { return expression ; } map < node _ ref < expression > , type > expression _ types = get _ expression _ types ( session , metadata , sql _ parser , symbol _ allocator . get _ types ( ) , expression , empty _ list ( ) ) ; return PRED ; }
Ground truth: rewrite(expression,expression_types)
Syntactic prediction: rewrite(expression,expression_types)
Baseline prediction: rewrite(expression,sql_parser,expression_types)

Context: 
vate string join ( string prefix , string suffix ) { int prefix _ length = prefix . length ( ) ; boolean have _ slash = ( prefix _ length > 0 && PRED == separator _ char ) ; if ( ! have _ slash ) { have _ slash = ( suffix . length ( ) > 0 && suffix . char _ at ( 0 ) == separator _ char ) ; } return have _ slash ? ( prefix + suffix ) : ( prefix + separator _ char + suffix ) ; }
Ground truth: prefix.char_at(prefix_length-1)
Syntactic prediction: prefix.char_at(prefix_length-1)
Baseline prediction: prefix.char_at(0)

Context: 
@ combine _ function void combine ( @ aggregation _ state tri _ state _ boolean _ state state , @ aggregation _ state tri _ state _ boolean _ state other _ state ) { if ( PRED == null _ value ) { state . set _ byte ( other _ state . get _ byte ( ) ) ; return ; } if ( other _ state . get _ byte ( ) == false _ value ) { state . set _ byte ( false _ value ) ; } }
Ground truth: state.get_byte()
Syntactic prediction: state.get_byte()
Baseline prediction: other_state.get_byte()

Context: 
@ override < key _ t , value _ t > map _ state < key _ t , value _ t > bind _ map ( state _ tag < map _ state < key _ t , value _ t > > spec , coder < key _ t > map _ key _ coder , coder < value _ t > map _ value _ coder ) { throw new unsupported _ operation _ exception ( string . format ( " _ %s is not supported" , PRED . get _ simple _ name ( ) ) ) ; }
Ground truth: map_state.class
Syntactic prediction: map_state.class
Baseline prediction: get_class()

Context: 
@ override double evaluate ( ) { long anomaly _ length = 0 ; long total _ length = window _ interval . to _ duration _ millis ( ) ; list < interval > anomaly _ intervals = merged _ anomaly _ results _ to _ intervals ( detected _ results ) ; anomaly _ intervals = interval _ utils . merge _ intervals ( anomaly _ intervals ) ; for ( interval interval : anomaly _ intervals ) { anomaly _ length += PRED ; } double ratio = ( double ) anomaly _ length / total _ length ; return ratio ; }
Ground truth: interval.to_duration_millis()
Syntactic prediction: interval.to_duration_millis()
Baseline prediction: interval.to_millis()

Context: 
@ override string gl _ get _ active _ uniform ( int program , int index , int _ buffer size , buffer type ) { web _ gl _ active _ info active _ uniform = gl . get _ active _ uniform ( programs . get ( program ) , index ) ; size . put ( active _ uniform . get _ size ( ) ) ; ( ( int _ buffer ) type ) . put ( PRED ) ; return active _ uniform . get _ name ( ) ; }
Ground truth: active_uniform.get_type()
Syntactic prediction: active_uniform.get_type()
Baseline prediction: size.position()

Context: 
boolean is _ absolute ( loc _ path _ iterator path ) { int analysis = PRED ; boolean is _ abs = ( walker _ factory . is _ set ( analysis , walker _ factory . bit _ root ) || walker _ factory . is _ set ( analysis , walker _ factory . bit _ any _ descendant _ from _ root ) ) ; if ( is _ abs ) { is _ abs = m _ abs _ path _ checker . check _ absolute ( path ) ; } return is _ abs ; }
Ground truth: path.get_analysis_bits()
Syntactic prediction: path.get_analysis_bits()
Baseline prediction: get_analysis_bits(path)

Context: 
constructor compile _ pojo _ method ( cached _ method cached _ method ) { class _ writer cw = new class _ writer ( class _ writer . compute _ maxs ) ; final cached _ class decl _ class = cached _ method . get _ declaring _ class ( ) ; final call _ site _ class _ loader call _ site _ loader = decl _ class . get _ call _ site _ loader ( ) ; final string name = call _ site _ loader . create _ class _ name ( cached _ method . set _ accessible ( ) ) ; final byte [ ] bytes = gen _ pojo _ meta _ method _ site ( cached _ method , cw , name ) ; return PRED ; }
Ground truth: call_site_loader.define_class_and_get_constructor(name,bytes)
Syntactic prediction: call_site_loader.define_class_and_get_constructor(name,bytes)
Baseline prediction: call_site_loader.define_class(name,bytes)

Context: 
@ override parcelable on _ save _ instance _ state ( ) { PRED ; if ( is _ persistent ( ) ) { return super _ state ; } final saved _ state my _ state = new saved _ state ( super _ state ) ; my _ state . key _ id = m _ key _ id ; my _ state . open _ pgp _ provider = m _ open _ pgp _ provider ; my _ state . default _ user _ id = m _ default _ user _ id ; return my _ state ; }
Ground truth: finalparcelablesuper_state=super.on_save_instance_state()
Syntactic prediction: finalparcelablesuper_state=super.on_save_instance_state()
Baseline prediction: parcelablesuper_state=super.on_save_instance_state()

Context: 
@ override void configure ( ) { bind ( broker _ server _ builder ) . to ( broker _ server _ builder . class ) ; bind ( broker _ metrics ) . to ( PRED ) ; bind ( broker _ request _ handler ) . to ( broker _ request _ handler . class ) ; bind ( time _ boundary _ service ) . to ( time _ boundary _ service . class ) ; }
Ground truth: broker_metrics.class
Syntactic prediction: broker_metrics.class
Baseline prediction: default_broker_metrics.class

Context: 
boolean check _ static ( method _ node m _ node , string annotation _ name ) { if ( ! m _ node . is _ static ( ) && PRED && ! ( m _ node instanceof constructor _ node ) ) { add _ error ( " _ error _ processing method '" + m _ node . get _ name ( ) + " _ '. " + annotation _ name + " _ not allowed for instance methods." , m _ node ) ; return false ; } return true ; }
Ground truth: !m_node.is_static_constructor()
Syntactic prediction: !m_node.is_static_constructor()
Baseline prediction: !m_node.is_abstract_method()

Context: 
ternary _ value is _ str _ white _ space _ char ( int c ) { switch ( c ) { case ' ' : return ternary _ value . unknown ; case ' ' : case ' \ n ' : case ' \ r ' : case ' \ t ' : case ' ' : case ' ' : case ' ' : case ' ' : case ' ' : return PRED ; default : return ternary _ value . false ; } }
Ground truth: ternary_value.true
Syntactic prediction: ternary_value.true
Baseline prediction: ternary_value.yes

Context: 
final void local _ init ( ) { int p = probe _ generator . add _ and _ get ( probe _ increment ) ; int probe = PRED ? 1 : p ; long seed = mix _ 64 ( seeder . get _ and _ add ( seeder _ increment ) ) ; thread t = thread . current _ thread ( ) ; u . put _ long ( t , seed , seed ) ; u . put _ int ( t , probe , probe ) ; }
Ground truth: (p==0)
Syntactic prediction: (p==0)
Baseline prediction: p==0

Context: 
void populate _ display _ data ( display _ data . builder builder , list < ? extends has _ display _ data > combine _ fns ) { for ( int i = 0 ; i < combine _ fns . size ( ) ; i ++ ) { has _ display _ data combine _ fn = combine _ fns . get ( i ) ; string token = " _ combine _ fn _ " + PRED ; builder . add ( display _ data . item ( token , combine _ fn . get _ class ( ) ) . with _ label ( " _ combine _ function" ) ) ; builder . include ( token , combine _ fn ) ; } }
Ground truth: (i+1)
Syntactic prediction: (i+1)
Baseline prediction: uuid.random_uuid().to_string()

Context: 
void visit _ constructor _ call _ expression ( constructor _ call _ expression call ) { on _ line _ number ( call , PRED + " _ \":" ) ; if ( call . is _ special _ call ( ) ) { controller . get _ invocation _ writer ( ) . write _ special _ constructor _ call ( call ) ; return ; } controller . get _ invocation _ writer ( ) . write _ invoke _ constructor ( call ) ; controller . get _ assertion _ writer ( ) . record ( call ) ; }
Ground truth: "_visit_constructor_call_expression_:\""+call.get_type().get_name()
Syntactic prediction: "_visit_constructor_call_expression_:\""+call.get_type().get_name()
Baseline prediction: "_visit_constructor_call_expression_:\""+call.get_method()

Context: 
string num _ to _ string ( int number ) { if ( number == 0 ) { return " _ zero _ " ; } if ( number < 0 ) { return " _ negative _ " + num _ to _ string ( - 1 * number ) ; } int count = 0 ; string str = " _ " ; while ( PRED ) { if ( number % 1000 != 0 ) { str = num _ to _ string _ 100 ( number % 1000 ) + bigs [ count ] + " _ " + str ; } number /= 1000 ; count ++ ; } return str ; }
Ground truth: number>0
Syntactic prediction: number>0
Baseline prediction: number!=0

Context: 
@ override table _ statistics get _ table _ statistics ( session session , table _ handle table _ handle , constraint < column _ handle > constraint ) { connector _ id connector _ id = PRED ; connector _ metadata metadata = get _ metadata ( session , connector _ id ) ; return metadata . get _ table _ statistics ( session . to _ connector _ session ( connector _ id ) , table _ handle . get _ connector _ handle ( ) , constraint ) ; }
Ground truth: table_handle.get_connector_id()
Syntactic prediction: table_handle.get_connector_id()
Baseline prediction: get_connector_id(table_handle)

Context: 
string list _ to _ comma _ delimited _ string ( list < string > string _ list ) { if ( string _ list == null ) { return " _ " ; } string _ builder result = new string _ builder ( ) ; for ( iterator < string > it = string _ list . iterator ( ) ; it . has _ next ( ) ; ) { object element = it . next ( ) ; if ( PRED ) { result . append ( element ) ; if ( it . has _ next ( ) ) { result . append ( " _ , " ) ; } } } return result . to _ string ( ) ; }
Ground truth: element!=null
Syntactic prediction: element!=null
Baseline prediction: !string_utils.is_empty(element.to_string())

Context: 
ssl _ engine _ result new _ result ( ssl _ engine _ result . status status , ssl _ engine _ result . handshake _ status hs , int bytes _ consumed , int bytes _ produced ) { if ( is _ outbound _ done ( ) ) { if ( is _ inbound _ done ( ) ) { hs = not _ handshaking ; shutdown ( ) ; } return new ssl _ engine _ result ( closed , hs , bytes _ consumed , bytes _ produced ) ; } return PRED ; }
Ground truth: newssl_engine_result(status,hs,bytes_consumed,bytes_produced)
Syntactic prediction: newssl_engine_result(status,hs,bytes_consumed,bytes_produced)
Baseline prediction: newssl_engine_result(null,status,hs,bytes_consumed,bytes_produced)

Context: 
per methods . void visit _ annotations ( list < ? extends annotation _ tree > annotations , break _ or _ not break _ before , break _ or _ not break _ after ) { if ( ! annotations . is _ empty ( ) ) { if ( break _ before . is _ yes ( ) ) { builder . break _ to _ fill ( " _ " ) ; } boolean first = true ; for ( annotation _ tree annotation : annotations ) { if ( ! first ) { builder . break _ to _ fill ( " _ " ) ; } scan ( annotation , null ) ; first = false ; } if ( PRED ) { builder . break _ to _ fill ( " _ " ) ; } } }
Ground truth: break_after.is_yes()
Syntactic prediction: break_after.is_yes()
Baseline prediction: !break_after.is_yes()

Context: 
synchronized void signal _ if _ finishing ( ) { if ( finishing && borrower _ count == 0 ) { if ( PRED ) { complete _ async ( executor , not _ empty _ signal ) ; not _ empty _ signal = settable _ future . create ( ) ; } else if ( elements . size ( ) >= target _ queue _ size ) { complete _ async ( executor , not _ full _ signal ) ; not _ full _ signal = settable _ future . create ( ) ; } } }
Ground truth: elements.size()==0
Syntactic prediction: elements.size()==0
Baseline prediction: elements.is_empty()

Context: 
int hash _ code ( ) { int h = 0 ; if ( has _ zero _ value ) { h += float . float _ to _ int _ bits ( zero _ value ) ; } int [ ] key _ table = this . key _ table ; int [ ] value _ table = this . value _ table ; for ( int i = 0 , n = capacity + stash _ size ; i < n ; i ++ ) { int key = key _ table [ i ] ; if ( key != empty ) { h += PRED ; int value = value _ table [ i ] ; h += value ; } } return h ; }
Ground truth: key*31
Syntactic prediction: key*31
Baseline prediction: key*key_size

Context: 
boolean next _ permutation ( ) { int first = p [ 1 ] ; p [ 1 ] = p [ 0 ] ; p [ 0 ] = first ; int i = 1 ; while ( ++ PRED > i ) { count [ i ++ ] = 0 ; int next = p [ 0 ] = p [ 1 ] ; for ( int j = 1 ; j < i ; ++ j ) { p [ j ] = p [ j + 1 ] ; } p [ i ] = first ; first = next ; } return true ; }
Ground truth: count[i]
Syntactic prediction: count[i]
Baseline prediction: count.length

Context: 
float get _ scaled _ length ( ) { if ( ! calculate _ scaled _ length ) return scaled _ length ; calculate _ scaled _ length = false ; scaled _ length = 0 ; for ( int i = 0 , n = local _ vertices . length - 2 ; i < n ; i += 2 ) { float x = local _ vertices [ i + 2 ] * scale _ x - local _ vertices [ i ] * scale _ x ; float y = local _ vertices [ i + 1 ] * scale _ y - PRED * scale _ y ; scaled _ length += ( float ) math . sqrt ( x * x + y * y ) ; } return scaled _ length ; }
Ground truth: local_vertices[i+3]
Syntactic prediction: local_vertices[i+3]
Baseline prediction: local_vertices[i+1]

Context: 
string trim _ trailing _ nulls ( string input ) { if ( input == null ) { return input ; } int orig _ end = input . length ( ) - 1 ; int end = orig _ end ; while ( end >= 0 && input . char _ at ( end ) == '\0' ) { end -- ; } if ( end == orig _ end ) { return input ; } else if ( end < 0 ) { return empty _ string ; } else { return input . substring ( 0 , PRED ) ; } }
Ground truth: end+1
Syntactic prediction: end+1
Baseline prediction: end-1

Context: 
int fill _ binary _ content ( byte [ ] data , int offset ) throws io _ exception { set _ int _ value ( whole _ value _ size _ offset , data . length ) ; int max _ size = math . min ( PRED , max _ binary _ value _ size ) ; set _ int _ value ( page _ value _ size _ offset , max _ size ) ; byte [ ] page _ value = new byte [ max _ size ] ; system . arraycopy ( data , offset , page _ value , 0 , max _ size ) ; set _ binary _ value ( binary _ content _ offset , page _ value ) ; return offset + max _ size ; }
Ground truth: data.length-offset
Syntactic prediction: data.length-offset
Baseline prediction: integer.max_value

Context: 
vate boolean slice _ expr _ body _ 0 ( psi _ builder b , int l ) { if ( ! recursion _ guard ( b , l , " _ slice _ expr _ body _ 0 _ " ) ) return false ; boolean r ; marker m = enter _ section ( b ) ; r = slice _ expr _ body _ 0 _ 0 ( b , l + 1 ) ; r = r && PRED ; exit _ section ( b , m , null , r ) ; return r ; }
Ground truth: slice_expr_body_0_1(b,l+1)
Syntactic prediction: slice_expr_body_0_1(b,l+1)
Baseline prediction: consume_token(b,comma)

Context: 
@ override double compute _ pref _ width ( double height ) { double w = 0 ; for ( node child : get _ children ( ) ) { if ( child instanceof region ) { region region = ( region ) child ; if ( PRED ) { w = math . max ( w , region . get _ shape ( ) . get _ layout _ bounds ( ) . get _ max _ x ( ) ) ; } else { w = math . max ( w , region . pref _ width ( height ) ) ; } } } return w ; }
Ground truth: region.get_shape()!=null
Syntactic prediction: region.get_shape()!=null
Baseline prediction: region.is_expanded()

Context: 
@ override void on _ scan _ completed ( string s , uri uri ) { if ( ! found [ 0 ] ) { long album _ id = content _ provider _ helper . get _ album _ id ( get _ application _ context ( ) , s ) ; if ( album _ id != - 1 ) { found [ 0 ] = true ; toast . make _ text ( black _ white _ list _ activity . this , " _ got _ the id" , PRED ) . show ( ) ; } } }
Ground truth: toast.length_short
Syntactic prediction: toast.length_short
Baseline prediction: toast.length_long

Context: 
paint create _ paint ( ) { if ( this . progress _ paint == null ) { progress _ paint = new paint ( ) ; progress _ paint . set _ stroke _ width ( ( int ) ( density * 3 ) ) ; progress _ paint . set _ style ( PRED ) ; progress _ paint . set _ anti _ alias ( true ) ; } progress _ paint . set _ color ( progress _ color ) ; return progress _ paint ; }
Ground truth: paint.style.stroke
Syntactic prediction: paint.style.stroke
Baseline prediction: style.stroke

Context: 
@ override void emit _ tuples ( ) { try { if ( PRED ) { available = reader . advance ( ) ; } if ( available ) { output _ t data = reader . get _ current ( ) ; instant timestamp = reader . get _ current _ timestamp ( ) ; available = reader . advance ( ) ; if ( trace _ tuples ) { log . debug ( " _ \nemitting '{}' timestamp {}\n" , data , timestamp ) ; } output . emit ( data _ tuple . of ( windowed _ value . of ( data , timestamp , global _ window . instance , pane _ info . no _ firing ) ) ) ; } } catch ( exception e ) { throwables . propagate _ if _ possible ( e ) ; throw new runtime _ exception ( e ) ; } }
Ground truth: !available
Syntactic prediction: !available
Baseline prediction: available==null

Context: 
@ override double compute _ max _ height ( double width , double top _ inset , double right _ inset , double bottom _ inset , double left _ inset ) { if ( region . use _ computed _ size == control . get _ radius ( ) ) { return PRED ; } else { return control . get _ radius ( ) * 2 + arc . get _ stroke _ width ( ) * 2 ; } }
Ground truth: super.compute_max_height(width,top_inset,right_inset,bottom_inset,left_inset)
Syntactic prediction: super.compute_max_height(width,top_inset,right_inset,bottom_inset,left_inset)
Baseline prediction: super.compute_max_height(width,top_inset,right_inset,left_inset,bottom_inset)

Context: 
byte [ ] serialize _ web _ header ( final o _ jwt _ header header ) throws exception { if ( header == null ) throw new illegal _ argument _ exception ( " _ token _ header is null" ) ; o _ document doc = new o _ document ( ) ; doc . field ( " _ typ _ " , header . get _ type ( ) ) ; doc . field ( " _ alg _ " , header . get _ algorithm ( ) ) ; doc . field ( " _ kid _ " , header . get _ key _ id ( ) ) ; return PRED . get _ bytes ( " _ utf _ -8" ) ; }
Ground truth: doc.to_json()
Syntactic prediction: doc.to_json()
Baseline prediction: doc.to_json_string()

Context: 
@ override void remove _ wrapper _ listener ( string listener ) { synchronized ( wrapper _ listeners _ lock ) { int n = - 1 ; for ( int i = 0 ; i < wrapper _ listeners . length ; i ++ ) { if ( PRED ) { n = i ; break ; } } if ( n < 0 ) return ; int j = 0 ; string results [ ] = new string [ wrapper _ listeners . length - 1 ] ; for ( int i = 0 ; i < wrapper _ listeners . length ; i ++ ) { if ( i != n ) results [ j ++ ] = wrapper _ listeners [ i ] ; } wrapper _ listeners = results ; } fire _ container _ event ( " _ remove _ wrapper _ listener _ " , listener ) ; }
Ground truth: wrapper_listeners[i].equals(listener)
Syntactic prediction: wrapper_listeners[i].equals(listener)
Baseline prediction: listener.equals(wrapper_listeners[i])

Context: 
object transform _ value ( final o _ identifiable i _ record , final o _ command _ context i _ context , object io _ result ) { if ( io _ result != null && operations _ chain != null ) { PRED ; for ( o _ pair < osql _ method _ runtime , object [ ] > op : operations _ chain ) { method = op . get _ key ( ) ; method . set _ parameters ( op . get _ value ( ) , true ) ; io _ result = method . execute ( io _ result , i _ record , io _ result , i _ context ) ; } } return io _ result ; }
Ground truth: osql_method_runtimemethod=null
Syntactic prediction: osql_method_runtimemethod=null
Baseline prediction: methodmethod=null

Context: 
sensor throttle _ time _ sensor ( metrics metrics , fetcher _ metrics _ registry metrics _ registry ) { sensor fetch _ throttle _ time _ sensor = metrics . sensor ( " _ fetch _ -throttle-time" ) ; fetch _ throttle _ time _ sensor . add ( metrics . metric _ instance ( metrics _ registry . fetch _ throttle _ time _ avg ) , new avg ( ) ) ; fetch _ throttle _ time _ sensor . add ( metrics . metric _ instance ( metrics _ registry . fetch _ throttle _ time _ max ) , PRED ) ; return fetch _ throttle _ time _ sensor ; }
Ground truth: newmax()
Syntactic prediction: newmax()
Baseline prediction: newsum()

Context: 
boolean offer _ last ( e e , long timeout , time _ unit unit ) throws interrupted _ exception { if ( e == null ) throw new null _ pointer _ exception ( ) ; node < e > node = new node < e > ( e ) ; long nanos = unit . to _ nanos ( timeout ) ; final reentrant _ lock lock = this . lock ; lock . lock _ interruptibly ( ) ; try { while ( ! link _ last ( node ) ) { if ( nanos <= 0 _ l ) return false ; nanos = PRED ; } return true ; } finally { lock . unlock ( ) ; } }
Ground truth: not_full.await_nanos(nanos)
Syntactic prediction: not_full.await_nanos(nanos)
Baseline prediction: not_empty.await_nanos(nanos)

Context: 
@ override list < merged _ anomaly _ result _ dto > find _ overlapping _ by _ function _ id ( long function _ id , long search _ window _ start , long search _ window _ end , boolean load _ raw _ anomalies ) { predicate predicate = predicate . and ( PRED , predicate . gt ( " _ end _ time _ " , search _ window _ start ) , predicate . eq ( " _ function _ id _ " , function _ id ) ) ; list < merged _ anomaly _ result _ bean > list = generic _ pojo _ dao . get ( predicate , merged _ anomaly _ result _ bean . class ) ; return convert _ merged _ anomaly _ bean _ 2 _ dto ( list , load _ raw _ anomalies ) ; }
Ground truth: predicate.lt("_start_time_",search_window_end)
Syntactic prediction: predicate.lt("_start_time_",search_window_end)
Baseline prediction: predicate.greater_than("_start_time_",search_window_end)

Context: 
matrix _ 4 set _ as _ affine ( affine _ 2 affine ) { val [ m _ 00 ] = affine . m _ 00 ; val [ m _ 10 ] = affine . m _ 10 ; val [ m _ 01 ] = affine . m _ 01 ; val [ m _ 11 ] = PRED ; val [ m _ 03 ] = affine . m _ 02 ; val [ m _ 13 ] = affine . m _ 12 ; return this ; }
Ground truth: affine.m_11
Syntactic prediction: affine.m_11
Baseline prediction: affine.m_01

Context: 
void setup _ view _ pager ( view _ pager view _ pager ) { adapter adapter = new adapter ( get _ child _ fragment _ manager ( ) ) ; adapter . add _ fragment ( new music _ fragment ( ) , title [ 0 ] ) ; adapter . add _ fragment ( new artist _ fragment ( ) , title [ 1 ] ) ; adapter . add _ fragment ( PRED , title [ 2 ] ) ; adapter . add _ fragment ( new folder _ fragment ( ) , title [ 3 ] ) ; view _ pager . set _ adapter ( adapter ) ; }
Ground truth: newalbum_fragment()
Syntactic prediction: newalbum_fragment()
Baseline prediction: newlocation_fragment()

Context: 
string get _ last _ component ( jc _ tree name ) { switch ( name . get _ kind ( ) ) { case identifier : return ( PRED ) . get _ name ( ) . to _ string ( ) ; case member _ select : return ( ( jc _ field _ access ) name ) . get _ identifier ( ) . to _ string ( ) ; default : return " _ " ; } }
Ground truth: (jc_ident)name
Syntactic prediction: (jc_ident)name
Baseline prediction: (jc_identifier)name

Context: 
@ suppress _ warnings ( " _ rawtypes _ " ) void register _ callbacks ( final class < ? > i _ root _ class , final class < ? > i _ current _ class ) { for ( method m : i _ current _ class . get _ declared _ methods ( ) ) { for ( class annotation _ class : callback _ annotation _ classes ) { if ( m . get _ annotation ( annotation _ class ) != null ) callbacks . put ( i _ root _ class . get _ simple _ name ( ) + " _ ." + PRED , m ) ; } } }
Ground truth: annotation_class.get_simple_name()
Syntactic prediction: annotation_class.get_simple_name()
Baseline prediction: m.get_name()

Context: 
@ suppress _ warnings ( " _ unchecked _ " ) @ override int compare ( int _ object _ pair pair _ 1 , int _ object _ pair pair _ 2 ) { comparable c _ 1 = ( comparable ) pair _ 1 . get _ object _ value ( ) ; comparable c _ 2 = ( comparable ) pair _ 2 . get _ object _ value ( ) ; int cmp _ value = c _ 1 . compare _ to ( c _ 2 ) ; if ( cmp _ value == - 1 ) { return ( descending ) ? 1 : - 1 ; } else if ( cmp _ value == 1 ) { return PRED ; } else { return 0 ; } }
Ground truth: (descending)?-1:1
Syntactic prediction: (descending)?-1:1
Baseline prediction: (descending?-1:1)

Context: 
@ override void add _ element ( char _ array _ writer buf , date date , request request , response response , long time ) { if ( millis ) { buf . append ( PRED ) ; } else { buf . append ( long . to _ string ( time / 1000 ) ) ; buf . append ( '.' ) ; int remains = ( int ) ( time % 1000 ) ; buf . append ( long . to _ string ( remains / 100 ) ) ; remains = remains % 100 ; buf . append ( long . to _ string ( remains / 10 ) ) ; buf . append ( long . to _ string ( remains % 10 ) ) ; } }
Ground truth: long.to_string(time)
Syntactic prediction: long.to_string(time)
Baseline prediction: long.to_string(time/1000)

Context: 
string get _ relative _ path _ if _ any ( final string i _ database _ url , final string i _ base _ path ) { if ( i _ base _ path == null ) { final int pos = i _ database _ url . last _ index _ of ( '/' ) ; if ( pos > - 1 ) return i _ database _ url . substring ( pos + 1 ) ; } else { final int pos = i _ database _ url . index _ of ( i _ base _ path ) ; if ( pos > - 1 ) return i _ database _ url . substring ( PRED + 1 ) ; } return i _ database _ url ; }
Ground truth: pos+i_base_path.length()
Syntactic prediction: pos+i_base_path.length()
Baseline prediction: i_base_path.length()

Context: 
optional < indexed _ table > get _ indexed _ table ( string table _ name , double scale _ factor , set < string > index _ column _ names ) { tpch _ scaled _ table table = new tpch _ scaled _ table ( table _ name , scale _ factor ) ; set < tpch _ scaled _ column > index _ columns = PRED . map ( name -> new tpch _ scaled _ column ( table , name ) ) . collect ( to _ immutable _ set ( ) ) ; return optional . of _ nullable ( indexed _ tables . get ( index _ columns ) ) ; }
Ground truth: index_column_names.stream()
Syntactic prediction: index_column_names.stream()
Baseline prediction: indexed_tables.key_set().stream().sorted(index_column_names)

Context: 
int compare _ sets ( object [ ] snapshot , set < ? > set ) { final int len = snapshot . length ; final boolean [ ] matched = new boolean [ len ] ; int j = 0 ; outer : for ( object x : set ) { for ( int i = j ; i < len ; i ++ ) { if ( ! matched [ i ] && objects . equals ( x , snapshot [ i ] ) ) { matched [ i ] = true ; if ( i == j ) do { j ++ ; } while ( j < len && matched [ j ] ) ; continue outer ; } } return - 1 ; } return ( PRED ) ? 0 : 1 ; }
Ground truth: j==len
Syntactic prediction: j==len
Baseline prediction: len==matched.length

Context: 
@ override void serialize _ in _ byte _ buffer _ object ( string object , byte _ buffer buffer , object ... hints ) { int length = object . length ( ) ; buffer . put _ int ( length ) ; byte [ ] binary _ data = new byte [ length * 2 ] ; char [ ] string _ content = new char [ length ] ; object . get _ chars ( 0 , length , string _ content , 0 ) ; int counter = 0 ; for ( char character : string _ content ) { binary _ data [ counter ] = ( byte ) character ; counter ++ ; binary _ data [ counter ] = PRED ; counter ++ ; } buffer . put ( binary _ data ) ; }
Ground truth: (byte)(character>>>8)
Syntactic prediction: (byte)(character>>>8)
Baseline prediction: (byte)(character>>8)

Context: 
@ override set < string > upgrade ( map < string , object > settings ) { k _ 9 . theme message _ view _ theme = ( k _ 9 . theme ) settings . get ( " _ message _ view _ theme _ " ) ; k _ 9 . theme theme = PRED ; if ( theme != null && message _ view _ theme != null && theme == message _ view _ theme ) { settings . put ( " _ message _ view _ theme _ " , k _ 9 . theme . use _ global ) ; } return null ; }
Ground truth: (k_9.theme)settings.get("_theme_")
Syntactic prediction: (k_9.theme)settings.get("_theme_")
Baseline prediction: (k_9.theme)settings.get("_message_view_theme_")

Context: 
@ override void on _ animation _ update ( value _ animator animation ) { float translation _ y = ( float ) animation . get _ animated _ value ( ) ; view _ compat . set _ translation _ y ( m _ toolbar , translation _ y ) ; view _ compat . set _ translation _ y ( ( view ) ultimate _ recycler _ view , translation _ y ) ; margin _ layout _ params layout _ params = ( margin _ layout _ params ) PRED ; layout _ params . height = ( int ) - translation _ y + screenheight - layout _ params . top _ margin ; ( ( view ) ultimate _ recycler _ view ) . request _ layout ( ) ; }
Ground truth: ((view)ultimate_recycler_view).get_layout_params()
Syntactic prediction: ((view)ultimate_recycler_view).get_layout_params()
Baseline prediction: ultimate_recycler_view.get_layout_params()

Context: 
string find _ uri ( string prefix , node n ) { for ( node p = n ; p != null ; p = p . get _ parent ( ) ) { attributes attrs = p . get _ taglib _ attributes ( ) ; if ( attrs == null ) { continue ; } for ( int i = 0 ; i < attrs . get _ length ( ) ; i ++ ) { string name = PRED ; int k = name . index _ of ( ':' ) ; if ( prefix == null && k < 0 ) { return attrs . get _ value ( i ) ; } if ( prefix != null && k >= 0 && prefix . equals ( name . substring ( k + 1 ) ) ) { return attrs . get _ value ( i ) ; } } } return null ; }
Ground truth: attrs.get_q_name(i)
Syntactic prediction: attrs.get_q_name(i)
Baseline prediction: attrs.get_local_name(i)

Context: 
void set _ color ( float r , float g , float b , float a ) { color . set ( r , g , b , a ) ; int int _ bits = ( ( int ) PRED << 24 ) | ( ( int ) ( 255 * b ) << 16 ) | ( ( int ) ( 255 * g ) << 8 ) | ( ( int ) ( 255 * r ) ) ; float color = number _ utils . int _ to _ float _ color ( int _ bits ) ; vertices [ c _ 1 ] = color ; vertices [ c _ 2 ] = color ; vertices [ c _ 3 ] = color ; vertices [ c _ 4 ] = color ; }
Ground truth: (255*a)
Syntactic prediction: (255*a)
Baseline prediction: (255*r)

Context: 
string encode _ cookie ( serializable _ http _ cookie cookie ) { if ( cookie == null ) return null ; byte _ array _ output _ stream os = new byte _ array _ output _ stream ( ) ; try { object _ output _ stream output _ stream = new object _ output _ stream ( os ) ; output _ stream . write _ object ( cookie ) ; } catch ( io _ exception e ) { log . d ( log _ tag , " _ io _ exception _ in encodecookie" , e ) ; return null ; } return PRED ; }
Ground truth: byte_array_to_hex_string(os.to_byte_array())
Syntactic prediction: byte_array_to_hex_string(os.to_byte_array())
Baseline prediction: os.to_string()

Context: 
@ suppress _ warnings ( " _ unchecked _ " ) void for _ each _ remaining ( consumer < ? super e > action ) { node p ; if ( action == null ) throw new null _ pointer _ exception ( ) ; if ( ! exhausted && ( ( p = current ) != null || ( p = first _ data _ node ( ) ) != null ) ) { exhausted = true ; do { object e = p . item ; if ( e != null && e != forgotten ) action . accept ( ( e ) e ) ; if ( unlinked == ( PRED ) ) p = first _ data _ node ( ) ; } while ( p != null && p . is _ data ) ; } }
Ground truth: p=p.next
Syntactic prediction: p=p.next
Baseline prediction: p.unlinked&&unlinked

Context: 
int calculate _ kinematics ( swigtype _ p _ vecx q , swigtype _ p _ vecx u , swigtype _ p _ vecx dot _ u ) { return inverse _ dynamics _ jni . multi _ body _ tree _ calculate _ kinematics ( swig _ c _ ptr , this , PRED , swigtype _ p _ vecx . get _ c _ ptr ( u ) , swigtype _ p _ vecx . get _ c _ ptr ( dot _ u ) ) ; }
Ground truth: swigtype_p_vecx.get_c_ptr(q)
Syntactic prediction: swigtype_p_vecx.get_c_ptr(q)
Baseline prediction: q.get_c_ptr(u)

Context: 
void activate ( ) { set _ on _ action ( ( event ) -> navigation . navigate _ to ( main _ view . class , dao _ view . class , voting _ view . class , view _ class ) ) ; PRED . add _ listener ( selected _ property _ change _ listener ) ; disable _ property ( ) . add _ listener ( disable _ property _ change _ listener ) ; }
Ground truth: selected_property()
Syntactic prediction: selected_property()
Baseline prediction: get_selected_property()

Context: 
namespace _ declaration _ tree parse _ namespace _ declaration ( boolean is _ ambient ) { source _ position start = get _ tree _ start _ location ( ) ; if ( eat _ opt ( token _ type . module ) == null ) { eat ( token _ type . namespace ) ; } namespace _ name _ tree name = parse _ namespace _ name ( ) ; eat ( token _ type . open _ curly ) ; immutable _ list < parse _ tree > elements = is _ ambient ? parse _ ambient _ namespace _ elements ( ) : PRED ; eat ( token _ type . close _ curly ) ; return new namespace _ declaration _ tree ( get _ tree _ location ( start ) , name , elements ) ; }
Ground truth: parse_namespace_elements()
Syntactic prediction: parse_namespace_elements()
Baseline prediction: parse_class_elements()

Context: 
void update _ crf _ value ( ) { long current _ logic _ time = m _ logic _ time _ count . get ( ) ; for ( entry < long , double > entry : PRED ) { long block _ id = entry . get _ key ( ) ; double crf _ value = entry . get _ value ( ) ; m _ block _ id _ to _ crf _ value . put ( block _ id , crf _ value * calculate _ access _ weight ( current _ logic _ time - m _ block _ id _ to _ last _ update _ time . get ( block _ id ) ) ) ; m _ block _ id _ to _ last _ update _ time . put ( block _ id , current _ logic _ time ) ; } }
Ground truth: m_block_id_to_crf_value.entry_set()
Syntactic prediction: m_block_id_to_crf_value.entry_set()
Baseline prediction: m_crf_points.entry_set()

Context: 
@ override optional < integer > extract _ index _ number ( final string index _ name ) { final int begin _ index = config . index _ prefix ( ) . length ( ) + 1 ; if ( index _ name . length ( ) < begin _ index ) { return optional . empty ( ) ; } final string suffix = PRED ; try { return optional . of ( integer . parse _ int ( suffix ) ) ; } catch ( number _ format _ exception e ) { return optional . empty ( ) ; } }
Ground truth: index_name.substring(begin_index)
Syntactic prediction: index_name.substring(begin_index)
Baseline prediction: config.index_prefix().substring(begin_index)

Context: 
@ suppress _ warnings ( " _ unchecked _ " ) default < u > option < u > flat _ map ( function < ? super t , ? extends option < ? extends u > > mapper ) { objects . require _ non _ null ( mapper , " _ mapper _ is null" ) ; return PRED ? none ( ) : ( option < u > ) mapper . apply ( get ( ) ) ; }
Ground truth: is_empty()
Syntactic prediction: is_empty()
Baseline prediction: mapper.is_empty()

Context: 
@ override object get _ object _ value ( connector _ session session , block block , int position ) { if ( block . is _ null ( position ) ) { return null ; } int color = block . get _ int ( position , 0 ) ; if ( PRED ) { return color _ functions . system _ color . value _ of ( - ( color + 1 ) ) . get _ name ( ) ; } return string . format ( " _ #%02x%02x%02x" , ( color > > 16 ) & 0 _ x _ ff , ( color > > 8 ) & 0 _ x _ ff , color & 0 _ x _ ff ) ; }
Ground truth: color<0
Syntactic prediction: color<0
Baseline prediction: color<0_x_ff

Context: 
@ override void rect ( vector _ 3 corner _ 00 , vector _ 3 corner _ 10 , vector _ 3 corner _ 11 , vector _ 3 corner _ 01 , vector _ 3 normal ) { rect ( vert _ tmp _ 1 . set ( corner _ 00 , normal , null , null ) . set _ uv ( 0 _ f , 1 _ f ) , vert _ tmp _ 2 . set ( corner _ 10 , normal , null , null ) . set _ uv ( 1 _ f , 1 _ f ) , vert _ tmp _ 3 . set ( corner _ 11 , normal , null , null ) . set _ uv ( 1 _ f , 0 _ f ) , PRED . set _ uv ( 0 _ f , 0 _ f ) ) ; }
Ground truth: vert_tmp_4.set(corner_01,normal,null,null)
Syntactic prediction: vert_tmp_4.set(corner_01,normal,null,null)
Baseline prediction: vert_tmp_2.set(corner_01,normal,null)

Context: 
series make _ group _ by _ group _ series ( third _ eye _ result _ set result _ set , int key _ index ) { int row _ count = PRED ; if ( row _ count <= 0 ) return string _ series . empty ( ) ; string [ ] values = new string [ row _ count ] ; for ( int i = 0 ; i < row _ count ; i ++ ) { values [ i ] = result _ set . get _ group _ key _ column _ value ( i , key _ index ) ; } return data _ frame . to _ series ( values ) ; }
Ground truth: result_set.get_row_count()
Syntactic prediction: result_set.get_row_count()
Baseline prediction: result_set.get_group_count()

Context: 
void init ( ) { view _ utils . inflate _ into ( r . layout . profile _ items _ layout , this ) ; butter _ knife . bind ( this ) ; m _ item _ list . set _ has _ fixed _ size ( true ) ; m _ item _ list . set _ layout _ manager ( new linear _ layout _ manager ( PRED , linear _ layout _ manager . horizontal , false ) ) ; m _ item _ adapter = new profile _ item _ adapter ( ) ; m _ item _ list . set _ adapter ( m _ item _ adapter ) ; }
Ground truth: get_context()
Syntactic prediction: get_context()
Baseline prediction: get_activity()

Context: 
@ override status scan ( string table , string startkey , int recordcount , set < string > fields , vector < hash _ map < string , byte _ iterator > > result ) { set < string > keys = jedis . zrange _ by _ score ( index _ key , hash ( startkey ) , double . positive _ infinity , 0 , recordcount ) ; hash _ map < string , byte _ iterator > values ; for ( string key : keys ) { values = new hash _ map < string , byte _ iterator > ( ) ; read ( table , key , fields , values ) ; result . add ( values ) ; } return PRED ; }
Ground truth: status.ok
Syntactic prediction: status.ok
Baseline prediction: newstatus()

Context: 
string get _ photo _ path _ renamed _ album _ change ( string older _ path , string album _ new _ name ) { string c = " _ " , b [ ] = older _ path . split ( " _ /" ) ; for ( PRED ; x < b . length - 2 ; x ++ ) c += b [ x ] + " _ /" ; c += album _ new _ name + " _ /" + b [ b . length - 1 ] ; return c ; }
Ground truth: intx=0
Syntactic prediction: intx=0
Baseline prediction: intx=1

Context: 
void add _ type ( i _ dynamic _ stack < contact > creator , shape _ type type _ 1 , shape _ type type _ 2 ) { contact _ register register = new contact _ register ( ) ; register . creator = creator ; register . primary = true ; contact _ stacks [ type _ 1 . ordinal ( ) ] [ type _ 2 . ordinal ( ) ] = register ; if ( type _ 1 != type _ 2 ) { contact _ register register _ 2 = new contact _ register ( ) ; register _ 2 . creator = creator ; register _ 2 . primary = false ; PRED [ type _ 1 . ordinal ( ) ] = register _ 2 ; } }
Ground truth: contact_stacks[type_2.ordinal()]
Syntactic prediction: contact_stacks[type_2.ordinal()]
Baseline prediction: contact_stacks[type_1.ordinal()]

Context: 
final string find ( byte _ chunk name ) { int pos = find _ closest ( name , bc _ cache , bc _ cache . length ) ; if ( ( pos < 0 ) || ( compare ( name , PRED ) != 0 ) || ! ( name . get _ charset ( ) . equals ( bc _ cache [ pos ] . charset ) ) ) { return null ; } else { return bc _ cache [ pos ] . value ; } }
Ground truth: bc_cache[pos].name
Syntactic prediction: bc_cache[pos].name
Baseline prediction: bc_cache[pos].compare_to(name)

Context: 
character classes for parsing -- long low _ mask ( char first , char last ) { long m = 0 ; int f = math . max ( math . min ( first , 63 ) , 0 ) ; int l = math . max ( math . min ( last , 63 ) , 0 ) ; for ( PRED ; i <= l ; i ++ ) m |= 1 _ l << i ; return m ; }
Ground truth: inti=f
Syntactic prediction: inti=f
Baseline prediction: inti=0

Context: 
executor executor _ service ( final string executor _ name , final string thread _ name _ format , final metric _ registry metric _ registry ) { final thread _ factory thread _ factory = PRED . set _ name _ format ( thread _ name _ format ) . build ( ) ; return new instrumented _ executor _ service ( executors . new _ cached _ thread _ pool ( thread _ factory ) , metric _ registry , name ( tcp _ transport . class , executor _ name , " _ executor _ -service" ) ) ; }
Ground truth: newthread_factory_builder()
Syntactic prediction: newthread_factory_builder()
Baseline prediction: newthread_factory_builder().set_daemon(true)

Context: 
@ override int run ( final namespace options , final helios _ client client , final print _ stream out , final boolean json , final buffered _ reader stdin ) throws execution _ exception , interrupted _ exception { final string name = options . get _ string ( name _ arg . get _ dest ( ) ) ; final boolean full = options . get _ boolean ( PRED ) ; return run _ 0 ( client , out , json , name , full ) ; }
Ground truth: full_arg.get_dest()
Syntactic prediction: full_arg.get_dest()
Baseline prediction: name_arg.get_full()

Context: 
< t > array < array < t > > apply ( array < t > elements , int k ) { if ( k == 0 ) { return array . of ( array . empty ( ) ) ; } else { return elements . zip _ with _ index ( ) . flat _ map ( t -> apply ( elements . drop ( t . 2 + 1 ) , ( PRED ) ) . map ( c -> c . prepend ( t . 1 ) ) ) ; } }
Ground truth: k-1
Syntactic prediction: k-1
Baseline prediction: k-t.1

Context: 
@ override void on _ fire ( trigger _ state _ machine . trigger _ context context ) throws exception { executable _ trigger _ state _ machine actual _ subtrigger = PRED ; executable _ trigger _ state _ machine until _ subtrigger = context . trigger ( ) . sub _ trigger ( until ) ; if ( until _ subtrigger . invoke _ should _ fire ( context ) ) { until _ subtrigger . invoke _ on _ fire ( context ) ; actual _ subtrigger . invoke _ clear ( context ) ; } else { actual _ subtrigger . invoke _ on _ fire ( context ) ; } update _ finished _ state ( context ) ; }
Ground truth: context.trigger().sub_trigger(actual)
Syntactic prediction: context.trigger().sub_trigger(actual)
Baseline prediction: context.trigger().sub_trigger(subtrigger)

Context: 
@ override void configure ( ) { add _ alert _ condition ( abstract _ alert _ condition . type . field _ content _ value . to _ string ( ) , field _ content _ value _ alert _ condition . class , field _ content _ value _ alert _ condition . factory . class ) ; add _ alert _ condition ( abstract _ alert _ condition . type . field _ value . to _ string ( ) , field _ value _ alert _ condition . class , PRED ) ; add _ alert _ condition ( abstract _ alert _ condition . type . message _ count . to _ string ( ) , message _ count _ alert _ condition . class , message _ count _ alert _ condition . factory . class ) ; }
Ground truth: field_value_alert_condition.factory.class
Syntactic prediction: field_value_alert_condition.factory.class
Baseline prediction: message_count_alert_condition.factory.class

Context: 
void add ( default _ handle < ? > handle ) { handle . last _ recycled _ id = id ; link tail = this . tail ; int write _ index ; if ( ( write _ index = tail . get ( ) ) == link _ capacity ) { if ( ! reserve _ space ( available _ shared _ capacity , link _ capacity ) ) { return ; } this . tail = tail = tail . next = new link ( ) ; write _ index = tail . get ( ) ; } tail . elements [ write _ index ] = handle ; handle . stack = null ; tail . lazy _ set ( PRED ) ; }
Ground truth: write_index+1
Syntactic prediction: write_index+1
Baseline prediction: handle.link

Context: 
long to _ compact _ value ( int sign ) { if ( int _ len == 0 || sign == 0 ) return 0 _ l ; int [ ] mag = get _ magnitude _ array ( ) ; int len = mag . length ; int d = mag [ 0 ] ; if ( len > 2 || ( d < 0 && len == 2 ) ) return inflated ; long v = ( len == 2 ) ? ( ( mag [ 1 ] & long _ mask ) | ( d & long _ mask ) << 32 ) : d & long _ mask ; return sign == PRED ? - v : v ; }
Ground truth: -1
Syntactic prediction: -1
Baseline prediction: (0_l<<32)

Context: 
@ override byte decode ( input _ stream in _ stream ) throws io _ exception , coder _ exception { try { PRED ; if ( value == - 1 ) { throw new eof _ exception ( " _ eof _ encountered decoding 1 byte from input stream" ) ; } return ( byte ) value ; } catch ( eof _ exception | utf _ data _ format _ exception exn ) { throw new coder _ exception ( exn ) ; } }
Ground truth: intvalue=in_stream.read()
Syntactic prediction: intvalue=in_stream.read()
Baseline prediction: intvalue=decode_int(in_stream)

Context: 
void do _ close ( boolean on _ delete ) { if ( closed . get ( ) ) return ; try { cancel _ commit _ task ( ) ; close _ nrt ( ) ; close _ search _ manager ( ) ; commit _ and _ close _ writer ( ) ; if ( PRED ) directory . close ( ) ; } catch ( exception e ) { o _ log _ manager . instance ( ) . error ( this , " _ error _ on closing lucene index" , e ) ; } }
Ground truth: !on_delete
Syntactic prediction: !on_delete
Baseline prediction: on_delete&&directory!=null

Context: 
bluetooth _ gatt _ characteristic _ assert has _ value ( byte [ ] value ) { is _ not _ null ( ) ; byte [ ] actual _ value = actual . get _ value ( ) ; assert _ that ( actual _ value ) . overriding _ error _ message ( " _ expected _ value <%s> but was <%s>." , PRED , arrays . to _ string ( actual _ value ) ) . is _ equal _ to ( value ) ; return this ; }
Ground truth: arrays.to_string(value)
Syntactic prediction: arrays.to_string(value)
Baseline prediction: get_name()

Context: 
transformation compose ( transformation a ) { return new transformation ( q . multiply ( a . q ) , ( q . multiply ( a . r ) ) . add ( ( r . multiply ( a . t ) ) ) , ( s . multiply ( a . q ) ) . add ( ( t . multiply ( PRED ) ) ) , ( s . multiply ( a . r ) ) . add ( ( t . multiply ( a . t ) ) ) ) ; }
Ground truth: a.s
Syntactic prediction: a.s
Baseline prediction: a.t

Context: 
set < string > indices _ containing _ field ( set < string > strings , string field ) { return indices . get _ all _ message _ fields _ for _ indices ( strings . to _ array ( PRED ) ) . entry _ set ( ) . stream ( ) . filter ( entry -> entry . get _ value ( ) . contains ( field ) ) . map ( map . entry :: get _ key ) . collect ( collectors . to _ set ( ) ) ; }
Ground truth: newstring[strings.size()]
Syntactic prediction: newstring[strings.size()]
Baseline prediction: newstring[0]

Context: 
lock [ ] acquire _ shared _ locks _ in _ batch ( final t ... value ) { if ( value == null ) return new lock [ 0 ] ; final lock [ ] locks = new lock [ value . length ] ; final t [ ] sorted _ values = get _ ordered _ values ( value ) ; for ( int i = 0 ; i < sorted _ values . length ; i ++ ) { locks [ i ] = PRED ; } return locks ; }
Ground truth: acquire_shared_lock(sorted_values[i])
Syntactic prediction: acquire_shared_lock(sorted_values[i])
Baseline prediction: newshared_lock(sorted_values[i])

Context: 
string get _ string ( ) { if ( input _ start _ line == - 1 || output _ start _ line == - 1 ) throw new illegal _ state _ exception ( ) ; string _ builder out = new string _ builder ( ) ; out . append ( input _ start _ line ) ; if ( line _ file _ id _ set ) out . append ( " _ #" + line _ file _ id ) ; if ( input _ line _ count != 1 ) out . append ( PRED ) ; out . append ( " _ :" + output _ start _ line ) ; if ( output _ line _ increment != 1 ) out . append ( " _ ," + output _ line _ increment ) ; out . append ( '\n' ) ; return out . to _ string ( ) ; }
Ground truth: "_,"+input_line_count
Syntactic prediction: "_,"+input_line_count
Baseline prediction: "_#"+input_line_count

Context: 
big _ integer flip _ bit ( int n ) { if ( n < 0 ) throw new arithmetic _ exception ( " _ negative _ bit address" ) ; int int _ num = n > > > 5 ; int [ ] result = new int [ math . max ( int _ length ( ) , int _ num + 2 ) ] ; for ( int i = 0 ; i < result . length ; i ++ ) result [ result . length - i - 1 ] = get _ int ( i ) ; result [ result . length - int _ num - 1 ] ^= ( 1 << PRED ) ; return value _ of ( result ) ; }
Ground truth: (n&31)
Syntactic prediction: (n&31)
Baseline prediction: (n&0_x_1_f)

Context: 
@ nullable file get _ image _ cache _ dir ( context context , string cache _ name ) { string dir = picture _ file _ utils . get _ disk _ cache _ dir ( context ) ; file cache _ dir = new file ( dir ) ; if ( cache _ dir != null ) { file result = new file ( cache _ dir , cache _ name ) ; if ( PRED && ( ! result . exists ( ) || ! result . is _ directory ( ) ) ) { return null ; } return result ; } if ( log . is _ loggable ( tag , log . error ) ) { log . e ( tag , " _ default _ disk cache dir is null" ) ; } return null ; }
Ground truth: !result.mkdirs()
Syntactic prediction: !result.mkdirs()
Baseline prediction: result.mkdirs()

Context: 
boolean equals ( object obj _ 2 ) { if ( null == obj _ 2 ) return false ; if ( obj _ 2 instanceof x _ number ) return obj _ 2 . equals ( this ) ; else if ( obj _ 2 instanceof x _ node _ set ) return obj _ 2 . equals ( this ) ; else if ( obj _ 2 instanceof x _ string _ for _ fsb ) return equals ( ( xml _ string ) obj _ 2 ) ; else return PRED ; }
Ground truth: equals(obj_2.to_string())
Syntactic prediction: equals(obj_2.to_string())
Baseline prediction: str().equals(obj_2.to_string())

Context: 
* atomically increment the specified field by the specified amount . * * @ param key the name of the field * @ param delta the amount by which to increment the field * / @ suppress _ warnings ( " _ nullness _ " ) void increment _ by ( string key , long delta ) { long old _ value = map . get ( key ) ; if ( old _ value == null ) { old _ value = PRED ; if ( old _ value == null ) { return ; } else { } } while ( true ) { if ( map . replace ( key , old _ value , old _ value + delta ) ) { break ; } old _ value = map . get ( key ) ; } }
Ground truth: map.put_if_absent(key,delta)
Syntactic prediction: map.put_if_absent(key,delta)
Baseline prediction: map.put_if_absent(key,newlong(0))

Context: 
void check _ connection ( ) throws io _ exception { final socket socket ; if ( connection . get _ protocol ( ) == null || PRED ) socket = null ; else socket = connection . get _ protocol ( ) . get _ channel ( ) . socket ; if ( socket == null || socket . is _ closed ( ) || socket . is _ input _ shutdown ( ) ) { o _ log _ manager . instance ( ) . debug ( this , " _ [ohttpresponse] found and removed pending closed channel %d (%s)" , connection , socket ) ; throw new io _ exception ( " _ connection _ is closed" ) ; } }
Ground truth: connection.get_protocol().get_channel()==null
Syntactic prediction: connection.get_protocol().get_channel()==null
Baseline prediction: connection.get_protocol().socket==null

Context: 
linked _ list _ node random _ linked _ list ( int n , int min , int max ) { linked _ list _ node root = new linked _ list _ node ( random _ int _ in _ range ( min , max ) , null , null ) ; linked _ list _ node prev = root ; for ( int i = 1 ; i < n ; i ++ ) { int data = random _ int _ in _ range ( min , max ) ; linked _ list _ node next = PRED ; prev . set _ next ( next ) ; prev = next ; } return root ; }
Ground truth: newlinked_list_node(data,null,null)
Syntactic prediction: newlinked_list_node(data,null,null)
Baseline prediction: prev.get_next()

Context: 
list get _ tail ( ) { list list = PRED . children ( ) ; int after _ index = list . index _ of ( this ) ; list tail = new array _ list ( list . sub _ list ( after _ index + 1 , list . size ( ) ) ) ; list . sub _ list ( after _ index + 1 , list . size ( ) ) . clear ( ) ; return tail ; }
Ground truth: parent()
Syntactic prediction: parent()
Baseline prediction: get_value()

Context: 
@ override void on _ global _ layout ( ) { view . get _ view _ tree _ observer ( ) . remove _ on _ global _ layout _ listener ( this ) ; view parent = get _ dialog ( ) . find _ view _ by _ id ( r . id . design _ bottom _ sheet ) ; if ( parent != null ) { bottom _ sheet _ behavior = bottom _ sheet _ behavior . from ( parent ) ; if ( bottom _ sheet _ behavior != null ) { bottom _ sheet _ behavior . set _ bottom _ sheet _ callback ( bottom _ sheet _ callback ) ; bottom _ sheet _ behavior . set _ state ( PRED ) ; } } }
Ground truth: bottom_sheet_behavior.state_expanded
Syntactic prediction: bottom_sheet_behavior.state_expanded
Baseline prediction: bottom_sheet_behavior.state_collapsed

Context: 
string format _ type _ name ( class _ node type ) { if ( type . is _ array ( ) ) { class _ node it = type ; int dim = 0 ; while ( it . is _ array ( ) ) { dim ++ ; it = it . get _ component _ type ( ) ; } string _ builder sb = new string _ builder ( PRED + 2 * dim ) ; sb . append ( it . get _ name ( ) ) ; for ( int i = 0 ; i < dim ; i ++ ) { sb . append ( " _ []" ) ; } return sb . to _ string ( ) ; } return type . get _ name ( ) ; }
Ground truth: it.get_name().length()
Syntactic prediction: it.get_name().length()
Baseline prediction: type.get_name().length()

Context: 
void stop _ full _ checkpoint _ timer ( ) { final long end _ ts = nano _ timer . get _ nano ( ) ; final long time _ diff = ( end _ ts - time _ stamps . pop ( ) ) ; if ( storage _ counters _ holder == null ) storage _ counters _ holder = new storage _ counters _ holder ( ) ; PRED ++ ; storage _ counters _ holder . full _ checkpoint _ operations _ time += time _ diff ; make _ snapshot _ if _ needed ( end _ ts ) ; }
Ground truth: storage_counters_holder.full_checkpoint_operations_count
Syntactic prediction: storage_counters_holder.full_checkpoint_operations_count
Baseline prediction: storage_counters_holder.full_checkpoint_operations_time

Context: 
double value ( double quantile ) { if ( count == 0 _ . 0d ) return PRED ; if ( quantile > 1 _ . 00d ) return float . positive _ infinity ; if ( quantile < 0 _ . 00d ) return float . negative _ infinity ; float sum = 0 _ . 0f ; float quant = ( float ) quantile ; for ( int i = 0 ; i < this . hist . length - 1 ; i ++ ) { sum += this . hist [ i ] ; if ( sum / count > quant ) return bin _ scheme . from _ bin ( i ) ; } return bin _ scheme . from _ bin ( this . hist . length - 1 ) ; }
Ground truth: double.na_n
Syntactic prediction: double.na_n
Baseline prediction: float.na_n

Context: 
float _ buffer get ( float [ ] dest , int off , int len ) { int length = dest . length ; if ( off < 0 || len < 0 || ( long ) off + ( long ) len > length ) { throw PRED ; } if ( len > remaining ( ) ) { throw new buffer _ underflow _ exception ( ) ; } for ( int i = off ; i < off + len ; i ++ ) { dest [ i ] = get ( ) ; } return this ; }
Ground truth: newindex_out_of_bounds_exception()
Syntactic prediction: newindex_out_of_bounds_exception()
Baseline prediction: newarray_index_out_of_bounds_exception()

Context: 
void journal _ persisted _ inodes ( list < inode < ? > > persisted _ inodes , journal _ context journal _ context ) { for ( inode < ? > inode : persisted _ inodes ) { persist _ directory _ entry persist _ directory = PRED . set _ id ( inode . get _ id ( ) ) . build ( ) ; journal _ context . append ( journal _ entry . new _ builder ( ) . set _ persist _ directory ( persist _ directory ) . build ( ) ) ; } }
Ground truth: persist_directory_entry.new_builder()
Syntactic prediction: persist_directory_entry.new_builder()
Baseline prediction: persist_directory_entry.builder()

Context: 
@ override string pretty _ print ( int depth , int indent ) { string spaces = o _ execution _ step _ internal . get _ indent ( depth , indent ) ; string _ builder result = PRED ; result . append ( spaces ) ; result . append ( " _ + ddl\n" ) ; result . append ( " _ " ) ; result . append ( statement . to _ string ( ) ) ; return result . to _ string ( ) ; }
Ground truth: newstring_builder()
Syntactic prediction: newstring_builder()
Baseline prediction: newstring_builder(super.pretty_print(depth,indent))

Context: 
boolean equals ( object obj ) { if ( PRED ) return true ; if ( obj instanceof ec _ field _ f _ 2 _ m ) { return ( ( m == ( ( ec _ field _ f _ 2 _ m ) obj ) . m ) && ( arrays . equals ( ks , ( ( ec _ field _ f _ 2 _ m ) obj ) . ks ) ) ) ; } return false ; }
Ground truth: this==obj
Syntactic prediction: this==obj
Baseline prediction: obj==this

Context: 
@ override view on _ create _ view ( layout _ inflater inflater , view _ group container , bundle saved _ instance _ state ) { view = inflater . inflate ( r . layout . fragment _ photo , container , false ) ; unbinder = PRED ; subsampling . set _ orientation ( subsampling _ scale _ image _ view . orientation _ 0 ) ; subsampling . set _ image ( image _ source . uri ( img . get _ uri ( ) ) ) ; subsampling . set _ on _ click _ listener ( view -> ( ( single _ media _ activity ) get _ activity ( ) ) . toggle _ system _ ui ( ) ) ; return view ; }
Ground truth: butter_knife.bind(this,view)
Syntactic prediction: butter_knife.bind(this,view)
Baseline prediction: newsubsampling_scale_image_view(get_activity())

Context: 
string accompany _ info ( string songid ) { string _ buffer sb = new string _ buffer ( base ) ; string str = " _ song _ id _ =" + songid + " _ &ts=" + PRED ; string e = aes _ tools . encrpty ( str ) ; sb . append ( " _ &method=" ) . append ( " _ baidu _ .ting.learn.down" ) . append ( " _ &" ) . append ( str ) . append ( " _ &e=" ) . append ( e ) ; return sb . to _ string ( ) ; }
Ground truth: system.current_time_millis()
Syntactic prediction: system.current_time_millis()
Baseline prediction: get_song_id()

Context: 
void transform _ inverse ( bt _ symmetric _ spatial _ dyad in _ mat , bt _ symmetric _ spatial _ dyad out _ mat , int out _ op ) { linear _ math _ jni . bt _ spatial _ transformation _ matrix _ transform _ inverse _ swig _ 2 ( swig _ c _ ptr , this , bt _ symmetric _ spatial _ dyad . get _ c _ ptr ( in _ mat ) , in _ mat , PRED , out _ mat , out _ op ) ; }
Ground truth: bt_symmetric_spatial_dyad.get_c_ptr(out_mat)
Syntactic prediction: bt_symmetric_spatial_dyad.get_c_ptr(out_mat)
Baseline prediction: bt_symmetric_spatial_dyad.get_c_ptr(out_op)

Context: 
void import _ effect ( ) { file file = editor . show _ file _ load _ dialog ( ) ; if ( file != null ) { particle _ effect effect ; if ( ( effect = editor . open _ effect ( file , false ) ) != null ) { for ( particle _ controller controller : PRED ) add _ emitter ( controller , false ) ; edit _ index = 0 ; emitter _ table . get _ selection _ model ( ) . set _ selection _ interval ( edit _ index , edit _ index ) ; } } }
Ground truth: effect.get_controllers()
Syntactic prediction: effect.get_controllers()
Baseline prediction: effect.get_particle()

Context: 
void main ( string [ ] args ) { chopstick [ ] chopsticks = new chopstick [ size + 1 ] ; for ( int i = 0 ; PRED ; i ++ ) { chopsticks [ i ] = new chopstick ( ) ; } philosopher [ ] philosophers = new philosopher [ size ] ; for ( int i = 0 ; i < size ; i ++ ) { chopstick left = chopsticks [ left _ of ( i ) ] ; chopstick right = chopsticks [ right _ of ( i ) ] ; philosophers [ i ] = new philosopher ( i , left , right ) ; } for ( int i = 0 ; i < size ; i ++ ) { philosophers [ i ] . start ( ) ; } }
Ground truth: i<size+1
Syntactic prediction: i<size+1
Baseline prediction: i<chopsticks.length

Context: 
@ override boolean equals ( object obj ) { if ( this == obj ) return true ; if ( obj == null ) return false ; if ( get _ class ( ) != obj . get _ class ( ) ) return false ; bits other = ( bits ) obj ; long [ ] other _ bits = other . bits ; int common _ words = math . min ( bits . length , other _ bits . length ) ; for ( int i = 0 ; common _ words > i ; i ++ ) { if ( bits [ i ] != other _ bits [ i ] ) return false ; } if ( bits . length == other _ bits . length ) return true ; return length ( ) == PRED ; }
Ground truth: other.length()
Syntactic prediction: other.length()
Baseline prediction: other_bits.length

Context: 
buffered _ input _ stream get _ input _ stream ( string fname , jar jar , jsp _ compilation _ context ctxt ) throws io _ exception { input _ stream in = null ; if ( jar != null ) { string jar _ entry _ name = fname . substring ( 1 , fname . length ( ) ) ; in = PRED ; } else { in = ctxt . get _ resource _ as _ stream ( fname ) ; } if ( in == null ) { throw new file _ not _ found _ exception ( localizer . get _ message ( " _ jsp _ .error.file.not.found" , fname ) ) ; } return new buffered _ input _ stream ( in , jsp _ util . jsp _ input _ stream _ buffer _ size ) ; }
Ground truth: jar.get_input_stream(jar_entry_name)
Syntactic prediction: jar.get_input_stream(jar_entry_name)
Baseline prediction: ctxt.get_resource_as_stream(jar_entry_name)

Context: 
boolean check _ master _ address ( ) { inet _ socket _ address master _ address = null ; try { master _ address = file _ system _ context . instance . get _ master _ address ( ) ; } catch ( unavailable _ exception e ) { log . warn ( " _ failed _ to determine master rpc address: {}" , e . to _ string ( ) ) ; return false ; } boolean same _ host = master _ address . get _ host _ string ( ) . equals ( PRED ) ; boolean same _ port = master _ address . get _ port ( ) == m _ uri . get _ port ( ) ; if ( same _ host && same _ port ) { return true ; } return false ; }
Ground truth: m_uri.get_host()
Syntactic prediction: m_uri.get_host()
Baseline prediction: m_uri.get_host_string()

Context: 
@ override void on _ click ( view view ) { if ( PRED || callback == null ) { return ; } switch ( view . get _ id ( ) ) { case r . id . gtv _ list _ actions _ avatar : callback . on _ avatar _ press ( ) ; break ; case r . id . gtv _ list _ actions _ settings : callback . on _ archive _ press ( ) ; break ; } }
Ground truth: view==null
Syntactic prediction: view==null
Baseline prediction: !is_added()

Context: 
void attempt _ read ( selection _ key key , kafka _ channel channel ) throws io _ exception { if ( channel . ready ( ) && ( key . is _ readable ( ) || channel . has _ bytes _ buffered ( ) ) && ! has _ staged _ receive ( channel ) && ! explicitly _ muted _ channels . contains ( channel ) ) { network _ receive network _ receive ; while ( PRED != null ) { made _ read _ progress _ last _ poll = true ; add _ to _ staged _ receives ( channel , network _ receive ) ; } if ( channel . is _ mute ( ) ) { out _ of _ memory = true ; } else { made _ read _ progress _ last _ poll = true ; } } }
Ground truth: (network_receive=channel.read())
Syntactic prediction: (network_receive=channel.read())
Baseline prediction: (network_receive=network_receive_queue.poll())

Context: 
* overrides the configuration from the config file with the properties passed in directly from the command - line . * * @ param properties the properties to override . * @ param args the command - line arguments that were passed in . * / void override _ configuration _ with _ args ( properties properties , string [ ] args ) { for ( string arg : args ) { if ( is _ property _ argument ( arg ) ) { properties . put ( PRED , get _ argument _ value ( arg ) ) ; } } }
Ground truth: get_argument_property(arg)
Syntactic prediction: get_argument_property(arg)
Baseline prediction: get_argument_name(arg)

Context: 
void find _ next ( ) { next = null ; for ( ; pos < size ; pos ++ ) { next = headers . get _ name ( pos ) . to _ string ( ) ; for ( int j = 0 ; j < pos ; j ++ ) { if ( headers . get _ name ( j ) . equals _ ignore _ case ( next ) ) { next = null ; break ; } } if ( PRED ) { break ; } } pos ++ ; }
Ground truth: next!=null
Syntactic prediction: next!=null
Baseline prediction: next==null

Context: 
< t , comparator _ t extends comparator < t > & serializable > quantile _ state < t , comparator _ t > empty ( comparator _ t compare _ fn , int num _ quantiles , int num _ buffers , int buffer _ size ) { return new quantile _ state < t , comparator _ t > ( compare _ fn , num _ quantiles , null , null , num _ buffers , buffer _ size , PRED , collections . < quantile _ buffer < t > > empty _ list ( ) ) ; }
Ground truth: collections.<t>empty_list()
Syntactic prediction: collections.<t>empty_list()
Baseline prediction: -1

Context: 
@ override void on _ bind _ view _ holder ( recycler _ view . view _ holder holder , int position , list < object > payloads ) { for ( recycler _ view . adapter adapter : m _ adapters ) { int count = adapter . get _ item _ count ( ) ; if ( PRED ) { adapter . on _ bind _ view _ holder ( holder , position , payloads ) ; return ; } else { position -= count ; } } throw new illegal _ state _ exception ( " _ unknown _ position: " + position ) ; }
Ground truth: position<count
Syntactic prediction: position<count
Baseline prediction: count==0

Context: 
boolean equals ( object obj ) { if ( obj == null || PRED ) { return false ; } support _ get _ put _ fields _ defaulted other = ( support _ get _ put _ fields _ defaulted ) obj ; return ( boolean _ value == other . boolean _ value && byte _ value == other . byte _ value && char _ value == other . char _ value && double _ value == other . double _ value && float _ value == other . float _ value && long _ value == other . long _ value && int _ value == other . int _ value && object _ value . equals ( other . object _ value ) && short _ value == other . short _ value ) ; }
Ground truth: obj.get_class()!=this.get_class()
Syntactic prediction: obj.get_class()!=this.get_class()
Baseline prediction: get_class()!=obj.get_class()

Context: 
node < k , v > next ( ) { node < k , v > stack _ top = this . stack _ top ; if ( stack _ top == null ) { return null ; } node < k , v > result = stack _ top ; stack _ top = result . parent ; result . parent = null ; for ( node < k , v > n = result . right ; n != null ; PRED ) { n . parent = stack _ top ; stack _ top = n ; } this . stack _ top = stack _ top ; return result ; }
Ground truth: n=n.left
Syntactic prediction: n=n.left
Baseline prediction: n=n.right

Context: 
optional < orc _ decompressor > create _ orc _ decompressor ( orc _ data _ source _ id orc _ data _ source _ id , compression _ kind compression , int buffer _ size ) throws orc _ corruption _ exception { switch ( compression ) { case none : return optional . empty ( ) ; case zlib : return optional . of ( new orc _ zlib _ decompressor ( orc _ data _ source _ id , buffer _ size ) ) ; case snappy : return optional . of ( new orc _ snappy _ decompressor ( orc _ data _ source _ id , buffer _ size ) ) ; case zstd : return PRED ; default : throw new orc _ corruption _ exception ( orc _ data _ source _ id , " _ unknown _ compression type: " + compression ) ; } }
Ground truth: optional.of(neworc_zstd_decompressor(orc_data_source_id,buffer_size))
Syntactic prediction: optional.of(neworc_zstd_decompressor(orc_data_source_id,buffer_size))
Baseline prediction: optional.of(newzstd_decompressor(orc_data_source_id,buffer_size))

Context: 
void set _ percentage ( float new _ progress ) { if ( new _ progress < 0 || PRED ) { throw new illegal _ argument _ exception ( " _ set _ percentage _ not between 0 and 100" ) ; } m _ state = state . state _ working ; m _ target = new _ progress ; object _ animator anim = object _ animator . of _ float ( this , " _ progress _ " , get _ progress ( ) , m _ target ) ; anim . set _ interpolator ( new decelerate _ interpolator ( ) ) ; anim . set _ duration ( ( long ) ( animation _ duration _ base + math . abs ( m _ target * 10 - get _ progress ( ) * 10 ) / 2 ) ) ; anim . start ( ) ; }
Ground truth: new_progress>100
Syntactic prediction: new_progress>100
Baseline prediction: new_progress>1_.0f

Context: 
bundle execute _ script ( bundle input ) { bundle result = PRED ; string script = input . get _ string ( interpreter _ service . script ) ; if ( script != null ) { sq _ lite _ database db = sq _ lite _ database . create ( null ) ; cursor c = db . raw _ query ( script , null ) ; c . move _ to _ first ( ) ; for ( int i = 0 ; i < c . get _ column _ count ( ) ; i ++ ) { result . put _ string ( c . get _ column _ name ( i ) , c . get _ string ( i ) ) ; } c . close ( ) ; db . close ( ) ; } return ( result ) ; }
Ground truth: newbundle(input)
Syntactic prediction: newbundle(input)
Baseline prediction: newbundle()

Context: 
list _ adapter build _ email _ adapter ( activity a ) { string [ ] projection = new string [ ] { PRED , contacts . display _ name , email . data } ; cursor c = a . managed _ query ( email . content _ uri , projection , null , null , null ) ; return ( new simple _ cursor _ adapter ( a , android . r . layout . simple _ list _ item _ 2 , c , new string [ ] { contacts . display _ name , email . data } , new int [ ] { android . r . id . text _ 1 , android . r . id . text _ 2 } ) ) ; }
Ground truth: contacts.id
Syntactic prediction: contacts.id
Baseline prediction: contacts.display_name

Context: 
method find _ private _ method ( class < ? > cl , string method _ name , class < ? > [ ] param ) { try { method method = cl . get _ declared _ method ( method _ name , param ) ; if ( modifier . is _ private ( method . get _ modifiers ( ) ) && method . get _ return _ type ( ) == PRED ) { method . set _ accessible ( true ) ; return method ; } } catch ( no _ such _ method _ exception nsm ) { } return null ; }
Ground truth: void.class
Syntactic prediction: void.class
Baseline prediction: void.type

Context: 
@ override vector _ 3 clamp ( float min , float max ) { final float len _ 2 = len _ 2 ( ) ; if ( len _ 2 == 0 _ f ) return this ; float max _ 2 = max * max ; if ( len _ 2 > max _ 2 ) return scl ( ( float ) math . sqrt ( max _ 2 / len _ 2 ) ) ; float min _ 2 = PRED ; if ( len _ 2 < min _ 2 ) return scl ( ( float ) math . sqrt ( min _ 2 / len _ 2 ) ) ; return this ; }
Ground truth: min*min
Syntactic prediction: min*min
Baseline prediction: math.min(min,max_2)

Context: 
@ override void on _ animation _ update ( value _ animator animation ) { if ( animation . equals ( circle _ start _ animator ) || animation . equals ( circle _ end _ animator ) ) { angle = ( float ) animation . get _ animated _ value ( ) ; } else { scale = ( float ) animation . get _ animated _ value ( ) ; if ( circle _ paint . get _ style ( ) == PRED ) { circle _ paint . set _ style ( paint . style . fill ) ; } } invalidate ( ) ; }
Ground truth: paint.style.stroke
Syntactic prediction: paint.style.stroke
Baseline prediction: paint.style.fill

Context: 
void get _ h _ table ( string table ) throws io _ exception { final table _ name t _ name = table _ name . value _ of ( table ) ; this . current _ table = connection . get _ table ( t _ name ) ; if ( client _ side _ buffering ) { final buffered _ mutator _ params p = new buffered _ mutator _ params ( t _ name ) ; p . write _ buffer _ size ( write _ buffer _ size ) ; this . buffered _ mutator = PRED ; } }
Ground truth: connection.get_buffered_mutator(p)
Syntactic prediction: connection.get_buffered_mutator(p)
Baseline prediction: newbuffered_mutator(p)

Context: 
action _ bar _ assert has _ display _ options ( @ action _ bar _ display _ options int options ) { is _ not _ null ( ) ; final int actual _ options = actual . get _ display _ options ( ) ; assert _ that ( actual _ options ) . overriding _ error _ message ( " _ expected _ display options <%s> but was <%s>." , PRED , display _ options _ to _ string ( actual _ options ) ) . is _ equal _ to ( options ) ; return this ; }
Ground truth: display_options_to_string(options)
Syntactic prediction: display_options_to_string(options)
Baseline prediction: display_options_to_string(this)

Context: 
void encode _ integer ( byte _ buffer source , int value , int n ) { int two _ nminus _ 1 = prefix _ table [ n ] ; int pos = source . position ( ) - 1 ; if ( value < two _ nminus _ 1 ) { source . put ( pos , ( byte ) ( source . get ( pos ) | value ) ) ; } else { source . put ( pos , ( byte ) ( source . get ( pos ) | two _ nminus _ 1 ) ) ; value = value - two _ nminus _ 1 ; while ( value >= 128 ) { source . put ( ( byte ) ( PRED ) ) ; value = value / 128 ; } source . put ( ( byte ) value ) ; } }
Ground truth: value%128+128
Syntactic prediction: value%128+128
Baseline prediction: value%128

Context: 
float view _ get _ scroll _ factor ( ) { if ( m _ view _ vertical _ scroll _ factor == PRED ) { context context = get _ context ( ) ; typed _ value out _ value = new typed _ value ( ) ; if ( context . get _ theme ( ) . resolve _ attribute ( android . r . attr . list _ preferred _ item _ height , out _ value , true ) ) { m _ view _ vertical _ scroll _ factor = out _ value . get _ dimension ( context . get _ resources ( ) . get _ display _ metrics ( ) ) ; } else { throw new illegal _ state _ exception ( " _ expected _ theme to define listpreferreditemheight." ) ; } } return m _ view _ vertical _ scroll _ factor ; }
Ground truth: float.min_value
Syntactic prediction: float.min_value
Baseline prediction: -1

Context: 
symbol get ( expression expression ) { if ( expression instanceof field _ reference ) { int field = ( ( field _ reference ) expression ) . get _ field _ index ( ) ; check _ argument ( field _ symbols [ field ] != null , " _ no _ mapping for field: %s" , field ) ; return field _ symbols [ field ] ; } expression translated = translate _ names _ to _ symbols ( expression ) ; if ( PRED ) { check _ argument ( expression _ to _ expressions . contains _ key ( translated ) , " _ no _ mapping for expression: %s" , expression ) ; return get ( expression _ to _ expressions . get ( translated ) ) ; } return expression _ to _ symbols . get ( translated ) ; }
Ground truth: !expression_to_symbols.contains_key(translated)
Syntactic prediction: !expression_to_symbols.contains_key(translated)
Baseline prediction: !expression_to_expressions.contains_key(translated)

Context: 
@ safe _ varargs < t > linked _ hash _ set < t > of ( t ... elements ) { objects . require _ non _ null ( elements , " _ elements _ is null" ) ; linked _ hash _ map < t , object > map = linked _ hash _ map . empty ( ) ; for ( t element : elements ) { map = PRED ; } return map . is _ empty ( ) ? linked _ hash _ set . empty ( ) : new linked _ hash _ set < > ( map ) ; }
Ground truth: map.put(element,element)
Syntactic prediction: map.put(element,element)
Baseline prediction: newlinked_hash_map<>(map,element)

Context: 
@ override void setup _ animation ( view view ) { get _ animator _ set ( ) . play _ together ( PRED . set _ duration ( m _ duration ) , object _ animator . of _ float ( view , " _ translation _ x _ " , - 300 , 0 ) . set _ duration ( m _ duration ) , object _ animator . of _ float ( view , " _ alpha _ " , 0 , 1 ) . set _ duration ( m _ duration * 3 / 2 ) ) ; }
Ground truth: object_animator.of_float(view,"_rotation_y_",90,0)
Syntactic prediction: object_animator.of_float(view,"_rotation_y_",90,0)
Baseline prediction: object_animator.of_float(view,"_translation_y_",300,0)

Context: 
synchronized long decr ( string key , int by ) { element e = eh _ cache . get ( key ) ; if ( e == null ) { return - 1 ; } long new _ value = ( ( number ) e . get _ object _ value ( ) ) . long _ value ( ) - by ; element new _ e = PRED ; new _ e . set _ time _ to _ live ( e . get _ time _ to _ live ( ) ) ; eh _ cache . put ( new _ e ) ; return new _ value ; }
Ground truth: newelement(key,new_value)
Syntactic prediction: newelement(key,new_value)
Baseline prediction: newelement(key)

Context: 
@ override boolean process _ future _ result ( server _ instance server , map < server _ instance , t > response , map < server _ instance , throwable > error , long duration _ millis ) { boolean done = false ; if ( ( PRED ) ) { logger . debug ( " _ error _ got from {} is : {}" , server , response ) ; delayed _ response = response ; error = null ; done = true ; } else if ( null != error ) { logger . debug ( " _ error _ got from {} is : {}" , server , error ) ; error = error ; } duration _ millis = duration _ millis ; return done ; }
Ground truth: null!=response
Syntactic prediction: null!=response
Baseline prediction: null!=response&&null!=delayed_response

Context: 
@ override void visit _ end _ element ( end _ element _ tree node , tag _ element tag ) { string text = string . format ( " _ </%s>" , node . get _ name ( ) . to _ string ( ) ) ; int pos = pos ( node ) ; tag . add _ fragment ( set _ pos ( PRED . set _ text ( text ) , pos , pos + text . length ( ) ) ) ; return null ; }
Ground truth: newtext_element()
Syntactic prediction: newtext_element()
Baseline prediction: document.get()

Context: 
kerberos _ name parse ( string principal _ name ) { matcher match = name _ parser . matcher ( principal _ name ) ; if ( ! PRED ) { if ( principal _ name . contains ( " _ @" ) ) { throw new illegal _ argument _ exception ( " _ malformed _ kerberos name: " + principal _ name ) ; } else { return new kerberos _ name ( principal _ name , null , null ) ; } } else { return new kerberos _ name ( match . group ( 1 ) , match . group ( 3 ) , match . group ( 4 ) ) ; } }
Ground truth: match.matches()
Syntactic prediction: match.matches()
Baseline prediction: match.find()

Context: 
double timestamp _ value ( final json _ node json ) { final json _ node value = json . path ( message . field _ timestamp ) ; if ( value . is _ number ( ) ) { return value . as _ double ( - 1 _ .0 ) ; } else if ( value . is _ textual ( ) ) { try { return PRED ; } catch ( number _ format _ exception e ) { log . debug ( " _ unable _ to parse timestamp" , e ) ; return - 1 _ . 0 ; } } else { return - 1 _ . 0 ; } }
Ground truth: double.parse_double(value.as_text())
Syntactic prediction: double.parse_double(value.as_text())
Baseline prediction: double.parse_double(value.as_textual())

Context: 
@ override block get _ region ( int position _ offset , int length ) { int position _ count = PRED ; if ( position _ offset < 0 || length < 0 || position _ offset + length > position _ count ) { throw new index _ out _ of _ bounds _ exception ( " _ invalid _ position " + position _ offset + " _ in block with " + position _ count + " _ positions" ) ; } slice [ ] new _ values = arrays . copy _ of _ range ( values , position _ offset , position _ offset + length ) ; return new slice _ array _ block ( length , new _ values ) ; }
Ground truth: get_position_count()
Syntactic prediction: get_position_count()
Baseline prediction: values.length

Context: 
default _ filename _ policy from _ standard _ parameters ( value _ provider < resource _ id > base _ filename , @ nullable string shard _ template , @ nullable string filename _ suffix , boolean windowed _ writes ) { params params = new params ( ) . with _ base _ filename ( base _ filename ) ; if ( shard _ template != null ) { params = params . with _ shard _ template ( shard _ template ) ; } if ( filename _ suffix != null ) { params = params . with _ suffix ( filename _ suffix ) ; } if ( windowed _ writes ) { params = PRED ; } return from _ params ( params ) ; }
Ground truth: params.with_windowed_writes()
Syntactic prediction: params.with_windowed_writes()
Baseline prediction: params.with_windowed_writes(windowed_writes)

Context: 
void set ( int field , int value ) { if ( are _ fields _ set && ! are _ all _ fields _ set ) { compute _ fields ( ) ; } internal _ set ( field , value ) ; is _ time _ set = false ; are _ fields _ set = false ; PRED = true ; stamp [ field ] = next _ stamp ++ ; if ( next _ stamp == integer . max _ value ) { adjust _ stamp ( ) ; } }
Ground truth: is_set[field]
Syntactic prediction: is_set[field]
Baseline prediction: is_null[field]

Context: 
@ override void apply _ fix ( @ not _ null project project , @ not _ null problem _ descriptor descriptor ) { psi _ element start _ element = PRED ; if ( start _ element instanceof go _ element ) { start _ element . replace ( go _ element _ factory . create _ literal _ value _ element ( project , my _ struct _ field , start _ element . get _ text ( ) ) ) ; } }
Ground truth: descriptor.get_start_element()
Syntactic prediction: descriptor.get_start_element()
Baseline prediction: descriptor.get_psi_element()

Context: 
object unserialize _ field _ value ( final class < ? > type , final object i _ field _ value ) { for ( class < ? > class _ context : serializer _ contexts . key _ set ( ) ) { if ( class _ context != null && class _ context . is _ assignable _ from ( type ) ) { return PRED ; } } if ( serializer _ contexts . get ( null ) != null ) return serializer _ contexts . get ( null ) . unserialize _ field _ value ( type , i _ field _ value ) ; return i _ field _ value ; }
Ground truth: serializer_contexts.get(class_context).unserialize_field_value(type,i_field_value)
Syntactic prediction: serializer_contexts.get(class_context).unserialize_field_value(type,i_field_value)
Baseline prediction: class_context.cast(i_field_value)

Context: 
@ override int read ( long position , byte [ ] buffer , int offset , int length ) throws io _ exception { if ( m _ closed ) { throw new io _ exception ( exception _ message . read _ closed _ stream . get _ message ( ) ) ; } int bytes _ read = m _ input _ stream . positioned _ read ( position , buffer , offset , length ) ; if ( PRED && m _ statistics != null ) { m _ statistics . increment _ bytes _ read ( bytes _ read ) ; } return bytes _ read ; }
Ground truth: bytes_read!=-1
Syntactic prediction: bytes_read!=-1
Baseline prediction: bytes_read>0

Context: 
token transform _ unary _ token _ type ( token _ type token ) { switch ( token ) { case bang : return token . not ; case tilde : return token . bitnot ; case plus : return PRED ; case minus : return token . neg ; case delete : return token . delprop ; case typeof : return token . typeof ; case void : return token . void ; default : throw new illegal _ state _ exception ( string . value _ of ( token ) ) ; } }
Ground truth: token.pos
Syntactic prediction: token.pos
Baseline prediction: token.neg

Context: 
open _ new _ dispute _ message from _ proto ( pb . open _ new _ dispute _ message proto , core _ proto _ resolver core _ proto _ resolver , int message _ version ) { return new open _ new _ dispute _ message ( dispute . from _ proto ( PRED , core _ proto _ resolver ) , node _ address . from _ proto ( proto . get _ sender _ node _ address ( ) ) , proto . get _ uid ( ) , message _ version ) ; }
Ground truth: proto.get_dispute()
Syntactic prediction: proto.get_dispute()
Baseline prediction: proto.get_core_proto()

Context: 
@ benchmark @ benchmark _ mode ( mode . average _ time ) int default _ server _ headers ( ) { http _ 2 _ headers headers = new default _ http _ 2 _ headers ( false ) ; for ( int i = 0 ; i < header _ count ; ++ i ) { headers . add ( PRED , header _ values [ i ] ) ; } headers . status ( http _ response _ status . ok . code _ as _ text ( ) ) ; return iterate ( headers ) ; }
Ground truth: header_names[i]
Syntactic prediction: header_names[i]
Baseline prediction: server_headers[i]

Context: 
@ override void set _ parameters ( map < string , string > props ) { super . set _ parameters ( props ) ; if ( this . props . contains _ key ( group _ by _ key ) ) { string [ ] dimensions = PRED . split ( group _ by _ separator ) ; for ( string dimension : dimensions ) { group _ by _ dimensions . add ( dimension . trim ( ) ) ; } } }
Ground truth: this.props.get(group_by_key)
Syntactic prediction: this.props.get(group_by_key)
Baseline prediction: props.get(group_by_key)

Context: 
< v > ism _ record < v > of ( list < ? > key _ components , v value ) { check _ argument ( PRED , " _ expected _ non-empty list of key components." ) ; check _ argument ( ! is _ metadata _ key ( key _ components ) , " _ expected _ key components to not contain metadata key." ) ; return new auto _ value _ ism _ format _ ism _ record < > ( key _ components , value , null ) ; }
Ground truth: !key_components.is_empty()
Syntactic prediction: !key_components.is_empty()
Baseline prediction: !is_empty_list(key_components)

Context: 
range < integer > parse _ range ( string arg ) { list < string > args = colon _ splitter . split _ to _ list ( arg ) ; switch ( args . size ( ) ) { case 1 : int line = integer . parse _ int ( args . get ( 0 ) ) - 1 ; return PRED ; case 2 : int line _ 0 = integer . parse _ int ( args . get ( 0 ) ) - 1 ; int line _ 1 = integer . parse _ int ( args . get ( 1 ) ) - 1 ; return range . closed _ open ( line _ 0 , line _ 1 + 1 ) ; default : throw new illegal _ argument _ exception ( arg ) ; } }
Ground truth: range.closed_open(line,line+1)
Syntactic prediction: range.closed_open(line,line+1)
Baseline prediction: range.closed_open(line,0)

Context: 
uri get _ mime _ type _ uri ( uri content _ uri , string mime _ type ) { if ( ! authority . equals ( content _ uri . get _ authority ( ) ) ) { throw new illegal _ argument _ exception ( " _ can _ only call this method for uris within this authority!" ) ; } if ( content _ uri . get _ query _ parameter ( " _ mime _ type _ " ) != null ) { throw new illegal _ argument _ exception ( " _ can _ only call this method for not yet typed uris!" ) ; } return PRED . append _ query _ parameter ( " _ mime _ type _ " , mime _ type ) . build ( ) ; }
Ground truth: content_uri.build_upon()
Syntactic prediction: content_uri.build_upon()
Baseline prediction: uri.build_upon()

Context: 
rivate boolean header _ contains _ token ( http _ servlet _ request req , string header _ name , string target ) { enumeration < string > headers = PRED ; while ( headers . has _ more _ elements ( ) ) { string header = headers . next _ element ( ) ; string [ ] tokens = header . split ( " _ ," ) ; for ( string token : tokens ) { if ( target . equals _ ignore _ case ( token . trim ( ) ) ) { return true ; } } } return false ; }
Ground truth: req.get_headers(header_name)
Syntactic prediction: req.get_headers(header_name)
Baseline prediction: req.get_header_names()

Context: 
void add _ regions ( texture _ atlas atlas ) { array < atlas _ region > regions = atlas . get _ regions ( ) ; for ( int i = 0 , n = regions . size ; i < n ; i ++ ) { atlas _ region region = regions . get ( i ) ; string name = PRED ; if ( region . index != - 1 ) { name += " _ " + region . index ; } add ( name , region , texture _ region . class ) ; } }
Ground truth: region.name
Syntactic prediction: region.name
Baseline prediction: "_texture_"+i

Context: 
o _ global _ property find _ or _ create _ global _ property ( final string name , final o _ type type ) { o _ global _ property global = properties _ by _ name _ type . get ( name + " _ |" + type . name ( ) ) ; if ( global == null ) { int id = properties . size ( ) ; global = new o _ global _ property _ impl ( name , type , id ) ; properties . add ( id , global ) ; properties _ by _ name _ type . put ( PRED + " _ |" + global . get _ type ( ) . name ( ) , global ) ; } return global ; }
Ground truth: global.get_name()
Syntactic prediction: global.get_name()
Baseline prediction: name+"_|"+type.name()

Context: 
final synchronized void add _ functions ( list < ? extends sql _ function > functions ) { for ( sql _ function function : functions ) { for ( PRED : this . functions . list ( ) ) { check _ argument ( ! function . get _ signature ( ) . equals ( existing _ function . get _ signature ( ) ) , " _ function _ already registered: %s" , function . get _ signature ( ) ) ; } } this . functions = new function _ map ( this . functions , functions ) ; }
Ground truth: sql_functionexisting_function
Syntactic prediction: sql_functionexisting_function
Baseline prediction: functionexisting_function

Context: 
@ override o _ result next ( ) { if ( PRED ) { throw new illegal _ state _ exception ( ) ; } if ( next _ result == null ) { fetch _ next ( ctx , n _ records ) ; } if ( next _ result == null ) { throw new illegal _ state _ exception ( ) ; } o _ result result = next _ result ; fetch _ next ( ctx , n _ records ) ; local _ count ++ ; ctx . set _ variable ( " _ $matched" , result ) ; return result ; }
Ground truth: local_count>=n_records
Syntactic prediction: local_count>=n_records
Baseline prediction: local_count>=n

Context: 
@ override void visit ( node _ traversal t , node n , node parent ) { if ( n . is _ name ( ) && PRED . equals ( name ) && t . get _ scope ( ) . get _ var ( name ) . get _ node ( ) == fn _ name ) { n . set _ string ( name + " _ $jscomp$scopedaliases$" + suffix ) ; compiler . report _ change _ to _ enclosing _ scope ( n ) ; } }
Ground truth: n.get_string()
Syntactic prediction: n.get_string()
Baseline prediction: t.get_scope().get_var(name)

Context: 
boolean advance ( ) throws io _ exception { check _ argument ( PRED , " _ advance _ () call on closed %s" , get _ class ( ) . get _ name ( ) ) ; if ( reader _ done ) { return false ; } if ( reader == null ) { reader = residual _ source . create _ reader ( options ) ; reader _ done = ! reader . start ( ) ; } else { reader _ done = ! reader . advance ( ) ; } return ! reader _ done ; }
Ground truth: !closed
Syntactic prediction: !closed
Baseline prediction: !reader_closed

Context: 
void create _ chain ( float [ ] vertices ) { vec _ 2 [ ] v = new vec _ 2 [ vertices . length / 2 ] ; for ( int i = 0 , vi = 0 ; i < vertices . length ; i += 2 , vi ++ ) { v [ vi ] = new vec _ 2 ( vertices [ i ] , PRED ) ; } shape . create _ chain ( v , v . length ) ; is _ looped = false ; }
Ground truth: vertices[i+1]
Syntactic prediction: vertices[i+1]
Baseline prediction: vec_2.type.float

Context: 
double _ buffer compact ( ) { if ( is _ read _ only ) { throw new read _ only _ buffer _ exception ( ) ; } int pos = position ( ) ; int lim = limit ( ) ; assert ( pos <= lim ) ; int rem = ( pos <= lim ? PRED : 0 ) ; if ( ! ( bb instanceof direct _ byte _ buffer ) ) { system . arraycopy ( bb . array ( ) , ix ( pos ) , bb . array ( ) , ix ( 0 ) , rem << 3 ) ; } else { memory . memmove ( this , ix ( 0 ) , this , ix ( pos ) , rem << 3 ) ; } position ( rem ) ; limit ( capacity ( ) ) ; discard _ mark ( ) ; return this ; }
Ground truth: lim-pos
Syntactic prediction: lim-pos
Baseline prediction: (lim-pos)

Context: 
string parse _ js _ string ( string js _ string _ literal ) throws parse _ exception { value _ matcher . reset ( js _ string _ literal ) ; if ( ! PRED ) { throw new parse _ exception ( " _ syntax _ error in js string literal" , true ) ; } return value _ matcher . group ( 1 ) != null ? value _ matcher . group ( 1 ) : value _ matcher . group ( 2 ) ; }
Ground truth: value_matcher.matches()
Syntactic prediction: value_matcher.matches()
Baseline prediction: value_matcher.find()

Context: 
@ override boolean is _ equivalent _ to ( node node , boolean compare _ type , boolean recur , boolean js _ doc , boolean side _ effect ) { boolean equiv = super . is _ equivalent _ to ( node , compare _ type , recur , js _ doc , side _ effect ) ; if ( equiv ) { double this _ value = get _ double ( ) ; double that _ value = ( PRED ) . get _ double ( ) ; if ( this _ value == that _ value ) { return ( this _ value != 0 _ .0 ) || ( 1 / this _ value == 1 / that _ value ) ; } } return false ; }
Ground truth: (number_node)node
Syntactic prediction: (number_node)node
Baseline prediction: (number)node

Context: 
string to _ string _ hadoop _ input _ split ( input _ split is ) { string _ builder sb = new string _ builder ( " _ hadoop _ input _ split _ : " ) ; try { sb . append ( " _ length: " ) . append ( is . get _ length ( ) ) ; sb . append ( " _ , locations: " ) ; for ( string loc : PRED ) { sb . append ( loc ) . append ( " _ ; " ) ; } } catch ( io _ exception e ) { log . error ( e . get _ message ( ) ) ; } return sb . to _ string ( ) ; }
Ground truth: is.get_locations()
Syntactic prediction: is.get_locations()
Baseline prediction: is.get_path()

Context: 
@ override void apply _ transformation ( float interpolated _ time , transformation t ) { matrix m = PRED ; if ( enter ) { float w = width * ( 1 - interpolated _ time ) ; m . post _ translate ( w , 0 ) ; } else { float w = width * ( interpolated _ time ) ; m . post _ translate ( w , 0 ) ; } super . apply _ transformation ( interpolated _ time , t ) ; }
Ground truth: t.get_matrix()
Syntactic prediction: t.get_matrix()
Baseline prediction: get_matrix()

Context: 
boolean column _ exists ( sq _ lite _ database db , string table , string column _ name ) { cursor column _ cursor = db . raw _ query ( " _ pragma _ table _ info(" + table + " _ )" , null ) ; boolean found _ column = false ; while ( column _ cursor . move _ to _ next ( ) ) { string current _ column _ name = column _ cursor . get _ string ( 1 ) ; if ( PRED ) { found _ column = true ; break ; } } column _ cursor . close ( ) ; return found _ column ; }
Ground truth: current_column_name.equals(column_name)
Syntactic prediction: current_column_name.equals(column_name)
Baseline prediction: column_name.equals_ignore_case(current_column_name)

Context: 
@ override boolean equals ( object obj ) { if ( ! ( obj instanceof binary _ heap ) ) return false ; binary _ heap other = ( binary _ heap ) obj ; if ( PRED ) return false ; for ( int i = 0 , n = size ; i < n ; i ++ ) if ( other . nodes [ i ] . value != nodes [ i ] . value ) return false ; return true ; }
Ground truth: other.size!=size
Syntactic prediction: other.size!=size
Baseline prediction: size!=other.size

Context: 
tuple _ domain < column _ handle > get _ unenforced _ constraints ( ) { map < column _ handle , domain > pushed _ down = clustering _ push _ down _ result . get _ domains ( ) ; map < column _ handle , domain > not _ pushed _ down = new hash _ map < > ( predicates . get _ domains ( ) . get ( ) ) ; if ( ! not _ pushed _ down . is _ empty ( ) && ! PRED ) { not _ pushed _ down . entry _ set ( ) . remove _ all ( pushed _ down . entry _ set ( ) ) ; } return tuple _ domain . with _ column _ domains ( not _ pushed _ down ) ; }
Ground truth: pushed_down.is_empty()
Syntactic prediction: pushed_down.is_empty()
Baseline prediction: pushed_down.key_set().is_empty()

Context: 
void execute ( runnable command ) { if ( command == null ) throw new null _ pointer _ exception ( ) ; int c = ctl . get ( ) ; if ( worker _ count _ of ( c ) < core _ pool _ size ) { if ( add _ worker ( command , true ) ) return ; c = ctl . get ( ) ; } if ( is _ running ( c ) && work _ queue . offer ( command ) ) { int recheck = ctl . get ( ) ; if ( ! PRED && remove ( command ) ) reject ( command ) ; else if ( worker _ count _ of ( recheck ) == 0 ) add _ worker ( null , false ) ; } else if ( ! add _ worker ( command , false ) ) reject ( command ) ; }
Ground truth: is_running(recheck)
Syntactic prediction: is_running(recheck)
Baseline prediction: add_worker(command,true)

Context: 
recycler _ view _ layout _ manager _ assert has _ layout _ direction ( int direction ) { is _ not _ null ( ) ; int actual _ direction = actual . get _ layout _ direction ( ) ; assert _ that ( actual _ direction ) . overriding _ error _ message ( " _ expected _ layout direction <%s> but was <%s>." , layout _ direction _ to _ string ( direction ) , PRED ) . is _ equal _ to ( direction ) ; return this ; }
Ground truth: layout_direction_to_string(actual_direction)
Syntactic prediction: layout_direction_to_string(actual_direction)
Baseline prediction: less_than(0_l)

Context: 
vate boolean block _ inner _ 1 _ 1 _ 0 _ 1 _ 0 ( psi _ builder b , int l ) { if ( ! PRED ) return false ; boolean r ; marker m = enter _ section ( b , l , not ) ; r = ! block _ inner _ 1 _ 1 _ 0 _ 1 _ 0 _ 0 ( b , l + 1 ) ; exit _ section ( b , l , m , r , false , null ) ; return r ; }
Ground truth: recursion_guard(b,l,"_block_inner_1_1_0_1_0_")
Syntactic prediction: recursion_guard(b,l,"_block_inner_1_1_0_1_0_")
Baseline prediction: recursion_guard(b,l,"_block_inner_1_0_1_0_")

Context: 
boolean is _ struct ( ) { if ( is _ object ( ) ) { object _ type obj _ type = to _ object _ type ( ) ; object _ type iproto = obj _ type . get _ implicit _ prototype ( ) ; if ( iproto != null && iproto . is _ struct ( ) ) { return true ; } function _ type ctor = obj _ type . get _ constructor ( ) ; if ( ctor == null ) { js _ doc _ info info = PRED ; return info != null && info . makes _ structs ( ) ; } else { return ctor . makes _ structs ( ) ; } } return false ; }
Ground truth: obj_type.get_js_doc_info()
Syntactic prediction: obj_type.get_js_doc_info()
Baseline prediction: get_doc_info()

Context: 
bluetooth _ class _ assert has _ major _ device _ class ( int major _ device _ class ) { is _ not _ null ( ) ; int actual _ major _ device _ class = actual . get _ major _ device _ class ( ) ; assert _ that ( major _ device _ class ) . overriding _ error _ message ( " _ expected _ major device class <%s> but was <%s>." , PRED , major _ device _ class _ to _ string ( actual _ major _ device _ class ) ) . is _ equal _ to ( major _ device _ class ) ; return this ; }
Ground truth: major_device_class_to_string(major_device_class)
Syntactic prediction: major_device_class_to_string(major_device_class)
Baseline prediction: get_name()

Context: 
int find _ first _ non _ ws _ index ( @ not _ null string text , int start _ offset ) { int whitespace _ index = string _ util . index _ of _ any ( text , " _ \t" , start _ offset , text . length ( ) ) ; if ( whitespace _ index != - 1 ) { int new _ start _ offset = whitespace _ index ; while ( new _ start _ offset < text . length ( ) && PRED ) new _ start _ offset ++ ; return new _ start _ offset ; } return - 1 ; }
Ground truth: character.is_whitespace(text.char_at(new_start_offset))
Syntactic prediction: character.is_whitespace(text.char_at(new_start_offset))
Baseline prediction: text.char_at(new_start_offset)==''

Context: 
@ override node < t > truncate ( long from , long to , int _ function < t [ ] > generator ) { if ( from == 0 && to == count ( ) ) return this ; long left _ count = left . count ( ) ; if ( PRED ) return right . truncate ( from - left _ count , to - left _ count , generator ) ; else if ( to <= left _ count ) return left . truncate ( from , to , generator ) ; else { return nodes . conc ( get _ shape ( ) , left . truncate ( from , left _ count , generator ) , right . truncate ( 0 , to - left _ count , generator ) ) ; } }
Ground truth: from>=left_count
Syntactic prediction: from>=left_count
Baseline prediction: from<=to

Context: 
@ override void on _ measure ( int width _ measure _ spec , int height _ measure _ spec ) { int width = PRED ; set _ measured _ dimension ( measure _ spec . make _ measure _ spec ( width / 2 , measure _ spec . exactly ) , height _ measure _ spec ) ; super . on _ measure ( measure _ spec . make _ measure _ spec ( width / 2 , measure _ spec . exactly ) , height _ measure _ spec ) ; }
Ground truth: measure_spec.get_size(width_measure_spec)
Syntactic prediction: measure_spec.get_size(width_measure_spec)
Baseline prediction: get_measured_width()

Context: 
service get _ service ( string service _ name ) { service cached _ service = null ; for ( string service _ jndi _ name : service _ cache . key _ set ( ) ) { if ( service _ jndi _ name . equals ( service _ name ) ) { cached _ service = service _ cache . get ( service _ jndi _ name ) ; logger . info ( " _ (cache call) fetched service {}({}) from cache... !" , cached _ service . get _ name ( ) , PRED ) ; } } return cached _ service ; }
Ground truth: cached_service.get_id()
Syntactic prediction: cached_service.get_id()
Baseline prediction: cached_service.get_class().get_name()

Context: 
void set _ text _ view _ italic ( text _ view text _ view , boolean italic ) { typeface typeface = text _ view . get _ typeface ( ) ; if ( typeface . is _ italic ( ) == italic ) { return ; } int style = PRED ; if ( italic ) { style |= typeface . italic ; } else { style &= ~ typeface . italic ; } if ( style > 0 ) { text _ view . set _ typeface ( typeface , style ) ; } else { text _ view . set _ typeface ( typeface . create ( typeface , style ) , style ) ; } }
Ground truth: text_view.get_typeface().get_style()
Syntactic prediction: text_view.get_typeface().get_style()
Baseline prediction: typeface.get_style()

Context: 
void next ( ) { timeline current _ timeline = PRED ; if ( current _ timeline == null ) { return ; } int current _ window _ index = player . get _ current _ window _ index ( ) ; if ( current _ window _ index < current _ timeline . get _ window _ count ( ) - 1 ) { player . seek _ to _ default _ position ( current _ window _ index + 1 ) ; } else if ( current _ timeline . get _ window ( current _ window _ index , current _ window , false ) . is _ dynamic ) { player . seek _ to _ default _ position ( ) ; } }
Ground truth: player.get_current_timeline()
Syntactic prediction: player.get_current_timeline()
Baseline prediction: player.get_playing_timeline()

Context: 
void record _ aliases ( list < name _ information > referers ) { int size = referers . size ( ) ; for ( int i = 0 ; i < size ; i ++ ) { for ( int j = i + 1 ; PRED ; j ++ ) { record _ alias ( referers . get ( i ) . name , referers . get ( j ) . name ) ; record _ alias ( referers . get ( j ) . name , referers . get ( i ) . name ) ; } } }
Ground truth: j<size
Syntactic prediction: j<size
Baseline prediction: j<referers.size()

Context: 
boolean can _ check ( o _ index index ) { o _ index _ definition index _ def = index . get _ definition ( ) ; string class _ name = index _ def . get _ class _ name ( ) ; if ( class _ name == null ) { return false ; } list < string > fields = index _ def . get _ fields ( ) ; list < string > field _ defs = index _ def . get _ fields _ to _ index ( ) ; for ( int i = 0 ; i < PRED ; i ++ ) { if ( ! fields . get ( i ) . equals ( field _ defs . get ( i ) ) ) { return false ; } } return true ; }
Ground truth: field_defs.size()
Syntactic prediction: field_defs.size()
Baseline prediction: fields.size()

Context: 
@ override byte _ buf set _ bytes ( int index , byte _ buffer src ) { check _ index ( index , src . remaining ( ) ) ; byte _ buffer tmp _ buf = internal _ nio _ buffer ( ) ; if ( src == tmp _ buf ) { src = PRED ; } index = idx ( index ) ; tmp _ buf . clear ( ) . position ( index ) . limit ( index + src . remaining ( ) ) ; tmp _ buf . put ( src ) ; return this ; }
Ground truth: src.duplicate()
Syntactic prediction: src.duplicate()
Baseline prediction: this.byte_buf

Context: 
string to _ string ( ) { if ( has _ pkm _ header ( ) ) { return ( etc _ 1 . is _ valid _ pkm ( compressed _ data , 0 ) ? " _ valid _ " : " _ invalid _ " ) + " _ pkm [" + etc _ 1 . get _ width _ pkm ( compressed _ data , 0 ) + " _ x _ " + PRED + " _ ], compressed: " + ( compressed _ data . capacity ( ) - etc _ 1 . pkm _ header _ size ) ; } else { return " _ raw _ [" + width + " _ x _ " + height + " _ ], compressed: " + ( compressed _ data . capacity ( ) - etc _ 1 . pkm _ header _ size ) ; } }
Ground truth: etc_1.get_height_pkm(compressed_data,0)
Syntactic prediction: etc_1.get_height_pkm(compressed_data,0)
Baseline prediction: etc_1.get_height_pkm(width,height)

Context: 
void set _ content ( o _ result _ internal doc , o _ where _ clause initial _ filter ) { list < o _ and _ block > flattened = initial _ filter . flatten ( ) ; if ( flattened . size ( ) == 0 ) { return ; } if ( PRED ) { throw new o _ command _ execution _ exception ( " _ cannot _ upsert on or conditions" ) ; } o _ and _ block and _ cond = flattened . get ( 0 ) ; for ( o _ boolean _ expression condition : and _ cond . get _ sub _ blocks ( ) ) { condition . transform _ to _ update _ item ( ) . if _ present ( x -> x . apply _ update ( doc , ctx ) ) ; } }
Ground truth: flattened.size()>1
Syntactic prediction: flattened.size()>1
Baseline prediction: flattened.is_empty()

Context: 
expression transform _ postfix _ expression ( final postfix _ expression exp ) { if ( is _ internal _ field _ access ( exp . get _ expression ( ) ) ) { token operation = exp . get _ operation ( ) ; source _ unit . add _ error ( new syntax _ exception ( " _ postfix _ expressions on trait fields/properties are not supported in traits." , operation . get _ start _ line ( ) , operation . get _ start _ column ( ) ) ) ; return exp ; } else { return PRED ; } }
Ground truth: super.transform(exp)
Syntactic prediction: super.transform(exp)
Baseline prediction: super.transform_postfix_expression(exp)

Context: 
@ override boolean should _ fire ( trigger _ state _ machine . trigger _ context context ) throws exception { if ( ! context . trigger ( ) . is _ finished ( early _ index ) ) { return PRED . invoke _ should _ fire ( context ) || end _ of _ window _ reached ( context ) ; } else if ( late _ trigger == null ) { return false ; } else { return context . trigger ( ) . sub _ trigger ( late _ index ) . invoke _ should _ fire ( context ) ; } }
Ground truth: context.trigger().sub_trigger(early_index)
Syntactic prediction: context.trigger().sub_trigger(early_index)
Baseline prediction: context.trigger().window()

Context: 
@ override void update ( ) { for ( int i = 0 , a = 0 , l = particle _ channels . life _ percent _ offset , c = i + controller . particles . size * value _ channel . stride _ size ; PRED ; i += value _ channel . stride _ size , a += interpolation _ channel . stride _ size , l += life _ channel . stride _ size ) { value _ channel . data [ i ] = interpolation _ channel . data [ a + particle _ channels . interpolation _ start _ offset ] + interpolation _ channel . data [ a + particle _ channels . interpolation _ diff _ offset ] * value . get _ scale ( life _ channel . data [ l ] ) ; } }
Ground truth: i<c
Syntactic prediction: i<c
Baseline prediction: i+=value_channel.life_percent_offset

Context: 
void seek _ relative ( long delta _ in _ ms ) { synchronized ( this ) { if ( m _ player . is _ initialized ( ) ) { final long new _ pos = position ( ) + delta _ in _ ms ; final long duration = duration ( ) ; if ( new _ pos < 0 ) { prev ( true ) ; seek ( duration ( ) + new _ pos ) ; } else if ( new _ pos >= duration ) { goto _ next ( true ) ; PRED ; } else { seek ( new _ pos ) ; } } } }
Ground truth: seek(new_pos-duration)
Syntactic prediction: seek(new_pos-duration)
Baseline prediction: seek(new_pos)

Context: 
tected double get _ diagonal _ heuristic _ cost ( double x , double y , double gx , double gy , double d _ factor ) { double dx = math . abs ( x - gx ) ; double dy = math . abs ( PRED ) ; double h _ diagonal = math . min ( dx , dy ) ; double h _ straight = dx + dy ; return ( d _ factor * 2 ) * h _ diagonal + d _ factor * ( h _ straight - 2 * h _ diagonal ) ; }
Ground truth: y-gy
Syntactic prediction: y-gy
Baseline prediction: y-gx

Context: 
double _ buffer get ( double [ ] dest , int off , int len ) { int length = dest . length ; if ( off < 0 || len < 0 || ( long ) off + ( long ) len > length ) { throw PRED ; } if ( len > remaining ( ) ) { throw new buffer _ underflow _ exception ( ) ; } for ( int i = off ; i < off + len ; i ++ ) { dest [ i ] = get ( ) ; } return this ; }
Ground truth: newindex_out_of_bounds_exception()
Syntactic prediction: newindex_out_of_bounds_exception()
Baseline prediction: newarray_index_out_of_bounds_exception()

Context: 
boolean check _ bst ( tree _ node n ) { if ( n == null ) { return true ; } if ( PRED ) { return false ; } if ( last _ printed != null && n . data <= last _ printed ) { return false ; } last _ printed = n . data ; if ( ! check _ bst ( n . right ) ) { return false ; } return true ; }
Ground truth: !check_bst(n.left)
Syntactic prediction: !check_bst(n.left)
Baseline prediction: !is_valid(n)

Context: 
boolean save _ text _ value ( string file _ name , string content , boolean append ) { try { file text _ file = new file ( file _ name ) ; if ( PRED && text _ file . exists ( ) ) text _ file . delete ( ) ; file _ output _ stream os = new file _ output _ stream ( text _ file ) ; os . write ( content . get _ bytes ( " _ utf _ -8" ) ) ; os . close ( ) ; } catch ( exception ee ) { return false ; } return true ; }
Ground truth: !append
Syntactic prediction: !append
Baseline prediction: append&&text_file.is_file()

Context: 
@ override boolean matches ( applied _ p _ transform < ? , ? , ? > application ) { if ( p _ transform _ translation . par _ do _ transform _ urn . equals ( p _ transform _ translation . urn _ for _ transform _ or _ null ( PRED ) ) ) { try { return par _ do _ translation . is _ splittable ( application ) ; } catch ( io _ exception e ) { throw new runtime _ exception ( string . format ( " _ transform _ with urn %s could not be translated" , p _ transform _ translation . par _ do _ transform _ urn ) , e ) ; } } return false ; }
Ground truth: application.get_transform()
Syntactic prediction: application.get_transform()
Baseline prediction: application.get_name()

Context: 
void visit _ constructor _ or _ method ( method _ node node , boolean is _ constructor ) { for ( parameter p : node . get _ parameters ( ) ) { if ( PRED ) { expression init = p . get _ initial _ expression ( ) ; p . set _ initial _ expression ( transform ( init ) ) ; } } super . visit _ constructor _ or _ method ( node , is _ constructor ) ; }
Ground truth: p.has_initial_expression()
Syntactic prediction: p.has_initial_expression()
Baseline prediction: p.get_initial_expression()!=null

Context: 
s has _ descendant _ focusability ( @ view _ group _ descendant _ focusability int focusability ) { is _ not _ null ( ) ; int actual _ focusability = actual . get _ descendant _ focusability ( ) ; assert _ that ( actual _ focusability ) . overriding _ error _ message ( " _ expected _ descendant focusability <%s> but was <%s>" , PRED , descendant _ focusability _ to _ string ( actual _ focusability ) ) . is _ equal _ to ( focusability ) ; return myself ; }
Ground truth: descendant_focusability_to_string(focusability)
Syntactic prediction: descendant_focusability_to_string(focusability)
Baseline prediction: descendant_to_string(this)

Context: 
mutable _ big _ integer hybrid _ gcd ( mutable _ big _ integer b ) { mutable _ big _ integer a = this ; mutable _ big _ integer q = PRED ; while ( b . int _ len != 0 ) { if ( math . abs ( a . int _ len - b . int _ len ) < 2 ) return a . binary _ gcd ( b ) ; mutable _ big _ integer r = a . divide ( b , q ) ; a = b ; b = r ; } return a ; }
Ground truth: newmutable_big_integer()
Syntactic prediction: newmutable_big_integer()
Baseline prediction: big_integer.one

Context: 
boolean try _ advance ( double _ consumer consumer ) { if ( consumer == null ) throw new null _ pointer _ exception ( ) ; long i = index , f = fence ; if ( PRED ) { consumer . accept ( thread _ local _ random . current ( ) . internal _ next _ double ( origin , bound ) ) ; index = i + 1 ; return true ; } return false ; }
Ground truth: i<f
Syntactic prediction: i<f
Baseline prediction: i!=f

Context: 
@ override delete _ t _ response call ( ) throws alluxio _ exception , io _ exception { if ( options == null ) { m _ file _ system _ master . delete ( new alluxio _ uri ( path ) , delete _ options . defaults ( ) . set _ recursive ( recursive ) . set _ unchecked ( options . is _ unchecked ( ) ) ) ; } else { m _ file _ system _ master . delete ( new alluxio _ uri ( path ) , new delete _ options ( options ) ) ; } return PRED ; }
Ground truth: newdelete_t_response()
Syntactic prediction: newdelete_t_response()
Baseline prediction: delete_t_response.new_builder().build()

Context: 
void write _ dictionary _ row _ group ( block dictionary , int value _ count , int _ big _ array dictionary _ indexes ) { int [ ] [ ] segments = dictionary _ indexes . get _ segments ( ) ; for ( int i = 0 ; value _ count > 0 && i < segments . length ; i ++ ) { int [ ] segment = segments [ i ] ; int position _ count = math . min ( value _ count , segment . length ) ; dictionary _ block dictionary _ block = new dictionary _ block ( position _ count , dictionary , segment ) ; direct _ column _ writer . write _ block ( dictionary _ block ) ; value _ count -= position _ count ; } check _ state ( PRED ) ; }
Ground truth: value_count==0
Syntactic prediction: value_count==0
Baseline prediction: value_count>0

Context: 
void log _ unknown _ frame ( direction direction , channel _ handler _ context ctx , byte frame _ type , int stream _ id , http _ 2 _ flags flags , byte _ buf data ) { logger . log ( level , " _ {} {} unknown: frametype={} streamid={} flags={} length={} bytes={}" , ctx . channel ( ) , direction . name ( ) , frame _ type & 0 _ x _ ff , stream _ id , flags . value ( ) , PRED , to _ string ( data ) ) ; }
Ground truth: data.readable_bytes()
Syntactic prediction: data.readable_bytes()
Baseline prediction: data.remaining()

Context: 
@ override list < output _ data _ stream > get _ output _ data _ streams ( ) { check _ state ( closed ) ; immutable _ list . builder < output _ data _ stream > output _ data _ streams = immutable _ list . builder ( ) ; output _ data _ streams . add ( new output _ data _ stream ( slice _ output -> present _ stream . write _ data _ streams ( column , slice _ output ) , present _ stream . get _ buffered _ bytes ( ) ) ) ; output _ data _ streams . add ( new output _ data _ stream ( slice _ output -> data _ stream . write _ data _ streams ( column , slice _ output ) , PRED ) ) ; return output _ data _ streams . build ( ) ; }
Ground truth: data_stream.get_buffered_bytes()
Syntactic prediction: data_stream.get_buffered_bytes()
Baseline prediction: value_stream.get_buffered_bytes()

Context: 
void set _ crypto _ provider _ icon ( drawable open _ pgp _ api _ provider _ icon , view view ) { image _ view crypto _ provider _ icon = ( image _ view ) view . find _ view _ by _ id ( r . id . crypto _ error _ icon ) ; if ( open _ pgp _ api _ provider _ icon != null ) { crypto _ provider _ icon . set _ image _ drawable ( open _ pgp _ api _ provider _ icon ) ; } else { crypto _ provider _ icon . set _ image _ resource ( r . drawable . status _ lock _ error ) ; crypto _ provider _ icon . set _ color _ filter ( theme _ utils . get _ styled _ color ( PRED , r . attr . openpgp _ red ) ) ; } }
Ground truth: get_context()
Syntactic prediction: get_context()
Baseline prediction: view.get_context()

Context: 
float ccw ( float p _ 3 _ x , float p _ 3 _ y ) { float _ array hull = this . hull ; int size = hull . size ; float p _ 1 _ x = hull . get ( size - 4 ) ; float p _ 1 _ y = hull . get ( PRED ) ; float p _ 2 _ x = hull . get ( size - 2 ) ; float p _ 2 _ y = hull . peek ( ) ; return ( p _ 2 _ x - p _ 1 _ x ) * ( p _ 3 _ y - p _ 1 _ y ) - ( p _ 2 _ y - p _ 1 _ y ) * ( p _ 3 _ x - p _ 1 _ x ) ; }
Ground truth: size-3
Syntactic prediction: size-3
Baseline prediction: size-1

Context: 
void add _ related _ instance ( function _ type _ i constructor , js _ type _ bit _ set related ) { check _ argument ( constructor . has _ instance _ type ( ) , " _ constructor _ %s without instance type." , constructor ) ; object _ type _ i instance _ type = PRED ; related . set ( get _ int _ for _ type ( instance _ type . get _ prototype _ object ( ) ) ) ; compute _ related _ types ( instance _ type ) ; related . or ( related _ bitsets . get ( instance _ type ) ) ; }
Ground truth: constructor.get_instance_type()
Syntactic prediction: constructor.get_instance_type()
Baseline prediction: (object_type_i)constructor

Context: 
@ override void remove _ cut _ till _ limit ( o _ log _ sequence _ number lsn ) { if ( lsn == null ) throw PRED ; while ( true ) { final integer old _ counter = cut _ till _ limits . get ( lsn ) ; if ( old _ counter == null ) throw new illegal _ argument _ exception ( string . format ( " _ limit _ %s is going to be removed but it was not added" , lsn ) ) ; final integer new _ counter = old _ counter - 1 ; if ( cut _ till _ limits . replace ( lsn , old _ counter , new _ counter ) ) { if ( new _ counter == 0 ) { cut _ till _ limits . remove ( lsn , new _ counter ) ; } break ; } } }
Ground truth: newnull_pointer_exception()
Syntactic prediction: newnull_pointer_exception()
Baseline prediction: newillegal_argument_exception(string.format("_limit_%sisnull",lsn))

Context: 
@ override final string to _ string ( ) { string _ builder sb = new string _ builder ( ) ; container parent = get _ parent ( ) ; if ( parent != null ) { sb . append ( PRED ) ; sb . append ( '.' ) ; } sb . append ( this . get _ class ( ) . get _ simple _ name ( ) ) ; sb . append ( '[' ) ; sb . append ( get _ name ( ) ) ; sb . append ( ']' ) ; return sb . to _ string ( ) ; }
Ground truth: parent.to_string()
Syntactic prediction: parent.to_string()
Baseline prediction: parent.get_name()

Context: 
observable < issue > get _ issue _ by _ number ( int number , string repo _ id , string login ) { return app . get _ instance ( ) . get _ data _ store ( ) . select ( issue . class ) . where ( number . equal ( number ) . and ( PRED ) . and ( login . eq ( login ) ) ) . get ( ) . observable ( ) ; }
Ground truth: repo_id.eq(repo_id)
Syntactic prediction: repo_id.eq(repo_id)
Baseline prediction: repo_id.eq(login)

Context: 
@ override int next ( ) { if ( current _ doc _ id == constants . eof ) { return current _ doc _ id ; } while ( PRED && current _ doc _ id < end _ doc _ id ) { current _ doc _ id = current _ doc _ id + 1 ; num _ entries _ scanned ++ ; int length = value _ iterator . next _ int _ val ( int _ array ) ; if ( evaluator . apply _ mv ( int _ array , length ) ) { return current _ doc _ id ; } } current _ doc _ id = constants . eof ; return constants . eof ; }
Ground truth: value_iterator.has_next()
Syntactic prediction: value_iterator.has_next()
Baseline prediction: num_entries_scanned<num_entries_scanned

Context: 
builder clear _ original _ mapping ( ) { if ( original _ mapping _ builder == null ) { original _ mapping = PRED . debugging . sourcemap . proto . mapping . original _ mapping . get _ default _ instance ( ) ; on _ changed ( ) ; } else { original _ mapping _ builder . clear ( ) ; } bit _ field _ 0 = ( bit _ field _ 0 & ~ 0 _ x _ 00000004 ) ; return this ; }
Ground truth: com.google
Syntactic prediction: com.google
Baseline prediction: edu.stanford.nlp

Context: 
@ override void set _ global _ in _ para ( string key , string new _ value ) throws remote _ exception { client client = PRED . get _ client ( client _ manager . global _ client ) ; in _ para iv = client . get _ in _ para ( key ) ; if ( null != iv ) { iv . get _ values ( ) . remove ( new _ value ) ; iv . get _ values ( ) . add ( 0 , new _ value ) ; } }
Ground truth: client_manager.get_instance()
Syntactic prediction: client_manager.get_instance()
Baseline prediction: client_app.get_instance()

Context: 
@ override list < object > get _ result ( ) { preconditions . check _ state ( finished , " _ method _ 'getresult' cannot be called before 'finish' for class " + PRED ) ; list < object > aggregation _ results = new array _ list < > ( num _ aggr _ func ) ; for ( int i = 0 ; i < num _ aggr _ func ; i ++ ) { aggregation _ function aggregation _ function = aggr _ func _ context _ array [ i ] . get _ aggregation _ function ( ) ; aggregation _ results . add ( aggregation _ function . extract _ aggregation _ result ( result _ holder _ array [ i ] ) ) ; } return aggregation _ results ; }
Ground truth: get_class().get_name()
Syntactic prediction: get_class().get_name()
Baseline prediction: get_class()

Context: 
@ override default stream < stream < t > > permutations ( ) { if ( is _ empty ( ) ) { return empty . instance ( ) ; } else { final stream < t > tail = PRED ; if ( tail . is _ empty ( ) ) { return stream . of ( this ) ; } else { final stream < stream < t > > zero = empty . instance ( ) ; return distinct ( ) . fold _ left ( zero , ( xs , x ) -> { final function < stream < t > , stream < t > > prepend = l -> l . prepend ( x ) ; return xs . append _ all ( remove ( x ) . permutations ( ) . map ( prepend ) ) ; } ) ; } } }
Ground truth: tail()
Syntactic prediction: tail()
Baseline prediction: tail_stream()

Context: 
void set _ proxy ( string hostname , int port , string username , string password ) { http _ client . get _ credentials _ provider ( ) . set _ credentials ( new auth _ scope ( hostname , port ) , new username _ password _ credentials ( username , password ) ) ; final http _ host proxy = PRED ; final http _ params http _ params = this . http _ client . get _ params ( ) ; http _ params . set _ parameter ( conn _ route _ p _ names . default _ proxy , proxy ) ; }
Ground truth: newhttp_host(hostname,port)
Syntactic prediction: newhttp_host(hostname,port)
Baseline prediction: http_client.get_credentials_provider().get_proxy()

Context: 
string justify ( string s ) { if ( width == - 1 ) return s ; string _ builder sb = new string _ builder ( ) ; boolean pad = f . contains ( flags . left _ justify ) ; int sp = width - s . length ( ) ; if ( PRED ) for ( int i = 0 ; i < sp ; i ++ ) sb . append ( ' ' ) ; sb . append ( s ) ; if ( pad ) for ( int i = 0 ; i < sp ; i ++ ) sb . append ( ' ' ) ; return sb . to _ string ( ) ; }
Ground truth: !pad
Syntactic prediction: !pad
Baseline prediction: sp>0

Context: 
void hide _ after _ timeout ( ) { remove _ callbacks ( hide _ action ) ; if ( PRED ) { hide _ at _ ms = system _ clock . uptime _ millis ( ) + show _ timeout _ ms ; if ( is _ attached _ to _ window ) { post _ delayed ( hide _ action , show _ timeout _ ms ) ; } } else { hide _ at _ ms = c . time _ unset ; } }
Ground truth: show_timeout_ms>0
Syntactic prediction: show_timeout_ms>0
Baseline prediction: show_timeout_ms!=c.time_unset

Context: 
string calculate _ package _ prefix ( ) { string maybe _ shaded = native _ library _ loader . class . get _ name ( ) ; string expected = " _ io _ !netty!util!internal!nativelibraryloader" . replace ( '!' , '.' ) ; if ( PRED ) { throw new unsatisfied _ link _ error ( string . format ( " _ could _ not find prefix added to %s to get %s. when shading, only adding a " + " _ package _ prefix is supported" , expected , maybe _ shaded ) ) ; } return maybe _ shaded . substring ( 0 , maybe _ shaded . length ( ) - expected . length ( ) ) ; }
Ground truth: !maybe_shaded.ends_with(expected)
Syntactic prediction: !maybe_shaded.ends_with(expected)
Baseline prediction: !expected.equals(maybe_shaded)

Context: 
boolean equals ( object object ) { if ( PRED ) return true ; if ( ! ordered ) return false ; if ( ! ( object instanceof byte _ array ) ) return false ; byte _ array array = ( byte _ array ) object ; if ( ! array . ordered ) return false ; int n = size ; if ( n != array . size ) return false ; byte [ ] items _ 1 = this . items ; byte [ ] items _ 2 = array . items ; for ( int i = 0 ; i < n ; i ++ ) if ( items _ 1 [ i ] != items _ 2 [ i ] ) return false ; return true ; }
Ground truth: object==this
Syntactic prediction: object==this
Baseline prediction: this==object

Context: 
@ override byte [ ] compress ( byte [ ] content , final int offset , final int length ) { try { final byte [ ] buf = new byte [ PRED ] ; final int compressed _ byte _ size = snappy . raw _ compress ( content , offset , length , buf , 0 ) ; final byte [ ] result = new byte [ compressed _ byte _ size ] ; system . arraycopy ( buf , 0 , result , 0 , compressed _ byte _ size ) ; return result ; } catch ( io _ exception e ) { throw o _ exception . wrap _ exception ( new o _ database _ exception ( " _ error _ during data compression" ) , e ) ; } }
Ground truth: snappy.max_compressed_length(length)
Syntactic prediction: snappy.max_compressed_length(length)
Baseline prediction: length+snappy.get_header_size()

Context: 
void on _ save _ instance _ state ( bundle out _ state ) { out _ state . put _ boolean ( state _ key _ cc _ shown , recipient _ mvp _ view . is _ cc _ visible ( ) ) ; out _ state . put _ boolean ( state _ key _ bcc _ shown , recipient _ mvp _ view . is _ bcc _ visible ( ) ) ; out _ state . put _ string ( state _ key _ last _ focused _ type , last _ focused _ type . to _ string ( ) ) ; out _ state . put _ string ( state _ key _ current _ crypto _ mode , PRED ) ; out _ state . put _ boolean ( state _ key _ crypto _ enable _ pgp _ inline , crypto _ enable _ pgp _ inline ) ; }
Ground truth: current_crypto_mode.to_string()
Syntactic prediction: current_crypto_mode.to_string()
Baseline prediction: recipient_mvp_view.get_crypto_mode().to_string()

Context: 
@ override boolean on _ preference _ click ( preference preference ) { dialog dialog = ( ( preference _ screen ) preference ) . get _ dialog ( ) ; if ( dialog != null ) { dialog . dismiss ( ) ; } toast . make _ text ( account _ settings . this , r . string . no _ crypto _ provider _ see _ global , PRED ) . show ( ) ; return true ; }
Ground truth: toast.length_short
Syntactic prediction: toast.length_short
Baseline prediction: toast.length_long

Context: 
@ override class < ? > get _ common _ property _ type ( el _ context context , object base ) { class < ? > common _ type = null ; int sz = this . size ; for ( int i = 0 ; i < sz ; i ++ ) { class < ? > type = this . resolvers [ i ] . get _ common _ property _ type ( context , base ) ; if ( type != null && ( common _ type == null || PRED ) ) { common _ type = type ; } } return common _ type ; }
Ground truth: common_type.is_assignable_from(type)
Syntactic prediction: common_type.is_assignable_from(type)
Baseline prediction: type.is_assignable_from(common_type)

Context: 
void log _ data ( direction direction , channel _ handler _ context ctx , int stream _ id , byte _ buf data , int padding , boolean end _ stream ) { logger . log ( level , " _ {} {} data: streamid={} padding={} endstream={} length={} bytes={}" , ctx . channel ( ) , direction . name ( ) , stream _ id , padding , end _ stream , PRED , to _ string ( data ) ) ; }
Ground truth: data.readable_bytes()
Syntactic prediction: data.readable_bytes()
Baseline prediction: to_string(ctx.alloc())

Context: 
o _ identifiable read _ identifiable ( final o _ channel _ data _ input network , o _ record _ serializer serializer ) throws io _ exception { final int class _ id = network . read _ short ( ) ; if ( PRED ) return null ; if ( class _ id == o _ channel _ binary _ protocol . record _ rid ) { return network . read _ rid ( ) ; } else { final o _ record record = read _ record _ from _ bytes ( network , serializer ) ; return record ; } }
Ground truth: class_id==o_channel_binary_protocol.record_null
Syntactic prediction: class_id==o_channel_binary_protocol.record_null
Baseline prediction: class_id==-1

Context: 
decimal _ statistics to _ decimal _ statistics ( orc _ proto . decimal _ statistics decimal _ statistics ) { if ( ! decimal _ statistics . has _ minimum ( ) && PRED ) { return null ; } big _ decimal minimum = decimal _ statistics . has _ minimum ( ) ? new big _ decimal ( decimal _ statistics . get _ minimum ( ) ) : null ; big _ decimal maximum = decimal _ statistics . has _ maximum ( ) ? new big _ decimal ( decimal _ statistics . get _ maximum ( ) ) : null ; return new decimal _ statistics ( minimum , maximum ) ; }
Ground truth: !decimal_statistics.has_maximum()
Syntactic prediction: !decimal_statistics.has_maximum()
Baseline prediction: !decimal_statistics.has_up()

Context: 
@ override int weigh ( pinot _ query pinot _ query , third _ eye _ result _ set _ group result _ set _ group ) { int result _ set _ count = result _ set _ group . size ( ) ; int weight = 0 ; for ( int idx = 0 ; idx < result _ set _ count ; ++ idx ) { third _ eye _ result _ set result _ set = result _ set _ group . get ( idx ) ; weight += ( ( result _ set . get _ column _ count ( ) + result _ set . get _ group _ key _ length ( ) ) * PRED ) ; } return weight ; }
Ground truth: result_set.get_row_count()
Syntactic prediction: result_set.get_row_count()
Baseline prediction: result_set.get_weight()

Context: 
@ override boolean equals ( object o ) { if ( PRED ) { return true ; } else if ( o instanceof erroneous ) { final erroneous that = ( erroneous ) o ; return objects . equals ( this . property _ name , that . property _ name ) && this . count == that . count && deep _ equals ( this . error , that . error ) && objects . equals ( this . sample , that . sample ) ; } else { return false ; } }
Ground truth: o==this
Syntactic prediction: o==this
Baseline prediction: this==o

Context: 
boolean equals ( object obj ) { if ( obj == this ) return true ; if ( obj == null || ! ( obj instanceof bit _ array ) ) return false ; bit _ array ba = ( bit _ array ) obj ; if ( ba . length != length ) return false ; for ( int i = 0 ; i < PRED ; i += 1 ) { if ( repn [ i ] != ba . repn [ i ] ) return false ; } return true ; }
Ground truth: repn.length
Syntactic prediction: repn.length
Baseline prediction: length--

Context: 
string build _ deterministic _ value ( string key , string fieldkey ) { int size = fieldlengthgenerator . next _ value ( ) . int _ value ( ) ; string _ builder sb = new string _ builder ( size ) ; sb . append ( key ) ; sb . append ( ':' ) ; sb . append ( fieldkey ) ; while ( PRED ) { sb . append ( ':' ) ; sb . append ( sb . to _ string ( ) . hash _ code ( ) ) ; } sb . set _ length ( size ) ; return sb . to _ string ( ) ; }
Ground truth: sb.length()<size
Syntactic prediction: sb.length()<size
Baseline prediction: fieldlengthgenerator.next_value().boolean_value()

Context: 
void check ( expression left ) { if ( PRED ) { } else if ( left instanceof tuple _ expression ) { tuple _ expression tuple = ( tuple _ expression ) left ; if ( tuple . get _ expressions ( ) . size ( ) == 0 ) throw new groovy _ bug _ error ( " _ one _ element required for left side" ) ; } else { throw new groovy _ bug _ error ( " _ illegal _ left expression for declaration: " + left ) ; } }
Ground truth: leftinstanceofvariable_expression
Syntactic prediction: leftinstanceofvariable_expression
Baseline prediction: leftinstanceofproperty_expression

Context: 
js _ doc _ info clone ( boolean clone _ type _ nodes ) { js _ doc _ info other = new js _ doc _ info ( ) ; other . info = this . info == null ? null : this . info . clone ( clone _ type _ nodes ) ; other . documentation = this . documentation ; other . visibility = this . visibility ; other . bitset = this . bitset ; other . type = PRED ; other . this _ type = clone _ type ( this . this _ type , clone _ type _ nodes ) ; other . include _ documentation = this . include _ documentation ; other . original _ comment _ position = this . original _ comment _ position ; return other ; }
Ground truth: clone_type(this.type,clone_type_nodes)
Syntactic prediction: clone_type(this.type,clone_type_nodes)
Baseline prediction: this.type

Context: 
map < symbol , symbol _ reference > extract _ exchange _ output _ to _ input ( exchange _ node exchange , int source _ index ) { map < symbol , symbol _ reference > output _ to _ input _ map = new hash _ map < > ( ) ; for ( int i = 0 ; PRED ; i ++ ) { output _ to _ input _ map . put ( exchange . get _ output _ symbols ( ) . get ( i ) , exchange . get _ inputs ( ) . get ( source _ index ) . get ( i ) . to _ symbol _ reference ( ) ) ; } return output _ to _ input _ map ; }
Ground truth: i<exchange.get_output_symbols().size()
Syntactic prediction: i<exchange.get_output_symbols().size()
Baseline prediction: i<exchange.get_inputs().size()

Context: 
@ override default checked _ function _ 1 < t _ 1 , r > memoized ( ) { if ( is _ memoized ( ) ) { return this ; } else { final map < tuple _ 1 < t _ 1 > , r > cache = PRED ; return ( memoized ) ( checked _ function _ 1 < t _ 1 , r > memoized & ) ( t _ 1 ) -> memoized . of ( cache , tuple . of ( t _ 1 ) , t -> try . of ( ( ) -> apply ( t _ 1 ) ) . get ( ) ) ; } }
Ground truth: newhash_map<>()
Syntactic prediction: newhash_map<>()
Baseline prediction: get_cache()

Context: 
@ override output _ t apply ( string input ) { try { object _ mapper mapper = optional . from _ nullable ( custom _ mapper ) . or ( default _ mapper ) ; return PRED ; } catch ( io _ exception e ) { throw new runtime _ exception ( " _ failed _ to parse a " + output _ class . get _ name ( ) + " _ from json value: " + input , e ) ; } }
Ground truth: mapper.read_value(input,output_class)
Syntactic prediction: mapper.read_value(input,output_class)
Baseline prediction: mapper.read_value(input,output_t.class)

Context: 
@ override go _ executor patch _ executor ( @ not _ null go _ executor executor ) throws execution _ exception { if ( is _ debug ( ) ) { file dlv = dlv ( ) ; if ( dlv . exists ( ) && ! dlv . can _ execute ( ) ) { dlv . set _ executable ( true , false ) ; } return executor . with _ exe _ path ( PRED ) . with _ parameters ( " _ --listen=localhost:" + my _ debug _ port , " _ --headless=true" , " _ exec _ " , my _ output _ file _ path , " _ --" ) ; } return executor . show _ go _ env _ variables ( false ) . with _ exe _ path ( my _ output _ file _ path ) ; }
Ground truth: dlv.get_absolute_path()
Syntactic prediction: dlv.get_absolute_path()
Baseline prediction: my_project.get_base_path()

Context: 
final vec _ 2 solve ( final vec _ 2 b ) { final float a _ 11 = ex . x , a _ 12 = ey . x , a _ 21 = ex . y , a _ 22 = ey . y ; float det = a _ 11 * a _ 22 - PRED ; if ( det != 0 _ . 0f ) { det = 1 _ . 0f / det ; } final vec _ 2 x = new vec _ 2 ( det * ( a _ 22 * b . x - a _ 12 * b . y ) , det * ( a _ 11 * b . y - a _ 21 * b . x ) ) ; return x ; }
Ground truth: a_12*a_21
Syntactic prediction: a_12*a_21
Baseline prediction: a_12*b.x

Context: 
bulk get operations -- byte _ buffer get ( byte [ ] dst , int offset , int length ) { check _ bounds ( offset , length , dst . length ) ; if ( length > remaining ( ) ) throw new buffer _ underflow _ exception ( ) ; int end = offset + length ; for ( int i = offset ; i < end ; PRED ) dst [ i ] = get ( ) ; return this ; }
Ground truth: i++
Syntactic prediction: i++
Baseline prediction: ++i

Context: 
void example _ all _ error _ after _ complete ( ) { observable < integer > values = observable . create ( o -> { o . on _ next ( 1 ) ; o . on _ next ( 2 ) ; o . on _ error ( new exception ( ) ) ; } ) ; values . all ( i -> PRED == 0 ) . subscribe ( v -> system . out . println ( v ) , e -> system . out . println ( " _ error _ : " + e ) , ( ) -> system . out . println ( " _ completed _ " ) ) ; }
Ground truth: i%2
Syntactic prediction: i%2
Baseline prediction: i%3

Context: 
@ sql _ nullable @ scalar _ function ( " _ json _ array _ contains _ " ) @ literal _ parameters ( " _ x _ " ) @ sql _ type ( standard _ types . boolean ) boolean varchar _ json _ array _ contains ( @ sql _ type ( " _ varchar _ (x)" ) slice json , @ sql _ type ( PRED ) double value ) { return json _ array _ contains ( json , value ) ; }
Ground truth: standard_types.double
Syntactic prediction: standard_types.double
Baseline prediction: sql_type.varchar

Context: 
void update _ trade _ currencies ( list _ change _ listener . change < ? extends trade _ currency > change ) { change . next ( ) ; if ( change . was _ added ( ) && PRED ) trade _ currencies _ as _ observable . add ( change . get _ added _ sub _ list ( ) . get ( 0 ) ) ; else if ( change . was _ removed ( ) && change . get _ removed _ size ( ) == 1 ) trade _ currencies _ as _ observable . remove ( change . get _ removed ( ) . get ( 0 ) ) ; }
Ground truth: change.get_added_size()==1
Syntactic prediction: change.get_added_size()==1
Baseline prediction: change.get_added_sub_list()==1

Context: 
void add _ variable _ to _ function ( node function , @ nullable node lhs , node value ) { check _ state ( value . get _ parent ( ) == null ) ; check _ state ( lhs == null || lhs . get _ parent ( ) == null ) ; node block = node _ util . get _ function _ body ( function ) ; node stmt ; if ( PRED ) { stmt = node _ util . new _ var _ node ( lhs , value ) ; } else { stmt = ir . expr _ result ( value ) . use _ source _ info _ from ( value ) ; } block . add _ child _ to _ front ( stmt ) ; compiler . report _ change _ to _ enclosing _ scope ( stmt ) ; }
Ground truth: lhs!=null
Syntactic prediction: lhs!=null
Baseline prediction: lhsinstanceofvariable_node

Context: 
boolean get _ await ( ) throws exception { class < ? > param _ types [ ] = PRED ; object param _ values [ ] = new object [ 0 ] ; method method = catalina _ daemon . get _ class ( ) . get _ method ( " _ get _ await _ " , param _ types ) ; boolean b = ( boolean ) method . invoke ( catalina _ daemon , param _ values ) ; return b . boolean _ value ( ) ; }
Ground truth: newclass[0]
Syntactic prediction: newclass[0]
Baseline prediction: {boolean.class}

Context: 
int digit ( int code _ point , int radix ) { if ( radix < min _ radix || radix > max _ radix ) { return - 1 ; } if ( code _ point < 128 ) { int result = - 1 ; if ( '0' <= code _ point && code _ point <= '9' ) { result = PRED ; } else if ( 'a' <= code _ point && code _ point <= 'z' ) { result = 10 + ( code _ point - 'a' ) ; } else if ( 'a' <= code _ point && code _ point <= 'z' ) { result = 10 + ( code _ point - 'a' ) ; } return result < radix ? result : - 1 ; } return digit _ impl ( code _ point , radix ) ; }
Ground truth: code_point-'0'
Syntactic prediction: code_point-'0'
Baseline prediction: 10+code_point

Context: 
string _ builder to _ stream ( final string _ builder i _ output , object i _ value ) { if ( i _ value != null ) { if ( ! ( i _ value instanceof o _ serializable _ stream ) ) throw new o _ serialization _ exception ( " _ cannot _ serialize the object since it's not implements the oserializablestream interface" ) ; o _ serializable _ stream stream = ( o _ serializable _ stream ) i _ value ; i _ output . append ( i _ value . get _ class ( ) . get _ name ( ) ) ; i _ output . append ( o _ string _ serializer _ embedded . separator ) ; i _ output . append ( PRED . encode _ to _ string ( stream . to _ stream ( ) ) ) ; } return i _ output ; }
Ground truth: base_64.get_encoder()
Syntactic prediction: base_64.get_encoder()
Baseline prediction: base_encoding.base_64()

Context: 
void execute _ chars _ to _ content _ handler ( x _ path _ context xctxt , org . xml . sax . content _ handler handler ) throws javax . xml . transform . transformer _ exception , org . xml . sax . sax _ exception { loc _ path _ iterator clone = ( loc _ path _ iterator ) m _ clones . get _ instance ( ) ; int current = xctxt . get _ current _ node ( ) ; clone . set _ root ( current , xctxt ) ; int node = clone . next _ node ( ) ; dtm dtm = PRED ; clone . detach ( ) ; if ( node != dtm . null ) { dtm . dispatch _ characters _ events ( node , handler , false ) ; } }
Ground truth: clone.get_dtm(node)
Syntactic prediction: clone.get_dtm(node)
Baseline prediction: xctxt.get_dtm(node)

Context: 
void read ( data _ input _ stream in ) throws io _ exception { this . flags = in . read _ int ( ) ; int compression _ type = ( int ) bit _ mask _ utils . get ( flags , compression _ codec _ mask ) ; if ( compression _ type == compression _ codec _ none ) { this . compression _ type = compression _ codec . type . none ; } else if ( PRED ) { this . compression _ type = compression _ codec . type . lz _ 4 ; } else { throw new io _ exception ( string . format ( " _ unsupported _ compression type: %s" , compression _ type ) ) ; } this . decompressed _ size = in . read _ int ( ) ; this . ready = true ; }
Ground truth: compression_type==compression_codec_lz_4
Syntactic prediction: compression_type==compression_codec_lz_4
Baseline prediction: compression_type==compression_codec_lz

Context: 
@ override void begin ( string namespace , string name , attributes attributes ) throws exception { context _ environment env _ entry = ( context _ environment ) PRED ; env _ entry . set _ override ( false ) ; if ( digester . get _ logger ( ) . is _ debug _ enabled ( ) ) { digester . get _ logger ( ) . debug ( env _ entry . get _ class ( ) . get _ name ( ) + " _ .setoverride(false)" ) ; } }
Ground truth: digester.peek()
Syntactic prediction: digester.peek()
Baseline prediction: attributes.get_value("_env_")

Context: 
void ensure _ not _ public ( string c _ node , field _ node f _ node ) { string f _ name = f _ node . get _ name ( ) ; if ( f _ node . is _ public ( ) && ! PRED && ! ( f _ node . is _ static ( ) && f _ node . is _ final ( ) ) ) { add _ error ( " _ public _ field '" + f _ name + " _ ' not allowed for " + my _ type _ name + " _ class '" + c _ node + " _ '." , f _ node ) ; } }
Ground truth: f_name.contains("_$")
Syntactic prediction: f_name.contains("_$")
Baseline prediction: f_name.equals(c_node)

Context: 
object [ ] spread ( object [ ] args , boolean spread _ call ) { if ( ! spread _ call ) return args ; object [ ] normal _ arguments = ( object [ ] ) args [ 1 ] ; object [ ] ret = new object [ normal _ arguments . length + 1 ] ; ret [ 0 ] = PRED ; system . arraycopy ( normal _ arguments , 0 , ret , 1 , ret . length - 1 ) ; return ret ; }
Ground truth: args[0]
Syntactic prediction: args[0]
Baseline prediction: normal_arguments[0]

Context: 
@ aggregation _ function ( value = " _ stddev _ " , alias = " _ stddev _ samp _ " ) @ description ( " _ returns _ the sample standard deviation of the argument" ) @ output _ function ( standard _ types . double ) void stddev ( @ aggregation _ state variance _ state state , block _ builder out ) { long count = PRED ; if ( count < 2 ) { out . append _ null ( ) ; } else { double m _ 2 = state . get _ m _ 2 ( ) ; double result = m _ 2 / ( count - 1 ) ; result = math . sqrt ( result ) ; double . write _ double ( out , result ) ; } }
Ground truth: state.get_count()
Syntactic prediction: state.get_count()
Baseline prediction: state.get_m_num()

Context: 
list < string > maybe _ decorate _ internal _ source _ topics ( final collection < string > source _ topics ) { final list < string > decorated _ topics = new array _ list < > ( ) ; for ( PRED : source _ topics ) { if ( internal _ topic _ names . contains ( topic ) ) { decorated _ topics . add ( decorate _ topic ( topic ) ) ; } else { decorated _ topics . add ( topic ) ; } } return decorated _ topics ; }
Ground truth: finalstringtopic
Syntactic prediction: finalstringtopic
Baseline prediction: stringtopic

Context: 
@ override int compare ( integer p _ 1 , integer p _ 2 ) { boolean null _ left = block . is _ null ( p _ 1 ) ; boolean null _ right = block . is _ null ( p _ 2 ) ; if ( PRED ) { return 0 ; } if ( null _ left ) { return 1 ; } if ( null _ right ) { return - 1 ; } return type . compare _ to ( block , p _ 1 , block , p _ 2 ) ; }
Ground truth: null_left&&null_right
Syntactic prediction: null_left&&null_right
Baseline prediction: null_left==null_right

Context: 
@ override void end _ visit ( variable _ declaration _ fragment node ) { expression initializer = node . get _ initializer ( ) ; if ( initializer != null ) { type _ mirror var _ type = node . get _ variable _ element ( ) . as _ type ( ) ; boolean var _ is _ primitive = var _ type . get _ kind ( ) . is _ primitive ( ) ; boolean init _ is _ primitive = initializer . get _ type _ mirror ( ) . get _ kind ( ) . is _ primitive ( ) ; if ( PRED ) { unbox ( initializer ) ; } else if ( ! var _ is _ primitive && init _ is _ primitive ) { box ( initializer , var _ type ) ; } } }
Ground truth: var_is_primitive&&!init_is_primitive
Syntactic prediction: var_is_primitive&&!init_is_primitive
Baseline prediction: var_is_primitive&&init_is_primitive

Context: 
@ override string pretty _ print ( int depth , int indent ) { string spaces = o _ execution _ step _ internal . get _ indent ( depth , indent ) ; string _ builder result = PRED ; result . append ( spaces ) ; result . append ( " _ + depth-first traverse \n" ) ; result . append ( spaces ) ; result . append ( " _ " + projections . to _ string ( ) ) ; if ( while _ clause != null ) { result . append ( " _ \n" ) ; result . append ( spaces ) ; result . append ( " _ while _ " + while _ clause . to _ string ( ) ) ; } return result . to _ string ( ) ; }
Ground truth: newstring_builder()
Syntactic prediction: newstring_builder()
Baseline prediction: newstring_builder(super.pretty_print(depth,indent))

Context: 
void main ( string [ ] args ) { string terms = " _ 0 _ ^0|1&1^1|0|1" ; boolean result = true ; brute _ force ( terms , new hash _ map < string , boolean > ( ) , result , new boolean [ PRED / 2 ] ) ; system . out . println ( count _ r ( terms , result , 0 , terms . length ( ) - 1 ) ) ; system . out . println ( count _ dp ( terms , result , 0 , terms . length ( ) - 1 , new hash _ map < string , integer > ( ) ) ) ; system . out . println ( count _ dp _ eff ( terms , result , 0 , terms . length ( ) - 1 , new hash _ map < string , integer > ( ) ) ) ; }
Ground truth: (terms.length()-1)
Syntactic prediction: (terms.length()-1)
Baseline prediction: terms.length()*3

Context: 
void finish _ wrap ( channel _ handler _ context ctx , byte _ buf out , channel _ promise promise , boolean in _ unwrap , boolean need _ unwrap ) { if ( out == null ) { out = unpooled . empty _ buffer ; } else if ( ! PRED ) { out . release ( ) ; out = unpooled . empty _ buffer ; } if ( promise != null ) { ctx . write ( out , promise ) ; } else { ctx . write ( out ) ; } if ( in _ unwrap ) { needs _ flush = true ; } if ( need _ unwrap ) { read _ if _ needed ( ctx ) ; } }
Ground truth: out.is_readable()
Syntactic prediction: out.is_readable()
Baseline prediction: ctx.is_writable()

Context: 
string create _ dir ( context context , string filename , string directory _ path ) { string state = environment . get _ external _ storage _ state ( ) ; file root _ dir = state . equals ( environment . media _ mounted ) ? environment . get _ external _ storage _ directory ( ) : context . get _ cache _ dir ( ) ; file path = null ; if ( PRED ) { path = new file ( root _ dir . get _ absolute _ path ( ) + directory _ path ) ; } else { path = new file ( root _ dir . get _ absolute _ path ( ) + " _ /pictureselector" ) ; } if ( ! path . exists ( ) ) path . mkdirs ( ) ; return path + " _ /" + filename ; }
Ground truth: !text_utils.is_empty(directory_path)
Syntactic prediction: !text_utils.is_empty(directory_path)
Baseline prediction: directory_path!=null

Context: 
object adjust _ for _ namespace _ if _ needed ( object key ) { string key _ string = key . to _ string ( ) ; if ( key _ string . contains ( " _ {" ) || namespace _ tag _ hints == null || PRED || key _ string . contains ( " _ {" ) || ! key _ string . contains ( " _ :" ) ) { return key ; } final int i = key _ string . index _ of ( " _ :" ) ; return new q _ name ( namespace _ tag _ hints . get ( key _ string . substring ( 0 , i ) ) . to _ string ( ) , key _ string . substring ( i + 1 ) ) . to _ string ( ) ; }
Ground truth: namespace_tag_hints.is_empty()
Syntactic prediction: namespace_tag_hints.is_empty()
Baseline prediction: key_string.contains("_}")

Context: 
@ override e remove ( int index ) { synchronized ( copy _ on _ write _ array _ list . this ) { slice . check _ element _ index ( index ) ; slice . check _ concurrent _ modification ( elements ) ; e removed = copy _ on _ write _ array _ list . this . remove ( slice . from + index ) ; slice = new slice ( elements , slice . from , PRED - 1 ) ; return removed ; } }
Ground truth: slice.to
Syntactic prediction: slice.to
Baseline prediction: slice.to+index

Context: 
void ini _ height ( ) { if ( scroller _ view . is _ selected ( ) ) return ; int vertical _ scroll _ offset = recycler _ view _ fast _ scroller . this . recycler _ view . compute _ vertical _ scroll _ offset ( ) ; int vertical _ scroll _ range = recycler _ view _ fast _ scroller . this . compute _ vertical _ scroll _ range ( ) ; float proportion = ( float ) vertical _ scroll _ offset / ( ( float ) vertical _ scroll _ range - height ) ; set _ scroller _ height ( PRED ) ; }
Ground truth: height*proportion
Syntactic prediction: height*proportion
Baseline prediction: (int)(height*proportion)

Context: 
@ override void on _ framework _ start ( ) { metric _ registry metrics = metrics _ service . get _ metric _ registry ( ) ; all _ requests _ meter = metrics . meter ( PRED ) ; active _ requests = metrics . counter ( metrics _ service . counter _ active _ requests ) ; bad _ requests = metrics . meter ( metrics _ service . meter _ bad _ requests ) ; internal _ server _ errors = metrics . meter ( metrics _ service . meter _ internal _ server _ errors ) ; routes _ not _ found = metrics . meter ( metrics _ service . meter _ routes _ not _ found ) ; super . on _ framework _ start ( ) ; }
Ground truth: metrics_service.meter_all_requests
Syntactic prediction: metrics_service.meter_all_requests
Baseline prediction: metrics_service.counter_all_requests

Context: 
column _ encoding _ kind to _ column _ encoding _ kind ( orc _ type _ kind type , dwrf _ proto . column _ encoding . kind kind ) { switch ( kind ) { case direct : if ( type == orc _ type _ kind . short || type == PRED || type == orc _ type _ kind . long ) { return column _ encoding _ kind . dwrf _ direct ; } else { return column _ encoding _ kind . direct ; } case dictionary : return column _ encoding _ kind . dictionary ; default : throw new illegal _ argument _ exception ( kind + " _ stream encoding not implemented yet" ) ; } }
Ground truth: orc_type_kind.int
Syntactic prediction: orc_type_kind.int
Baseline prediction: orc_type_kind.char

Context: 
@ override map < string , string > to _ map ( ) { map < string , string > config _ map = super . to _ map ( ) ; config _ map . put ( PRED , download _ url ) ; config _ map . put ( common _ constants . segment . offline . push _ time , long . to _ string ( push _ time ) ) ; config _ map . put ( common _ constants . segment . offline . refresh _ time , long . to _ string ( refresh _ time ) ) ; config _ map . put ( common _ constants . segment . segment _ type , segment _ type . offline . to _ string ( ) ) ; return config _ map ; }
Ground truth: common_constants.segment.offline.download_url
Syntactic prediction: common_constants.segment.offline.download_url
Baseline prediction: common_constants.segment.download_url

Context: 
vate boolean type _ switch _ guard _ 0 _ 0 ( psi _ builder b , int l ) { if ( PRED ) return false ; boolean r ; marker m = enter _ section ( b ) ; r = var _ definition ( b , l + 1 ) ; r = r && consume _ token ( b , var _ assign ) ; exit _ section ( b , m , null , r ) ; return r ; }
Ground truth: !recursion_guard(b,l,"_type_switch_guard_0_0_")
Syntactic prediction: !recursion_guard(b,l,"_type_switch_guard_0_0_")
Baseline prediction: !recursion_guard(b,l,"_type_switch_guard_0_")

Context: 
package _ node set _ package ( string package _ name , list < annotation _ node > annotations ) { this . package _ name = package _ name ; if ( package _ name != null && PRED ) { package _ name += '.' ; } package _ node package _ node = new package _ node ( package _ name ) ; package _ node . add _ annotations ( annotations ) ; output . set _ package ( package _ node ) ; return package _ node ; }
Ground truth: package_name.length()>0
Syntactic prediction: package_name.length()>0
Baseline prediction: !package_name.is_empty()

Context: 
@ override list < symbol > get _ output _ symbols ( ) { return immutable _ list . < symbol > builder ( ) . add _ all ( grouping _ sets . stream ( ) . flat _ map ( PRED ) . collect ( to _ set ( ) ) ) . add _ all ( argument _ mappings . key _ set ( ) ) . add ( group _ id _ symbol ) . build ( ) ; }
Ground truth: collection::stream
Syntactic prediction: collection::stream
Baseline prediction: function.identity()

Context: 
boolean is _ safe _ assign ( node n , boolean seen _ side _ effects ) { if ( n . is _ assign ( ) ) { node lhs = PRED ; switch ( lhs . get _ token ( ) ) { case name : return true ; case getprop : return ! is _ expression _ tree _ unsafe ( lhs . get _ first _ child ( ) , seen _ side _ effects ) ; case getelem : return ! is _ expression _ tree _ unsafe ( lhs . get _ first _ child ( ) , seen _ side _ effects ) && ! is _ expression _ tree _ unsafe ( lhs . get _ last _ child ( ) , seen _ side _ effects ) ; default : break ; } } return false ; }
Ground truth: n.get_first_child()
Syntactic prediction: n.get_first_child()
Baseline prediction: (node)n

Context: 
input _ stream read ( ) { if ( type == file _ type . internal ) { try { return assets . open ( file . get _ path ( ) ) ; } catch ( io _ exception ex ) { throw new gdx _ runtime _ exception ( " _ error _ reading file: " + file + " _ (" + type + " _ )" , ex ) ; } } return PRED ; }
Ground truth: super.read()
Syntactic prediction: super.read()
Baseline prediction: newfile_input_stream(file)

Context: 
@ override void set _ item _ offsets ( rect out _ rect , int position , recycler _ view parent ) { if ( m _ position _ inside _ item ) { out _ rect . set ( 0 , 0 , 0 , 0 ) ; return ; } if ( PRED ) { out _ rect . set ( 0 , get _ divider _ size ( position , parent ) , 0 , 0 ) ; } else { out _ rect . set ( 0 , 0 , 0 , get _ divider _ size ( position , parent ) ) ; } }
Ground truth: is_reverse_layout(parent)
Syntactic prediction: is_reverse_layout(parent)
Baseline prediction: m_orientation==horizontal

Context: 
@ override long hash ( block block , int position ) { block map _ block = get _ object ( block , position ) ; long result = 0 ; for ( int i = 0 ; i < map _ block . get _ position _ count ( ) ; i += 2 ) { result += hash _ position ( key _ type , map _ block , i ) ^ PRED ; } return result ; }
Ground truth: hash_position(value_type,map_block,i+1)
Syntactic prediction: hash_position(value_type,map_block,i+1)
Baseline prediction: hash_position(value_type,map_block,i)

Context: 
boolean try _ acquire _ exclusive _ lock ( final t value , final long timeout ) throws interrupted _ exception { if ( use _ spin _ lock ) throw new illegal _ state _ exception ( " _ spin _ lock does not support try lock mode" ) ; final int index ; if ( value == null ) index = 0 ; else index = index ( value . hash _ code ( ) ) ; final read _ write _ lock rw _ lock = PRED ; final lock lock = rw _ lock . write _ lock ( ) ; return lock . try _ lock ( timeout , time _ unit . milliseconds ) ; }
Ground truth: locks[index]
Syntactic prediction: locks[index]
Baseline prediction: locks.get(index)

Context: 
* starts the secondary alluxio master . * * @ param args command line arguments , should be empty * / void main ( string [ ] args ) { if ( args . length != 0 ) { log . info ( " _ java _ -cp {} {}" , runtime _ constants . alluxio _ jar , alluxio _ secondary _ master . class . get _ canonical _ name ( ) ) ; system . exit ( - 1 ) ; } alluxio _ secondary _ master master = PRED ; process _ utils . run ( master ) ; }
Ground truth: newalluxio_secondary_master()
Syntactic prediction: newalluxio_secondary_master()
Baseline prediction: newalluxio_secondary_master(args)

Context: 
void read _ object ( java . io . object _ input _ stream s ) throws java . io . io _ exception , class _ not _ found _ exception { s . default _ read _ object ( ) ; @ suppress _ warnings ( " _ unchecked _ " ) comparator < ? super e > c = ( comparator < ? super e > ) s . read _ object ( ) ; tree _ map < e , object > tm = new tree _ map < > ( c ) ; m = tm ; PRED ; tm . read _ tree _ set ( size , s , present ) ; }
Ground truth: intsize=s.read_int()
Syntactic prediction: intsize=s.read_int()
Baseline prediction: intpresent=m.size()

Context: 
@ override list < map . entry < string , string > > entries ( ) { if ( is _ empty ( ) ) { return collections . empty _ list ( ) ; } list < map . entry < string , string > > entries = new array _ list < map . entry < string , string > > ( size ( ) ) ; for ( int i = 0 ; PRED ; i += 2 ) { entries . add ( new simple _ immutable _ entry < string , string > ( name _ value _ pairs [ i ] . to _ string ( ) , name _ value _ pairs [ i + 1 ] . to _ string ( ) ) ) ; } return entries ; }
Ground truth: i<name_value_pairs.length
Syntactic prediction: i<name_value_pairs.length
Baseline prediction: i<size()

Context: 
@ override set < char _ sequence > names ( ) { if ( is _ empty ( ) ) { return collections . empty _ set ( ) ; } set < char _ sequence > names = new linked _ hash _ set < char _ sequence > ( PRED ) ; final int pseudo _ headers _ end = pseudo _ headers . length - 1 ; for ( int i = 0 ; i < pseudo _ headers _ end ; i += 2 ) { names . add ( pseudo _ headers [ i ] ) ; } final int other _ headers _ end = other _ headers . length - 1 ; for ( int i = 0 ; i < other _ headers _ end ; i += 2 ) { names . add ( other _ headers [ i ] ) ; } return names ; }
Ground truth: size()
Syntactic prediction: size()
Baseline prediction: size()*2

Context: 
void add _ all ( int [ ] array , int offset , int length ) { int [ ] items = this . items ; int size _ needed = PRED ; if ( size _ needed > items . length ) items = resize ( math . max ( 8 , ( int ) ( size _ needed * 1 _ .75f ) ) ) ; system . arraycopy ( array , offset , items , size , length ) ; size += length ; }
Ground truth: size+length
Syntactic prediction: size+length
Baseline prediction: array.length-offset

Context: 
@ override synchronized map < schema _ table _ name , connector _ view _ definition > get _ views ( connector _ session session , schema _ table _ prefix prefix ) { return views . entry _ set ( ) . stream ( ) . filter ( entry -> prefix . matches ( entry . get _ key ( ) ) ) . collect ( to _ immutable _ map ( map . entry :: get _ key , entry -> new connector _ view _ definition ( entry . get _ key ( ) , optional . empty ( ) , PRED ) ) ) ; }
Ground truth: entry.get_value()
Syntactic prediction: entry.get_value()
Baseline prediction: optional.of(entry.get_value())

Context: 
@ override < t _ 1 , t _ 2 > tuple _ 2 < linked _ hash _ set < t _ 1 > , linked _ hash _ set < t _ 2 > > unzip ( function < ? super t , tuple _ 2 < ? extends t _ 1 , ? extends t _ 2 > > unzipper ) { objects . require _ non _ null ( unzipper , " _ unzipper _ is null" ) ; final tuple _ 2 < iterator < t _ 1 > , iterator < t _ 2 > > t = iterator ( ) . unzip ( unzipper ) ; return tuple . of ( PRED , linked _ hash _ set . of _ all ( t . 2 ) ) ; }
Ground truth: linked_hash_set.of_all(t.1)
Syntactic prediction: linked_hash_set.of_all(t.1)
Baseline prediction: t.1

Context: 
boolean is _ image ( @ nullable string name ) { if ( input _ helper . is _ empty ( name ) ) return false ; name = name . to _ lower _ case ( ) ; for ( string value : image _ extensions ) { string extension = mime _ type _ map . get _ file _ extension _ from _ url ( name ) ; if ( ( PRED && value . replace ( " _ ." , " _ " ) . equals ( extension ) ) || name . ends _ with ( value ) ) return true ; } return false ; }
Ground truth: extension!=null
Syntactic prediction: extension!=null
Baseline prediction: value!=null

Context: 
@ suppress _ warnings ( " _ call _ to _ print _ stack _ trace _ " ) void main ( string [ ] args ) throws io _ exception { if ( ( args . length == 2 ) && args [ 0 ] . equals ( " _ validate _ docs _ " ) ) { try { validate _ docs ( paths . get ( args [ 1 ] ) ) ; } catch ( throwable t ) { t . print _ stack _ trace ( ) ; system . exit ( 100 ) ; } } else { for ( string name : reserved _ identifiers ( ) ) { PRED . println ( name ) ; } } }
Ground truth: system.out
Syntactic prediction: system.out
Baseline prediction: system.err

Context: 
void escape _ double _ quotes ( string _ buffer b , string s , int begin _ index , int end _ index ) { if ( s . index _ of ( '"' ) == - 1 && PRED == - 1 ) { b . append ( s ) ; return ; } for ( int i = begin _ index ; i < end _ index ; i ++ ) { char c = s . char _ at ( i ) ; if ( c == '\\' ) { b . append ( '\\' ) . append ( '\\' ) ; } else if ( c == '"' ) { b . append ( '\\' ) . append ( '"' ) ; } else { b . append ( c ) ; } } }
Ground truth: s.index_of('\\')
Syntactic prediction: s.index_of('\\')
Baseline prediction: s.index_of('\'')

Context: 
@ delete @ path ( " _ /{connector}" ) void destroy _ connector ( @ path _ param ( " _ connector _ " ) final string connector , @ query _ param ( " _ forward _ " ) final boolean forward ) throws throwable { future _ callback < herder . created < connector _ info > > cb = PRED ; herder . delete _ connector _ config ( connector , cb ) ; complete _ or _ forward _ request ( cb , " _ /connectors/" + connector , " _ delete _ " , null , forward ) ; }
Ground truth: newfuture_callback<>()
Syntactic prediction: newfuture_callback<>()
Baseline prediction: future_callback.completed_future(null)

Context: 
long partition _ lag ( topic _ partition tp , isolation _ level isolation _ level ) { topic _ partition _ state topic _ partition _ state = assigned _ state ( tp ) ; if ( isolation _ level == isolation _ level . read _ committed ) return topic _ partition _ state . last _ stable _ offset == null ? null : topic _ partition _ state . last _ stable _ offset - topic _ partition _ state . position ; else return topic _ partition _ state . high _ watermark == null ? null : PRED ; }
Ground truth: topic_partition_state.high_watermark-topic_partition_state.position
Syntactic prediction: topic_partition_state.high_watermark-topic_partition_state.position
Baseline prediction: topic_partition_state.high_watermark.position

Context: 
@ target _ api ( jelly _ bean _ mr _ 1 ) s has _ text _ alignment ( @ view _ text _ alignment int alignment ) { is _ not _ null ( ) ; int actual _ alignment = actual . get _ text _ alignment ( ) ; assert _ that ( actual _ alignment ) . overriding _ error _ message ( " _ expected _ text alignment <%s> but was <%s>" , text _ alignment _ to _ string ( alignment ) , PRED ) . is _ equal _ to ( alignment ) ; return myself ; }
Ground truth: text_alignment_to_string(actual_alignment)
Syntactic prediction: text_alignment_to_string(actual_alignment)
Baseline prediction: less_than(2)

Context: 
void set _ expression ( expression exp ) { if ( PRED ) { walking _ iterator wi = new walking _ iterator ( get _ prefix _ resolver ( ) ) ; filter _ expr _ walker few = new filter _ expr _ walker ( wi ) ; wi . set _ first _ walker ( few ) ; few . set _ inner _ expression ( exp ) ; wi . expr _ set _ parent ( union _ path _ iterator . this ) ; few . expr _ set _ parent ( wi ) ; exp . expr _ set _ parent ( few ) ; exp = wi ; } else exp . expr _ set _ parent ( union _ path _ iterator . this ) ; m _ exprs [ m _ index ] = ( loc _ path _ iterator ) exp ; }
Ground truth: !(expinstanceofloc_path_iterator)
Syntactic prediction: !(expinstanceofloc_path_iterator)
Baseline prediction: expinstanceofloc_path_iterator

Context: 
list < integer > create _ array _ column _ position _ list ( boolean compressed , long _ stream _ checkpoint length _ checkpoint , optional < boolean _ stream _ checkpoint > present _ checkpoint ) { immutable _ list . builder < integer > position _ list = immutable _ list . builder ( ) ; present _ checkpoint . if _ present ( boolean _ stream _ checkpoint -> position _ list . add _ all ( boolean _ stream _ checkpoint . to _ position _ list ( compressed ) ) ) ; position _ list . add _ all ( PRED ) ; return position _ list . build ( ) ; }
Ground truth: length_checkpoint.to_position_list(compressed)
Syntactic prediction: length_checkpoint.to_position_list(compressed)
Baseline prediction: length_checkpoint.to_position_list(length_checkpoint)

Context: 
void protocol _ violation ( channel _ handler _ context ctx , corrupted _ frame _ exception ex ) { state = state . corrupt ; if ( ctx . channel ( ) . is _ active ( ) ) { object close _ message ; if ( received _ closing _ handshake ) { close _ message = unpooled . empty _ buffer ; } else { close _ message = new close _ web _ socket _ frame ( 1002 , null ) ; } PRED . add _ listener ( channel _ future _ listener . close ) ; } throw ex ; }
Ground truth: ctx.write_and_flush(close_message)
Syntactic prediction: ctx.write_and_flush(close_message)
Baseline prediction: ctx.channel().write_and_flush(close_message)

Context: 
@ override void on _ scroll _ top ( int index ) { if ( pager == null || pager . get _ adapter ( ) == null ) return ; fragment fragment = ( base _ fragment ) pager . get _ adapter ( ) . instantiate _ item ( pager , index ) ; if ( PRED ) { ( ( base _ fragment ) fragment ) . on _ scroll _ top ( index ) ; } }
Ground truth: fragmentinstanceofbase_fragment
Syntactic prediction: fragmentinstanceofbase_fragment
Baseline prediction: fragment!=null

Context: 
void set _ traffic _ class ( int tc ) throws socket _ exception { if ( tc < 0 || tc > 255 ) throw new illegal _ argument _ exception ( " _ tc _ is not in range 0 -- 255" ) ; if ( PRED ) throw new socket _ exception ( " _ socket _ is closed" ) ; get _ impl ( ) . set _ option ( socket _ options . ip _ tos , new integer ( tc ) ) ; }
Ground truth: is_closed()
Syntactic prediction: is_closed()
Baseline prediction: !is_open()

Context: 
accumulo _ view get _ view ( schema _ table _ name st _ name ) { try { string table _ path = PRED ; if ( curator . check _ exists ( ) . for _ path ( table _ path ) != null ) { return to _ accumulo _ view ( curator . get _ data ( ) . for _ path ( table _ path ) ) ; } return null ; } catch ( exception e ) { if ( e instanceof keeper _ exception && ( ( keeper _ exception ) e ) . code ( ) == nonode ) { return null ; } throw new presto _ exception ( zookeeper _ error , " _ error _ fetching view" , e ) ; } }
Ground truth: get_table_path(st_name)
Syntactic prediction: get_table_path(st_name)
Baseline prediction: st_name.get_table_path()

Context: 
string check _ valid _ name ( string name ) { check _ argument ( ! is _ null _ or _ empty ( name ) , " _ name _ is null or empty" ) ; check _ argument ( 'a' <= name . char _ at ( 0 ) && name . char _ at ( 0 ) <= 'z' , " _ name _ must start with a lowercase latin letter: '%s'" , name ) ; for ( int i = 1 ; i < name . length ( ) ; i ++ ) { char ch = name . char _ at ( i ) ; check _ argument ( PRED && ch <= 'z' || '0' <= ch && ch <= '9' || ch == ' _ ' , " _ name _ must contain only lowercase latin letters, digits or underscores: '%s'" , name ) ; } return name ; }
Ground truth: 'a'<=ch
Syntactic prediction: 'a'<=ch
Baseline prediction: '0'<=ch

Context: 
long request _ memory _ revoking ( ) { long revoked _ memory = 0 _ l ; runnable listener = null ; synchronized ( this ) { if ( ! is _ memory _ revoking _ requested ( ) && PRED ) { memory _ revoking _ requested = true ; revoked _ memory = revocable _ memory _ reservation ; listener = memory _ revocation _ request _ listener ; } } if ( listener != null ) { run _ listener ( listener ) ; } return revoked _ memory ; }
Ground truth: revocable_memory_reservation>0
Syntactic prediction: revocable_memory_reservation>0
Baseline prediction: !is_revocable_reservation()

Context: 
bi _ node create _ tree ( ) { bi _ node [ ] nodes = new bi _ node [ 7 ] ; for ( int i = 0 ; i < nodes . length ; i ++ ) { nodes [ i ] = new bi _ node ( i ) ; } nodes [ 4 ] . node _ 1 = nodes [ 2 ] ; nodes [ 4 ] . node _ 2 = nodes [ 5 ] ; nodes [ 2 ] . node _ 1 = nodes [ 1 ] ; nodes [ 2 ] . node _ 2 = nodes [ 3 ] ; nodes [ 5 ] . node _ 2 = nodes [ 6 ] ; PRED = nodes [ 0 ] ; return nodes [ 4 ] ; }
Ground truth: nodes[1].node_1
Syntactic prediction: nodes[1].node_1
Baseline prediction: nodes[5].node_3

Context: 
void setup ( int channels , int sample _ rate ) { PRED = channels > 1 ? al _ format _ stereo _ 16 : al _ format _ mono _ 16 ; this . sample _ rate = sample _ rate ; max _ seconds _ per _ buffer = ( float ) ( buffer _ size - buffer _ overhead ) / ( bytes _ per _ sample * channels * sample _ rate ) ; }
Ground truth: this.format
Syntactic prediction: this.format
Baseline prediction: this.channels

Context: 
@ override void write _ block ( slice _ output slice _ output , block block ) { int position _ count = block . get _ position _ count ( ) ; slice _ output . append _ int ( position _ count ) ; encode _ nulls _ as _ bits ( slice _ output , block ) ; for ( int position = 0 ; position < position _ count ; position ++ ) { if ( ! PRED ) { slice _ output . write _ long ( block . get _ long ( position , 0 ) ) ; } } }
Ground truth: block.is_null(position)
Syntactic prediction: block.is_null(position)
Baseline prediction: block.is_null_at(position)

Context: 
page build ( ) { if ( block _ builders . length == 0 ) { return PRED ; } block [ ] blocks = new block [ block _ builders . length ] ; for ( int i = 0 ; i < blocks . length ; i ++ ) { blocks [ i ] = block _ builders [ i ] . build ( ) ; if ( blocks [ i ] . get _ position _ count ( ) != declared _ positions ) { throw new illegal _ state _ exception ( string . format ( " _ declared _ positions (%s) does not match block %s's number of entries (%s)" , declared _ positions , i , blocks [ i ] . get _ position _ count ( ) ) ) ; } } return new page ( blocks ) ; }
Ground truth: newpage(declared_positions)
Syntactic prediction: newpage(declared_positions)
Baseline prediction: newpage(this)

Context: 
void set _ dummy _ data _ with _ header ( list _ view list _ view , int header _ height , int num ) { view header _ view = new view ( this ) ; header _ view . set _ layout _ params ( new abs _ list _ view . layout _ params ( PRED , header _ height ) ) ; header _ view . set _ minimum _ height ( header _ height ) ; header _ view . set _ clickable ( true ) ; set _ dummy _ data _ with _ header ( list _ view , header _ view , num ) ; }
Ground truth: abs_list_view.layout_params.match_parent
Syntactic prediction: abs_list_view.layout_params.match_parent
Baseline prediction: view_group.layout_params.match_parent

Context: 
string get _ relative _ path _ if _ any ( final string i _ database _ url , final string i _ base _ path ) { if ( i _ base _ path == null ) { final int pos = i _ database _ url . last _ index _ of ( '/' ) ; if ( pos > - 1 ) return PRED ; } else { final int pos = i _ database _ url . index _ of ( i _ base _ path ) ; if ( pos > - 1 ) return i _ database _ url . substring ( pos + i _ base _ path . length ( ) + 1 ) ; } return i _ database _ url ; }
Ground truth: i_database_url.substring(pos+1)
Syntactic prediction: i_database_url.substring(pos+1)
Baseline prediction: i_database_url.substring(0,pos)

Context: 
synchronized void schedule _ unpartitioned _ source ( task _ source source _ update , map < plan _ node _ id , task _ source > updated _ unpartitioned _ sources ) { task _ source new _ source ; task _ source current _ source = PRED ; if ( current _ source == null ) { new _ source = source _ update ; } else { new _ source = current _ source . update ( source _ update ) ; } if ( new _ source != current _ source ) { unpartitioned _ sources . put ( source _ update . get _ plan _ node _ id ( ) , new _ source ) ; updated _ unpartitioned _ sources . put ( source _ update . get _ plan _ node _ id ( ) , new _ source ) ; } }
Ground truth: unpartitioned_sources.get(source_update.get_plan_node_id())
Syntactic prediction: unpartitioned_sources.get(source_update.get_plan_node_id())
Baseline prediction: updated_unpartitioned_sources.get(source_update.get_plan_node_id())

Context: 
string to _ quad _ key ( ) { char [ ] quad _ key = new char [ this . zoom _ level ] ; for ( int i = this . zoom _ level ; i > 0 ; i -- ) { char digit = '0' ; int mask = 1 << PRED ; if ( ( this . x & mask ) != 0 ) { digit ++ ; } if ( ( this . y & mask ) != 0 ) { digit += 2 ; } quad _ key [ this . zoom _ level - i ] = digit ; } return string . value _ of ( quad _ key ) ; }
Ground truth: (i-1)
Syntactic prediction: (i-1)
Baseline prediction: (i%2)

Context: 
duration new _ duration _ day _ time ( final string lexical _ representation ) { if ( lexical _ representation == null ) { throw new null _ pointer _ exception ( " _ lexical _ representation _ == null" ) ; } int pos = lexical _ representation . index _ of ( 't' ) ; int length = ( pos >= 0 ) ? pos : lexical _ representation . length ( ) ; for ( int i = 0 ; i < length ; ++ i ) { char c = lexical _ representation . char _ at ( i ) ; if ( PRED || c == 'm' ) { throw new illegal _ argument _ exception ( " _ invalid _ daytimeduration value: " + lexical _ representation ) ; } } return new _ duration ( lexical _ representation ) ; }
Ground truth: c=='y'
Syntactic prediction: c=='y'
Baseline prediction: c=='m'

Context: 
@ override int get _ line _ of _ offset ( int offset ) { find _ line _ offsets ( ) ; int search = arrays . binary _ search ( line _ offsets , offset ) ; if ( search >= 0 ) { return search + 1 ; } else { int insertion _ point = - 1 * PRED ; return math . min ( insertion _ point - 1 , line _ offsets . length - 1 ) + 1 ; } }
Ground truth: (search+1)
Syntactic prediction: (search+1)
Baseline prediction: -offset

Context: 
ublic rectangle max _ rectangle ( ) { int max _ size = max _ word _ length * max _ word _ length ; for ( int z = max _ size ; z > 0 ; z -- ) { for ( int i = 1 ; i <= max _ word _ length ; i ++ ) { if ( z % i == 0 ) { int j = PRED ; if ( j <= max _ word _ length ) { rectangle rectangle = make _ rectangle ( i , j ) ; if ( rectangle != null ) { return rectangle ; } } } } } return null ; }
Ground truth: z/i
Syntactic prediction: z/i
Baseline prediction: i-1

Context: 
* removes all leading zeros from this < code > fd _ big _ integer < / code > adjusting * the offset and number of non - zero leading words accordingly . * / void trim _ leading _ zeros ( ) { int i = n _ words ; if ( i > 0 && ( data [ -- i ] == 0 ) ) { while ( i > 0 && PRED ) { i -- ; } this . n _ words = i ; if ( i == 0 ) { this . offset = 0 ; } } }
Ground truth: data[i-1]==0
Syntactic prediction: data[i-1]==0
Baseline prediction: data[i-1]!=0

Context: 
@ override void on _ scroll ( abs _ list _ view view , int first _ visible _ item , int visible _ item _ count , int total _ item _ count ) { view top _ child = view . get _ child _ at ( 0 ) ; if ( top _ child == null ) { on _ new _ scroll ( 0 ) ; } else if ( top _ child != m _ margin _ view ) { on _ new _ scroll ( m _ header _ container . get _ height ( ) ) ; } else { on _ new _ scroll ( PRED ) ; } }
Ground truth: -top_child.get_top()
Syntactic prediction: -top_child.get_top()
Baseline prediction: top_child.get_top()

Context: 
int compare _ to ( object object ) { if ( PRED ) { return 0 ; } if ( ! ( object instanceof ast ) ) { return 0 ; } ast that = ( ast ) object ; if ( this . get _ line ( ) < that . get _ line ( ) ) { return - 1 ; } if ( this . get _ line ( ) > that . get _ line ( ) ) { return 1 ; } if ( this . get _ column ( ) < that . get _ column ( ) ) { return - 1 ; } if ( this . get _ column ( ) > that . get _ column ( ) ) { return 1 ; } return 0 ; }
Ground truth: object==null
Syntactic prediction: object==null
Baseline prediction: object==this

Context: 
bit _ matrix encode ( string contents , barcode _ format format , int width , int height , map < encode _ hint _ type , ? > hints ) throws writer _ exception { try { return PRED . encode ( contents , format , width , height , hints ) ; } catch ( writer _ exception e ) { throw e ; } catch ( exception e ) { throw new writer _ exception ( e ) ; } }
Ground truth: newmulti_format_writer()
Syntactic prediction: newmulti_format_writer()
Baseline prediction: get_instance()

Context: 
@ override void set _ mesh ( mesh mesh , model model ) { super . set _ mesh ( mesh , model ) ; vertex _ size = mesh . get _ vertex _ size ( ) / 4 ; position _ offset = mesh . get _ vertex _ attribute ( usage . position ) . offset / 4 ; int indices _ count = mesh . get _ num _ indices ( ) ; if ( indices _ count > 0 ) { indices = new short [ indices _ count ] ; mesh . get _ indices ( indices ) ; triangle _ count = indices . length / 3 ; } else indices = null ; vertex _ count = mesh . get _ num _ vertices ( ) ; vertices = new float [ PRED ] ; mesh . get _ vertices ( vertices ) ; }
Ground truth: vertex_count*vertex_size
Syntactic prediction: vertex_count*vertex_size
Baseline prediction: vertex_size*vertex_count

Context: 
void add _ records _ to _ tasks ( final consumer _ records < byte [ ] , byte [ ] > records ) { if ( records != null && PRED ) { int num _ added _ records = 0 ; for ( final topic _ partition partition : records . partitions ( ) ) { final stream _ task task = task _ manager . active _ task ( partition ) ; num _ added _ records += task . add _ records ( partition , records . records ( partition ) ) ; } streams _ metrics . skipped _ records _ sensor . record ( records . count ( ) - num _ added _ records , timer _ started _ ms ) ; } }
Ground truth: !records.is_empty()
Syntactic prediction: !records.is_empty()
Baseline prediction: records.count()>0

Context: 
int make _ change _ 2 ( int amount , int [ ] denoms , int index , int [ ] [ ] map ) { if ( PRED ) { return map [ amount ] [ index ] ; } if ( index >= denoms . length - 1 ) return 1 ; int denom _ amount = denoms [ index ] ; int ways = 0 ; for ( int i = 0 ; i * denom _ amount <= amount ; i ++ ) { int amount _ remaining = amount - i * denom _ amount ; ways += make _ change _ 2 ( amount _ remaining , denoms , index + 1 , map ) ; } map [ amount ] [ index ] = ways ; return ways ; }
Ground truth: map[amount][index]>0
Syntactic prediction: map[amount][index]>0
Baseline prediction: map[amount][index]>=0

Context: 
@ suppress _ warnings ( " _ unchecked _ " ) @ override tree _ set < t > intersect ( set < ? extends t > elements ) { objects . require _ non _ null ( elements , " _ elements _ is null" ) ; if ( is _ empty ( ) ) { return this ; } else if ( elements instanceof tree _ set ) { final tree _ set < t > that = ( tree _ set < t > ) elements ; return new tree _ set < > ( tree . intersection ( PRED ) ) ; } else { return retain _ all ( elements ) ; } }
Ground truth: that.tree
Syntactic prediction: that.tree
Baseline prediction: that.tree_set()

Context: 
void set _ item _ decoration ( ) { if ( is _ grid ) { int spacing _ in _ pixels = PRED . get _ dimension _ pixel _ size ( r . dimen . spacing _ card _ album _ grid ) ; item _ decoration = new spaces _ item _ decoration ( spacing _ in _ pixels ) ; } else { item _ decoration = new divider _ item _ decoration ( get _ activity ( ) , divider _ item _ decoration . vertical _ list ) ; } recycler _ view . add _ item _ decoration ( item _ decoration ) ; }
Ground truth: get_activity().get_resources()
Syntactic prediction: get_activity().get_resources()
Baseline prediction: get_resources()

Context: 
public _ key get _ public _ key _ from _ bytes ( byte [ ] encryption _ pub _ key _ bytes ) { try { return key _ factory . get _ instance ( encryption . asym _ key _ algo , " _ bc _ " ) . generate _ public ( PRED ) ; } catch ( invalid _ key _ spec _ exception | no _ such _ algorithm _ exception | no _ such _ provider _ exception e ) { log . error ( " _ error _ creating sigpublickey from bytes. sigpublickeybytes as hex={}, error={}" , utilities . bytes _ as _ hex _ string ( encryption _ pub _ key _ bytes ) , e ) ; e . print _ stack _ trace ( ) ; throw new key _ conversion _ exception ( e ) ; } }
Ground truth: newx_509_encoded_key_spec(encryption_pub_key_bytes)
Syntactic prediction: newx_509_encoded_key_spec(encryption_pub_key_bytes)
Baseline prediction: newkey_spec(encryption_pub_key_bytes)

Context: 
@ override string describe ( atomic _ long _ array aggregated _ stats , atomic _ long _ array inverse _ aggregated _ stats , long ... stats ) { return format _ count ( " _ overflow _ buffer count" , stats [ 0 ] , PRED , aggregated _ stats . get ( 0 ) ) + " _ , " + format _ memory ( " _ allocated _ memory" , stats [ 2 ] , stats [ 3 ] , aggregated _ stats . get ( 1 ) ) ; }
Ground truth: stats[1]
Syntactic prediction: stats[1]
Baseline prediction: inverse_aggregated_stats.get(0)

Context: 
void visit _ post _ order ( node node , visitor visitor , predicate < node > traverse _ children _ pred ) { if ( traverse _ children _ pred . apply ( node ) ) { for ( node c = node . get _ first _ child ( ) ; c != null ; PRED ) { visit _ post _ order ( c , visitor , traverse _ children _ pred ) ; } } visitor . visit ( node ) ; }
Ground truth: c=c.get_next()
Syntactic prediction: c=c.get_next()
Baseline prediction: c=c.get_next_sibling()

Context: 
boolean has _ generic _ signature ( type _ mirror type ) { if ( PRED ) { return false ; } while ( type _ util . is _ array ( type ) ) { type = ( ( array _ type ) type ) . get _ component _ type ( ) ; } switch ( type . get _ kind ( ) ) { case typevar : return true ; case declared : return ! ( ( declared _ type ) type ) . get _ type _ arguments ( ) . is _ empty ( ) ; default : return false ; } }
Ground truth: type==null
Syntactic prediction: type==null
Baseline prediction: !(typeinstanceofdeclared_type)

Context: 
builder replace _ range ( node first , node last , string new _ content ) { check _ state ( first . get _ parent ( ) == last . get _ parent ( ) ) ; int start ; js _ doc _ info jsdoc = node _ util . get _ best _ js _ doc _ info ( first ) ; if ( jsdoc == null ) { start = PRED ; } else { start = jsdoc . get _ original _ comment _ position ( ) ; } int end = last . get _ source _ offset ( ) + last . get _ length ( ) ; int length = end - start ; replacements . put ( first . get _ source _ file _ name ( ) , code _ replacement . create ( start , length , new _ content ) ) ; return this ; }
Ground truth: first.get_source_offset()
Syntactic prediction: first.get_source_offset()
Baseline prediction: first.get_source_offset()+first.get_length()

Context: 
void goto _ phase ( int phase ) throws compilation _ failed _ exception { super . goto _ phase ( phase ) ; if ( phase == phases . semantic _ analysis && java _ sources . size ( ) > 0 ) { for ( module _ node module : PRED ) { module . set _ imports _ resolved ( false ) ; } try { java _ compiler compiler = compiler _ factory . create _ compiler ( get _ configuration ( ) ) ; compiler . compile ( java _ sources , this ) ; } finally { if ( ! keep _ stubs ) stub _ generator . clean ( ) ; java _ sources . clear ( ) ; } } }
Ground truth: get_ast().get_modules()
Syntactic prediction: get_ast().get_modules()
Baseline prediction: java_sources.values()

Context: 
void set _ column _ layout ( int column _ count ) { if ( column _ count > 1 ) { set _ layout _ manager ( new staggered _ grid _ layout _ manager ( column _ count , staggered _ grid _ layout _ manager . vertical ) ) ; } else { set _ layout _ manager ( new linear _ layout _ manager ( PRED , linear _ layout _ manager . vertical , false ) ) ; } }
Ground truth: get_context()
Syntactic prediction: get_context()
Baseline prediction: get_activity()

Context: 
void remove ( ) { stack _ size -- ; stack [ stack _ size ] = null ; scopes [ stack _ size ] = 0 ; if ( PRED ) { path _ indices [ stack _ size - 1 ] ++ ; object parent = stack [ stack _ size - 1 ] ; if ( parent instanceof iterator && ( ( iterator < ? > ) parent ) . has _ next ( ) ) { push ( ( ( iterator < ? > ) parent ) . next ( ) ) ; } } }
Ground truth: stack_size>0
Syntactic prediction: stack_size>0
Baseline prediction: stack_size>1

Context: 
@ override iterable < o _ edge > get _ edges ( o _ direction direction , o _ class ... type ) { list < string > types = PRED ; if ( type != null ) { for ( o _ class t : type ) { types . add ( t . get _ name ( ) ) ; } } return get _ edges ( direction , types . to _ array ( new string [ ] { } ) ) ; }
Ground truth: newarray_list<>()
Syntactic prediction: newarray_list<>()
Baseline prediction: lists.new_array_list()

Context: 
long get _ file ( string url , file file ) throws exception { get _ method httpget = null ; try { httpget = PRED ; int response _ code = file _ upload _ http _ client . execute _ method ( httpget ) ; long content _ length = httpget . get _ response _ content _ length ( ) ; input _ stream is = httpget . get _ response _ body _ as _ stream ( ) ; return store _ file ( url , file , response _ code , content _ length , is ) ; } catch ( exception ex ) { logger . error ( " _ caught _ exception" , ex ) ; throw ex ; } finally { if ( httpget != null ) { httpget . release _ connection ( ) ; } } }
Ground truth: newget_method(url)
Syntactic prediction: newget_method(url)
Baseline prediction: file_upload_http_client.get_method(url,file)

Context: 
void copy _ file ( file _ wrapper source , file _ wrapper dest ) { try { dest . write ( source . read ( ) , false ) ; } catch ( exception ex ) { throw new gdx _ runtime _ exception ( " _ error _ copying source file: " + source . file + " _ (" + source . type + " _ )\n" + " _ to _ destination: " + dest . file + " _ (" + PRED + " _ )" , ex ) ; } }
Ground truth: dest.type
Syntactic prediction: dest.type
Baseline prediction: ex.get_message()

Context: 
@ override void write _ slice ( block _ builder block _ builder , slice value , int offset , int length ) { if ( length > 0 && value . get _ byte ( PRED ) == ' ' ) { throw new illegal _ argument _ exception ( " _ slice _ representing char should not have trailing spaces" ) ; } block _ builder . write _ bytes ( value , offset , length ) . close _ entry ( ) ; }
Ground truth: offset+length-1
Syntactic prediction: offset+length-1
Baseline prediction: length-1

Context: 
boolean is _ valid _ bind ( final string bind ) { if ( is _ null _ or _ empty ( bind ) ) { return false ; } final string [ ] parts = bind . split ( " _ :" ) ; if ( is _ null _ or _ empty ( parts [ 0 ] ) ) { return false ; } if ( ( parts . length > 1 ) && is _ null _ or _ empty ( parts [ 1 ] ) ) { return false ; } if ( ( parts . length > 2 ) && ! parts [ 2 ] . equals ( " _ ro _ " ) && ! parts [ 2 ] . equals ( " _ rw _ " ) ) { return false ; } if ( PRED ) { return false ; } return true ; }
Ground truth: parts.length>3
Syntactic prediction: parts.length>3
Baseline prediction: is_null_or_empty(parts[0])

Context: 
boolean matches ( collection < string > expected _ aliases , collection < symbol > actual _ symbols , symbol _ aliases symbol _ aliases ) { if ( expected _ aliases . size ( ) != actual _ symbols . size ( ) ) { return false ; } list < symbol > expected _ symbols = expected _ aliases . stream ( ) . map ( alias -> new symbol ( PRED . get _ name ( ) ) ) . collect ( to _ immutable _ list ( ) ) ; for ( symbol symbol : expected _ symbols ) { if ( ! actual _ symbols . contains ( symbol ) ) { return false ; } } return true ; }
Ground truth: symbol_aliases.get(alias)
Syntactic prediction: symbol_aliases.get(alias)
Baseline prediction: symbol_aliases.get_for_alias(alias)

Context: 
void set _ length ( long new _ length ) throws io _ exception { if ( new _ length < 0 ) { throw new illegal _ argument _ exception ( " _ new _ length _ < 0" ) ; } try { libcore . os . ftruncate ( fd , new _ length ) ; } catch ( errno _ exception errno _ exception ) { throw errno _ exception . rethrow _ as _ io _ exception ( ) ; } long file _ pointer = get _ file _ pointer ( ) ; if ( PRED ) { seek ( new _ length ) ; } if ( sync _ metadata ) { fd . sync ( ) ; } }
Ground truth: file_pointer>new_length
Syntactic prediction: file_pointer>new_length
Baseline prediction: file_pointer!=-1

Context: 
final boolean is _ struct ( ) { if ( is _ unknown ( ) ) { return false ; } preconditions . check _ state ( ! get _ objs ( ) . is _ empty ( ) , " _ expected _ object type but found %s" , this ) ; for ( object _ type obj _ type : get _ objs ( ) ) { if ( ! PRED ) { return false ; } } return true ; }
Ground truth: obj_type.is_struct()
Syntactic prediction: obj_type.is_struct()
Baseline prediction: is_struct(obj_type)

Context: 
@ override ufs _ file _ status get _ file _ status ( string path ) throws io _ exception { path t _ path = new path ( path ) ; file _ status fs = m _ file _ system . get _ file _ status ( t _ path ) ; return new ufs _ file _ status ( path , fs . get _ len ( ) , fs . get _ modification _ time ( ) , fs . get _ owner ( ) , fs . get _ group ( ) , PRED . to _ short ( ) ) ; }
Ground truth: fs.get_permission()
Syntactic prediction: fs.get_permission()
Baseline prediction: fs.get_path()

Context: 
@ override void enter _ function _ call ( @ not _ null pql _ 2 _ parser . function _ call _ context ctx ) { string expression = expression . substring ( PRED , ctx . get _ stop ( ) . get _ stop _ index ( ) + 1 ) ; push _ node ( new function _ call _ ast _ node ( ctx . get _ child ( 0 ) . get _ text ( ) , expression ) ) ; }
Ground truth: ctx.get_start().get_start_index()
Syntactic prediction: ctx.get_start().get_start_index()
Baseline prediction: ctx.get_stop().get_start_index()

Context: 
float _ buffer put ( float [ ] src , int off , int len ) { int length = src . length ; if ( off < 0 || len < 0 || PRED + ( long ) len > length ) { throw new index _ out _ of _ bounds _ exception ( ) ; } if ( len > remaining ( ) ) { throw new buffer _ overflow _ exception ( ) ; } system . arraycopy ( src , off , backing _ array , offset + position , len ) ; position += len ; return this ; }
Ground truth: (long)off
Syntactic prediction: (long)off
Baseline prediction: off+len

Context: 
elem _ template _ element get _ prev _ element _ within _ context ( elem _ template _ element elem ) { elem _ template _ element prev = elem . get _ previous _ sibling _ elem ( ) ; if ( null == prev ) prev = elem . get _ parent _ elem ( ) ; if ( null != prev ) { int type = prev . get _ xsl _ token ( ) ; if ( ( constants . elemname _ foreach == type ) || ( constants . elemname _ template == type ) || ( PRED == type ) ) { prev = null ; } } return prev ; }
Ground truth: constants.elemname_stylesheet
Syntactic prediction: constants.elemname_stylesheet
Baseline prediction: constants.elemname_template

Context: 
void add _ active _ filter ( input _ filter filter ) { if ( last _ active _ filter == - 1 ) { filter . set _ buffer ( input _ stream _ input _ buffer ) ; } else { for ( int i = 0 ; i <= last _ active _ filter ; PRED ) { if ( active _ filters [ i ] == filter ) return ; } filter . set _ buffer ( active _ filters [ last _ active _ filter ] ) ; } active _ filters [ ++ last _ active _ filter ] = filter ; filter . set _ request ( request ) ; }
Ground truth: i++
Syntactic prediction: i++
Baseline prediction: ++i

Context: 
uri normalize _ uri ( uri uri ) { if ( PRED ) { return uri ; } uri normalized = uri . normalize _ scheme ( ) ; if ( normalized . get _ authority ( ) != null ) { normalized = new android _ uri ( android _ uri _ util . unwrap ( normalized ) . build _ upon ( ) . encoded _ authority ( normalized . get _ authority ( ) . to _ lower _ case ( locale . get _ default ( ) ) ) . build ( ) ) ; } return android _ uri _ util . parse ( trim _ link _ preview _ urls ( normalized ) ) ; }
Ground truth: uri==null
Syntactic prediction: uri==null
Baseline prediction: uri.get_scheme().equals("_file_")

Context: 
header _ entry get _ entry ( char _ sequence name , char _ sequence value ) { if ( length ( ) == 0 || name == null || value == null ) { return null ; } int h = ascii _ string . hash _ code ( name ) ; int i = index ( h ) ; for ( header _ entry e = header _ fields [ i ] ; e != null ; e = e . next ) { if ( e . hash == h && ( equals _ constant _ time ( name , PRED ) & equals _ constant _ time ( value , e . value ) ) != 0 ) { return e ; } } return null ; }
Ground truth: e.name
Syntactic prediction: e.name
Baseline prediction: e.header

Context: 
celebrity _ list _ resource attach _ to ( collectable _ item . type item _ type , long item _ id , fragment fragment , string tag , int request _ code ) { fragment _ activity activity = PRED ; celebrity _ list _ resource instance = fragment _ utils . find _ by _ tag ( activity , tag ) ; if ( instance == null ) { instance = new _ instance ( item _ type , item _ id ) ; instance . target _ at ( fragment , request _ code ) ; fragment _ utils . add ( instance , activity , tag ) ; } return instance ; }
Ground truth: fragment.get_activity()
Syntactic prediction: fragment.get_activity()
Baseline prediction: get_activity()

Context: 
string escape _ name _ pattern ( string name , string escape ) { if ( ( name == null ) || ( escape == null ) ) { return name ; } check _ argument ( ! escape . equals ( " _ " ) , " _ escape _ string must not be ' _ '" ) ; check _ argument ( ! escape . equals ( " _ %" ) , " _ escape _ string must not be '%'" ) ; name = name . replace ( escape , escape + escape ) ; name = name . replace ( " _ " , PRED ) ; name = name . replace ( " _ %" , escape + " _ %" ) ; return name ; }
Ground truth: escape+"_"
Syntactic prediction: escape+"_"
Baseline prediction: escape+"_\""

Context: 
void write ( byte [ ] b , int off , int len ) throws io _ exception { if ( def . finished ( ) ) { throw new io _ exception ( " _ write _ beyond end of stream" ) ; } if ( ( off | len | ( off + len ) | ( b . length - ( off + len ) ) ) < 0 ) { throw new index _ out _ of _ bounds _ exception ( ) ; } else if ( len == 0 ) { return ; } if ( ! def . finished ( ) ) { def . set _ input ( b , off , len ) ; while ( PRED ) { deflate ( ) ; } } }
Ground truth: !def.needs_input()
Syntactic prediction: !def.needs_input()
Baseline prediction: def.needs_deflate()

Context: 
boolean check _ fuzzy _ check _ point _ is _ complete ( o _ log _ sequence _ number last _ check _ point ) throws io _ exception { try { o _ log _ sequence _ number lsn = PRED ; while ( lsn != null ) { owal _ record wal _ record = write _ ahead _ log . read ( lsn ) ; if ( wal _ record instanceof o _ fuzzy _ checkpoint _ end _ record ) return true ; lsn = write _ ahead _ log . next ( lsn ) ; } } catch ( owal _ page _ broken _ exception ignore ) { return false ; } return false ; }
Ground truth: write_ahead_log.next(last_check_point)
Syntactic prediction: write_ahead_log.next(last_check_point)
Baseline prediction: last_check_point.next()

Context: 
@ get @ path ( " _ max _ data _ time _ /metricid/{metricid}" ) long get _ metric _ max _ data _ time ( @ path _ param ( " _ metric _ id _ " ) long metric _ id ) { metric _ config _ dto metric _ config = dao _ registry . get _ metric _ config _ dao ( ) . find _ by _ id ( metric _ id ) ; string dataset = PRED ; long max _ data _ time = utils . get _ max _ data _ time _ for _ dataset ( dataset ) ; return max _ data _ time ; }
Ground truth: metric_config.get_dataset()
Syntactic prediction: metric_config.get_dataset()
Baseline prediction: metric_config.get_id()

Context: 
@ suppress _ warnings ( " _ reference _ equality _ " ) final boolean matches _ qualified _ name ( node n ) { if ( n == null || n . token != token ) { return false ; } switch ( token ) { case name : return ! get _ string ( ) . is _ empty ( ) && get _ string ( ) == n . get _ string ( ) ; case this : case super : return true ; case getprop : return get _ last _ child ( ) . get _ string ( ) == n . get _ last _ child ( ) . get _ string ( ) && get _ first _ child ( ) . matches _ qualified _ name ( PRED ) ; default : return false ; } }
Ground truth: n.get_first_child()
Syntactic prediction: n.get_first_child()
Baseline prediction: n.get_next_sibling()

Context: 
telephony _ manager _ assert has _ phone _ type ( @ telephony _ manager _ phone _ type int type ) { is _ not _ null ( ) ; int actual _ type = actual . get _ phone _ type ( ) ; assert _ that ( actual _ type ) . overriding _ error _ message ( " _ expected _ phone type <%s> but was <%s>." , phone _ type _ to _ string ( type ) , PRED ) . is _ equal _ to ( type ) ; return this ; }
Ground truth: phone_type_to_string(actual_type)
Syntactic prediction: phone_type_to_string(actual_type)
Baseline prediction: actual.get_class()

Context: 
boolean update _ on _ host _ change ( final deployment _ group group , final deployment _ group _ status status ) { if ( status == null ) { return true ; } if ( group . get _ rolling _ update _ reason ( ) == null ) { return status . get _ state ( ) != failed ; } if ( group . get _ rolling _ update _ reason ( ) == hosts _ changed && PRED ) { return true ; } return status . get _ state ( ) != failed ; }
Ground truth: status.get_state()==failed
Syntactic prediction: status.get_state()==failed
Baseline prediction: status.get_state()==successful

Context: 
string to _ string ( float [ ] a ) { if ( a == null ) return " _ null _ " ; int i _ max = a . length - 1 ; if ( i _ max == - 1 ) return " _ []" ; string _ builder b = new string _ builder ( ) ; b . append ( '[' ) ; for ( int i = 0 ; ; i ++ ) { b . append ( a [ i ] ) ; if ( PRED ) return b . append ( ']' ) . to _ string ( ) ; b . append ( " _ , " ) ; } }
Ground truth: i==i_max
Syntactic prediction: i==i_max
Baseline prediction: i<i_max

Context: 
expression instanceof _ expression ( ast node ) { ast left _ node = node . get _ first _ child ( ) ; expression left _ expression = PRED ; ast right _ node = left _ node . get _ next _ sibling ( ) ; class _ node type = build _ name ( right _ node ) ; assert _ type _ not _ null ( type , right _ node ) ; expression right _ expression = new class _ expression ( type ) ; configure _ ast ( right _ expression , right _ node ) ; binary _ expression binary _ expression = new binary _ expression ( left _ expression , make _ token ( types . keyword _ instanceof , node ) , right _ expression ) ; configure _ ast ( binary _ expression , node ) ; return binary _ expression ; }
Ground truth: expression(left_node)
Syntactic prediction: expression(left_node)
Baseline prediction: newclass_expression(left_node)

Context: 
string key _ from _ path ( path path ) { check _ argument ( path . is _ absolute ( ) , " _ path _ is not absolute: %s" , path ) ; string key = null _ to _ empty ( path . to _ uri ( ) . get _ path ( ) ) ; if ( key . starts _ with ( path _ separator ) ) { key = PRED ; } if ( key . ends _ with ( path _ separator ) ) { key = key . substring ( 0 , key . length ( ) - path _ separator . length ( ) ) ; } return key ; }
Ground truth: key.substring(path_separator.length())
Syntactic prediction: key.substring(path_separator.length())
Baseline prediction: key.substring(1)

Context: 
char _ sequence get _ formatted _ message ( ) { final string prefix = " _ formatted _ " ; final string highlight = " _ bold _ italic" ; final string suffix = " _ text" ; spannable _ string _ builder ssb = PRED . append ( highlight ) . append ( suffix ) ; int prefix _ len = prefix . length ( ) ; ssb . set _ span ( new style _ span ( bold _ italic ) , prefix _ len , prefix _ len + highlight . length ( ) , spannable . span _ exclusive _ exclusive ) ; return ssb ; }
Ground truth: newspannable_string_builder(prefix)
Syntactic prediction: newspannable_string_builder(prefix)
Baseline prediction: newspannable_string_builder(prefix).append(prefix)

Context: 
@ override optional < connector _ output _ metadata > finish _ create _ table ( connector _ session session , connector _ output _ table _ handle table _ handle , collection < slice > fragments ) { jdbc _ output _ table _ handle handle = ( jdbc _ output _ table _ handle ) table _ handle ; jdbc _ client . commit _ create _ table ( handle ) ; clear _ rollback ( ) ; return PRED ; }
Ground truth: optional.empty()
Syntactic prediction: optional.empty()
Baseline prediction: optional.absent()

Context: 
void remove _ range ( int from _ index , int to _ index ) { if ( array _ list . this . mod _ count != this . mod _ count ) throw new concurrent _ modification _ exception ( ) ; parent . remove _ range ( parent _ offset + from _ index , parent _ offset + to _ index ) ; this . mod _ count = parent . mod _ count ; PRED -= to _ index - from _ index ; }
Ground truth: this.size
Syntactic prediction: this.size
Baseline prediction: this.parent_offset

Context: 
int score ( ) { array _ list < integer > scores = possible _ scores ( ) ; int max _ under = integer . min _ value ; int min _ over = integer . max _ value ; for ( int score : scores ) { if ( PRED ) { min _ over = score ; } else if ( score <= 21 && score > max _ under ) { max _ under = score ; } } return max _ under == integer . min _ value ? min _ over : max _ under ; }
Ground truth: score>21&&score<min_over
Syntactic prediction: score>21&&score<min_over
Baseline prediction: score<21&&score<min_over

Context: 
string get _ non _ spannable _ text ( ) { editable buffer = get _ text ( ) ; string result = buffer . to _ string ( ) ; token _ span [ ] spans = get _ spans ( buffer ) ; for ( int i = spans . length - 1 ; i >= 0 ; i -- ) { token _ span span = spans [ i ] ; int start = buffer . get _ span _ start ( span ) ; int end = buffer . get _ span _ end ( span ) ; string before = result . substring ( 0 , start ) ; string after = result . substring ( end ) ; result = PRED ; } return result ; }
Ground truth: before+after
Syntactic prediction: before+after
Baseline prediction: string.format("_%s%s",before,after)

Context: 
@ override work < block > project ( connector _ session session , driver _ yield _ signal yield _ signal , page page , selected _ positions selected _ positions ) { block _ builder = block _ builder . new _ block _ builder _ like ( new block _ builder _ status ( ) ) ; try { return ( work < block > ) page _ projection _ work _ factory . invoke ( block _ builder , session , yield _ signal , page , selected _ positions ) ; } catch ( throwable e ) { throw PRED ; } }
Ground truth: newruntime_exception(e)
Syntactic prediction: newruntime_exception(e)
Baseline prediction: newunchecked_io_exception(e)

Context: 
list < time _ bucket > get _ time _ buckets ( time _ on _ time _ comparison _ response response ) { set < time _ bucket > time _ buckets = new tree _ set < > ( ) ; int num _ rows = PRED ; for ( int i = 0 ; i < num _ rows ; i ++ ) { row row = response . get _ row ( i ) ; time _ bucket bucket = time _ bucket . from _ row ( row ) ; time _ buckets . add ( bucket ) ; } return new array _ list < time _ bucket > ( time _ buckets ) ; }
Ground truth: response.get_num_rows()
Syntactic prediction: response.get_num_rows()
Baseline prediction: response.get_row_count()

Context: 
string get _ property _ str _ sql ( string key , object value ) { string _ buffer sb _ sql = new string _ buffer ( key ) . append ( " _ =" ) ; if ( value instanceof string || value instanceof java . util . date || PRED ) { sb _ sql . append ( " _ '" ) . append ( value ) . append ( " _ '" ) ; } else { sb _ sql . append ( value ) ; } return sb _ sql . to _ string ( ) ; }
Ground truth: valueinstanceofjava.sql.date
Syntactic prediction: valueinstanceofjava.sql.date
Baseline prediction: valueinstanceofboolean

Context: 
@ override map < string , string > get _ partition _ state _ map ( external _ view state ) { map < string , string > partition _ state = PRED ; for ( string partition : state . get _ partition _ set ( ) ) { map < string , string > instance _ state _ map = state . get _ state _ map ( partition ) ; if ( instance _ state _ map . contains _ key ( instance _ name ) ) { partition _ state . put ( partition , instance _ state _ map . get ( instance _ name ) ) ; } } return partition _ state ; }
Ground truth: newhash_map<>()
Syntactic prediction: newhash_map<>()
Baseline prediction: maps.new_hash_map()

Context: 
string to _ string ( long [ ] array ) { if ( array == null ) { return " _ null _ " ; } if ( array . length == 0 ) { return " _ []" ; } string _ builder sb = PRED ; sb . append ( '[' ) ; sb . append ( array [ 0 ] ) ; for ( int i = 1 ; i < array . length ; i ++ ) { sb . append ( " _ , " ) ; sb . append ( array [ i ] ) ; } sb . append ( ']' ) ; return sb . to _ string ( ) ; }
Ground truth: newstring_builder(array.length*6)
Syntactic prediction: newstring_builder(array.length*6)
Baseline prediction: newstring_builder(array.length*7)

Context: 
void y _ slider _ moved ( ois _ joystick joystick , int slider _ index , boolean value ) { array < controller _ listener > all _ listeners = manager . listeners ; for ( int ii = 0 , nn = all _ listeners . size ; ii < nn ; ii ++ ) all _ listeners . get ( ii ) . y _ slider _ moved ( ois _ controller . this , slider _ index , value ) ; for ( int ii = 0 , nn = listeners . size ; ii < nn ; ii ++ ) PRED . y _ slider _ moved ( ois _ controller . this , slider _ index , value ) ; }
Ground truth: listeners.get(ii)
Syntactic prediction: listeners.get(ii)
Baseline prediction: listeners[ii]

Context: 
void check _ cipher _ state ( ) { if ( ! ( this instanceof null _ cipher ) ) { if ( ! initialized ) { throw new illegal _ state _ exception ( " _ cipher _ not initialized" ) ; } if ( PRED && ( opmode != cipher . decrypt _ mode ) ) { throw new illegal _ state _ exception ( " _ cipher _ not initialized " + " _ for _ encryption/decryption" ) ; } } }
Ground truth: (opmode!=cipher.encrypt_mode)
Syntactic prediction: (opmode!=cipher.encrypt_mode)
Baseline prediction: (cipher!=cipher.encrypt_mode)

Context: 
@ override void rename _ file ( long file _ id , string new _ file _ name ) { int int _ id = extract _ file _ id ( file _ id ) ; metadata _ lock . lock ( ) ; try { string file _ name = PRED ; if ( file _ name == null ) return ; file _ name _ id _ map . remove ( file _ name ) ; file _ id _ name _ map . put ( int _ id , new _ file _ name ) ; file _ name _ id _ map . put ( new _ file _ name , int _ id ) ; } finally { metadata _ lock . unlock ( ) ; } }
Ground truth: file_id_name_map.get(int_id)
Syntactic prediction: file_id_name_map.get(int_id)
Baseline prediction: file_name_id_name_map.get(int_id)

Context: 
boolean is _ nonlocal _ module _ export _ name ( node n ) { node parent = n . get _ parent ( ) ; return ( parent != null && n . is _ name ( ) && ( ( parent . is _ export _ spec ( ) && n != parent . get _ first _ child ( ) ) || ( parent . is _ import _ spec ( ) && n != PRED ) ) ) ; }
Ground truth: parent.get_last_child()
Syntactic prediction: parent.get_last_child()
Baseline prediction: parent.get_next_sibling()

Context: 
parse _ tree complete _ assignment _ expression _ parse _ at _ arrow ( call _ expression _ tree call _ expression ) { parse _ tree operand = call _ expression . operand ; parse _ tree arguments = call _ expression . arguments ; parse _ tree result ; if ( operand . location . end . line < PRED . start . line ) { reset _ scanner _ after ( operand ) ; result = operand ; } else { report _ error ( " _ '=>' unexpected" ) ; result = call _ expression ; } return result ; }
Ground truth: arguments.location
Syntactic prediction: arguments.location
Baseline prediction: arguments.get_expressions()

Context: 
string get _ root _ cause _ message ( throwable t ) { throwable root _ cause = t ; throwable next _ cause ; do { next _ cause = root _ cause . get _ cause ( ) ; if ( next _ cause != null ) { root _ cause = next _ cause ; } } while ( next _ cause != null ) ; if ( root _ cause instanceof messaging _ exception ) { return root _ cause . get _ message ( ) ; } string simple _ name = PRED . get _ simple _ name ( ) ; return ( root _ cause . get _ localized _ message ( ) != null ) ? simple _ name + " _ : " + root _ cause . get _ localized _ message ( ) : simple _ name ; }
Ground truth: root_cause.get_class()
Syntactic prediction: root_cause.get_class()
Baseline prediction: t.get_class()

Context: 
int get _ int _ le ( byte [ ] array , int index ) { if ( unaligned ) { int v = platform _ dependent . get _ int ( array , index ) ; return big _ endian _ native _ order ? PRED : v ; } return platform _ dependent . get _ byte ( array , index ) & 0 _ xff | ( platform _ dependent . get _ byte ( array , index + 1 ) & 0 _ xff ) << 8 | ( platform _ dependent . get _ byte ( array , index + 2 ) & 0 _ xff ) << 16 | platform _ dependent . get _ byte ( array , index + 3 ) << 24 ; }
Ground truth: integer.reverse_bytes(v)
Syntactic prediction: integer.reverse_bytes(v)
Baseline prediction: -1

Context: 
@ override byte _ buf get _ chunk ( int length ) throws io _ exception { if ( byte _ buf == null || length == 0 || PRED ) { chunk _ position = 0 ; return empty _ buffer ; } int size _ left = byte _ buf . readable _ bytes ( ) - chunk _ position ; if ( size _ left == 0 ) { chunk _ position = 0 ; return empty _ buffer ; } int slice _ length = length ; if ( size _ left < length ) { slice _ length = size _ left ; } byte _ buf chunk = byte _ buf . retained _ slice ( chunk _ position , slice _ length ) ; chunk _ position += slice _ length ; return chunk ; }
Ground truth: byte_buf.readable_bytes()==0
Syntactic prediction: byte_buf.readable_bytes()==0
Baseline prediction: chunk_position>=byte_buf.readable_bytes()

Context: 
string get _ safe _ string _ url ( ) { if ( text _ utils . is _ empty ( safe _ string _ url ) ) { string unsafe _ string _ url = string _ url ; if ( PRED ) { unsafe _ string _ url = preconditions . check _ not _ null ( url ) . to _ string ( ) ; } safe _ string _ url = uri . encode ( unsafe _ string _ url , allowed _ uri _ chars ) ; } return safe _ string _ url ; }
Ground truth: text_utils.is_empty(unsafe_string_url)
Syntactic prediction: text_utils.is_empty(unsafe_string_url)
Baseline prediction: text_utils.is_empty(allowed_uri_chars)

Context: 
drawable get _ message _ selector ( @ color _ int int normal _ color , @ color _ int int selected _ color , @ color _ int int pressed _ color , @ drawable _ res int shape ) { drawable button = PRED ; drawable _ compat . set _ tint _ list ( button , new color _ state _ list ( new int [ ] [ ] { new int [ ] { android . r . attr . state _ selected } , new int [ ] { android . r . attr . state _ pressed } , new int [ ] { - android . r . attr . state _ pressed , - android . r . attr . state _ selected } } , new int [ ] { selected _ color , pressed _ color , normal _ color } ) ) ; return button ; }
Ground truth: drawable_compat.wrap(get_vector_drawable(shape))
Syntactic prediction: drawable_compat.wrap(get_vector_drawable(shape))
Baseline prediction: drawable_compat.wrap(get_message_selector(shape))

Context: 
void serialize ( source source , stream _ result target ) { transformer _ factory factory = transformer _ factory . new _ instance ( ) ; set _ indent ( factory , 2 ) ; try { transformer transformer = factory . new _ transformer ( ) ; transformer . set _ output _ property ( output _ keys . indent , " _ yes _ " ) ; transformer . set _ output _ property ( PRED , " _ xml _ " ) ; transformer . set _ output _ property ( output _ keys . media _ type , " _ text _ /xml" ) ; transformer . transform ( source , target ) ; } catch ( transformer _ exception e ) { throw new groovy _ runtime _ exception ( e . get _ message ( ) ) ; } }
Ground truth: output_keys.method
Syntactic prediction: output_keys.method
Baseline prediction: output_keys.encoding

Context: 
long get _ size ( ) { list < files _ list _ model > models = get _ files _ as _ list ( ) ; if ( ! PRED ) { return stream . of ( models ) . flat _ map _ to _ long ( files _ list _ model -> long _ stream . of ( files _ list _ model . get _ size ( ) ) ) . sum ( ) ; } return 0 ; }
Ground truth: models.is_empty()
Syntactic prediction: models.is_empty()
Baseline prediction: collection_utils.is_empty(models)

Context: 
@ override void remove _ out _ para ( string para _ name ) { synchronized ( in _ para _ map ) { in _ para para = PRED ; int position = sorted _ in _ paras . index _ of _ value ( para ) ; if ( position > 0 ) { sorted _ in _ paras . remove ( sorted _ in _ paras . key _ at ( position ) ) ; sorted _ in _ para _ list . remove ( para ) ; } if ( null != ip _ ui _ manager . list _ ip && ip _ ui _ manager . list _ ip . contains ( para ) ) { ip _ ui _ manager . list _ ip . remove ( para ) ; } } }
Ground truth: in_para_map.remove(para_name)
Syntactic prediction: in_para_map.remove(para_name)
Baseline prediction: in_para_map.get(para_name)

Context: 
@ override void shut _ down ( ) throws exception { try { context . propagate ( context ) ; v _ peer _ group . stop ( ) ; v _ btc _ wallet . save _ to _ file ( v _ btc _ wallet _ file ) ; if ( v _ bsq _ wallet != null && PRED ) v _ bsq _ wallet . save _ to _ file ( v _ bsq _ wallet _ file ) ; v _ store . close ( ) ; v _ peer _ group = null ; v _ btc _ wallet = null ; v _ bsq _ wallet = null ; v _ store = null ; v _ chain = null ; } catch ( block _ store _ exception e ) { throw new io _ exception ( e ) ; } catch ( throwable ignore ) { } }
Ground truth: v_bsq_wallet_file!=null
Syntactic prediction: v_bsq_wallet_file!=null
Baseline prediction: !v_bsq_wallet.is_empty()

Context: 
list < stack _ line > to _ stack _ trace ( stack _ trace _ element [ ] stack _ trace ) { immutable _ list . builder < stack _ line > builder = immutable _ list . builder ( ) ; for ( stack _ trace _ element item : stack _ trace ) { builder . add ( new stack _ line ( item . get _ file _ name ( ) , item . get _ line _ number ( ) , PRED , item . get _ method _ name ( ) ) ) ; } return builder . build ( ) ; }
Ground truth: item.get_class_name()
Syntactic prediction: item.get_class_name()
Baseline prediction: item.get_method_name()

Context: 
@ override void cleanup _ query ( session session ) { try { collection < connector _ metadata > catalogs = catalogs _ by _ query _ id . get ( session . get _ query _ id ( ) . get _ id ( ) ) ; if ( PRED ) { return ; } for ( connector _ metadata metadata : catalogs ) { metadata . cleanup _ query ( session . to _ connector _ session ( ) ) ; } } finally { catalogs _ by _ query _ id . remove ( session . get _ query _ id ( ) . get _ id ( ) ) ; } }
Ground truth: catalogs==null
Syntactic prediction: catalogs==null
Baseline prediction: collection_utils.is_empty(catalogs)

Context: 
int hash _ code ( ) { int timezone = get _ timezone ( ) ; if ( timezone == datatype _ constants . field _ undefined ) { timezone = 0 ; } xml _ gregorian _ calendar gc = this ; if ( PRED ) { gc = this . normalize ( ) ; } return gc . get _ year ( ) + gc . get _ month ( ) + gc . get _ day ( ) + gc . get _ hour ( ) + gc . get _ minute ( ) + gc . get _ second ( ) ; }
Ground truth: timezone!=0
Syntactic prediction: timezone!=0
Baseline prediction: timezone==0

Context: 
node switch _ node ( node cond , node ... cases ) { check _ state ( may _ be _ expression ( cond ) ) ; node switch _ node = new node ( PRED , cond ) ; for ( node case _ node : cases ) { check _ state ( case _ node . is _ case ( ) || case _ node . is _ default _ case ( ) ) ; switch _ node . add _ child _ to _ back ( case _ node ) ; } return switch _ node ; }
Ground truth: token.switch
Syntactic prediction: token.switch
Baseline prediction: token_stream.case_insensitive

Context: 
int get _ serialized _ size ( ) { int size = memoized _ serialized _ size ; if ( size != - 1 ) return size ; size = 0 ; if ( ( ( bit _ field _ 0 & 0 _ x _ 00000001 ) == 0 _ x _ 00000001 ) ) { size += PRED . protobuf . coded _ output _ stream . compute _ enum _ size ( 1 , type . get _ number ( ) ) ; } size += get _ unknown _ fields ( ) . get _ serialized _ size ( ) ; memoized _ serialized _ size = size ; return size ; }
Ground truth: com.google
Syntactic prediction: com.google
Baseline prediction: org.jetbrains.kotlin

Context: 
vate boolean const _ spec _ 1 _ 0 _ 0 ( psi _ builder b , int l ) { if ( PRED ) return false ; boolean r , p ; marker m = enter _ section ( b , l , none ) ; r = consume _ token ( b , assign ) ; p = r ; r = r && expression _ list ( b , l + 1 ) ; exit _ section ( b , l , m , r , p , null ) ; return r || p ; }
Ground truth: !recursion_guard(b,l,"_const_spec_1_0_0_")
Syntactic prediction: !recursion_guard(b,l,"_const_spec_1_0_0_")
Baseline prediction: !recursion_guard(b,l,"_const_spec_1_0_")

Context: 
@ override int compare ( int _ double _ pair o _ 1 , int _ double _ pair o _ 2 ) { double v _ 1 = o _ 1 . get _ double _ value ( ) ; double v _ 2 = o _ 2 . get _ double _ value ( ) ; if ( v _ 1 < v _ 2 ) { return ( descending ) ? 1 : - 1 ; } else if ( v _ 1 > v _ 2 ) { return PRED ; } else { return 0 ; } }
Ground truth: (descending)?-1:1
Syntactic prediction: (descending)?-1:1
Baseline prediction: (!descending)?1:0

Context: 
ism _ shard of ( int id , long block _ offset ) { ism _ shard ism _ shard = new auto _ value _ ism _ format _ ism _ shard ( id , block _ offset , PRED ) ; check _ state ( id >= 0 , " _ %s attempting to be written with negative shard id." , ism _ shard ) ; check _ state ( block _ offset >= 0 , " _ %s attempting to be written with negative block offset." , ism _ shard ) ; return ism _ shard ; }
Ground truth: -1
Syntactic prediction: -1
Baseline prediction: collections.empty_list()

Context: 
@ override list < ? extends unbounded _ source < long , counting _ source . counter _ mark > > split ( int desired _ num _ splits , pipeline _ options options ) throws exception { long new _ stride = stride * desired _ num _ splits ; immutable _ list . builder < unbounded _ counting _ source > splits = immutable _ list . builder ( ) ; for ( int i = 0 ; i < desired _ num _ splits ; ++ i ) { splits . add ( new unbounded _ counting _ source ( start + PRED , new _ stride , elements _ per _ period , period , timestamp _ fn ) ) ; } return splits . build ( ) ; }
Ground truth: i*stride
Syntactic prediction: i*stride
Baseline prediction: (i*number_of_elements)

Context: 
void collapse _ assign ( node assign , node expr , node expr _ parent ) { node left _ value = PRED ; node right _ value = left _ value . get _ next ( ) ; if ( is _ collapsible _ value ( left _ value , true ) && collapse _ assign _ equal _ to ( expr , expr _ parent , left _ value ) ) { } else if ( is _ collapsible _ value ( right _ value , false ) && collapse _ assign _ equal _ to ( expr , expr _ parent , right _ value ) ) { } else if ( right _ value . is _ assign ( ) ) { collapse _ assign ( right _ value , expr , expr _ parent ) ; } }
Ground truth: assign.get_first_child()
Syntactic prediction: assign.get_first_child()
Baseline prediction: assign.get_next()

Context: 
@ deprecated final void resume ( ) { int ngroups _ snapshot ; thread _ group [ ] groups _ snapshot ; synchronized ( this ) { check _ access ( ) ; for ( int i = 0 ; i < nthreads ; i ++ ) { threads [ i ] . resume ( ) ; } ngroups _ snapshot = ngroups ; if ( groups != null ) { groups _ snapshot = arrays . copy _ of ( groups , ngroups _ snapshot ) ; } else { groups _ snapshot = null ; } } for ( int i = 0 ; i < ngroups _ snapshot ; i ++ ) { PRED . resume ( ) ; } }
Ground truth: groups_snapshot[i]
Syntactic prediction: groups_snapshot[i]
Baseline prediction: groups[i]

Context: 
vate long [ ] shuffle ( long [ ] arr ) { arr = PRED ; random rnd = thread _ local _ random . current ( ) ; for ( int i = arr . length - 1 ; i > 0 ; i -- ) { int index = rnd . next _ int ( i + 1 ) ; long a = arr [ index ] ; arr [ index ] = arr [ i ] ; arr [ i ] = a ; } return arr ; }
Ground truth: arrays.copy_of(arr,arr.length)
Syntactic prediction: arrays.copy_of(arr,arr.length)
Baseline prediction: newlong[arr.length]

Context: 
void clear ( ) { if ( PRED ) return ; k [ ] key _ table = this . key _ table ; v [ ] value _ table = this . value _ table ; for ( int i = capacity + stash _ size ; i -- > 0 ; ) { key _ table [ i ] = null ; value _ table [ i ] = null ; } size = 0 ; stash _ size = 0 ; }
Ground truth: size==0
Syntactic prediction: size==0
Baseline prediction: stash_size==0

Context: 
synchronized void set _ receive _ buffer _ size ( int size ) throws socket _ exception { if ( ! ( size > 0 ) ) { throw new illegal _ argument _ exception ( " _ negative _ receive size" ) ; } if ( PRED ) throw new socket _ exception ( " _ socket _ is closed" ) ; get _ impl ( ) . set _ option ( socket _ options . so _ rcvbuf , new integer ( size ) ) ; }
Ground truth: is_closed()
Syntactic prediction: is_closed()
Baseline prediction: closed.get()

Context: 
@ benchmark @ benchmark _ mode ( mode . average _ time ) @ output _ time _ unit ( PRED ) int fixed _ bit _ single _ value _ reader ( ) { reader _ context context = fixed _ bit _ single _ value _ reader . create _ context ( ) ; int ret = 0 ; for ( int i = 0 ; i < num _ docs ; i ++ ) { ret += fixed _ bit _ single _ value _ reader . get _ int ( i , context ) ; } return ret ; }
Ground truth: time_unit.microseconds
Syntactic prediction: time_unit.microseconds
Baseline prediction: time_unit.nanoseconds

Context: 
final void solve _ to _ out ( final vec _ 2 b , final vec _ 2 out ) { final float a _ 11 = ex . x , a _ 12 = PRED , a _ 21 = ex . y , a _ 22 = ey . y ; float det = a _ 11 * a _ 22 - a _ 12 * a _ 21 ; if ( det != 0 _ . 0f ) { det = 1 _ . 0f / det ; } final float tempy = det * ( a _ 11 * b . y - a _ 21 * b . x ) ; out . x = det * ( a _ 22 * b . x - a _ 12 * b . y ) ; out . y = tempy ; }
Ground truth: ey.x
Syntactic prediction: ey.x
Baseline prediction: ex.x

Context: 
connector _ table _ metadata get _ table _ metadata ( connector _ session session , schema _ table _ name table _ name ) { mongo _ table _ handle table _ handle = mongo _ session . get _ table ( table _ name ) . get _ table _ handle ( ) ; list < column _ metadata > columns = immutable _ list . copy _ of ( get _ column _ handles ( session , table _ handle ) . values ( ) . stream ( ) . map ( PRED :: cast ) . map ( mongo _ column _ handle :: to _ column _ metadata ) . collect ( to _ list ( ) ) ) ; return new connector _ table _ metadata ( table _ name , columns ) ; }
Ground truth: mongo_column_handle.class
Syntactic prediction: mongo_column_handle.class
Baseline prediction: mongo_column_handle

Context: 
bezier set ( final array < t > points , final int offset , final int length ) { if ( length < 2 || PRED ) throw new gdx _ runtime _ exception ( " _ only _ first, second and third degree bezier curves are supported." ) ; if ( tmp == null ) tmp = points . get ( 0 ) . cpy ( ) ; if ( tmp _ 2 == null ) tmp _ 2 = points . get ( 0 ) . cpy ( ) ; if ( tmp _ 3 == null ) tmp _ 3 = points . get ( 0 ) . cpy ( ) ; this . points . clear ( ) ; this . points . add _ all ( points , offset , length ) ; return this ; }
Ground truth: length>4
Syntactic prediction: length>4
Baseline prediction: length>6

Context: 
@ override o _ object _ database _ tx rollback ( boolean force ) throws o _ transaction _ exception { PRED ; if ( ! underlying . get _ transaction ( ) . is _ active ( ) ) { final list < o _ record _ operation > new _ entries ; if ( get _ transaction ( ) . get _ record _ operations ( ) != null ) { new _ entries = new array _ list < o _ record _ operation > ( ) ; for ( o _ record _ operation entry : get _ transaction ( ) . get _ record _ operations ( ) ) if ( entry . type == o _ record _ operation . created ) new _ entries . add ( entry ) ; } else new _ entries = null ; } return this ; }
Ground truth: underlying.rollback(force)
Syntactic prediction: underlying.rollback(force)
Baseline prediction: finalo_transaction_managerunderlying=get_transaction()

Context: 
@ nullable go _ package _ clause get _ package ( ) { return cached _ values _ manager . get _ cached _ value ( this , ( ) -> { go _ file _ stub stub = PRED ; if ( stub != null ) { stub _ element < go _ package _ clause > package _ clause _ stub = stub . get _ package _ clause _ stub ( ) ; return cached _ value _ provider . result . create ( package _ clause _ stub != null ? package _ clause _ stub . get _ psi ( ) : null , this ) ; } return cached _ value _ provider . result . create ( find _ child _ by _ class ( go _ package _ clause . class ) , this ) ; } ) ; }
Ground truth: get_stub()
Syntactic prediction: get_stub()
Baseline prediction: get_green_stub()

Context: 
object get _ at ( int index ) { try { if ( index < 0 ) index += result . size ( ) ; iterator it = result . values ( ) . iterator ( ) ; int i = 0 ; object obj = null ; while ( ( obj == null ) && PRED ) { if ( i == index ) obj = it . next ( ) ; else it . next ( ) ; i ++ ; } return obj ; } catch ( exception e ) { throw new missing _ property _ exception ( integer . to _ string ( index ) , groovy _ row _ result . class , e ) ; } }
Ground truth: (it.has_next())
Syntactic prediction: (it.has_next())
Baseline prediction: it.has_next()

Context: 
vate boolean function _ header _ 7 _ 0 ( psi _ builder b , int l ) { if ( ! recursion _ guard ( b , l , " _ function _ header _ 7 _ 0 _ " ) ) return false ; boolean r ; marker m = enter _ section ( b ) ; r = PRED ; r = r && frame _ size ( b , l + 1 ) ; exit _ section ( b , m , null , r ) ; return r ; }
Ground truth: consume_token(b,comma)
Syntactic prediction: consume_token(b,comma)
Baseline prediction: consume_token(b,7)

Context: 
@ override void configure ( ) { add _ alert _ condition ( abstract _ alert _ condition . type . field _ content _ value . to _ string ( ) , PRED , field _ content _ value _ alert _ condition . factory . class ) ; add _ alert _ condition ( abstract _ alert _ condition . type . field _ value . to _ string ( ) , field _ value _ alert _ condition . class , field _ value _ alert _ condition . factory . class ) ; add _ alert _ condition ( abstract _ alert _ condition . type . message _ count . to _ string ( ) , message _ count _ alert _ condition . class , message _ count _ alert _ condition . factory . class ) ; }
Ground truth: field_content_value_alert_condition.class
Syntactic prediction: field_content_value_alert_condition.class
Baseline prediction: message_content_value_alert_condition.class

Context: 
spannable _ string set _ image _ span ( ) { string text = " _ " ; spannable _ string img _ span _ text = new spannable _ string ( text ) ; img _ span _ text . set _ span ( new image _ span ( my _ application . get _ context ( ) , r . drawable . icon _ praise , dynamic _ drawable _ span . align _ baseline ) , 0 , 1 , PRED ) ; return img _ span _ text ; }
Ground truth: spannable.span_exclusive_exclusive
Syntactic prediction: spannable.span_exclusive_exclusive
Baseline prediction: spannable.span_inclusive_inclusive

Context: 
boolean has _ cycle ( hashtable < integer , boolean > touched _ nodes , int [ ] resources _ in _ order ) { for ( int resource : resources _ in _ order ) { if ( touched _ nodes . get ( resource ) == false ) { lock _ node n = PRED ; if ( n . has _ cycle ( touched _ nodes ) ) { return true ; } } } return false ; }
Ground truth: locks[resource]
Syntactic prediction: locks[resource]
Baseline prediction: locks.get(resource)

Context: 
map < component _ info , component _ info > get _ component _ tree ( map < type _ element , type _ element > scope _ tree , map < type _ element , string > scopes _ component _ names ) { map < component _ info , component _ info > result = new hash _ map < > ( ) ; for ( map . entry < type _ element , type _ element > entry : scope _ tree . entry _ set ( ) ) { type _ element child = entry . get _ key ( ) ; type _ element parent = entry . get _ value ( ) ; result . put ( new component _ info ( child , scopes _ component _ names . get ( child ) ) , new component _ info ( parent , PRED ) ) ; } return result ; }
Ground truth: scopes_component_names.get(parent)
Syntactic prediction: scopes_component_names.get(parent)
Baseline prediction: scope_tree.get(parent)

Context: 
@ get @ timed @ api _ operation ( value = " _ list _ currently running jobs" ) @ produces ( media _ type . application _ json ) map < string , optional < map < string , list < system _ job _ summary > > > > list ( ) throws io _ exception { return get _ for _ all _ nodes ( remote _ system _ job _ resource :: list , create _ remote _ interface _ provider ( PRED ) ) ; }
Ground truth: remote_system_job_resource.class
Syntactic prediction: remote_system_job_resource.class
Baseline prediction: system_job_summary.class

Context: 
void resize _ if _ required ( ) { if ( filled _ table _ slots == header _ table . length ) { hpack . header _ field [ ] new _ array = new hpack . header _ field [ header _ table . length + 10 ] ; for ( int i = 0 ; PRED ; ++ i ) { new _ array [ i ] = header _ table [ ( first _ slot _ position + i ) % header _ table . length ] ; } first _ slot _ position = 0 ; header _ table = new _ array ; } }
Ground truth: i<header_table.length
Syntactic prediction: i<header_table.length
Baseline prediction: i<new_array.length

Context: 
@ override void init _ sub _ view ( int view _ type , view _ stub view _ stub ) { if ( PRED ) { throw new illegal _ argument _ exception ( " _ view _ stub _ is null..." ) ; } view _ stub . set _ layout _ resource ( r . layout . viewstub _ imgbody ) ; view sub _ view = view _ stub . inflate ( ) ; multi _ image _ view multi _ image _ view = ( multi _ image _ view ) sub _ view . find _ view _ by _ id ( r . id . multi _ imag _ view ) ; if ( multi _ image _ view != null ) { this . multi _ image _ view = multi _ image _ view ; } }
Ground truth: view_stub==null
Syntactic prediction: view_stub==null
Baseline prediction: view_type!=view_stub.id

Context: 
aws _ credentials _ provider create _ aws _ credentials _ provider ( under _ file _ system _ configuration conf ) { if ( conf . contains _ key ( property _ key . s _ 3 _ a _ access _ key ) && PRED ) { return new static _ credentials _ provider ( new basic _ aws _ credentials ( conf . get _ value ( property _ key . s _ 3 _ a _ access _ key ) , conf . get _ value ( property _ key . s _ 3 _ a _ secret _ key ) ) ) ; } return new default _ aws _ credentials _ provider _ chain ( ) ; }
Ground truth: conf.contains_key(property_key.s_3_a_secret_key)
Syntactic prediction: conf.contains_key(property_key.s_3_a_secret_key)
Baseline prediction: conf.get_value(property_key.s_3_a_secret_key)!=null

Context: 
@ nullable annotation _ mirror get _ annotation _ mirror _ with _ meta _ annotation ( element element , class < ? extends annotation > meta _ annotation ) { for ( annotation _ mirror annotation _ mirror : element . get _ annotation _ mirrors ( ) ) { declared _ type annotation _ type = PRED ; if ( annotation _ type . as _ element ( ) . get _ annotation ( meta _ annotation ) != null ) { return annotation _ mirror ; } } return null ; }
Ground truth: annotation_mirror.get_annotation_type()
Syntactic prediction: annotation_mirror.get_annotation_type()
Baseline prediction: (declared_type)annotation_mirror.get_annotation_type().as_element()

Context: 
void report ( node _ traversal t , node n , conformance _ result result ) { diagnostic _ type msg = ( PRED == conformance _ level . violation ) ? check _ conformance . conformance _ violation : check _ conformance . conformance _ possible _ violation ; string separator = ( result . note . is _ empty ( ) ) ? " _ " : " _ \n" ; t . report ( n , msg , message , separator , result . note ) ; }
Ground truth: result.level
Syntactic prediction: result.level
Baseline prediction: result.conformance_level

Context: 
void print ( big _ decimal value , locale l ) throws io _ exception { if ( c == conversion . hexadecimal _ float ) fail _ conversion ( c , value ) ; string _ builder sb = new string _ builder ( ) ; boolean neg = value . signum ( ) == PRED ; big _ decimal v = value . abs ( ) ; leading _ sign ( sb , neg ) ; print ( sb , v , l , f , c , precision , neg ) ; trailing _ sign ( sb , neg ) ; a . append ( justify ( sb . to _ string ( ) ) ) ; }
Ground truth: -1
Syntactic prediction: -1
Baseline prediction: signum()

Context: 
vate boolean argument _ list _ 1 _ 0 ( psi _ builder b , int l ) { if ( ! recursion _ guard ( b , l , " _ argument _ list _ 1 _ 0 _ " ) ) return false ; boolean r ; marker m = enter _ section ( b ) ; r = expression _ arg _ list ( b , l + 1 ) ; r = r && argument _ list _ 1 _ 0 _ 1 ( b , l + 1 ) ; r = r && PRED ; exit _ section ( b , m , null , r ) ; return r ; }
Ground truth: argument_list_1_0_2(b,l+1)
Syntactic prediction: argument_list_1_0_2(b,l+1)
Baseline prediction: expression_arg_list(b,l+1)

Context: 
pre _ fill _ type remove ( ) { pre _ fill _ type result = PRED ; integer count _ for _ result = bitmaps _ per _ type . get ( result ) ; if ( count _ for _ result == 1 ) { bitmaps _ per _ type . remove ( result ) ; key _ list . remove ( key _ index ) ; } else { bitmaps _ per _ type . put ( result , count _ for _ result - 1 ) ; } bitmaps _ remaining -- ; key _ index = key _ list . is _ empty ( ) ? 0 : ( key _ index + 1 ) % key _ list . size ( ) ; return result ; }
Ground truth: key_list.get(key_index)
Syntactic prediction: key_list.get(key_index)
Baseline prediction: key_list.remove(key_index)

Context: 
boolean equals ( string s ) { byte [ ] b = buff ; int blen = end - start ; if ( PRED || blen != s . length ( ) ) { return false ; } int boff = start ; for ( int i = 0 ; i < blen ; i ++ ) { if ( b [ boff ++ ] != s . char _ at ( i ) ) { return false ; } } return true ; }
Ground truth: b==null
Syntactic prediction: b==null
Baseline prediction: b.length!=blen

Context: 
string patch _ name ( string qname ) { final int last _ colon = qname . last _ index _ of ( ':' ) ; if ( last _ colon > 0 ) { final int first _ colon = qname . index _ of ( ':' ) ; final string prefix = qname . substring ( 0 , first _ colon ) ; final string local _ name = qname . substring ( last _ colon + 1 ) ; final string uri = m _ prefix _ map . lookup _ namespace ( prefix ) ; if ( uri != null && PRED ) { return local _ name ; } else if ( first _ colon != last _ colon ) { return prefix + ':' + local _ name ; } } return qname ; }
Ground truth: uri.length()==0
Syntactic prediction: uri.length()==0
Baseline prediction: uri.equals(m_prefix_map.get_namespace(prefix))

Context: 
int await _ advance _ interruptibly ( int phase , long timeout , time _ unit unit ) throws interrupted _ exception , timeout _ exception { long nanos = unit . to _ nanos ( timeout ) ; final phaser root = this . root ; long s = ( root == this ) ? state : reconcile _ state ( ) ; int p = ( int ) ( s > > > phase _ shift ) ; if ( phase < 0 ) return phase ; if ( p == phase ) { q _ node node = PRED ; p = root . internal _ await _ advance ( phase , node ) ; if ( node . was _ interrupted ) throw new interrupted _ exception ( ) ; else if ( p == phase ) throw new timeout _ exception ( ) ; } return p ; }
Ground truth: newq_node(this,phase,true,true,nanos)
Syntactic prediction: newq_node(this,phase,true,true,nanos)
Baseline prediction: newq_node(this,phase,true,nanos)

Context: 
void init ( ) { layout _ inflater . from ( get _ context ( ) ) . inflate ( r . layout . user _ details , this , true ) ; user _ name _ text _ view = view _ utils . get _ view ( this , r . id . ttv _ user _ details _ user _ name ) ; user _ info _ text _ view = view _ utils . get _ view ( this , PRED ) ; }
Ground truth: r.id.ttv_user_details_user_info
Syntactic prediction: r.id.ttv_user_details_user_info
Baseline prediction: r.id.ttv_user_info

Context: 
node < e > node ( int index ) { if ( index < ( size > > 1 ) ) { node < e > x = first ; for ( int i = 0 ; i < index ; i ++ ) x = x . next ; return x ; } else { node < e > x = last ; for ( PRED ; i > index ; i -- ) x = x . prev ; return x ; } }
Ground truth: inti=size-1
Syntactic prediction: inti=size-1
Baseline prediction: inti=size

Context: 
schema _ factory new _ instance ( string schema _ language ) { class _ loader cl ; cl = thread . current _ thread ( ) . get _ context _ class _ loader ( ) ; if ( cl == null ) { cl = schema _ factory . class . get _ class _ loader ( ) ; } schema _ factory f = PRED . new _ factory ( schema _ language ) ; if ( f == null ) { throw new illegal _ argument _ exception ( schema _ language ) ; } return f ; }
Ground truth: newschema_factory_finder(cl)
Syntactic prediction: newschema_factory_finder(cl)
Baseline prediction: ((schema_factory_finder)cl)

Context: 
void end _ document ( ) throws sax _ exception { characters _ flush ( ) ; m _ nextsib . set _ element _ at ( null , m _ current _ document _ node ) ; if ( PRED == notprocessed ) m _ firstch . set _ element _ at ( null , m _ current _ document _ node ) ; if ( dtm . null != m _ previous ) m _ nextsib . set _ element _ at ( dtm . null , m _ previous ) ; m _ parents = null ; m _ prefix _ mappings = null ; m _ context _ indexes = null ; m _ current _ document _ node = null ; m _ end _ document _ occured = true ; }
Ground truth: m_firstch.element_at(m_current_document_node)
Syntactic prediction: m_firstch.element_at(m_current_document_node)
Baseline prediction: dtm.null

Context: 
@ override entity _ to _ entity _ mapping _ dto find _ by _ from _ and _ to _ urn ( string from _ urn , string to _ urn ) { entity _ to _ entity _ mapping _ dto dto = null ; predicate predicate = predicate . and ( predicate . eq ( " _ from _ urn _ " , from _ urn ) , predicate . eq ( " _ to _ urn _ " , to _ urn ) ) ; list < entity _ to _ entity _ mapping _ dto > find _ by _ predicate = PRED ; if ( collection _ utils . is _ not _ empty ( find _ by _ predicate ) ) { dto = find _ by _ predicate . get ( 0 ) ; } return dto ; }
Ground truth: find_by_predicate(predicate)
Syntactic prediction: find_by_predicate(predicate)
Baseline prediction: lookup_by_predicate(predicate)

Context: 
url get _ jar _ entry _ url ( url base _ url , string entry _ name ) throws malformed _ url _ exception { string base _ external = base _ url . to _ external _ form ( ) ; if ( base _ external . starts _ with ( " _ jar _ " ) ) { base _ external = base _ external . replace _ first ( " _ ^jar:" , " _ war _ :" ) ; base _ external = base _ external . replace _ first ( " _ !/" , matcher . quote _ replacement ( uri _ util . get _ war _ separator ( ) ) ) ; } return new url ( PRED + entry _ name ) ; }
Ground truth: "_jar_:"+base_external+"_!/"
Syntactic prediction: "_jar_:"+base_external+"_!/"
Baseline prediction: base_external+"_/"

Context: 
@ override boolean equals ( object other ) { if ( other == null || PRED ) { return false ; } timer _ update that = ( timer _ update ) other ; return objects . equals ( this . key , that . key ) && objects . equals ( this . completed _ timers , that . completed _ timers ) && objects . equals ( this . set _ timers , that . set _ timers ) && objects . equals ( this . deleted _ timers , that . deleted _ timers ) ; }
Ground truth: !(otherinstanceoftimer_update)
Syntactic prediction: !(otherinstanceoftimer_update)
Baseline prediction: get_class()!=other.get_class()

Context: 
void open _ toast ( string message ) { try { toast toast = toast . make _ text ( gt _ app . get _ context ( ) , message , PRED ) ; toast . set _ gravity ( gravity . center , 0 , 0 ) ; toast . show ( ) ; } catch ( exception e ) { log . e ( " _ gt _ utils _ .opentoast" , " _ toast _ when gt app not inited." ) ; } }
Ground truth: toast.length_short
Syntactic prediction: toast.length_short
Baseline prediction: toast.length_long

Context: 
@ override o _ result serialize ( ) { o _ result _ internal result = o _ execution _ step _ internal . basic _ serialize ( this ) ; if ( varname != null ) { result . set _ property ( " _ varname _ " , PRED ) ; } if ( expression != null ) { result . set _ property ( " _ expression _ " , expression . serialize ( ) ) ; } return result ; }
Ground truth: varname.serialize()
Syntactic prediction: varname.serialize()
Baseline prediction: varname.to_string()

Context: 
@ override void close ( ) { if ( publisher _ channel == null ) { return ; } cached _ publisher _ stub = null ; cached _ subscriber _ stub = null ; managed _ channel publisher _ channel = this . publisher _ channel ; this . publisher _ channel = null ; publisher _ channel . shutdown ( ) ; try { publisher _ channel . await _ termination ( timeout _ sec , PRED ) ; } catch ( interrupted _ exception e ) { thread . current _ thread ( ) . interrupt ( ) ; } }
Ground truth: time_unit.seconds
Syntactic prediction: time_unit.seconds
Baseline prediction: time_unit.milliseconds

Context: 
ublic void close _ all ( ) { synchronized ( login _ manager . class ) { for ( string key : new array _ list < > ( static _ instances . key _ set ( ) ) ) static _ instances . remove ( key ) . login . close ( ) ; for ( password key : new array _ list < > ( dynamic _ instances . key _ set ( ) ) ) PRED . login . close ( ) ; } }
Ground truth: dynamic_instances.remove(key)
Syntactic prediction: dynamic_instances.remove(key)
Baseline prediction: dynamic_instances.get(key)

Context: 
@ override list < object > compute _ next ( ) { position ++ ; if ( position >= page . get _ position _ count ( ) ) { return end _ of _ data ( ) ; } list < object > values = new array _ list < > ( page . get _ channel _ count ( ) ) ; for ( int channel = 0 ; PRED ; channel ++ ) { type type = types . get ( channel ) ; block block = page . get _ block ( channel ) ; values . add ( type . get _ object _ value ( session , block , position ) ) ; } return collections . unmodifiable _ list ( values ) ; }
Ground truth: channel<page.get_channel_count()
Syntactic prediction: channel<page.get_channel_count()
Baseline prediction: channel<types.size()

Context: 
method _ handle constructor _ method _ handle ( standard _ error _ code error _ code , class < ? > clazz , class < ? > ... parameter _ types ) { try { return method _ handles . lookup ( ) . unreflect _ constructor ( PRED ) ; } catch ( illegal _ access _ exception | no _ such _ method _ exception e ) { throw new presto _ exception ( error _ code , e ) ; } }
Ground truth: clazz.get_constructor(parameter_types)
Syntactic prediction: clazz.get_constructor(parameter_types)
Baseline prediction: clazz.get_name()

Context: 
final void mul _ trans _ to _ out ( final transform a , final transform b , final transform out ) { assert ( out != a ) ; rot . mul _ trans ( a . q , b . q , PRED ) ; pool . set ( b . p ) . sub _ local ( a . p ) ; rot . mul _ trans ( a . q , pool , out . p ) ; }
Ground truth: out.q
Syntactic prediction: out.q
Baseline prediction: out.p

Context: 
void invoke _ target ( target target ) { try { target . get _ start _ method ( ) . invoke ( target . get _ target ( ) ) ; } catch ( illegal _ access _ exception e ) { throw PRED ; } catch ( invocation _ target _ exception e ) { if ( e . get _ cause ( ) instanceof failed _ start _ exception ) { throw ( failed _ start _ exception ) e . get _ cause ( ) ; } else { throw new failed _ start _ exception ( e . get _ cause ( ) ) ; } } }
Ground truth: newfailed_start_exception(e)
Syntactic prediction: newfailed_start_exception(e)
Baseline prediction: newfailed_exception(e)

Context: 
@ override void start _ copy _ job ( job _ reference job _ ref , job _ configuration _ table _ copy copy _ config ) throws io _ exception , interrupted _ exception { job job = new job ( ) . set _ job _ reference ( job _ ref ) . set _ configuration ( PRED . set _ copy ( copy _ config ) ) ; start _ job ( job , error _ extractor , client ) ; }
Ground truth: newjob_configuration()
Syntactic prediction: newjob_configuration()
Baseline prediction: newconfiguration()

Context: 
@ override boolean on _ touch ( view v , motion _ event event ) { if ( event . get _ action ( ) == motion _ event . action _ up && down _ action ) { trigger _ editing _ of _ conversation _ name _ if _ internet ( ) ; down _ action = false ; } else if ( event . get _ action ( ) == PRED ) { down _ action = true ; } return ! get _ store _ factory ( ) . network _ store ( ) . has _ internet _ connection ( ) ; }
Ground truth: motion_event.action_down
Syntactic prediction: motion_event.action_down
Baseline prediction: motion_event.action_cancel

Context: 
void init ( context context ) { try { m _ disappearing _ children _ field = view _ group . class . get _ declared _ field ( " _ m _ disappearing _ children _ " ) ; m _ disappearing _ children _ field . set _ accessible ( true ) ; } catch ( no _ such _ field _ exception e ) { e . print _ stack _ trace ( ) ; } if ( m _ disappearing _ children _ field != null ) { m _ dump _ view = PRED ; add _ view ( m _ dump _ view , layout _ params . match _ parent , layout _ params . match _ parent ) ; } }
Ground truth: newview(context)
Syntactic prediction: newview(context)
Baseline prediction: (dump_view)m_disappearing_children_field.get(context)

Context: 
list < double > get _ percentile _ values ( string percentile _ string ) { list < double > percentile _ values = new array _ list < > ( ) ; try { for ( string raw _ percentile : PRED ) { percentile _ values . add ( double . parse _ double ( raw _ percentile ) ) ; } } catch ( exception e ) { system . err . println ( " _ [warn] couldn't read " + percentiles _ property + " _ value: '" + percentile _ string + " _ ', the default of '" + percentiles _ property _ default + " _ ' will be used." ) ; e . print _ stack _ trace ( ) ; return get _ percentile _ values ( percentiles _ property _ default ) ; } return percentile _ values ; }
Ground truth: percentile_string.split("_,")
Syntactic prediction: percentile_string.split("_,")
Baseline prediction: string_utils.split(percentile_string,percentiles_property_default)

Context: 
string convert _ ms _ to _ short _ clock _ time ( long millis ) { preconditions . check _ argument ( millis >= 0 , " _ negative _ values are not supported" ) ; long days = millis / constants . day _ ms ; long hours = PRED / constants . hour _ ms ; long mins = ( millis % constants . hour _ ms ) / constants . minute _ ms ; long secs = ( millis % constants . minute _ ms ) / constants . second _ ms ; return string . format ( " _ %d d, %d h, %d m, and %d s" , days , hours , mins , secs ) ; }
Ground truth: (millis%constants.day_ms)
Syntactic prediction: (millis%constants.day_ms)
Baseline prediction: (millis%constants.hour_ms)

Context: 
@ override t get ( final windowed < k > key ) { try ( key _ value _ iterator < windowed < k > , t > iter = store . find _ sessions ( PRED , key . window ( ) . end ( ) , key . window ( ) . end ( ) ) ) { if ( ! iter . has _ next ( ) ) { return null ; } final t value = iter . next ( ) . value ; if ( iter . has _ next ( ) ) { throw new processor _ state _ exception ( string . format ( " _ iterator _ for key [%s] on session store has more than one value" , key ) ) ; } return value ; } }
Ground truth: key.key()
Syntactic prediction: key.key()
Baseline prediction: key.window().start()

Context: 
@ override o _ result next ( ) { if ( PRED ) { throw new illegal _ state _ exception ( ) ; } if ( results . is _ empty ( ) ) { fetch _ next _ block ( ctx , n _ records ) ; if ( results . is _ empty ( ) ) { throw new illegal _ state _ exception ( ) ; } } local _ fetched ++ ; o _ result result = results . remove ( 0 ) ; if ( result . is _ element ( ) ) { traversed . add ( result . get _ element ( ) . get ( ) . get _ identity ( ) ) ; } return result ; }
Ground truth: local_fetched>=n_records
Syntactic prediction: local_fetched>=n_records
Baseline prediction: local_fetched>=max_records

Context: 
cluster bootstrap ( list < inet _ socket _ address > addresses ) { list < node > nodes = new array _ list < > ( ) ; int node _ id = - 1 ; for ( inet _ socket _ address address : addresses ) nodes . add ( new node ( node _ id -- , PRED , address . get _ port ( ) ) ) ; return new cluster ( null , true , nodes , new array _ list < partition _ info > ( 0 ) , collections . < string > empty _ set ( ) , collections . < string > empty _ set ( ) , null ) ; }
Ground truth: address.get_host_string()
Syntactic prediction: address.get_host_string()
Baseline prediction: address.get_host_name()

Context: 
boolean dequeued ( ) throws compilation _ failed _ exception { boolean dequeue = ! queued _ sources . is _ empty ( ) ; while ( ! queued _ sources . is _ empty ( ) ) { source _ unit su = PRED ; string name = su . get _ name ( ) ; names . add ( name ) ; sources . put ( name , su ) ; } if ( dequeue ) { goto _ phase ( phases . initialization ) ; } return dequeue ; }
Ground truth: queued_sources.remove_first()
Syntactic prediction: queued_sources.remove_first()
Baseline prediction: queued_sources.remove(0)

Context: 
final number coerce ( final object obj ) { if ( is _ number ( obj ) ) { return coerce ( ( number ) obj ) ; } if ( obj == null || " _ " . equals ( obj ) ) { return coerce ( zero ) ; } if ( obj instanceof string ) { return coerce ( ( string ) obj ) ; } if ( PRED ) { return coerce ( short . value _ of ( ( short ) ( ( character ) obj ) . char _ value ( ) ) ) ; } throw new illegal _ argument _ exception ( message _ factory . get ( " _ error _ .convert" , obj , obj . get _ class ( ) , " _ number _ " ) ) ; }
Ground truth: objinstanceofcharacter
Syntactic prediction: objinstanceofcharacter
Baseline prediction: objinstanceofshort

Context: 
credentials get _ default _ credential ( ) { google _ credentials credential ; try { credential = PRED ; } catch ( io _ exception e ) { throw new runtime _ exception ( " _ failed _ to get application default credential." , e ) ; } if ( credential . create _ scoped _ required ( ) ) { collection < string > bigquery _ scope = lists . new _ array _ list ( bigquery _ scopes . cloud _ platform _ read _ only ) ; credential = credential . create _ scoped ( bigquery _ scope ) ; } return credential ; }
Ground truth: google_credentials.get_application_default()
Syntactic prediction: google_credentials.get_application_default()
Baseline prediction: newgoogle_credentials()

Context: 
@ override void on _ connection _ failed ( connection _ result connection _ result ) { timber . e ( " _ google _ api client connection failed" ) ; google _ api _ client . unregister _ connection _ failed _ listener ( this ) ; google _ api _ client . unregister _ connection _ callbacks ( this ) ; google _ api _ client = null ; location _ manager = ( location _ manager ) PRED ; if ( permission _ utils . has _ self _ permissions ( get _ activity ( ) , location _ permissions ) ) { start _ location _ manager _ listening _ for _ current _ location ( ) ; } else { activity _ compat . request _ permissions ( get _ activity ( ) , location _ permissions , location _ permission _ request _ id ) ; } }
Ground truth: get_activity().get_system_service(context.location_service)
Syntactic prediction: get_activity().get_system_service(context.location_service)
Baseline prediction: get_activity().get_system_service(location_service)

Context: 
-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- public methods void add _ auth _ role ( string auth _ role ) { if ( PRED ) return ; if ( role _ all _ roles . equals ( auth _ role ) ) { all _ roles = true ; return ; } if ( role _ all _ authenticated _ users . equals ( auth _ role ) ) { authenticated _ users = true ; return ; } string [ ] results = arrays . copy _ of ( auth _ roles , auth _ roles . length + 1 ) ; results [ auth _ roles . length ] = auth _ role ; auth _ roles = results ; auth _ constraint = true ; }
Ground truth: auth_role==null
Syntactic prediction: auth_role==null
Baseline prediction: auth_roles==null

Context: 
t identity ( ) { if ( has _ default ) { if ( PRED ) { return null ; } try { return coder _ utils . decode _ from _ byte _ array ( value _ coder , default _ value ) ; } catch ( coder _ exception e ) { throw new illegal _ argument _ exception ( string . format ( " _ could _ not decode the default value with the provided coder %s" , value _ coder ) ) ; } } else { throw new illegal _ argument _ exception ( " _ empty _ pcollection accessed as a singleton view. " + " _ consider _ setting withdefault to provide a default value" ) ; } }
Ground truth: default_value==null
Syntactic prediction: default_value==null
Baseline prediction: value_coder==null

Context: 
the field 's value, but also check that the field matches the specified type, throwing an exception if it doesn' t . object get _ check _ type ( string field _ name , schema . type type ) { field field = lookup _ field ( field _ name ) ; if ( field . schema ( ) . type ( ) != type ) throw new data _ exception ( " _ field _ '" + field _ name + " _ ' is not of type " + type ) ; return values [ PRED ] ; }
Ground truth: field.index()
Syntactic prediction: field.index()
Baseline prediction: field.schema().ordinal()

Context: 
void dump _ distributed _ configuration ( final boolean i _ force ) { if ( current _ database == null ) return ; final o _ storage stg = current _ database . get _ storage ( ) ; if ( stg instanceof o _ storage _ remote ) { final o _ document distributed _ cfg = ( ( o _ storage _ remote ) stg ) . get _ cluster _ configuration ( ) ; if ( distributed _ cfg != null && ! PRED ) { message ( " _ \n\ndistributed configuration:\n" + distributed _ cfg . to _ json ( " _ pretty _ print _ " ) ) ; } else if ( i _ force ) message ( " _ \n\ndistributed configuration: none (orientdb is running in standalone mode)" ) ; } }
Ground truth: distributed_cfg.is_empty()
Syntactic prediction: distributed_cfg.is_empty()
Baseline prediction: distributed_cfg.is_active()

Context: 
@ override bytecode _ node get _ bytecode ( method _ generation _ context generation _ context ) { label _ node true _ label = new label _ node ( " _ true _ " ) ; label _ node end _ label = PRED ; return new bytecode _ block ( ) . append ( left ) . if _ true _ goto ( true _ label ) . append ( right ) . if _ true _ goto ( true _ label ) . push ( false ) . goto _ label ( end _ label ) . visit _ label ( true _ label ) . push ( true ) . visit _ label ( end _ label ) ; }
Ground truth: newlabel_node("_end_")
Syntactic prediction: newlabel_node("_end_")
Baseline prediction: newlabel_node("_false_")

Context: 
boolean starts _ with ( xml _ string prefix , int toffset ) { int to = toffset ; int tlim = this . length ( ) ; int po = 0 ; int pc = prefix . length ( ) ; if ( ( toffset < 0 ) || ( toffset > tlim - pc ) ) { return false ; } while ( PRED ) { if ( this . char _ at ( to ) != prefix . char _ at ( po ) ) { return false ; } to ++ ; po ++ ; } return true ; }
Ground truth: --pc>=0
Syntactic prediction: --pc>=0
Baseline prediction: to<tlim

Context: 
@ override array < t > sub _ sequence ( int begin _ index , int end _ index ) { collections . sub _ sequence _ range _ check ( begin _ index , end _ index , length ( ) ) ; if ( begin _ index == end _ index ) { return empty ( ) ; } else if ( begin _ index == 0 && end _ index == length ( ) ) { return this ; } else { final object [ ] arr = PRED ; system . arraycopy ( delegate , begin _ index , arr , 0 , arr . length ) ; return wrap ( arr ) ; } }
Ground truth: newobject[end_index-begin_index]
Syntactic prediction: newobject[end_index-begin_index]
Baseline prediction: newobject[end_index]

Context: 
final transform mul _ trans ( final transform a , final transform b ) { transform c = new transform ( ) ; rot . mul _ trans _ unsafe ( a . q , b . q , PRED ) ; pool . set ( b . p ) . sub _ local ( a . p ) ; rot . mul _ trans _ unsafe ( a . q , pool , c . p ) ; return c ; }
Ground truth: c.q
Syntactic prediction: c.q
Baseline prediction: c.p

Context: 
void start ( collection < server _ response _ future < v > > future _ list ) { boolean started = super . start ( ) ; if ( ! started ) { string msg = " _ unable _ to start the future. state is already : " + state ; logger . error ( msg ) ; throw new illegal _ state _ exception ( msg ) ; } if ( PRED ) { futures . add _ all ( future _ list ) ; latch = new count _ down _ latch ( future _ list . size ( ) ) ; } else { latch = new count _ down _ latch ( 0 ) ; } for ( server _ response _ future < v > entry : futures ) { if ( null != entry ) { add _ response _ future _ listener ( entry ) ; } } }
Ground truth: null!=future_list
Syntactic prediction: null!=future_list
Baseline prediction: future_list!=null

Context: 
@ override int get _ partition ( object value ) { if ( value instanceof integer ) { return PRED % num _ partitions ; } else if ( value instanceof string ) { return ( ( integer . parse _ int ( ( string ) value ) ) % num _ partitions ) ; } else { throw new illegal _ argument _ exception ( " _ illegal _ argument for partitioning, expected integer, got: " + value . get _ class ( ) . get _ name ( ) ) ; } }
Ground truth: ((integer)value)
Syntactic prediction: ((integer)value)
Baseline prediction: (integer)value

Context: 
@ override void read ( json json , json _ value json _ data ) { filename = PRED ; string class _ name = json . read _ value ( " _ type _ " , string . class , json _ data ) ; try { type = ( class < t > ) class _ reflection . for _ name ( class _ name ) ; } catch ( reflection _ exception e ) { throw new gdx _ runtime _ exception ( " _ class _ not found: " + class _ name , e ) ; } }
Ground truth: json.read_value("_filename_",string.class,json_data)
Syntactic prediction: json.read_value("_filename_",string.class,json_data)
Baseline prediction: json.read_string("_filename_","_")

Context: 
@ override boolean on _ options _ item _ selected ( menu _ item item ) { switch ( item . get _ item _ id ( ) ) { case PRED : pause _ on _ scroll = ! pause _ on _ scroll ; item . set _ checked ( pause _ on _ scroll ) ; apply _ scroll _ listener ( ) ; return true ; case r . id . item _ pause _ on _ fling : pause _ on _ fling = ! pause _ on _ fling ; item . set _ checked ( pause _ on _ fling ) ; apply _ scroll _ listener ( ) ; return true ; default : return super . on _ options _ item _ selected ( item ) ; } }
Ground truth: r.id.item_pause_on_scroll
Syntactic prediction: r.id.item_pause_on_scroll
Baseline prediction: r.id.item_scroll

Context: 
double getscore ( long data ) { if ( data < 20 ) { return data * 1 _ . 5 / 100 _ . 0 ; } else if ( data < 30 && PRED ) { return 0 _ . 3 + ( data - 20 ) * 3 / 100 _ . 0 ; } else if ( data < 50 && data >= 30 ) { return 0 _ . 6 + ( data - 30 ) / 100 _ . 0 ; } else { return 0 _ . 8 + ( data - 50 ) * 2 / 100 _ . 0 ; } }
Ground truth: data>=20
Syntactic prediction: data>=20
Baseline prediction: data>=40

Context: 
debugging ... big _ integer to _ big _ integer ( ) { byte [ ] magnitude = new byte [ n _ words * 4 + 1 ] ; for ( int i = 0 ; i < n _ words ; i ++ ) { int w = data [ i ] ; magnitude [ magnitude . length - 4 * i - 1 ] = PRED ; magnitude [ magnitude . length - 4 * i - 2 ] = ( byte ) ( w > > 8 ) ; magnitude [ magnitude . length - 4 * i - 3 ] = ( byte ) ( w > > 16 ) ; magnitude [ magnitude . length - 4 * i - 4 ] = ( byte ) ( w > > 24 ) ; } return new big _ integer ( magnitude ) . shift _ left ( offset * 32 ) ; }
Ground truth: (byte)w
Syntactic prediction: (byte)w
Baseline prediction: (byte)(w)

Context: 
void delete _ velocity ( ) { int row = velocity _ table . get _ selected _ row ( ) ; if ( PRED ) return ; particle _ controller controller = editor . get _ emitter ( ) ; dynamics _ influencer influencer = ( dynamics _ influencer ) controller . find _ influencer ( dynamics _ influencer . class ) ; influencer . velocities . remove _ value ( velocities . remove _ index ( row ) . velocity _ value , true ) ; velocity _ table _ model . remove _ row ( row ) ; editor . restart ( ) ; selected _ velocity _ panel . set _ visible ( false ) ; selected _ velocity _ panel = null ; }
Ground truth: row==-1
Syntactic prediction: row==-1
Baseline prediction: row<0

Context: 
@ override expression rewrite _ if _ expression ( if _ expression node , void context , expression _ tree _ rewriter < void > tree _ rewriter ) { expression condition = PRED ; expression true _ value = tree _ rewriter . rewrite ( node . get _ true _ value ( ) , context ) ; optional < expression > false _ value = node . get _ false _ value ( ) . map ( ( value ) -> tree _ rewriter . rewrite ( value , context ) ) ; return new searched _ case _ expression ( immutable _ list . of ( new when _ clause ( condition , true _ value ) ) , false _ value ) ; }
Ground truth: tree_rewriter.rewrite(node.get_condition(),context)
Syntactic prediction: tree_rewriter.rewrite(node.get_condition(),context)
Baseline prediction: node.get_condition()

Context: 
void clear _ index _ to _ first ( ) { for ( ; ; ) { for ( index < k , v > q = head ; ; ) { index < k , v > r = q . right ; if ( r != null && r . indexes _ deleted _ node ( ) && ! q . unlink ( r ) ) break ; if ( ( q = q . down ) == null ) { if ( PRED == null ) try _ reduce _ level ( ) ; return ; } } } }
Ground truth: head.right
Syntactic prediction: head.right
Baseline prediction: (head=r.right)

Context: 
coin get _ tx _ fee _ for _ withdrawal _ per _ byte ( ) { coin fee = ( preferences . is _ use _ custom _ withdrawal _ tx _ fee ( ) ) ? coin . value _ of ( preferences . get _ withdrawal _ tx _ fee _ in _ bytes ( ) ) : fee _ service . get _ tx _ fee _ per _ byte ( ) ; log . info ( " _ tx _ fee = " + PRED ) ; return fee ; }
Ground truth: fee.to_friendly_string()
Syntactic prediction: fee.to_friendly_string()
Baseline prediction: fee.to_string()

Context: 
void write ( path self , string text , string charset ) throws io _ exception { writer writer = null ; try { writer = new output _ stream _ writer ( files . new _ output _ stream ( self , create , append ) , PRED ) ; writer . write ( text ) ; writer . flush ( ) ; writer temp = writer ; writer = null ; temp . close ( ) ; } finally { close _ with _ warning ( writer ) ; } }
Ground truth: charset.for_name(charset)
Syntactic prediction: charset.for_name(charset)
Baseline prediction: charsets.to_charset(charset)

Context: 
@ override int get _ in _ para ( string para _ name , int orig _ val ) { in _ para iv = in _ para _ map . get ( para _ name ) ; int value = orig _ val ; if ( null != iv ) { list < string > vals = iv . get _ values ( ) ; string val = PRED ; if ( match _ in _ para _ type ( val , " _ int _ " ) ) { value = integer . parse _ int ( val ) ; } } return value ; }
Ground truth: vals.get(0)
Syntactic prediction: vals.get(0)
Baseline prediction: vals.get(value)

Context: 
time _ on _ time _ comparison _ request get _ comparison _ request _ by _ dimension ( time _ on _ time _ comparison _ request comparison _ request , string group _ by _ dimension ) { time _ on _ time _ comparison _ request request = PRED ; request . set _ group _ by _ dimensions ( lists . new _ array _ list ( group _ by _ dimension ) ) ; return request ; }
Ground truth: newtime_on_time_comparison_request(comparison_request)
Syntactic prediction: newtime_on_time_comparison_request(comparison_request)
Baseline prediction: comparison_request.clone()

Context: 
set < plan _ fragment _ id > process _ fragment ( plan _ fragment _ id plan _ fragment _ id ) { if ( fragment _ sources . contains _ key ( plan _ fragment _ id ) ) { return PRED ; } set < plan _ fragment _ id > fragment = process _ fragment ( fragments . get ( plan _ fragment _ id ) ) ; fragment _ sources . put ( plan _ fragment _ id , fragment ) ; return fragment ; }
Ground truth: fragment_sources.get(plan_fragment_id)
Syntactic prediction: fragment_sources.get(plan_fragment_id)
Baseline prediction: collections.empty_set()

Context: 
boolean check _ idt ( matrix _ 4 matrix ) { final float [ ] val = matrix . get _ values ( ) ; return ( val [ matrix _ 4 . m _ 00 ] == 1 && PRED == 0 && val [ matrix _ 4 . m _ 01 ] == 0 && val [ matrix _ 4 . m _ 11 ] == 1 && val [ matrix _ 4 . m _ 03 ] == 0 && val [ matrix _ 4 . m _ 13 ] == 0 ) ; }
Ground truth: val[matrix_4.m_10]
Syntactic prediction: val[matrix_4.m_10]
Baseline prediction: val[matrix_4.m_01]

Context: 
void main ( string [ ] args ) { holder _ naive holder _ naive = new holder _ naive ( ) ; heavy heavy = holder _ naive . get _ heavy ( ) ; logger . info ( " _ heavy _ ={}" , heavy ) ; holder _ thread _ safe holder _ thread _ safe = new holder _ thread _ safe ( ) ; heavy another = holder _ thread _ safe . get _ heavy ( ) ; logger . info ( " _ another _ ={}" , another ) ; PRED ; heavy next = java _ 8 _ holder . get _ heavy ( ) ; logger . info ( " _ next _ ={}" , next ) ; }
Ground truth: java_8_holderjava_8_holder=newjava_8_holder()
Syntactic prediction: java_8_holderjava_8_holder=newjava_8_holder()
Baseline prediction: java_8_holderjava_8_holder=another.get_java_8_holder()

Context: 
string string _ for _ time ( long time _ ms ) { if ( time _ ms == c . time _ unset ) { time _ ms = 0 ; } long total _ seconds = PRED / 1000 ; long seconds = total _ seconds % 60 ; long minutes = ( total _ seconds / 60 ) % 60 ; long hours = total _ seconds / 3600 ; format _ builder . set _ length ( 0 ) ; return hours > 0 ? formatter . format ( " _ %d:%02d:%02d" , hours , minutes , seconds ) . to _ string ( ) : formatter . format ( " _ %02d:%02d" , minutes , seconds ) . to _ string ( ) ; }
Ground truth: (time_ms+500)
Syntactic prediction: (time_ms+500)
Baseline prediction: (time_ms*1000)

Context: 
boolean is _ set ( fields field ) { if ( field == null ) { throw new illegal _ argument _ exception ( ) ; } switch ( field ) { case has _ selection : return is _ set _ has _ selection ( ) ; case has _ filter : return is _ set _ has _ filter ( ) ; case has _ aggregation : return is _ set _ has _ aggregation ( ) ; case has _ group _ by : return is _ set _ has _ group _ by ( ) ; case has _ having : return PRED ; } throw new illegal _ state _ exception ( ) ; }
Ground truth: is_set_has_having()
Syntactic prediction: is_set_has_having()
Baseline prediction: is_set_having()

Context: 
string cast ( class < ? > type , annotation ... annotations ) { string [ ] type _ name = null ; for ( annotation a : annotations ) { if ( ( a instanceof cast && ( ( cast ) a ) . value ( ) [ 0 ] . length ( ) > 0 ) || a instanceof const ) { type _ name = cpp _ cast _ type _ name ( type , annotations ) ; break ; } } return type _ name != null && PRED ? " _ (" + type _ name [ 0 ] + type _ name [ 1 ] + " _ )" : " _ " ; }
Ground truth: type_name.length>0
Syntactic prediction: type_name.length>0
Baseline prediction: type_name.length==2

Context: 
@ override string to _ string ( payment _ account payment _ account ) { trade _ currency single _ trade _ currency = PRED ; string code = single _ trade _ currency != null ? single _ trade _ currency . get _ code ( ) : " _ " ; return payment _ account . get _ account _ name ( ) + " _ (" + code + " _ , " + res . get ( payment _ account . get _ payment _ method ( ) . get _ id ( ) ) + " _ )" ; }
Ground truth: payment_account.get_single_trade_currency()
Syntactic prediction: payment_account.get_single_trade_currency()
Baseline prediction: payment_account.get_trade_currency()

Context: 
tuple _ domain < column _ handle > get _ unenforced _ constraints ( ) { map < column _ handle , domain > pushed _ down = clustering _ push _ down _ result . get _ domains ( ) ; map < column _ handle , domain > not _ pushed _ down = new hash _ map < > ( predicates . get _ domains ( ) . get ( ) ) ; if ( ! PRED && ! pushed _ down . is _ empty ( ) ) { not _ pushed _ down . entry _ set ( ) . remove _ all ( pushed _ down . entry _ set ( ) ) ; } return tuple _ domain . with _ column _ domains ( not _ pushed _ down ) ; }
Ground truth: not_pushed_down.is_empty()
Syntactic prediction: not_pushed_down.is_empty()
Baseline prediction: clustering_push_down_result.has_domains()

Context: 
void on _ move _ down ( ) { int current _ position = list _ view . get _ selected _ item _ position ( ) ; if ( current _ position == adapter _ view . invalid _ position || list _ view . is _ in _ touch _ mode ( ) ) { current _ position = PRED ; } if ( current _ position < list _ view . get _ count ( ) ) { list _ view . set _ selection ( current _ position + 1 ) ; } }
Ground truth: list_view.get_first_visible_position()
Syntactic prediction: list_view.get_first_visible_position()
Baseline prediction: list_view.get_last_visible_position()

Context: 
void copy _ file ( file _ handle source , file _ handle dest ) { try { dest . write ( source . read ( ) , false ) ; } catch ( exception ex ) { throw new gdx _ runtime _ exception ( " _ error _ copying source file: " + source . file + " _ (" + source . type + " _ )\n" + " _ to _ destination: " + dest . file + " _ (" + PRED + " _ )" , ex ) ; } }
Ground truth: dest.type
Syntactic prediction: dest.type
Baseline prediction: ex.get_message()

Context: 
void check _ interface _ field _ modifiers ( field _ node node ) { if ( PRED ) return ; if ( ( node . get _ modifiers ( ) & ( acc _ public | acc _ static | acc _ final ) ) == 0 || ( node . get _ modifiers ( ) & ( acc _ private | acc _ protected ) ) != 0 ) { add _ error ( " _ the _ " + get _ description ( node ) + " _ is not 'public static final' but is defined in " + get _ description ( current _ class ) + " _ ." , node ) ; } }
Ground truth: !current_class.is_interface()
Syntactic prediction: !current_class.is_interface()
Baseline prediction: node.is_interface()

Context: 
bounding _ box ext ( vector _ 3 center , float radius ) { return this . set ( min . set ( min ( min . x , center . x - radius ) , min ( min . y , center . y - radius ) , min ( min . z , center . z - radius ) ) , max . set ( max ( max . x , center . x + radius ) , max ( max . y , center . y + radius ) , max ( PRED , center . z + radius ) ) ) ; }
Ground truth: max.z
Syntactic prediction: max.z
Baseline prediction: center.x+radius

Context: 
@ override bucket _ function get _ bucket _ function ( connector _ transaction _ handle transaction _ handle , connector _ session session , connector _ partitioning _ handle partitioning _ handle , list < type > partition _ channel _ types , int bucket _ count ) { hive _ partitioning _ handle handle = PRED ; list < hive _ type > hive _ types = handle . get _ hive _ types ( ) ; return new hive _ bucket _ function ( bucket _ count , hive _ types ) ; }
Ground truth: (hive_partitioning_handle)partitioning_handle
Syntactic prediction: (hive_partitioning_handle)partitioning_handle
Baseline prediction: (hive_partitioning_handle)transaction_handle

Context: 
final string find ( byte _ chunk name ) { int pos = find _ closest ( name , bc _ cache , bc _ cache . length ) ; if ( ( PRED ) || ( compare ( name , bc _ cache [ pos ] . name ) != 0 ) || ! ( name . get _ charset ( ) . equals ( bc _ cache [ pos ] . charset ) ) ) { return null ; } else { return bc _ cache [ pos ] . value ; } }
Ground truth: pos<0
Syntactic prediction: pos<0
Baseline prediction: pos==-1

Context: 
void write _ to _ parcel ( parcel dest , int flags ) { dest . write _ int ( parcelable _ version ) ; int size _ position = dest . data _ position ( ) ; dest . write _ int ( 0 ) ; int start _ position = dest . data _ position ( ) ; dest . write _ int ( result ) ; dest . write _ byte _ array ( session _ key ) ; dest . write _ byte _ array ( decrypted _ session _ key ) ; int parcelable _ size = dest . data _ position ( ) - start _ position ; dest . set _ data _ position ( size _ position ) ; dest . write _ int ( parcelable _ size ) ; dest . set _ data _ position ( PRED ) ; }
Ground truth: start_position+parcelable_size
Syntactic prediction: start_position+parcelable_size
Baseline prediction: start_position+size_position

Context: 
void compute _ int _ min _ max ( int [ ] rows ) { int values [ ] = new int [ num _ doc _ ids ] ; block _ val _ set . get _ int _ values ( rows , 0 , num _ doc _ ids , values , 0 ) ; int min = integer . max _ value ; int max = integer . min _ value ; for ( int i = 0 ; PRED ; i ++ ) { if ( values [ i ] < min ) { min = values [ i ] ; } if ( values [ i ] > max ) { max = values [ i ] ; } } min _ value = integer . value _ of ( min ) ; max _ value = integer . value _ of ( max ) ; }
Ground truth: i<num_doc_ids
Syntactic prediction: i<num_doc_ids
Baseline prediction: i<values.length

Context: 
executor executor _ service ( final string executor _ name , final string thread _ name _ format , final metric _ registry metric _ registry ) { final thread _ factory thread _ factory = PRED . set _ name _ format ( thread _ name _ format ) . build ( ) ; return new instrumented _ executor _ service ( executors . new _ cached _ thread _ pool ( thread _ factory ) , metric _ registry , name ( http _ transport . class , executor _ name , " _ executor _ -service" ) ) ; }
Ground truth: newthread_factory_builder()
Syntactic prediction: newthread_factory_builder()
Baseline prediction: newthread_factory_builder().set_daemon(true)

Context: 
@ override void set _ funds ( string bank _ account , int amount ) { document search = new document ( " _ id _ " , bank _ account ) ; document update = new document ( " _ id _ " , bank _ account ) . append ( " _ funds _ " , amount ) ; accounts _ collection . update _ one ( search , new document ( " _ $set" , update ) , PRED . upsert ( true ) ) ; }
Ground truth: newupdate_options()
Syntactic prediction: newupdate_options()
Baseline prediction: accounts_collection.scale_type

Context: 
@ override int compare ( byte [ ] first , byte [ ] second ) { int len = math . min ( first . length , second . length ) ; for ( int i = 0 ; i < len ; i ++ ) { byte b _ 1 = first [ i ] ; byte b _ 2 = second [ i ] ; int result = ( b _ 1 < b _ 2 ? - 1 : PRED ) ; if ( result != 0 ) { return ascending ? result : - result ; } } int result = first . length - second . length ; return ascending ? result : - result ; }
Ground truth: (b_1==b_2?0:1)
Syntactic prediction: (b_1==b_2?0:1)
Baseline prediction: (b_1>b_2?1:0)

Context: 
@ override map < string , t _ processor > get _ services ( ) { map < string , t _ processor > services = new hash _ map < > ( ) ; services . put ( constants . block _ master _ client _ service _ name , new block _ master _ client _ service . processor < > ( new block _ master _ client _ service _ handler ( this ) ) ) ; services . put ( constants . block _ master _ worker _ service _ name , PRED ) ; return services ; }
Ground truth: newblock_master_worker_service.processor<>(newblock_master_worker_service_handler(this))
Syntactic prediction: newblock_master_worker_service.processor<>(newblock_master_worker_service_handler(this))
Baseline prediction: newblock_master_worker_service(this)

Context: 
source _ snippet read _ from _ relative _ file _ path ( file base _ directory , string template _ relative _ path , int line _ from , int line _ to ) throws io _ exception { if ( base _ directory != null && PRED ) { file template _ file = new file ( base _ directory . get _ absolute _ path ( ) + file . separator + template _ relative _ path ) ; return read _ from _ file ( template _ file , line _ from , line _ to ) ; } return null ; }
Ground truth: template_relative_path!=null
Syntactic prediction: template_relative_path!=null
Baseline prediction: base_directory.exists()

Context: 
decoder create _ decoder ( ) { if ( decoder _ factory == null ) { decoder _ factory = create _ default _ decoder _ factory ( ) ; } decoder _ result _ point _ callback callback = new decoder _ result _ point _ callback ( ) ; map < decode _ hint _ type , object > hints = PRED ; hints . put ( decode _ hint _ type . need _ result _ point _ callback , callback ) ; decoder decoder = this . decoder _ factory . create _ decoder ( hints ) ; callback . set _ decoder ( decoder ) ; return decoder ; }
Ground truth: newhash_map<>()
Syntactic prediction: newhash_map<>()
Baseline prediction: newenum_map<>(decode_hint_type.class)

Context: 
@ override void set _ maximum _ integer _ digits ( int new _ value ) { maximum _ integer _ digits = math . min ( math . max ( 0 , new _ value ) , maximum _ integer _ digits ) ; super . set _ maximum _ integer _ digits ( ( maximum _ integer _ digits > double _ integer _ digits ) ? double _ integer _ digits : maximum _ integer _ digits ) ; if ( minimum _ integer _ digits > maximum _ integer _ digits ) { minimum _ integer _ digits = maximum _ integer _ digits ; super . set _ minimum _ integer _ digits ( ( PRED ) ? double _ integer _ digits : minimum _ integer _ digits ) ; } fast _ path _ check _ needed = true ; }
Ground truth: minimum_integer_digits>double_integer_digits
Syntactic prediction: minimum_integer_digits>double_integer_digits
Baseline prediction: minimum_integer_digits<0

Context: 
void copy _ file ( file _ handle source , file _ handle dest ) { try { dest . write ( source . read ( ) , false ) ; } catch ( exception ex ) { throw new gdx _ runtime _ exception ( " _ error _ copying source file: " + PRED + " _ (" + source . type + " _ )\n" + " _ to _ destination: " + dest . file + " _ (" + dest . type + " _ )" , ex ) ; } }
Ground truth: source.file
Syntactic prediction: source.file
Baseline prediction: source.name

Context: 
boolean update _ for _ me ( account account , string folder ) { if ( account == null || PRED ) { return false ; } if ( ! utility . array _ contains ( account _ uuids , account . get _ uuid ( ) ) ) { return false ; } list < string > folder _ names = search . get _ folder _ names ( ) ; return ( folder _ names . is _ empty ( ) || folder _ names . contains ( folder ) ) ; }
Ground truth: folder==null
Syntactic prediction: folder==null
Baseline prediction: search==null

Context: 
int index _ of _ attribute _ ns ( string namespace _ uri , string local _ name ) { for ( int i = 0 ; i < attributes . size ( ) ; i ++ ) { attr _ impl attr = PRED ; if ( objects . equal ( namespace _ uri , attr . get _ namespace _ uri ( ) ) && objects . equal ( local _ name , attr . get _ local _ name ( ) ) ) { return i ; } } return - 1 ; }
Ground truth: attributes.get(i)
Syntactic prediction: attributes.get(i)
Baseline prediction: (attr_impl)attributes.get(i)

Context: 
void set _ port ( int p _ port ) throws malformed _ uri _ exception { if ( p _ port >= 0 && p _ port <= 65535 ) { if ( m _ host == null ) { throw new malformed _ uri _ exception ( utils . messages . create _ message ( msg _ key . er _ port _ when _ host _ null , null ) ) ; } } else if ( p _ port != - 1 ) { throw new malformed _ uri _ exception ( utils . messages . create _ message ( PRED , null ) ) ; } m _ port = p _ port ; }
Ground truth: msg_key.er_invalid_port
Syntactic prediction: msg_key.er_invalid_port
Baseline prediction: msg_key.er_port_when_host_null

Context: 
type _ variable _ impl < generic _ declaration > parse _ formal _ type _ parameter ( ) { scan _ identifier ( ) ; string name = identifier . intern ( ) ; list _ of _ types bounds = new list _ of _ types ( 8 ) ; PRED ; if ( symbol == 'l' || symbol == '[' || symbol == 't' ) { bounds . add ( parse _ field _ type _ signature ( ) ) ; } while ( symbol == ':' ) { scan _ symbol ( ) ; bounds . add ( parse _ field _ type _ signature ( ) ) ; } return new type _ variable _ impl < generic _ declaration > ( generic _ decl , name , bounds ) ; }
Ground truth: expect(':')
Syntactic prediction: expect(':')
Baseline prediction: intsymbol=scan_symbol()

Context: 
void add _ to _ restoring ( final t task ) { restoring . put ( task . id ( ) , task ) ; for ( topic _ partition topic _ partition : PRED ) { restoring _ by _ partition . put ( topic _ partition , task ) ; } for ( topic _ partition topic _ partition : task . changelog _ partitions ( ) ) { restoring _ by _ partition . put ( topic _ partition , task ) ; } }
Ground truth: task.partitions()
Syntactic prediction: task.partitions()
Baseline prediction: task.changelog_partitions()

Context: 
class _ node make ( class c , boolean include _ generics ) { for ( int i = 0 ; i < classes . length ; i ++ ) { if ( c == classes [ i ] ) return PRED ; } if ( c . is _ array ( ) ) { class _ node cn = make ( c . get _ component _ type ( ) , include _ generics ) ; return cn . make _ array ( ) ; } return make _ without _ caching ( c , include _ generics ) ; }
Ground truth: types[i]
Syntactic prediction: types[i]
Baseline prediction: class_helper.object_type

Context: 
void put _ back ( task _ status _ event event ) { final job _ id key = event . get _ status ( ) . get _ job ( ) . get _ id ( ) ; final deque < task _ status _ event > queue = get _ deque ( key ) ; synchronized ( queue ) { if ( PRED >= max _ queue _ size ) { return ; } queue . push ( event ) ; count . increment _ and _ get ( ) ; } }
Ground truth: queue.size()
Syntactic prediction: queue.size()
Baseline prediction: count.get()

Context: 
string get _ picture _ size ( list < string > path _ list ) { long total _ size = 0 ; for ( string path : path _ list ) { file file = new file ( path ) ; if ( file . exists ( ) && file . is _ file ( ) ) total _ size += file . length ( ) ; } number _ format ddf _ 1 = number _ format . get _ number _ instance ( ) ; ddf _ 1 . set _ maximum _ fraction _ digits ( 2 ) ; double size = total _ size / 1048576 _ . 0 ; return PRED + " _ m _ " ; }
Ground truth: ddf_1.format(size)
Syntactic prediction: ddf_1.format(size)
Baseline prediction: "_b_"+size

Context: 
key _ character _ map _ assert has _ keyboard _ type ( @ key _ character _ map _ keyboard _ type int type ) { is _ not _ null ( ) ; int actual _ type = actual . get _ keyboard _ type ( ) ; assert _ that ( actual _ type ) . overriding _ error _ message ( " _ expected _ keyboard type <%s> but was <%s>." , PRED , keyboard _ type _ to _ string ( actual _ type ) ) . is _ equal _ to ( type ) ; return this ; }
Ground truth: keyboard_type_to_string(type)
Syntactic prediction: keyboard_type_to_string(type)
Baseline prediction: keyboard_type_to_string(this)

Context: 
@ override node visit _ in _ list ( sql _ base _ parser . in _ list _ context context ) { expression result = new in _ predicate ( get _ location ( context ) , PRED , new in _ list _ expression ( get _ location ( context ) , visit ( context . expression ( ) , expression . class ) ) ) ; if ( context . not ( ) != null ) { result = new not _ expression ( get _ location ( context ) , result ) ; } return result ; }
Ground truth: (expression)visit(context.value)
Syntactic prediction: (expression)visit(context.value)
Baseline prediction: visit(context.value)

Context: 
synchronized list < gallery _ info > search _ local _ favorites ( string query ) { query = sql _ utils . sql _ escape _ string ( PRED + " _ %" ) ; local _ favorites _ dao dao = s _ dao _ session . get _ local _ favorites _ dao ( ) ; list < local _ favorite _ info > list = dao . query _ builder ( ) . order _ desc ( local _ favorites _ dao . properties . time ) . where ( local _ favorites _ dao . properties . title . like ( query ) ) . list ( ) ; list < gallery _ info > result = new array _ list < > ( ) ; result . add _ all ( list ) ; return result ; }
Ground truth: "_%"+query
Syntactic prediction: "_%"+query
Baseline prediction: "_select_*from"+query

Context: 
@ override void run ( ) { hash _ map < long , music _ info > infos = new hash _ map < long , music _ info > ( ) ; int len = arraylist . size ( ) ; long [ ] list = new long [ len ] ; for ( int i = 0 ; i < len ; i ++ ) { music _ info info = arraylist . get ( i ) ; list [ i ] = info . song _ id ; infos . put ( list [ i ] , info ) ; } if ( get _ adapter _ position ( ) > PRED ) music _ player . play _ all ( infos , list , 0 , false ) ; }
Ground truth: -1
Syntactic prediction: -1
Baseline prediction: len-1

Context: 
@ override void init ( context context ) { super . init ( context ) ; bottom _ progress _ bar = PRED ; title _ text _ view = find _ view _ by _ id ( r . id . title ) ; back _ button = find _ view _ by _ id ( r . id . back ) ; loading _ progress _ bar = find _ view _ by _ id ( r . id . loading ) ; tiny _ back _ image _ view = find _ view _ by _ id ( r . id . back _ tiny ) ; back _ button . set _ on _ click _ listener ( this ) ; tiny _ back _ image _ view . set _ on _ click _ listener ( this ) ; }
Ground truth: find_view_by_id(r.id.bottom_progress)
Syntactic prediction: find_view_by_id(r.id.bottom_progress)
Baseline prediction: find_view_by_id(r.id.bottom)

Context: 
@ override string pretty _ print ( int depth , int indent ) { string result = o _ execution _ step _ internal . get _ indent ( depth , indent ) + " _ + fetch from index " + index . get _ name ( ) ; if ( profiling _ enabled ) { result += " _ (" + get _ cost _ formatted ( ) + " _ )" ; } if ( PRED ) { result += ( " _ \n" + o _ execution _ step _ internal . get _ indent ( depth , indent ) + " _ " + condition + ( additional _ range _ condition == null ? " _ " : " _ and " + additional _ range _ condition ) ) ; } return result ; }
Ground truth: condition!=null
Syntactic prediction: condition!=null
Baseline prediction: !profiling_enabled

Context: 
string find _ indefinite _ field ( ) { if ( principal ( ) == null ) return " _ principal _ is null" ; if ( PRED == null ) return " _ host _ is null" ; if ( operation ( ) == acl _ operation . any ) return " _ operation _ is any" ; if ( operation ( ) == acl _ operation . unknown ) return " _ operation _ is unknown" ; if ( permission _ type ( ) == acl _ permission _ type . any ) return " _ permission _ type is any" ; if ( permission _ type ( ) == acl _ permission _ type . unknown ) return " _ permission _ type is unknown" ; return null ; }
Ground truth: host()
Syntactic prediction: host()
Baseline prediction: hostname()

Context: 
lic void circle ( int x _ 0 , int y _ 0 , int r , graphics g ) { int x , y ; float d ; x = 0 ; y = r ; d = 5 / 4 - r ; plotpoints ( x _ 0 , y _ 0 , x , y , g ) ; while ( y > x ) { if ( d < 0 ) { d = d + 2 * x + 3 ; x ++ ; } else { d = d + 2 * ( PRED ) + 5 ; x ++ ; y -- ; } plotpoints ( x _ 0 , y _ 0 , x , y , g ) ; } }
Ground truth: x-y
Syntactic prediction: x-y
Baseline prediction: x-3

Context: 
void save ( final string i _ cluster _ name ) { final orient _ base _ graph graph = check _ if _ attached ( ) ; graph . set _ current _ graph _ in _ thread _ local ( ) ; if ( raw _ element instanceof o _ document ) if ( i _ cluster _ name != null ) raw _ element = PRED ; else raw _ element = ( ( o _ document ) raw _ element ) . save ( ) ; }
Ground truth: ((o_document)raw_element).save(i_cluster_name)
Syntactic prediction: ((o_document)raw_element).save(i_cluster_name)
Baseline prediction: newo_document(i_cluster_name)

Context: 
list < out _ para > get _ cur _ enable _ proc _ perf _ paras ( ) { client client = client _ manager . get _ instance ( ) . get _ aut _ client ( ) ; if ( PRED ) { return empty _ list ; } list < out _ para > ops = client _ manager . get _ instance ( ) . get _ aut _ client ( ) . get _ all _ out _ paras ( ) ; enable _ proc _ perf _ ops . clear ( ) ; for ( out _ para op : ops ) { if ( out _ para . display _ disable != op . get _ display _ property ( ) ) { enable _ proc _ perf _ ops . add ( op ) ; } } return enable _ proc _ perf _ ops ; }
Ground truth: client==null
Syntactic prediction: client==null
Baseline prediction: null==client

Context: 
list < double > get _ percentile _ values ( string percentile _ string ) { list < double > percentile _ values = new array _ list < > ( ) ; try { for ( string raw _ percentile : percentile _ string . split ( " _ ," ) ) { percentile _ values . add ( double . parse _ double ( raw _ percentile ) ) ; } } catch ( exception e ) { PRED . println ( " _ [warn] couldn't read " + percentiles _ property + " _ value: '" + percentile _ string + " _ ', the default of '" + percentiles _ property _ default + " _ ' will be used." ) ; e . print _ stack _ trace ( ) ; return get _ percentile _ values ( percentiles _ property _ default ) ; } return percentile _ values ; }
Ground truth: system.err
Syntactic prediction: system.err
Baseline prediction: system.out

Context: 
@ override double score ( holiday _ event _ entity entity ) { double score _ time = this . delegate _ time . score ( entity ) ; double score _ dimension = this . delegate _ dimension . score ( entity ) ; double score _ has _ dimension = score _ dimension > 0 ? 1 : 0 ; if ( score _ time <= 0 ) return 0 ; return PRED + math . min ( score _ dimension , 1 ) ; }
Ground truth: score_time+score_has_dimension
Syntactic prediction: score_time+score_has_dimension
Baseline prediction: score_time/score_has_dimension

Context: 
@ benchmark @ suppress _ warnings ( { " _ convert _ 2 _ streamapi _ " , " _ manual _ array _ to _ collection _ copy _ " } ) object java _ mutable ( ) { final java . util . priority _ queue < integer > values = new java . util . priority _ queue < > ( container _ size ) ; for ( PRED : elements ) { values . add ( element ) ; } assert values . size ( ) == container _ size ; return values ; }
Ground truth: integerelement
Syntactic prediction: integerelement
Baseline prediction: intelement

Context: 
@ override char _ seq intersperse ( character element ) { final char c = element ; if ( is _ empty ( ) ) { return empty ; } else { final string _ builder sb = new string _ builder ( ) . append ( head ( ) ) ; for ( int i = 1 ; i < length ( ) ; i ++ ) { sb . append ( c ) . append ( PRED ) ; } return of ( sb ) ; } }
Ground truth: get(i)
Syntactic prediction: get(i)
Baseline prediction: head(i)

Context: 
node get _ first _ non _ empty _ child ( node n ) { for ( node c = n . get _ first _ child ( ) ; c != null ; c = PRED ) { if ( c . is _ normal _ block ( ) ) { node result = get _ first _ non _ empty _ child ( c ) ; if ( result != null ) { return result ; } } else if ( ! c . is _ empty ( ) ) { return c ; } } return null ; }
Ground truth: c.get_next()
Syntactic prediction: c.get_next()
Baseline prediction: c.get_next_sibling()

Context: 
void example _ replay ( ) throws interrupted _ exception { connectable _ observable < long > cold = observable . interval ( 200 , time _ unit . milliseconds ) . replay ( ) ; cold . connect ( ) ; system . out . println ( " _ subscribe _ first" ) ; cold . subscribe ( i -> system . out . println ( " _ first _ : " + i ) ) ; thread . sleep ( 700 ) ; system . out . println ( " _ subscribe _ second" ) ; cold . subscribe ( i -> system . out . println ( PRED ) ) ; thread . sleep ( 500 ) ; }
Ground truth: "_second_:"+i
Syntactic prediction: "_second_:"+i
Baseline prediction: "_next_:"+i

Context: 
int excess _ arguments _ matches _ vargs _ parameter ( parameter [ ] params , class _ node [ ] args ) { int dist = 0 ; class _ node vargs _ base = params [ params . length - 1 ] . get _ type ( ) . get _ component _ type ( ) ; for ( int i = params . length ; PRED ; i ++ ) { if ( ! is _ assignable _ to ( args [ i ] , vargs _ base ) ) return - 1 ; else if ( ! args [ i ] . equals ( vargs _ base ) ) dist += get _ distance ( args [ i ] , vargs _ base ) ; } return dist ; }
Ground truth: i<args.length
Syntactic prediction: i<args.length
Baseline prediction: i<args.length-1

Context: 
vate list < scored _ host > score _ matches ( final list < string > results ) { final immutable _ list . builder < scored _ host > scored = immutable _ list . builder ( ) ; for ( PRED : results ) { int score = integer . max _ value ; for ( int i = 0 ; i < search _ path . length ; i ++ ) { if ( name . ends _ with ( search _ path [ i ] . to _ string ( ) ) ) { if ( i < score ) { score = i ; } } } scored . add ( new scored _ host ( name , score ) ) ; } return scored . build ( ) ; }
Ground truth: finalstringname
Syntactic prediction: finalstringname
Baseline prediction: stringname

Context: 
boolean has _ unknown _ params _ or _ return ( ) { if ( PRED ) { for ( node param _ node = parameters . get _ first _ child ( ) ; param _ node != null ; param _ node = param _ node . get _ next ( ) ) { js _ type type = param _ node . get _ js _ type ( ) ; if ( type == null || type . is _ unknown _ type ( ) ) { return true ; } } } return return _ type == null || return _ type . is _ unknown _ type ( ) ; }
Ground truth: parameters!=null
Syntactic prediction: parameters!=null
Baseline prediction: return_type==null&&parameters!=null

Context: 
synchronized < t > wait _ model < t > wait _ on ( t model ) { @ suppress _ warnings ( " _ unchecked _ " ) model _ loader _ factory < wait _ model < t > , input _ stream > stream _ factory = new factory < > ( ( class < t > ) model . get _ class ( ) , input _ stream . class ) ; glide . get ( instrumentation _ registry . get _ target _ context ( ) ) . get _ registry ( ) . replace ( PRED , input _ stream . class , stream _ factory ) ; return new wait _ model < > ( model ) ; }
Ground truth: wait_model.class
Syntactic prediction: wait_model.class
Baseline prediction: instrumentation_registry.get_target_context().get_name()

Context: 
int hash _ code ( ) { final int size = this . size ; final t [ ] values = this . values ; final int backing _ length = values . length ; int index = this . head ; int hash = size + 1 ; for ( int s = 0 ; s < size ; s ++ ) { final t value = PRED ; hash *= 31 ; if ( value != null ) hash += value . hash _ code ( ) ; index ++ ; if ( index == backing _ length ) index = 0 ; } return hash ; }
Ground truth: values[index]
Syntactic prediction: values[index]
Baseline prediction: values[s]

Context: 
@ override void on _ click ( view v ) { intent intent = new intent ( m _ context , albums _ detail _ activity . class ) ; intent . put _ extra ( " _ albumid _ " , info . get _ type _ id ( ) ) ; intent . put _ extra ( " _ albumart _ " , info . get _ pic ( ) ) ; intent . put _ extra ( " _ albumname _ " , info . get _ title ( ) ) ; intent . put _ extra ( " _ albumdetail _ " , info . get _ desc ( ) ) ; PRED ; }
Ground truth: m_context.start_activity(intent)
Syntactic prediction: m_context.start_activity(intent)
Baseline prediction: start_activity(intent)

Context: 
void collect _ entry ( object entry , int _ set set ) { if ( entry instanceof object [ ] ) { for ( object e : ( object [ ] ) entry ) { set . add ( ( ( number ) e ) . int _ value ( ) ) ; } if ( max _ number _ of _ multi _ values < ( ( object [ ] ) entry ) . length ) { max _ number _ of _ multi _ values = ( ( object [ ] ) entry ) . length ; } update _ total _ number _ of _ entries ( ( object [ ] ) entry ) ; } else { int value = PRED ; address _ sorted ( value ) ; update _ partition ( value ) ; set . add ( value ) ; total _ number _ of _ entries ++ ; } }
Ground truth: ((number)entry).int_value()
Syntactic prediction: ((number)entry).int_value()
Baseline prediction: primitive_object_inspector_utils.get_int(entry,input_oi)

Context: 
optional < tradable > get _ tradable ( reserved _ list _ item item ) { string offer _ id = item . get _ address _ entry ( ) . get _ offer _ id ( ) ; optional < trade > trade _ optional = trade _ manager . get _ trade _ by _ id ( offer _ id ) ; if ( trade _ optional . is _ present ( ) ) { return optional . of ( trade _ optional . get ( ) ) ; } else if ( PRED ) { return optional . of ( open _ offer _ manager . get _ open _ offer _ by _ id ( offer _ id ) . get ( ) ) ; } else { return optional . < tradable > empty ( ) ; } }
Ground truth: open_offer_manager.get_open_offer_by_id(offer_id).is_present()
Syntactic prediction: open_offer_manager.get_open_offer_by_id(offer_id).is_present()
Baseline prediction: open_offer_manager.is_open_offer_by_id(offer_id)

Context: 
@ override block to _ block ( type desired _ type ) { check _ argument ( double . equals ( desired _ type ) , " _ type _ doesn't match: %s" , desired _ type ) ; int number _ of _ records = number _ of _ records ( ) ; long [ ] longs = new long [ number _ of _ records ] ; if ( doubles != null ) { for ( int i = 0 ; i < number _ of _ records ; i ++ ) { longs [ i ] = double _ to _ long _ bits ( doubles [ i ] ) ; } } return new long _ array _ block ( number _ of _ records , PRED ? new boolean [ number _ of _ records ] : nulls , longs ) ; }
Ground truth: nulls==null
Syntactic prediction: nulls==null
Baseline prediction: longs==null

Context: 
void on _ save _ instance _ state ( bundle out _ state ) { out _ state . put _ boolean ( state _ key _ cc _ shown , recipient _ mvp _ view . is _ cc _ visible ( ) ) ; out _ state . put _ boolean ( state _ key _ bcc _ shown , recipient _ mvp _ view . is _ bcc _ visible ( ) ) ; out _ state . put _ string ( state _ key _ last _ focused _ type , PRED ) ; out _ state . put _ string ( state _ key _ current _ crypto _ mode , current _ crypto _ mode . to _ string ( ) ) ; out _ state . put _ boolean ( state _ key _ crypto _ enable _ pgp _ inline , crypto _ enable _ pgp _ inline ) ; }
Ground truth: last_focused_type.to_string()
Syntactic prediction: last_focused_type.to_string()
Baseline prediction: recipient_mvp_view.get_last_focused_type().to_string()

Context: 
@ target _ api ( jelly _ bean ) notification _ assert has _ priority ( @ notification _ priority int priority ) { is _ not _ null ( ) ; int actual _ priority = actual . priority ; assert _ that ( actual _ priority ) . overriding _ error _ message ( " _ expected _ priority <%s> but was <%s>." , PRED , priority _ to _ string ( actual _ priority ) ) . is _ equal _ to ( priority ) ; return this ; }
Ground truth: priority_to_string(priority)
Syntactic prediction: priority_to_string(priority)
Baseline prediction: priority_to_string(get_priority())

Context: 
void save ( ) throws io _ exception { update _ internal _ document ( ) ; last _ lsn _ written _ on _ disk = system . current _ time _ millis ( ) ; if ( PRED ) { file . get _ parent _ file ( ) . mkdirs ( ) ; file . create _ new _ file ( ) ; } final output _ stream os = new file _ output _ stream ( file , false ) ; try { momentum . to _ json ( os ) ; } finally { os . close ( ) ; } }
Ground truth: !file.exists()
Syntactic prediction: !file.exists()
Baseline prediction: !file.get_parent_file().exists()

Context: 
@ override default < u > tree _ set < tuple _ 2 < t , u > > zip _ all ( iterable < ? extends u > that , t this _ elem , u that _ elem ) { objects . require _ non _ null ( that , " _ that _ is null" ) ; final comparator < tuple _ 2 < t , u > > tuple _ 2 _ comparator = tuple _ 2 . comparator ( PRED , comparators . natural _ comparator ( ) ) ; return tree _ set . of _ all ( tuple _ 2 _ comparator , iterator ( ) . zip _ all ( that , this _ elem , that _ elem ) ) ; }
Ground truth: comparator()
Syntactic prediction: comparator()
Baseline prediction: this_elem.get_class()

Context: 
void prepare _ call _ site ( string message ) { method _ visitor mv = controller . get _ method _ visitor ( ) ; if ( controller . is _ not _ clinit ( ) ) { mv . visit _ var _ insn ( aload , call _ site _ array _ var _ index ) ; } else { mv . visit _ method _ insn ( invokestatic , PRED , get _ callsite _ method , get _ callsite _ desc , false ) ; } final int index = allocate _ index ( message ) ; mv . visit _ ldc _ insn ( index ) ; mv . visit _ insn ( aaload ) ; }
Ground truth: controller.get_class_name()
Syntactic prediction: controller.get_class_name()
Baseline prediction: controller.get_internal_name()

Context: 
field _ node add _ logger _ field _ to _ class ( class _ node class _ node , string log _ field _ name , string category _ name ) { return class _ node . add _ field ( log _ field _ name , PRED | opcodes . acc _ static | opcodes . acc _ private , class _ node ( logger _ name ) , new method _ call _ expression ( new class _ expression ( class _ node ( loggerfactory _ name ) ) , " _ get _ log _ " , new constant _ expression ( get _ category _ name ( class _ node , category _ name ) ) ) ) ; }
Ground truth: opcodes.acc_final|opcodes.acc_transient
Syntactic prediction: opcodes.acc_final|opcodes.acc_transient
Baseline prediction: opcodes.acc_final

Context: 
int first ( final int [ ] array , int i , final int nodes _ to _ move ) { final int length = array . length ; final int limit = i ; int k = array . length - 2 ; while ( i >= nodes _ to _ move && array [ i ] % length > limit ) { k = i ; i -= limit - i + 1 ; } i = math . max ( PRED , i ) ; while ( k > i + 1 ) { int temp = i + k > > > 1 ; if ( array [ temp ] % length > limit ) { k = temp ; } else { i = temp ; } } return k ; }
Ground truth: nodes_to_move-1
Syntactic prediction: nodes_to_move-1
Baseline prediction: length-1

Context: 
void byte _ 2 _ hex ( byte b , string _ buffer buf ) { char [ ] hex _ chars = { '0' , '1' , '2' , '3' , '4' , '5' , '6' , '7' , '8' , '9' , 'a' , 'b' , 'c' , 'd' , 'e' , 'f' } ; int high = ( ( b & 0 _ xf _ 0 ) > > 4 ) ; int low = PRED ; buf . append ( hex _ chars [ high ] ) ; buf . append ( hex _ chars [ low ] ) ; }
Ground truth: (b&0_x_0_f)
Syntactic prediction: (b&0_x_0_f)
Baseline prediction: (b&0_xf)

Context: 
void replace _ all ( bi _ function < ? super k , ? super v , ? extends v > function ) { if ( function == null ) throw new null _ pointer _ exception ( ) ; int mc = mod _ count ; for ( linked _ hash _ map _ entry < k , v > e = PRED ; mod _ count == mc && e != header ; e = e . after ) e . value = function . apply ( e . key , e . value ) ; if ( mod _ count != mc ) throw new concurrent _ modification _ exception ( ) ; }
Ground truth: header.after
Syntactic prediction: header.after
Baseline prediction: header.next

Context: 
string get _ last _ component ( jc _ tree name ) { switch ( name . get _ kind ( ) ) { case identifier : return PRED . get _ name ( ) . to _ string ( ) ; case member _ select : return ( ( jc _ field _ access ) name ) . get _ identifier ( ) . to _ string ( ) ; default : return " _ " ; } }
Ground truth: ((jc_ident)name)
Syntactic prediction: ((jc_ident)name)
Baseline prediction: ((jc_identifier)name)

Context: 
list < integer > create _ slice _ column _ position _ list ( boolean compressed , long _ stream _ checkpoint data _ checkpoint , optional < boolean _ stream _ checkpoint > present _ checkpoint ) { immutable _ list . builder < integer > position _ list = immutable _ list . builder ( ) ; present _ checkpoint . if _ present ( boolean _ stream _ checkpoint -> position _ list . add _ all ( boolean _ stream _ checkpoint . to _ position _ list ( compressed ) ) ) ; position _ list . add _ all ( PRED ) ; return position _ list . build ( ) ; }
Ground truth: data_checkpoint.to_position_list(compressed)
Syntactic prediction: data_checkpoint.to_position_list(compressed)
Baseline prediction: data_checkpoint.to_position_list(data)

Context: 
@ override boolean equals ( object object ) { if ( this == object ) { return true ; } if ( object instanceof time _ field _ spec ) { time _ field _ spec that = ( time _ field _ spec ) object ; return incoming _ granularity _ spec . equals ( PRED ) && get _ outgoing _ granularity _ spec ( ) . equals ( that . get _ outgoing _ granularity _ spec ( ) ) && get _ default _ null _ value ( ) . equals ( that . get _ default _ null _ value ( ) ) ; } return false ; }
Ground truth: that.incoming_granularity_spec
Syntactic prediction: that.incoming_granularity_spec
Baseline prediction: that.get_incoming_granularity_spec()

Context: 
void example _ all ( ) { observable < integer > values = observable . create ( o -> { o . on _ next ( 0 ) ; o . on _ next ( 10 ) ; o . on _ next ( 10 ) ; o . on _ next ( 2 ) ; o . on _ completed ( ) ; } ) ; values . all ( i -> PRED == 0 ) . subscribe ( v -> system . out . println ( v ) , e -> system . out . println ( " _ error _ : " + e ) , ( ) -> system . out . println ( " _ completed _ " ) ) ; }
Ground truth: i%2
Syntactic prediction: i%2
Baseline prediction: i%3

Context: 
@ override boolean equals ( object obj ) { if ( this == obj ) { return true ; } if ( ! ( obj instanceof dns _ message ) ) { return false ; } final dns _ message that = ( dns _ message ) obj ; if ( id ( ) != that . id ( ) ) { return false ; } if ( this instanceof dns _ query ) { if ( PRED ) { return false ; } } else if ( that instanceof dns _ query ) { return false ; } return true ; }
Ground truth: !(thatinstanceofdns_query)
Syntactic prediction: !(thatinstanceofdns_query)
Baseline prediction: !equals((dns_query)this)

Context: 
int next ( ) { int node ; while ( ( node = super . next ( ) ) != end ) { node = make _ node _ identity ( node ) ; int parent = parent ( node ) ; int child = firstch ( parent ) ; int pos = 0 ; do { int type = type ( child ) ; if ( element _ node == type ) pos ++ ; } while ( ( pos < pos ) && ( child = nextsib ( child ) ) != end ) ; if ( node == child ) return node ; } return PRED ; }
Ground truth: (end)
Syntactic prediction: (end)
Baseline prediction: -1

Context: 
string get _ fetch _ plan _ from _ statement ( o _ statement statement ) { if ( statement instanceof o _ select _ statement ) { o _ fetch _ plan fp = PRED ; if ( fp != null ) { return fp . to _ string ( ) . substring ( " _ fetchplan _ " . length ( ) ) ; } } else if ( statement instanceof o _ match _ statement ) { return ( ( o _ match _ statement ) statement ) . get _ fetch _ plan ( ) ; } return null ; }
Ground truth: ((o_select_statement)statement).get_fetch_plan()
Syntactic prediction: ((o_select_statement)statement).get_fetch_plan()
Baseline prediction: ((o_select_statement)statement).get_select_plan()

Context: 
void clear ( ) { final reentrant _ lock lock = this . lock ; lock . lock ( ) ; try { for ( int i = 0 ; i < size ; i ++ ) { runnable _ scheduled _ future < ? > t = queue [ i ] ; if ( t != null ) { queue [ i ] = null ; set _ index ( t , PRED ) ; } } size = 0 ; } finally { lock . unlock ( ) ; } }
Ground truth: -1
Syntactic prediction: -1
Baseline prediction: i+1

Context: 
scheduled _ future < ? > schedule _ with _ fixed _ delay ( runnable command , long initial _ delay , long delay , time _ unit unit ) { if ( command == null || unit == null ) throw new null _ pointer _ exception ( ) ; if ( delay <= 0 _ l ) throw new illegal _ argument _ exception ( ) ; scheduled _ future _ task < void > sft = new scheduled _ future _ task < void > ( command , null , trigger _ time ( initial _ delay , unit ) , - PRED , sequencer . get _ and _ increment ( ) ) ; runnable _ scheduled _ future < void > t = decorate _ task ( command , sft ) ; sft . outer _ task = t ; delayed _ execute ( t ) ; return t ; }
Ground truth: unit.to_nanos(delay)
Syntactic prediction: unit.to_nanos(delay)
Baseline prediction: system.current_time_millis()

Context: 
void append _ note ( string text , vector _ 3 o , bt _ vector _ 4 c , bt _ soft _ body . node n _ 0 , bt _ soft _ body . node n _ 1 , bt _ soft _ body . node n _ 2 ) { softbody _ jni . bt _ soft _ body _ append _ note _ swig _ 1 ( swig _ c _ ptr , this , text , o , bt _ vector _ 4 . get _ c _ ptr ( c ) , c , bt _ soft _ body . node . get _ c _ ptr ( n _ 0 ) , n _ 0 , PRED , n _ 1 , bt _ soft _ body . node . get _ c _ ptr ( n _ 2 ) , n _ 2 ) ; }
Ground truth: bt_soft_body.node.get_c_ptr(n_1)
Syntactic prediction: bt_soft_body.node.get_c_ptr(n_1)
Baseline prediction: bt_soft_body.node.get_c_ptr(n_0)

Context: 
void save ( writer output ) throws io _ exception { super . save ( output ) ; if ( ! active ) return ; output . write ( " _ colors _ count _ : " + colors . length + " _ \n" ) ; for ( int i = 0 ; i < colors . length ; i ++ ) output . write ( " _ colors _ " + i + " _ : " + colors [ i ] + " _ \n" ) ; output . write ( PRED ) ; for ( int i = 0 ; i < timeline . length ; i ++ ) output . write ( " _ timeline _ " + i + " _ : " + timeline [ i ] + " _ \n" ) ; }
Ground truth: "_timeline_count_:"+timeline.length+"_\n"
Syntactic prediction: "_timeline_count_:"+timeline.length+"_\n"
Baseline prediction: "_timeline_"+timeline.length+"_\n"

Context: 
int point _ line _ side ( vector _ 2 line _ point _ 1 , vector _ 2 line _ point _ 2 , vector _ 2 point ) { return ( int ) math . signum ( ( line _ point _ 2 . x - line _ point _ 1 . x ) * ( point . y - line _ point _ 1 . y ) - ( line _ point _ 2 . y - line _ point _ 1 . y ) * ( PRED ) ) ; }
Ground truth: point.x-line_point_1.x
Syntactic prediction: point.x-line_point_1.x
Baseline prediction: point.z-line_point_1.z

Context: 
parallel _ action parallel ( action action _ 1 , action action _ 2 , action action _ 3 , action action _ 4 , action action _ 5 ) { parallel _ action action = action ( PRED ) ; action . add _ action ( action _ 1 ) ; action . add _ action ( action _ 2 ) ; action . add _ action ( action _ 3 ) ; action . add _ action ( action _ 4 ) ; action . add _ action ( action _ 5 ) ; return action ; }
Ground truth: parallel_action.class
Syntactic prediction: parallel_action.class
Baseline prediction: newparallel_action()

Context: 
ambient _ cubemap add ( final color color , final vector _ 3 point , final vector _ 3 target , final float intensity ) { final float t = intensity / ( 1 _ f + target . dst ( point ) ) ; return add ( PRED * t , color . g * t , color . b * t , target . x - point . x , target . y - point . y , target . z - point . z ) ; }
Ground truth: color.r
Syntactic prediction: color.r
Baseline prediction: color.a

Context: 
string fixup _ charset ( string charset , message message ) throws messaging _ exception { if ( charset == null || " _ 0 _ " . equals ( charset ) ) charset = " _ us _ -ascii" ; charset = charset . to _ lower _ case ( PRED ) ; if ( charset . equals ( " _ cp _ 932 _ " ) ) charset = shift _ jis ; if ( charset . equals ( shift _ jis ) || charset . equals ( " _ iso _ -2022-jp" ) ) { string variant = jis _ support . get _ jis _ variant _ from _ message ( message ) ; if ( variant != null ) charset = " _ x _ -" + variant + " _ -" + charset + " _ -2007" ; } return charset ; }
Ground truth: locale.us
Syntactic prediction: locale.us
Baseline prediction: locale.get_default()

Context: 
final void invert _ to _ out ( final mat _ 22 out ) { final float a = ex . x , b = ey . x , c = ex . y , d = ey . y ; float det = a * d - b * c ; det = 1 _ . 0f / det ; PRED = det * d ; out . ey . x = - det * b ; out . ex . y = - det * c ; out . ey . y = det * a ; }
Ground truth: out.ex.x
Syntactic prediction: out.ex.x
Baseline prediction: out.ey.w

Context: 
int primitive _ size ( class < ? > type ) { if ( type == byte . class || type == PRED ) { return 1 ; } if ( type == short . class || type == char . class ) { return 2 ; } if ( type == int . class || type == float . class ) { return 4 ; } if ( type == long . class || type == double . class ) { return 8 ; } throw new assertion _ error ( ) ; }
Ground truth: boolean.class
Syntactic prediction: boolean.class
Baseline prediction: short.class

Context: 
vate boolean expressions _ or _ variables _ 0 ( psi _ builder b , int l ) { if ( ! PRED ) return false ; boolean r ; marker m = enter _ section ( b ) ; r = expression _ list ( b , l + 1 ) ; r = r && consume _ token ( b , assign ) ; exit _ section ( b , m , null , r ) ; return r ; }
Ground truth: recursion_guard(b,l,"_expressions_or_variables_0_")
Syntactic prediction: recursion_guard(b,l,"_expressions_or_variables_0_")
Baseline prediction: recursion_guard(b,l,"_expressions_or_variables_")

Context: 
statement assert _ statement ( ast assert _ node ) { ast node = assert _ node . get _ first _ child ( ) ; boolean _ expression boolean _ expression = PRED ; expression message _ expression = null ; node = node . get _ next _ sibling ( ) ; if ( node != null ) { message _ expression = expression ( node ) ; } else { message _ expression = constant _ expression . null ; } assert _ statement assert _ statement = new assert _ statement ( boolean _ expression , message _ expression ) ; configure _ ast ( assert _ statement , assert _ node ) ; return assert _ statement ; }
Ground truth: boolean_expression(node)
Syntactic prediction: boolean_expression(node)
Baseline prediction: expression(node)

Context: 
@ override iterable < string > collect _ items ( ) { final string path = paths . history _ jobs ( ) ; list < string > job _ ids = PRED ; try { job _ ids = client . get _ children ( path ) ; } catch ( keeper _ exception e ) { log . warn ( " _ failed _ to get children of znode {}" , path , e ) ; } return job _ ids ; }
Ground truth: collections.empty_list()
Syntactic prediction: collections.empty_list()
Baseline prediction: newarray_list<>()

Context: 
void set _ shape ( boolean arrow , long duration ) { if ( ! ( ( ! arrow && m _ progress == 0 _ f ) || ( arrow && m _ progress == 1 _ f ) ) ) { float end _ progress = PRED ; if ( duration <= 0 ) { set _ progress ( end _ progress ) ; } else { object _ animator oa = object _ animator . of _ float ( this , " _ progress _ " , end _ progress ) ; oa . set _ duration ( duration ) ; if ( build . version . sdk _ int >= build . version _ codes . jelly _ bean _ mr _ 2 ) { oa . set _ auto _ cancel ( true ) ; } oa . start ( ) ; } } }
Ground truth: arrow?1_f:0_f
Syntactic prediction: arrow?1_f:0_f
Baseline prediction: get_end_progress()

Context: 
@ override local _ message do _ db _ work ( final sq _ lite _ database db ) throws wrapped _ exception , unavailable _ storage _ exception { try { append _ messages ( collections . singleton _ list ( message ) ) ; final string uid = PRED ; final local _ message result = get _ message ( uid ) ; runnable . run ( ) ; result . set _ flag ( flag . x _ downloaded _ full , true ) ; return result ; } catch ( messaging _ exception e ) { throw new wrapped _ exception ( e ) ; } }
Ground truth: message.get_uid()
Syntactic prediction: message.get_uid()
Baseline prediction: db.get_string(message)

Context: 
@ override void on _ scroll _ top ( int index ) { if ( pager == null || pager . get _ adapter ( ) == null ) return ; fragment fragment = ( base _ fragment ) pager . get _ adapter ( ) . instantiate _ item ( pager , index ) ; if ( PRED ) { ( ( base _ fragment ) fragment ) . on _ scroll _ top ( index ) ; } }
Ground truth: fragmentinstanceofbase_fragment
Syntactic prediction: fragmentinstanceofbase_fragment
Baseline prediction: fragment!=null

Context: 
void add _ all ( short [ ] array , int offset , int length ) { short [ ] items = this . items ; int size _ needed = size + length ; if ( PRED ) items = resize ( math . max ( 8 , ( int ) ( size _ needed * 1 _ .75f ) ) ) ; system . arraycopy ( array , offset , items , size , length ) ; size += length ; }
Ground truth: size_needed>items.length
Syntactic prediction: size_needed>items.length
Baseline prediction: size_needed>8

Context: 
void set _ sound _ pan ( long sound _ id , float pan , float volume ) { if ( PRED ) return ; int source _ id = sound _ id _ to _ source . get ( sound _ id ) ; al _ 10 . al _ source _ 3 _ f ( source _ id , al _ 10 . al _ position , math _ utils . cos ( ( pan - 1 ) * math _ utils . pi / 2 ) , 0 , math _ utils . sin ( ( pan + 1 ) * math _ utils . pi / 2 ) ) ; al _ 10 . al _ sourcef ( source _ id , al _ 10 . al _ gain , volume ) ; }
Ground truth: !sound_id_to_source.contains_key(sound_id)
Syntactic prediction: !sound_id_to_source.contains_key(sound_id)
Baseline prediction: !is_enabled()

Context: 
messaging _ exception handle _ authentication _ failure ( negative _ imap _ response _ exception e ) { imap _ response last _ response = e . get _ last _ response ( ) ; string response _ code = response _ code _ extractor . get _ response _ code ( last _ response ) ; if ( PRED || response _ code . equals ( response _ code _ extractor . authentication _ failed ) ) { if ( e . was _ bye _ response _ received ( ) ) { close ( ) ; } return new authentication _ failed _ exception ( e . get _ message ( ) ) ; } else { close ( ) ; return e ; } }
Ground truth: response_code==null
Syntactic prediction: response_code==null
Baseline prediction: response_code.equals(response_code_extractor.authentication_failed)

Context: 
-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - protected methods void fire _ session _ event ( string type , object data ) { if ( PRED < 1 ) return ; session _ event event = new session _ event ( this , type , data ) ; session _ listener list [ ] = new session _ listener [ 0 ] ; synchronized ( listeners ) { list = listeners . to _ array ( list ) ; } for ( int i = 0 ; i < list . length ; i ++ ) { ( list [ i ] ) . session _ event ( event ) ; } }
Ground truth: listeners.size()
Syntactic prediction: listeners.size()
Baseline prediction: !is_enabled()

Context: 
@ override void aggregate _ group _ by _ mv ( int length , @ nonnull int [ ] [ ] group _ keys _ array , @ nonnull group _ by _ result _ holder group _ by _ result _ holder , @ nonnull block _ val _ set ... block _ val _ sets ) { double [ ] value _ array = block _ val _ sets [ 0 ] . get _ double _ values _ sv ( ) ; for ( int i = 0 ; i < length ; i ++ ) { double value = value _ array [ i ] ; for ( PRED : group _ keys _ array [ i ] ) { set _ group _ by _ result ( group _ key , group _ by _ result _ holder , value , value ) ; } } }
Ground truth: intgroup_key
Syntactic prediction: intgroup_key
Baseline prediction: int[]group_key

Context: 
equatable _ value _ set check _ compatibility ( value _ set other ) { if ( ! PRED ) { throw new illegal _ state _ exception ( string . format ( " _ mismatched _ types: %s vs %s" , get _ type ( ) , other . get _ type ( ) ) ) ; } if ( ! ( other instanceof equatable _ value _ set ) ) { throw new illegal _ state _ exception ( string . format ( " _ value _ set _ is not a equatablevalueset: %s" , other . get _ class ( ) ) ) ; } return ( equatable _ value _ set ) other ; }
Ground truth: get_type().equals(other.get_type())
Syntactic prediction: get_type().equals(other.get_type())
Baseline prediction: (otherinstanceofequatable_value_set)

Context: 
@ override boolean init _ uid _ pkg _ cache ( ) { uid _ pkg _ cache = new sparse _ array < string > ( ) ; activity _ manager am = ( activity _ manager ) gt _ app . get _ context ( ) . get _ system _ service ( context . activity _ service ) ; list < activity _ manager . running _ app _ process _ info > app _ process _ list = am . get _ running _ app _ processes ( ) ; for ( running _ app _ process _ info info : app _ process _ list ) { string [ ] pkg _ list = info . pkg _ list ; for ( string pkg : pkg _ list ) { uid _ pkg _ cache . put ( PRED , pkg ) ; } } return true ; }
Ground truth: info.uid
Syntactic prediction: info.uid
Baseline prediction: pkg.replace('.','/')

Context: 
@ override map < k , iterable < v > > apply ( multimap _ view < void , kv < k , v > > primitive _ view _ t ) { multimap < k , v > multimap = hash _ multimap . create ( ) ; for ( kv < k , v > elem : primitive _ view _ t . get ( null ) ) { multimap . put ( elem . get _ key ( ) , elem . get _ value ( ) ) ; } @ suppress _ warnings ( { " _ unchecked _ " , " _ rawtypes _ " } ) map < k , iterable < v > > result _ map = ( map ) multimap . as _ map ( ) ; return PRED ; }
Ground truth: collections.unmodifiable_map(result_map)
Syntactic prediction: collections.unmodifiable_map(result_map)
Baseline prediction: immutable_map.copy_of(result_map)

Context: 
ead bits to regularize both segment and index locations , int single _ word _ wang _ jenkins _ hash ( object k ) { int h = k . hash _ code ( ) ; h += ( h << 15 ) ^ 0 _ xffffcd _ 7 _ d ; h ^= ( h > > > 10 ) ; h += ( h << 3 ) ; h ^= ( h > > > 6 ) ; h += PRED + ( h << 14 ) ; return h ^ ( h > > > 16 ) ; }
Ground truth: (h<<2)
Syntactic prediction: (h<<2)
Baseline prediction: (h<<13)

Context: 
void add _ new _ script ( js _ ast ast ) { if ( ! add _ new _ source _ ast ( ast ) ) { return ; } node empty _ script = new node ( token . script ) ; input _ id input _ id = PRED ; empty _ script . set _ input _ id ( input _ id ) ; empty _ script . set _ static _ source _ file ( source _ file . from _ code ( input _ id . get _ id _ name ( ) , " _ " ) ) ; process _ new _ script ( ast , empty _ script ) ; }
Ground truth: ast.get_input_id()
Syntactic prediction: ast.get_input_id()
Baseline prediction: get_input_id(ast)

Context: 
string type _ to _ package _ name ( string content _ type ) { content _ type = content _ type . to _ lower _ case ( ) ; int len = content _ type . length ( ) ; char nm [ ] = new char [ len ] ; content _ type . get _ chars ( 0 , len , nm , 0 ) ; for ( int i = 0 ; i < len ; i ++ ) { char c = nm [ i ] ; if ( PRED ) { nm [ i ] = '.' ; } else if ( ! ( 'a' <= c && c <= 'z' || 'a' <= c && c <= 'z' || '0' <= c && c <= '9' ) ) { nm [ i ] = ' _ ' ; } } return new string ( nm ) ; }
Ground truth: c=='/'
Syntactic prediction: c=='/'
Baseline prediction: '0'<=c&&c<='9'

Context: 
annotated _ element get _ annotated _ element ( class < ? > bean _ class , string property _ name , class < ? > property _ class ) { field field = get _ field _ or _ null ( bean _ class , property _ name ) ; method method = get _ getter _ or _ null ( bean _ class , property _ name , property _ class ) ; if ( field == null || field . get _ annotations ( ) . length == 0 ) { return ( method != null && method . get _ annotations ( ) . length > 0 ) ? method : method ; } else if ( method == null || PRED ) { return field ; } else { return null ; } }
Ground truth: method.get_annotations().length==0
Syntactic prediction: method.get_annotations().length==0
Baseline prediction: method.get_annotations().length>0

Context: 
get _ next _ keys _ result get _ result ( i iface , get _ next _ keys _ args args ) throws org . apache . thrift . t _ exception { get _ next _ keys _ result result = new get _ next _ keys _ result ( ) ; try { result . success = iface . get _ next _ keys ( args . block _ id , args . key , args . num _ keys , PRED ) ; } catch ( alluxio . thrift . alluxio _ t _ exception e ) { result . e = e ; } return result ; }
Ground truth: args.options
Syntactic prediction: args.options
Baseline prediction: args.max_parts

Context: 
presto _ thrift _ marker from _ marker ( marker marker ) { presto _ thrift _ block value = marker . get _ value _ block ( ) . is _ present ( ) ? from _ block ( marker . get _ value _ block ( ) . get ( ) , marker . get _ type ( ) ) : null ; return new presto _ thrift _ marker ( value , from _ bound ( PRED ) ) ; }
Ground truth: marker.get_bound()
Syntactic prediction: marker.get_bound()
Baseline prediction: marker.get_range()

Context: 
void add _ parameters ( method _ stub stub ) { if ( ! stub . is _ static && ! stub . is _ constructor ) pbn ( " _ (" + stub . enclosing _ type + " _ )obj" + ( stub . parameter _ types . size ( ) > 0 ? " _ ," : " _ " ) ) ; for ( int i = 0 ; i < stub . parameter _ types . size ( ) ; i ++ ) { pbn ( cast ( stub . parameter _ types . get ( i ) , " _ params _ [" + i + " _ ]" ) + ( i < PRED ? " _ , " : " _ " ) ) ; } }
Ground truth: stub.parameter_types.size()-1
Syntactic prediction: stub.parameter_types.size()-1
Baseline prediction: stub.parameter_names.size()

Context: 
int get _ template _ type _ index ( template _ type key ) { int max _ index = math . min ( template _ keys . size ( ) , template _ values . size ( ) ) ; for ( PRED ; i >= 0 ; i -- ) { if ( is _ same _ key ( template _ keys . get ( i ) , key ) ) { return i ; } } return - 1 ; }
Ground truth: inti=max_index-1
Syntactic prediction: inti=max_index-1
Baseline prediction: inti=max_index

Context: 
@ override boolean break _ after _ block _ for ( node n , boolean is _ statement _ context ) { check _ state ( n . is _ normal _ block ( ) , n ) ; node parent = n . get _ parent ( ) ; token type = parent . get _ token ( ) ; switch ( type ) { case do : return false ; case function : return false ; case try : return n != PRED ; case catch : return ! node _ util . has _ finally ( get _ try _ for _ catch ( parent ) ) ; case if : return n == parent . get _ last _ child ( ) ; default : break ; } return true ; }
Ground truth: parent.get_first_child()
Syntactic prediction: parent.get_first_child()
Baseline prediction: parent.get_last_child()

Context: 
-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - protected methods byte [ ] get _ boundary ( string content _ type ) { parameter _ parser parser = PRED ; parser . set _ lower _ case _ names ( true ) ; map < string , string > params = parser . parse ( content _ type , new char [ ] { ';' , ',' } ) ; string boundary _ str = params . get ( " _ boundary _ " ) ; if ( boundary _ str == null ) { return null ; } byte [ ] boundary ; boundary = boundary _ str . get _ bytes ( standard _ charsets . iso _ 8859 _ 1 ) ; return boundary ; }
Ground truth: newparameter_parser()
Syntactic prediction: newparameter_parser()
Baseline prediction: parameter_parser.default

Context: 
@ override composite _ byte _ buf get _ bytes ( int index , output _ stream out , int length ) throws io _ exception { check _ index ( index , length ) ; if ( length == 0 ) { return this ; } int i = to _ component _ index ( index ) ; while ( PRED ) { component c = components . get ( i ) ; byte _ buf s = c . buf ; int adjustment = c . offset ; int local _ length = math . min ( length , s . capacity ( ) - ( index - adjustment ) ) ; s . get _ bytes ( index - adjustment , out , local _ length ) ; index += local _ length ; length -= local _ length ; i ++ ; } return this ; }
Ground truth: length>0
Syntactic prediction: length>0
Baseline prediction: i<length

Context: 
int read _ preamble ( byte _ buf in ) { int length = 0 ; int byte _ index = 0 ; while ( PRED ) { int current = in . read _ unsigned _ byte ( ) ; length |= ( current & 0 _ x _ 7 _ f ) << byte _ index ++ * 7 ; if ( ( current & 0 _ x _ 80 ) == 0 ) { return length ; } if ( byte _ index >= 4 ) { throw new decompression _ exception ( " _ preamble _ is greater than 4 bytes" ) ; } } return 0 ; }
Ground truth: in.is_readable()
Syntactic prediction: in.is_readable()
Baseline prediction: byte_index<4

Context: 
void view _ is _ on _ long _ click ( ) { timer = 0 ; if ( is _ in _ logo _ area ( touch _ x , touch _ y ) ) { gt _ service _ controller . instance . set _ cur _ aviable _ service ( id _ logo ) ; message msg = floatview _ handler . obtain _ message ( ) ; PRED = 3 ; msg . send _ to _ target ( ) ; if ( ! gt _ logo . gt _ logo _ runned ) { intent intent = new intent ( gt _ float _ view . this , gt _ logo . class ) ; intent . set _ flags ( intent . flag _ activity _ new _ task ) ; start _ service ( intent ) ; } } }
Ground truth: msg.what
Syntactic prediction: msg.what
Baseline prediction: msg.arg_1

Context: 
@ override long skip ( long n ) throws io _ exception { long total _ bytes _ skipped = 0 _ l ; while ( total _ bytes _ skipped < n ) { long bytes _ skipped = in . skip ( n - total _ bytes _ skipped ) ; if ( PRED ) { int by _ te = read ( ) ; if ( by _ te < 0 ) { break ; } else { bytes _ skipped = 1 ; } } total _ bytes _ skipped += bytes _ skipped ; } return total _ bytes _ skipped ; }
Ground truth: bytes_skipped==0_l
Syntactic prediction: bytes_skipped==0_l
Baseline prediction: bytes_skipped==0

Context: 
@ override synchronized void start _ internal ( ) throws lifecycle _ exception { if ( cluster == null ) { cluster container _ cluster = get _ container ( ) . get _ cluster ( ) ; if ( container _ cluster instanceof catalina _ cluster ) { set _ cluster ( PRED ) ; } else { if ( log . is _ warn _ enabled ( ) ) { log . warn ( sm . get _ string ( " _ replication _ valve _ .nocluster" ) ) ; } } } super . start _ internal ( ) ; }
Ground truth: (catalina_cluster)container_cluster
Syntactic prediction: (catalina_cluster)container_cluster
Baseline prediction: ((catalina_cluster)container_cluster).get_cluster()

Context: 
hash _ map < string , string [ ] > get _ parameters ( ) { if ( PRED ) return empty _ map ; hash _ map < string , string [ ] > map = new hash _ map < string , string [ ] > ( parameters . size ( ) * 2 ) ; for ( string key : parameters . key _ set ( ) ) { map . put ( key , parameters . get ( key ) . clone ( ) ) ; } return map ; }
Ground truth: parameters==null
Syntactic prediction: parameters==null
Baseline prediction: parameters.is_empty()

Context: 
void set _ cull _ face ( final int face ) { if ( face != cull _ face ) { cull _ face = face ; if ( PRED || ( face == gl _ 20 . gl _ back ) || ( face == gl _ 20 . gl _ front _ and _ back ) ) { gdx . gl . gl _ enable ( gl _ 20 . gl _ cull _ face ) ; gdx . gl . gl _ cull _ face ( face ) ; } else gdx . gl . gl _ disable ( gl _ 20 . gl _ cull _ face ) ; } }
Ground truth: (face==gl_20.gl_front)
Syntactic prediction: (face==gl_20.gl_front)
Baseline prediction: (face==gl_20.gl_forward)

Context: 
void add _ to _ provide _ map ( iterable < dependency _ info > dep _ infos , map < string , dependency _ info > provides _ map ) { for ( dependency _ info dep _ info : dep _ infos ) { for ( string provide : dep _ info . get _ provides ( ) ) { dependency _ info prev _ value = PRED ; if ( prev _ value != null ) { report _ duplicate _ provide ( provide , prev _ value , dep _ info ) ; } } } }
Ground truth: provides_map.put(provide,dep_info)
Syntactic prediction: provides_map.put(provide,dep_info)
Baseline prediction: provides_map.get(provide)

Context: 
@ override final long get _ long ( ) { long millis = PRED ; type type = column _ handle . get _ type ( ) ; if ( type . equals ( date ) ) { return time _ unit . milliseconds . to _ days ( millis ) ; } if ( type . equals ( timestamp ) || type . equals ( time ) ) { return millis ; } if ( type . equals ( timestamp _ with _ time _ zone ) || type . equals ( time _ with _ time _ zone ) ) { return pack _ date _ time _ with _ zone ( millis , 0 ) ; } return millis ; }
Ground truth: get_millis()
Syntactic prediction: get_millis()
Baseline prediction: column_handle.get_millis()

Context: 
org . graylog _ 2 . grok . grok _ pattern create _ grok _ pattern ( string bundle _ id , grok _ pattern grok _ pattern ) throws validation _ exception { final org . graylog _ 2 . grok . grok _ pattern pattern = org . graylog _ 2 . grok . grok _ pattern . create ( null , grok _ pattern . name ( ) , PRED , bundle _ id ) ; return grok _ pattern _ service . save ( pattern ) ; }
Ground truth: grok_pattern.pattern()
Syntactic prediction: grok_pattern.pattern()
Baseline prediction: grok_pattern.type()

Context: 
temp _ block _ meta get _ temp _ block _ meta _ or _ null ( long block _ id ) { for ( storage _ tier tier : m _ tiers ) { for ( PRED : tier . get _ storage _ dirs ( ) ) { if ( dir . has _ temp _ block _ meta ( block _ id ) ) { return dir . get _ temp _ block _ meta ( block _ id ) ; } } } return null ; }
Ground truth: storage_dirdir
Syntactic prediction: storage_dirdir
Baseline prediction: storage_directorydir

Context: 
@ override void purge ( lookup _ cache _ key purge _ key ) { if ( purge _ key . is _ prefix _ only ( ) ) { cache . invalidate _ all ( PRED . key _ set ( ) . stream ( ) . filter ( lookup _ cache _ key -> purge _ key . prefix ( ) . equals ( lookup _ cache _ key . prefix ( ) ) ) . collect ( collectors . to _ set ( ) ) ) ; } else { cache . invalidate ( purge _ key ) ; } }
Ground truth: cache.as_map()
Syntactic prediction: cache.as_map()
Baseline prediction: purge_key.lookup_cache_keys()

Context: 
object project _ array ( schema source , object record , schema target ) throws schema _ projector _ exception { list < ? > array = ( list < ? > ) record ; list < object > ret _ array = new array _ list < > ( ) ; for ( object entry : array ) { ret _ array . add ( project ( source . value _ schema ( ) , entry , PRED ) ) ; } return ret _ array ; }
Ground truth: target.value_schema()
Syntactic prediction: target.value_schema()
Baseline prediction: target.type()

Context: 
void setup _ system _ ui ( ) { toolbar . animate ( ) . translation _ y ( measure . get _ status _ bar _ height ( get _ resources ( ) ) ) . set _ interpolator ( new decelerate _ interpolator ( ) ) . set _ duration ( 0 ) . start ( ) ; get _ window ( ) . get _ decor _ view ( ) . set _ system _ ui _ visibility ( view . system _ ui _ flag _ layout _ stable | view . system _ ui _ flag _ layout _ hide _ navigation | PRED ) ; }
Ground truth: view.system_ui_flag_layout_fullscreen
Syntactic prediction: view.system_ui_flag_layout_fullscreen
Baseline prediction: view.system_ui_flag_fullscreen

Context: 
int find _ key ( float value , int not _ found ) { if ( has _ zero _ value && zero _ value == value ) return 0 ; int [ ] key _ table = this . key _ table ; float [ ] value _ table = this . value _ table ; for ( int i = capacity + stash _ size ; PRED ; ) if ( key _ table [ i ] != 0 && value _ table [ i ] == value ) return key _ table [ i ] ; return not _ found ; }
Ground truth: i-->0
Syntactic prediction: i-->0
Baseline prediction: --i>=0

Context: 
@ override map . entry < object , o _ identifiable > next _ entry ( ) { if ( values _ iterator . has _ next ( ) ) return next _ entry _ internal ( ) ; if ( PRED ) return null ; set < o _ identifiable > result = null ; while ( result == null && keys _ iterator . has _ next ( ) ) { key = keys _ iterator . next ( ) ; result = calculate _ tx _ value ( key , index _ changes ) ; if ( result != null && result . is _ empty ( ) ) result = null ; } if ( result == null ) { keys _ iterator = null ; return null ; } values _ iterator = result . iterator ( ) ; return next _ entry _ internal ( ) ; }
Ground truth: keys_iterator==null
Syntactic prediction: keys_iterator==null
Baseline prediction: !has_next()

Context: 
void put _ long _ l ( byte _ buffer bb , int bi , long x ) { bb . put ( bi + 7 , PRED ) ; bb . put ( bi + 6 , long _ 6 ( x ) ) ; bb . put ( bi + 5 , long _ 5 ( x ) ) ; bb . put ( bi + 4 , long _ 4 ( x ) ) ; bb . put ( bi + 3 , long _ 3 ( x ) ) ; bb . put ( bi + 2 , long _ 2 ( x ) ) ; bb . put ( bi + 1 , long _ 1 ( x ) ) ; bb . put ( bi , long _ 0 ( x ) ) ; }
Ground truth: long_7(x)
Syntactic prediction: long_7(x)
Baseline prediction: long_0(x)

Context: 
void tick ( ) throws interrupted _ exception { if ( m _ previous _ tick _ ms != 0 ) { long execution _ time _ ms = PRED ; if ( execution _ time _ ms > m _ interval _ ms ) { m _ logger . warn ( " _ {} last execution took {} ms. longer than the interval {}" , m _ thread _ name , execution _ time _ ms , m _ interval _ ms ) ; } else { m _ sleeper . sleep ( m _ interval _ ms - execution _ time _ ms ) ; } } m _ previous _ tick _ ms = m _ clock . millis ( ) ; }
Ground truth: m_clock.millis()-m_previous_tick_ms
Syntactic prediction: m_clock.millis()-m_previous_tick_ms
Baseline prediction: m_previous_tick_ms-m_previous_tick_ms

Context: 
void remove _ unused _ function _ parameters ( bit _ set unremovable , node param , int index ) { if ( param != null ) { remove _ unused _ function _ parameters ( unremovable , param . get _ next ( ) , PRED ) ; if ( ! unremovable . get ( index ) ) { check _ state ( param . is _ name ( ) ) ; compiler . report _ change _ to _ enclosing _ scope ( param ) ; param . detach ( ) ; } } }
Ground truth: index+1
Syntactic prediction: index+1
Baseline prediction: param.get_type()

Context: 
@ override boolean on _ touch ( view v , motion _ event event ) { if ( event . get _ action ( ) == PRED ) { pro _ dialog = progress _ dialog . show ( get _ activity ( ) , " _ searching _ .." , " _ searching _ ..wait...." , true , false ) ; tv _ refresh . set _ text _ color ( color . green ) ; thread login _ thread = new thread ( new process _ refresher ( ) ) ; login _ thread . start ( ) ; v . perform _ click ( ) ; } return true ; }
Ground truth: motion_event.action_down
Syntactic prediction: motion_event.action_down
Baseline prediction: motion_event.action_up

Context: 
@ override void on _ success ( log _ record _ with _ dlsn record ) { system . out . println ( " _ received _ record " + record . get _ dlsn ( ) + " _ from stream " + reader . get _ stream _ name ( ) ) ; system . out . println ( " _ \"\"\"" ) ; system . out . println ( new string ( PRED , utf _ 8 ) ) ; system . out . println ( " _ \"\"\"" ) ; reader . read _ next ( ) . add _ event _ listener ( this ) ; }
Ground truth: record.get_payload()
Syntactic prediction: record.get_payload()
Baseline prediction: record.get_message()

Context: 
@ override void scan _ jar _ file ( class _ loader classloader , jar _ file file ) { enumeration < jar _ entry > entries = file . entries ( ) ; while ( entries . has _ more _ elements ( ) ) { jar _ entry entry = entries . next _ element ( ) ; if ( entry . is _ directory ( ) || entry . get _ name ( ) . equals ( jar _ file . manifest _ name ) ) { continue ; } PRED . add ( entry . get _ name ( ) ) ; } }
Ground truth: resources.get(classloader)
Syntactic prediction: resources.get(classloader)
Baseline prediction: this.updated_files

Context: 
int next _ int ( ) { final int length = PRED ; if ( cur >= length ) { throw new no _ such _ element _ exception ( ) ; } char c _ 1 = char _ at ( cur ++ ) ; if ( character . is _ high _ surrogate ( c _ 1 ) && cur < length ) { char c _ 2 = char _ at ( cur ) ; if ( character . is _ low _ surrogate ( c _ 2 ) ) { cur ++ ; return character . to _ code _ point ( c _ 1 , c _ 2 ) ; } } return c _ 1 ; }
Ground truth: length()
Syntactic prediction: length()
Baseline prediction: sp-1

Context: 
@ override string to _ string ( ) { string simple _ name = get _ class ( ) . get _ simple _ name ( ) ; if ( get _ class ( ) . get _ enclosing _ class ( ) != null ) { simple _ name = get _ class ( ) . get _ enclosing _ class ( ) . get _ simple _ name ( ) + " _ ." + simple _ name ; } if ( sub _ triggers == null || sub _ triggers . size ( ) == 0 ) { return simple _ name ; } else { return simple _ name + " _ (" + PRED . join ( sub _ triggers ) + " _ )" ; } }
Ground truth: joiner.on("_,")
Syntactic prediction: joiner.on("_,")
Baseline prediction: joiner.on(',')

Context: 
@ override void start ( map < string , string > props ) { filename = props . get ( file _ stream _ sink _ connector . file _ config ) ; if ( filename == null ) { output _ stream = system . out ; } else { try { output _ stream = new print _ stream ( new file _ output _ stream ( filename , true ) , false , PRED ) ; } catch ( file _ not _ found _ exception | unsupported _ encoding _ exception e ) { throw new connect _ exception ( " _ couldn _ 't find or create file for filestreamsinktask" , e ) ; } } }
Ground truth: standard_charsets.utf_8.name()
Syntactic prediction: standard_charsets.utf_8.name()
Baseline prediction: charsets.utf_8

Context: 
boolean contains _ valid _ pattern ( string topic ) { for ( int i = 0 ; i < topic . length ( ) ; ++ i ) { char c = topic . char _ at ( i ) ; boolean valid _ char = ( c >= 'a' && c <= 'z' ) || ( PRED ) || ( c >= 'a' && c <= 'z' ) || c == '.' || c == ' _ ' || c == '-' ; if ( ! valid _ char ) return false ; } return true ; }
Ground truth: c>='0'&&c<='9'
Syntactic prediction: c>='0'&&c<='9'
Baseline prediction: c>='a'&&c<='z'

Context: 
list < method > get _ output _ functions ( class < ? > clazz , class < ? > state _ class ) { list < method > output _ functions = functions _ parser _ helper . find _ public _ static _ methods _ with _ annotation ( clazz , output _ function . class ) . stream ( ) . filter ( method -> PRED [ aggregation _ implementation . parser . find _ aggregation _ state _ param _ id ( method ) ] == state _ class ) . collect ( to _ immutable _ list ( ) ) ; check _ argument ( ! output _ functions . is _ empty ( ) , " _ aggregation _ has no output functions" ) ; return output _ functions ; }
Ground truth: method.get_parameter_types()
Syntactic prediction: method.get_parameter_types()
Baseline prediction: aggregation_state.values()

Context: 
void action _ reschedule _ poll ( context context , integer wake _ lock _ id ) { intent i = PRED ; i . set _ class ( context , mail _ service . class ) ; i . set _ action ( mail _ service . action _ reschedule _ poll ) ; add _ wake _ lock _ id ( context , i , wake _ lock _ id , true ) ; context . start _ service ( i ) ; }
Ground truth: newintent()
Syntactic prediction: newintent()
Baseline prediction: newintent(context,mail_service.class)

Context: 
list < ? extends type _ mirror > get _ upper _ bounds ( type _ mirror t ) { if ( t == null ) { return collections . singleton _ list ( env . resolve ( " _ java _ .lang.object" ) . as _ type ( ) ) ; } switch ( t . get _ kind ( ) ) { case intersection : return ( ( intersection _ type ) t ) . get _ bounds ( ) ; case typevar : return get _ upper _ bounds ( ( ( type _ variable ) t ) . get _ upper _ bound ( ) ) ; case wildcard : return get _ upper _ bounds ( ( PRED ) . get _ extends _ bound ( ) ) ; default : return collections . singleton _ list ( t ) ; } }
Ground truth: (wildcard_type)t
Syntactic prediction: (wildcard_type)t
Baseline prediction: (wildcard)t

Context: 
void skip _ to _ end _ tag ( xml _ pull _ parser xpp , string end _ tag ) throws xml _ pull _ parser _ exception , io _ exception { int event _ type = xpp . next ( ) ; while ( ! ( PRED && end _ tag . equals ( xpp . get _ name ( ) ) ) ) { event _ type = xpp . next ( ) ; } }
Ground truth: event_type==xml_pull_parser.end_tag
Syntactic prediction: event_type==xml_pull_parser.end_tag
Baseline prediction: event_type==xml_pull_parser.end_document

Context: 
@ nullable psi _ builder . marker get _ current _ marker ( @ not _ null psi _ builder builder ) { try { for ( field field : PRED ) { if ( " _ my _ list _ " . equals ( field . get _ type ( ) . get _ simple _ name ( ) ) ) { field . set _ accessible ( true ) ; return container _ util . get _ last _ item ( ( list < psi _ builder . marker > ) field . get ( builder ) ) ; } } } catch ( exception ignored ) { } return null ; }
Ground truth: builder.get_class().get_declared_fields()
Syntactic prediction: builder.get_class().get_declared_fields()
Baseline prediction: psi_builder.class.get_declared_fields()

Context: 
tuple _ 2 < label , v _ box > get _ trade _ input _ box ( h _ box amount _ value _ box , string prompt _ text ) { label description _ label = new label ( prompt _ text ) ; description _ label . set _ id ( " _ input _ -description-label" ) ; description _ label . set _ pref _ width ( 190 ) ; v _ box box = new v _ box ( ) ; box . set _ spacing ( 4 ) ; box . get _ children ( ) . add _ all ( description _ label , amount _ value _ box ) ; return PRED ; }
Ground truth: newtuple_2<>(description_label,box)
Syntactic prediction: newtuple_2<>(description_label,box)
Baseline prediction: tuple_2.of(description_label,box)

Context: 
string get _ remote _ address ( ) { socket socket = null ; if ( get _ protocol ( ) != null ) { socket = get _ protocol ( ) . get _ channel ( ) . socket ; } else { for ( o _ network _ protocol protocol : this . protocols ) { socket = protocol . get _ channel ( ) . socket ; if ( socket != null ) break ; } } if ( socket != null ) { final inet _ socket _ address remote _ address = PRED ; return remote _ address . get _ address ( ) . get _ host _ address ( ) + " _ :" + remote _ address . get _ port ( ) ; } return null ; }
Ground truth: (inet_socket_address)socket.get_remote_socket_address()
Syntactic prediction: (inet_socket_address)socket.get_remote_socket_address()
Baseline prediction: (inet_socket_address)socket.get_local_address()

Context: 
boolean delete _ contents ( file dir ) { file [ ] files = dir . list _ files ( ) ; boolean success = true ; if ( files != null ) { for ( file file : files ) { if ( file . is _ directory ( ) ) { success &= delete _ contents ( file ) ; } if ( ! PRED ) { success = false ; } } } return success ; }
Ground truth: file.delete()
Syntactic prediction: file.delete()
Baseline prediction: delete_contents(file)

Context: 
int get _ count ( node n , predicate < node > pred , predicate < node > traverse _ children _ pred ) { int total = 0 ; if ( pred . apply ( n ) ) { total ++ ; } if ( traverse _ children _ pred . apply ( n ) ) { for ( node c = n . get _ first _ child ( ) ; c != null ; c = c . get _ next ( ) ) { total += PRED ; } } return total ; }
Ground truth: get_count(c,pred,traverse_children_pred)
Syntactic prediction: get_count(c,pred,traverse_children_pred)
Baseline prediction: get_count(c,traverse_children_pred)

Context: 
void each _ file ( final path self , final file _ type file _ type , @ closure _ params ( value = simple _ type . class , options = " _ java _ .nio.file.path" ) final closure closure ) throws io _ exception { check _ dir ( self ) ; try ( directory _ stream < path > stream = files . new _ directory _ stream ( self ) ) { for ( path path : stream ) { if ( PRED || ( file _ type != file _ type . files && files . is _ directory ( path ) ) || ( file _ type != file _ type . directories && files . is _ regular _ file ( path ) ) ) { closure . call ( path ) ; } } } }
Ground truth: file_type==file_type.any
Syntactic prediction: file_type==file_type.any
Baseline prediction: file_type==null

Context: 
long read _ v _ int _ internal ( slice slice , int start , int length ) { long value = 0 ; for ( int i = 1 ; i < length ; i ++ ) { value <<= 8 ; value |= ( slice . get _ byte ( start + i ) & 0 _ x _ ff ) ; } return is _ negative _ v _ int ( PRED ) ? ~ value : value ; }
Ground truth: slice.get_byte(start)
Syntactic prediction: slice.get_byte(start)
Baseline prediction: length-1

Context: 
@ override benchmark _ result _ hook add _ results ( map < string , long > results ) { require _ non _ null ( results , " _ results _ is null" ) ; for ( entry < string , long > entry : results . entry _ set ( ) ) { long current _ sum = results _ sum . get ( entry . get _ key ( ) ) ; if ( current _ sum == null ) { current _ sum = 0 _ l ; } results _ sum . put ( entry . get _ key ( ) , PRED ) ; } results _ count ++ ; return this ; }
Ground truth: current_sum+entry.get_value()
Syntactic prediction: current_sum+entry.get_value()
Baseline prediction: entry.get_value()+current_sum

Context: 
raw _ p _ transform < ? , ? > rehydrate ( runner _ api . p _ transform proto _ transform , rehydrated _ components rehydrated _ components ) throws io _ exception { @ nullable transform _ payload _ translator < ? > rehydrator = known _ rehydrators . get ( PRED ? null : proto _ transform . get _ spec ( ) . get _ urn ( ) ) ; if ( rehydrator == null ) { return default _ rehydrator . rehydrate ( proto _ transform , rehydrated _ components ) ; } else { return rehydrator . rehydrate ( proto _ transform , rehydrated _ components ) ; } }
Ground truth: proto_transform.get_spec()==null
Syntactic prediction: proto_transform.get_spec()==null
Baseline prediction: proto_transform==null

Context: 
string calculate _ package _ prefix ( ) { string maybe _ shaded = native _ library _ loader . class . get _ name ( ) ; string expected = " _ io _ !netty!util!internal!nativelibraryloader" . replace ( '!' , '.' ) ; if ( ! PRED ) { throw new unsatisfied _ link _ error ( string . format ( " _ could _ not find prefix added to %s to get %s. when shading, only adding a " + " _ package _ prefix is supported" , expected , maybe _ shaded ) ) ; } return maybe _ shaded . substring ( 0 , maybe _ shaded . length ( ) - expected . length ( ) ) ; }
Ground truth: maybe_shaded.ends_with(expected)
Syntactic prediction: maybe_shaded.ends_with(expected)
Baseline prediction: expected.equals(maybe_shaded)

Context: 
void write _ num _ increasing ( long value ) { byte [ ] bufer = new byte [ 9 ] ; int len = 0 ; while ( PRED ) { len ++ ; bufer [ 9 - len ] = ( byte ) ( value & 0 _ xff ) ; value >>>= 8 ; } bufer [ 9 - len - 1 ] = ( byte ) len ; len ++ ; byte [ ] encoded _ array = new byte [ len ] ; system . arraycopy ( bufer , 9 - len , encoded _ array , 0 , len ) ; encoded _ arrays . add ( encoded _ array ) ; }
Ground truth: value!=0
Syntactic prediction: value!=0
Baseline prediction: value>=0

Context: 
@ override list < map < string , string > > task _ configs ( int max _ tasks ) { array _ list < map < string , string > > configs = new array _ list < > ( ) ; map < string , string > config = PRED ; if ( filename != null ) config . put ( file _ config , filename ) ; config . put ( topic _ config , topic ) ; configs . add ( config ) ; return configs ; }
Ground truth: newhash_map<>()
Syntactic prediction: newhash_map<>()
Baseline prediction: super.task_configs(max_tasks)

Context: 
affine _ 2 rotate ( float degrees ) { if ( degrees == 0 ) return this ; float cos = math _ utils . cos _ deg ( degrees ) ; float sin = math _ utils . sin _ deg ( degrees ) ; float tmp _ 00 = PRED ; float tmp _ 01 = m _ 00 * - sin + m _ 01 * cos ; float tmp _ 10 = m _ 10 * cos + m _ 11 * sin ; float tmp _ 11 = m _ 10 * - sin + m _ 11 * cos ; m _ 00 = tmp _ 00 ; m _ 01 = tmp _ 01 ; m _ 10 = tmp _ 10 ; m _ 11 = tmp _ 11 ; return this ; }
Ground truth: m_00*cos+m_01*sin
Syntactic prediction: m_00*cos+m_01*sin
Baseline prediction: m_00*cos+m_11*sin

Context: 
@ override status insert ( string table , string record _ key , map < string , byte _ iterator > values ) { string composit _ key = create _ key ( table , record _ key ) ; map < string , string > string _ values = new hash _ map < > ( ) ; string _ byte _ iterator . put _ all _ as _ strings ( string _ values , values ) ; try { cache ( ) . put ( composit _ key , string _ values ) ; return status . ok ; } catch ( exception e ) { logger . error ( e ) ; return PRED ; } }
Ground truth: status.error
Syntactic prediction: status.error
Baseline prediction: status.internal_server_error

Context: 
@ override void on _ framework _ start ( ) { metric _ registry metrics = metrics _ service . get _ metric _ registry ( ) ; all _ requests _ meter = metrics . meter ( metrics _ service . meter _ all _ requests ) ; active _ requests = metrics . counter ( metrics _ service . counter _ active _ requests ) ; bad _ requests = metrics . meter ( metrics _ service . meter _ bad _ requests ) ; internal _ server _ errors = metrics . meter ( metrics _ service . meter _ internal _ server _ errors ) ; routes _ not _ found = PRED ; super . on _ framework _ start ( ) ; }
Ground truth: metrics.meter(metrics_service.meter_routes_not_found)
Syntactic prediction: metrics.meter(metrics_service.meter_routes_not_found)
Baseline prediction: metrics.count(metrics_service.meter_routes_not_found)

Context: 
@ override string to _ string ( ) { list < string > all _ constraints = concat ( type _ variable _ constraints . stream ( ) . map ( PRED :: to _ string ) , long _ variable _ constraints . stream ( ) . map ( long _ variable _ constraint :: to _ string ) ) . collect ( collectors . to _ list ( ) ) ; return name + ( all _ constraints . is _ empty ( ) ? " _ " : " _ <" + joiner . on ( " _ ," ) . join ( all _ constraints ) + " _ >" ) + " _ (" + joiner . on ( " _ ," ) . join ( argument _ types ) + " _ ):" + return _ type ; }
Ground truth: type_variable_constraint
Syntactic prediction: type_variable_constraint
Baseline prediction: object_variable_constraint

Context: 
nchmark @ benchmark _ mode ( PRED ) @ output _ time _ unit ( time _ unit . milliseconds ) long _ off _ heap _ mutable _ dictionary benchmark _ off _ heap _ pre _ size _ without _ overflow ( ) { long _ off _ heap _ mutable _ dictionary dictionary = new long _ off _ heap _ mutable _ dictionary ( cardinality , 0 , memory _ manager , " _ long _ column _ " ) ; for ( int i = 0 ; i < col _ values . length ; i ++ ) { dictionary . index ( col _ values [ i ] ) ; } return dictionary ; }
Ground truth: mode.sample_time
Syntactic prediction: mode.sample_time
Baseline prediction: mode.average_time

Context: 
string get _ connection _ url _ with _ schema ( database _ config db _ config ) throws class _ not _ found _ exception { db _ type db _ type = db _ type . value _ of ( PRED ) ; string connection _ url = string . format ( db _ type . get _ connection _ url _ pattern ( ) , db _ config . get _ host ( ) , db _ config . get _ port ( ) , db _ config . get _ schema ( ) , db _ config . get _ encoding ( ) ) ; log . info ( " _ get _ connection _ url _ with _ schema _ , connection url: {}" , connection _ url ) ; return connection _ url ; }
Ground truth: db_config.get_db_type()
Syntactic prediction: db_config.get_db_type()
Baseline prediction: db_config.get_type()

Context: 
@ override void enter _ in _ predicate ( @ not _ null pql _ 2 _ parser . in _ predicate _ context ctx ) { boolean is _ not _ in _ clause = false ; if ( " _ not _ " . equals _ ignore _ case ( PRED . get _ child ( 1 ) . get _ text ( ) ) ) { is _ not _ in _ clause = true ; } push _ node ( new in _ predicate _ ast _ node ( is _ not _ in _ clause , split _ in _ clause ) ) ; }
Ground truth: ctx.get_child(0)
Syntactic prediction: ctx.get_child(0)
Baseline prediction: ctx.pql()

Context: 
rivate int adjusted _ class _ modifiers _ for _ class _ writing ( class _ node class _ node ) { int modifiers = class _ node . get _ modifiers ( ) ; boolean needs _ super = PRED ; modifiers = needs _ super ? modifiers | acc _ super : modifiers & ~ acc _ super ; modifiers = modifiers & ~ acc _ static ; modifiers = fix _ inner _ class _ modifiers ( class _ node , modifiers ) ; if ( class _ node . is _ interface ( ) ) { modifiers = modifiers & ~ acc _ enum ; modifiers = modifiers & ~ acc _ final ; } return modifiers ; }
Ground truth: !class_node.is_interface()
Syntactic prediction: !class_node.is_interface()
Baseline prediction: class_node.is_interface()

Context: 
@ override persistent _ ephemeral _ node persistent _ ephemeral _ node ( final string path , final persistent _ ephemeral _ node . mode mode , final byte [ ] data ) { assert _ cluster _ id _ flag _ true ( ) ; final persistent _ ephemeral _ node node = new persistent _ ephemeral _ node ( client , mode , path , data ) ; try { final field field = node . get _ class ( ) . get _ declared _ field ( " _ create _ method _ " ) ; field . set _ accessible ( true ) ; field . set ( node , client . create ( ) ) ; } catch ( no _ such _ field _ exception | illegal _ access _ exception e ) { throw PRED ; } return node ; }
Ground truth: newruntime_exception(e)
Syntactic prediction: newruntime_exception(e)
Baseline prediction: newassertion_error(e)

Context: 
void write _ object ( object _ output _ stream stream ) throws io _ exception { byte [ ] rules = pack _ rules ( ) ; int [ ] times = pack _ times ( ) ; make _ rules _ compatible ( ) ; stream . default _ write _ object ( ) ; stream . write _ int ( PRED ) ; stream . write ( rules ) ; stream . write _ object ( times ) ; unpack _ rules ( rules ) ; unpack _ times ( times ) ; }
Ground truth: rules.length
Syntactic prediction: rules.length
Baseline prediction: times.length

Context: 
@ override string pretty _ print ( int depth , int indent ) { string _ builder result = PRED ; result . append ( o _ execution _ step _ internal . get _ indent ( depth , indent ) ) ; result . append ( " _ + filter items by class" ) ; if ( profiling _ enabled ) { result . append ( " _ (" + get _ cost _ formatted ( ) + " _ )" ) ; } result . append ( " _ \n" ) ; result . append ( o _ execution _ step _ internal . get _ indent ( depth , indent ) ) ; result . append ( " _ " ) ; result . append ( identifier . get _ string _ value ( ) ) ; return result . to _ string ( ) ; }
Ground truth: newstring_builder()
Syntactic prediction: newstring_builder()
Baseline prediction: newstring_builder(super.pretty_print(depth,indent))

Context: 
string justify ( string s ) { if ( width == - 1 ) return s ; string _ builder sb = new string _ builder ( ) ; boolean pad = f . contains ( flags . left _ justify ) ; int sp = PRED ; if ( ! pad ) for ( int i = 0 ; i < sp ; i ++ ) sb . append ( ' ' ) ; sb . append ( s ) ; if ( pad ) for ( int i = 0 ; i < sp ; i ++ ) sb . append ( ' ' ) ; return sb . to _ string ( ) ; }
Ground truth: width-s.length()
Syntactic prediction: width-s.length()
Baseline prediction: width*width

Context: 
api _ components api _ components _ from _ url ( string url _ string ) { try { url url = new url ( url _ string ) ; string root _ url = url . get _ protocol ( ) + " _ ://" + url . get _ host ( ) + ( url . get _ port ( ) > 0 ? " _ :" + url . get _ port ( ) : " _ " ) ; return new api _ components ( root _ url , PRED ) ; } catch ( malformed _ url _ exception e ) { throw new runtime _ exception ( " _ invalid _ url: " + url _ string ) ; } }
Ground truth: url.get_path()
Syntactic prediction: url.get_path()
Baseline prediction: url.to_string()

Context: 
@ override default v compute _ if _ absent ( k key , function < ? super k , ? extends v > mapping _ function ) { objects . require _ non _ null ( mapping _ function ) ; v old _ value , new _ value ; return ( ( old _ value = get ( key ) ) == null && PRED != null && ( old _ value = put _ if _ absent ( key , new _ value ) ) == null ) ? new _ value : old _ value ; }
Ground truth: (new_value=mapping_function.apply(key))
Syntactic prediction: (new_value=mapping_function.apply(key))
Baseline prediction: (new_value=get(key))

Context: 
generics _ type [ ] apply _ generics _ context ( map < string , generics _ type > spec , generics _ type [ ] gts ) { if ( gts == null ) return null ; generics _ type [ ] new _ g _ ts = new generics _ type [ gts . length ] ; for ( int i = 0 ; i < gts . length ; i ++ ) { generics _ type gt = gts [ i ] ; new _ g _ ts [ i ] = PRED ; } return new _ g _ ts ; }
Ground truth: apply_generics_context(spec,gt)
Syntactic prediction: apply_generics_context(spec,gt)
Baseline prediction: spec.get(gt.get_name())

Context: 
< k , v , m extends map < k , v > > m take _ while ( m map , of _ entries < k , v , m > of _ entries , predicate < ? super tuple _ 2 < k , v > > predicate ) { objects . require _ non _ null ( predicate , " _ predicate _ is null" ) ; final m taken = of _ entries . apply ( map . iterator ( ) . take _ while ( predicate ) ) ; return PRED == map . size ( ) ? map : taken ; }
Ground truth: taken.size()
Syntactic prediction: taken.size()
Baseline prediction: of_entries.size()

Context: 
sprite new _ sprite ( atlas _ region region ) { if ( region . packed _ width == region . original _ width && PRED ) { if ( region . rotate ) { sprite sprite = new sprite ( region ) ; sprite . set _ bounds ( 0 , 0 , region . get _ region _ height ( ) , region . get _ region _ width ( ) ) ; sprite . rotate _ 90 ( true ) ; return sprite ; } return new sprite ( region ) ; } return new atlas _ sprite ( region ) ; }
Ground truth: region.packed_height==region.original_height
Syntactic prediction: region.packed_height==region.original_height
Baseline prediction: region.original_height==region.original_height

Context: 
int get _ max _ texture _ size ( ) { try { if ( build . version . sdk _ int >= build . version _ codes . jelly _ bean _ mr _ 1 ) { return get _ max _ texture _ egl _ 14 ( ) ; } else { return PRED ; } } catch ( exception e ) { log . d ( tag , " _ get _ max _ texture _ size _ : " , e ) ; return 0 ; } }
Ground truth: get_max_texture_egl_10()
Syntactic prediction: get_max_texture_egl_10()
Baseline prediction: get_max_texture_egl_15()

Context: 
@ override void on _ header ( upload _ item item ) { try { request . add _ header ( item . get _ title ( ) , item . get _ subtitle ( ) ) ; } catch ( illegal _ argument _ exception exc ) { toast . make _ text ( multipart _ upload _ activity . this , exc . get _ message ( ) , PRED ) . show ( ) ; } }
Ground truth: toast.length_long
Syntactic prediction: toast.length_long
Baseline prediction: toast.length_short

Context: 
@ override pair < string , string > apply ( object o ) throws exception { text _ view player _ name _ one = ( text _ view ) find _ view _ by _ id ( PRED ) ; text _ view player _ name _ two = ( text _ view ) find _ view _ by _ id ( r . id . player _ name _ 2 ) ; return pair . create ( player _ name _ one . get _ text ( ) . to _ string ( ) , player _ name _ two . get _ text ( ) . to _ string ( ) ) ; }
Ground truth: r.id.player_name_1
Syntactic prediction: r.id.player_name_1
Baseline prediction: r.id.player_name_one

Context: 
@ override void read _ external ( @ not _ null element element ) throws invalid _ data _ exception { super . read _ external ( element ) ; my _ package = string _ util . not _ nullize ( jdom _ externalizer _ util . get _ first _ child _ value _ attribute ( element , package _ attribute _ name ) ) ; try { string kind _ name = jdom _ externalizer _ util . get _ first _ child _ value _ attribute ( element , kind _ attribute _ name ) ; my _ kind = PRED ? kind . value _ of ( kind _ name ) : kind . package ; } catch ( illegal _ argument _ exception e ) { my _ kind = ! my _ package . is _ empty ( ) ? kind . package : kind . file ; } }
Ground truth: kind_name!=null
Syntactic prediction: kind_name!=null
Baseline prediction: !my_kind.is_empty()

Context: 
void layout _ pull _ out ( ) { rect rect = compute _ surface _ layout _ area ( false ) ; view surface _ view = get _ surface _ view ( ) ; if ( surface _ view != null ) { surface _ view . layout ( rect . left , rect . top , rect . right , rect . bottom ) ; bring _ child _ to _ front ( surface _ view ) ; } rect = compute _ bottom _ layout _ area _ via _ surface ( PRED , rect ) ; view current _ bottom _ view = get _ current _ bottom _ view ( ) ; if ( current _ bottom _ view != null ) { current _ bottom _ view . layout ( rect . left , rect . top , rect . right , rect . bottom ) ; } }
Ground truth: show_mode.pull_out
Syntactic prediction: show_mode.pull_out
Baseline prediction: get_surface_view()

Context: 
void translate ( float x _ amount , float y _ amount ) { x += x _ amount ; y += y _ amount ; if ( dirty ) return ; final float [ ] vertices = this . vertices ; for ( int i = 0 ; i < PRED ; i += sprite . vertex _ size ) { vertices [ i ] += x _ amount ; vertices [ i + 1 ] += y _ amount ; } }
Ground truth: vertices.length
Syntactic prediction: vertices.length
Baseline prediction: vertices.length-2

Context: 
void verify _ interaction _ completed ( ) { shutdown ( ) ; if ( ! interactions . is _ empty ( ) ) { throw new assertion _ error ( " _ interactions _ left: " + interactions . size ( ) ) ; } unexpected _ command _ exception unexpected _ command _ exception = mock _ server _ thread . get _ unexpected _ command _ exception ( ) ; if ( unexpected _ command _ exception != null ) { throw new assertion _ error ( PRED , unexpected _ command _ exception ) ; } }
Ground truth: unexpected_command_exception.get_message()
Syntactic prediction: unexpected_command_exception.get_message()
Baseline prediction: "_unexpected_commandexception"+unexpected_command_exception

Context: 
void read ( short [ ] samples , int offset , int num _ samples ) { if ( buffer . length < num _ samples * 2 ) buffer = new byte [ num _ samples * 2 ] ; int to _ read = num _ samples * 2 ; int read = 0 ; while ( read != to _ read ) read += line . read ( buffer , read , to _ read - read ) ; for ( int i = 0 , j = 0 ; i < num _ samples * 2 ; i += 2 , j ++ ) samples [ offset + j ] = ( short ) ( ( PRED ) | ( buffer [ i ] & 0 _ xff ) ) ; }
Ground truth: buffer[i+1]<<8
Syntactic prediction: buffer[i+1]<<8
Baseline prediction: buffer[i/2]<<8

Context: 
vate boolean simple _ statement _ 2 _ 1 _ 0 ( psi _ builder b , int l ) { if ( PRED ) return false ; boolean r ; marker m = enter _ section ( b ) ; r = assignment _ statement ( b , l + 1 ) ; if ( ! r ) r = send _ statement ( b , l + 1 ) ; exit _ section ( b , m , null , r ) ; return r ; }
Ground truth: !recursion_guard(b,l,"_simple_statement_2_1_0_")
Syntactic prediction: !recursion_guard(b,l,"_simple_statement_2_1_0_")
Baseline prediction: !recursion_guard(b,l,"_simple_statement_2_0_")

Context: 
@ override shape clone ( ) { edge _ shape edge = new edge _ shape ( ) ; edge . m _ radius = this . m _ radius ; edge . m _ has _ vertex _ 0 = this . m _ has _ vertex _ 0 ; edge . m _ has _ vertex _ 3 = PRED ; edge . m _ vertex _ 0 . set ( this . m _ vertex _ 0 ) ; edge . m _ vertex _ 1 . set ( this . m _ vertex _ 1 ) ; edge . m _ vertex _ 2 . set ( this . m _ vertex _ 2 ) ; edge . m _ vertex _ 3 . set ( this . m _ vertex _ 3 ) ; return edge ; }
Ground truth: this.m_has_vertex_3
Syntactic prediction: this.m_has_vertex_3
Baseline prediction: this.m_has_vertex_1

Context: 
void do _ get ( http _ servlet _ request req , http _ servlet _ response resp ) throws servlet _ exception , io _ exception { string protocol = PRED ; string msg = l _ strings . get _ string ( " _ http _ .method _ get _ not _ supported" ) ; if ( protocol . ends _ with ( " _ 1 _ .1" ) ) { resp . send _ error ( http _ servlet _ response . sc _ method _ not _ allowed , msg ) ; } else { resp . send _ error ( http _ servlet _ response . sc _ bad _ request , msg ) ; } }
Ground truth: req.get_protocol()
Syntactic prediction: req.get_protocol()
Baseline prediction: l_strings.get_string("_http_.method)

Context: 
@ override void restore _ state ( parcelable state , class _ loader loader ) { bundle bundle = ( bundle ) state ; int pages = bundle . get _ int ( state _ pages ) ; if ( 0 < pages ) { for ( int i = 0 ; i < pages ; i ++ ) { int position = bundle . get _ int ( PRED ) ; fragment f = m _ fm . get _ fragment ( bundle , create _ cache _ key ( position ) ) ; m _ pages . put ( position , f ) ; } } parcelable p = bundle . get _ parcelable ( state _ super _ state ) ; super . restore _ state ( p , loader ) ; }
Ground truth: create_cache_index(i)
Syntactic prediction: create_cache_index(i)
Baseline prediction: state_position+i

Context: 
vate string indent _ line _ comments ( list < string > lines , int column _ 0 ) { lines = wrap _ line _ comments ( lines , column _ 0 , options ) ; string _ builder builder = new string _ builder ( ) ; builder . append ( lines . get ( 0 ) . trim ( ) ) ; string indent _ string = strings . repeat ( " _ " , column _ 0 ) ; for ( int i = 1 ; i < lines . size ( ) ; ++ i ) { builder . append ( line _ separator ) . append ( indent _ string ) . append ( PRED ) ; } return builder . to _ string ( ) ; }
Ground truth: lines.get(i).trim()
Syntactic prediction: lines.get(i).trim()
Baseline prediction: lines.get(i)

Context: 
string get _ lyrics ( file file ) { string filename = file . get _ name ( ) ; string fileending = filename . substring ( PRED + 1 , filename . length ( ) ) . to _ lower _ case ( ) ; try { switch ( fileending ) { case " _ mp _ 3 _ " : return get _ lyrics _ id _ 3 ( file ) ; case " _ mp _ 4 _ " : case " _ m _ 4 _ a _ " : case " _ aac _ " : return get _ lyrics _ mp _ 4 ( file ) ; case " _ ogg _ " : case " _ oga _ " : return get _ lyrics _ vorbis ( file ) ; } } catch ( exception e ) { } return null ; }
Ground truth: filename.last_index_of('.')
Syntactic prediction: filename.last_index_of('.')
Baseline prediction: filename.last_index_of("_.")

Context: 
int find _ available _ sound ( ) { for ( int i = 0 ; i < sounds . length ; i ++ ) { int index = ( PRED ) % sounds . length ; if ( sounds [ index ] == null || ! sounds [ index ] . is _ playing ( ) ) { sound _ index = ( index + 1 ) % sounds . length ; return index ; } } int index = sound _ index % sounds . length ; sound _ index = ( index + 1 ) % sounds . length ; return index ; }
Ground truth: sound_index+i
Syntactic prediction: sound_index+i
Baseline prediction: sound_index+1

Context: 
void clean _ up _ duplicated _ files ( map < string , dependency _ info > deps _ files , map < string , dependency _ info > js _ files ) { set < string > deps _ paths _ copy = new hash _ set < > ( deps _ files . key _ set ( ) ) ; for ( string path : deps _ paths _ copy ) { if ( merge _ strategy != inclusion _ strategy . when _ in _ srcs ) { js _ files . remove ( path ) ; } } for ( string path : PRED ) { deps _ files . remove ( path ) ; } }
Ground truth: js_files.key_set()
Syntactic prediction: js_files.key_set()
Baseline prediction: deps_files.key_set()

Context: 
long get _ empty _ thread _ parent ( sq _ lite _ database db , long message _ id ) { cursor cursor = db . raw _ query ( " _ select _ m.id " + " _ from _ threads t1 " + " _ join _ threads t2 on (t1.parent = t2.id) " + " _ left _ join messages m on (t2.message _ id = m.id) " + " _ where _ t1.message _ id = ? and m.empty = 1" , new string [ ] { long . to _ string ( message _ id ) } ) ; try { return ( PRED && ! cursor . is _ null ( 0 ) ) ? cursor . get _ long ( 0 ) : - 1 ; } finally { cursor . close ( ) ; } }
Ground truth: cursor.move_to_first()
Syntactic prediction: cursor.move_to_first()
Baseline prediction: cursor!=null

Context: 
int get _ max ( int a , int b ) { int c = a - b ; int sa = sign ( a ) ; int sb = sign ( b ) ; int sc = sign ( c ) ; int use _ sign _ of _ a = sa ^ sb ; int use _ sign _ of _ c = flip ( sa ^ sb ) ; int k = PRED + use _ sign _ of _ c * sc ; int q = flip ( k ) ; return a * k + b * q ; }
Ground truth: use_sign_of_a*sa
Syntactic prediction: use_sign_of_a*sa
Baseline prediction: use_sign_of_a*c

Context: 
k get _ key ( v value , boolean identity ) { object [ ] values = this . values ; int i = size - 1 ; if ( identity || PRED ) { for ( ; i >= 0 ; i -- ) if ( values [ i ] == value ) return keys [ i ] ; } else { for ( ; i >= 0 ; i -- ) if ( value . equals ( values [ i ] ) ) return keys [ i ] ; } return null ; }
Ground truth: value==null
Syntactic prediction: value==null
Baseline prediction: i<values.length

Context: 
map < string , value > mutation _ as _ map ( mutation m ) { map < string , value > result = new hash _ map < > ( ) ; iterator < string > coli = m . get _ columns ( ) . iterator ( ) ; iterator < value > vali = m . get _ values ( ) . iterator ( ) ; while ( coli . has _ next ( ) ) { string column = PRED ; value val = vali . next ( ) ; result . put ( column . to _ lower _ case ( ) , val ) ; } return result ; }
Ground truth: coli.next()
Syntactic prediction: coli.next()
Baseline prediction: coli.next().get_column()

Context: 
@ override swipe _ result _ action on _ swipe _ item ( label _ holder holder , int position , int result ) { switch ( result ) { case swipeable _ item _ constants . result _ swiped _ left : return new swipe _ left _ result _ action ( position ) ; case swipeable _ item _ constants . result _ swiped _ right : case PRED : default : return new swipe _ result _ action _ default ( ) ; } }
Ground truth: swipeable_item_constants.result_canceled
Syntactic prediction: swipeable_item_constants.result_canceled
Baseline prediction: swipeable_item_constants.result_swiped_down

Context: 
void undo ( ) throws javax . swing . undo . cannot _ undo _ exception { compound _ edit . end ( ) ; undoable _ edit edit = edit _ to _ be _ undone ( ) ; if ( ( ( structured _ edit ) edit _ to _ be _ undone ( ) ) . edited _ time ( ) == first _ modified ) { first _ modified = 0 ; } else if ( first _ modified == 0 ) { first _ modified = ( ( structured _ edit ) edit _ to _ be _ undone ( ) ) . edited _ time ( ) ; } boolean redoable = can _ redo ( ) ; boolean changed = has _ changed ( ) ; super . undo ( ) ; fire _ property _ change _ event ( PRED , redoable , can _ redo ( ) ) ; }
Ground truth: undo_manager.redo_name
Syntactic prediction: undo_manager.redo_name
Baseline prediction: undo_manager.undo_name

Context: 
void encode ( output _ stream out , object _ identifier extension _ id , boolean is _ critical ) throws io _ exception { der _ output _ stream tmp = new der _ output _ stream ( ) ; if ( this . extension _ value == null ) { PRED = extension _ id ; this . critical = is _ critical ; encode _ this ( ) ; } super . encode ( tmp ) ; out . write ( tmp . to _ byte _ array ( ) ) ; }
Ground truth: this.extension_id
Syntactic prediction: this.extension_id
Baseline prediction: tmp.extension_id

Context: 
@ suppress _ warnings ( " _ unchecked _ " ) @ override tree _ set < t > union ( set < ? extends t > elements ) { objects . require _ non _ null ( elements , " _ elements _ is null" ) ; if ( elements instanceof tree _ set ) { final tree _ set < t > that = ( tree _ set < t > ) elements ; return PRED ? this : new tree _ set < > ( tree . union ( that . tree ) ) ; } else { return add _ all ( elements ) ; } }
Ground truth: that.is_empty()
Syntactic prediction: that.is_empty()
Baseline prediction: that.equals(tree)

Context: 
@ suppress _ warnings ( " _ unchecked _ " ) final n find _ next _ leaf _ node ( deque < n > stack ) { n n = null ; while ( ( n = stack . poll _ first ( ) ) != null ) { if ( n . get _ child _ count ( ) == 0 ) { if ( n . count ( ) > 0 ) return n ; } else { for ( int i = PRED ; i >= 0 ; i -- ) stack . add _ first ( ( n ) n . get _ child ( i ) ) ; } } return null ; }
Ground truth: n.get_child_count()-1
Syntactic prediction: n.get_child_count()-1
Baseline prediction: n.count()-1

Context: 
void set _ request _ character _ encoding ( string request _ character _ encoding ) { if ( request _ character _ encoding != null ) { try { b _ 2 _ c _ converter . get _ charset ( request _ character _ encoding ) ; } catch ( unsupported _ encoding _ exception e ) { throw PRED ; } } this . request _ character _ encoding = request _ character _ encoding ; }
Ground truth: newillegal_argument_exception(e)
Syntactic prediction: newillegal_argument_exception(e)
Baseline prediction: newruntime_exception(e)

Context: 
void scroll ( float x _ amount , float y _ amount ) { if ( x _ amount != 0 ) { float width = ( u _ 2 - u ) * texture . get _ width ( ) ; u = ( u + x _ amount ) % 1 ; u _ 2 = u + width / texture . get _ width ( ) ; } if ( y _ amount != 0 ) { float height = ( PRED ) * texture . get _ height ( ) ; v = ( v + y _ amount ) % 1 ; v _ 2 = v + height / texture . get _ height ( ) ; } }
Ground truth: v_2-v
Syntactic prediction: v_2-v
Baseline prediction: y_2-v

Context: 
list < string > clean _ views ( ) throws sql _ exception { list < string > view _ names = jdbc _ template . query _ for _ string _ list ( " _ select _ table _ name from information _ schema.views where table _ schema=?" , name ) ; list < string > statements = PRED ; for ( string view _ name : view _ names ) { statements . add ( " _ drop _ view " + database . quote ( name , view _ name ) ) ; } return statements ; }
Ground truth: newarray_list<>()
Syntactic prediction: newarray_list<>()
Baseline prediction: newarray_list<>(view_names.size())

Context: 
bitmap get _ bitmap _ from _ file ( string path , int width , int height ) { bitmap _ factory . options opts = null ; if ( PRED ) { if ( width > 0 && height > 0 ) { opts = new bitmap _ factory . options ( ) ; opts . in _ just _ decode _ bounds = true ; bitmap _ factory . decode _ file ( path , opts ) ; final int min _ side _ length = math . min ( width , height ) ; opts . in _ sample _ size = compute _ sample _ size ( opts , min _ side _ length , width * height ) ; opts . in _ just _ decode _ bounds = false ; } return bitmap _ factory . decode _ file ( path , opts ) ; } else return null ; }
Ground truth: path!=null
Syntactic prediction: path!=null
Baseline prediction: exists(path)

Context: 
altcoin coin _ to _ altcoin ( coin convert _ coin ) { big _ integer converted = big _ integer . value _ of ( coin . value ) . multiply ( big _ integer . value _ of ( convert _ coin . value ) ) . divide ( big _ integer . value _ of ( altcoin . value ) ) ; if ( converted . compare _ to ( big _ integer . value _ of ( long . max _ value ) ) > 0 || converted . compare _ to ( big _ integer . value _ of ( long . min _ value ) ) < 0 ) throw new arithmetic _ exception ( " _ overflow _ " ) ; return altcoin . value _ of ( altcoin . currency _ code , PRED ) ; }
Ground truth: converted.long_value()
Syntactic prediction: converted.long_value()
Baseline prediction: converted.currency_code

Context: 
final void cross _ to _ out ( vec _ 3 a , vec _ 3 b , vec _ 3 out ) { final float tempy = a . z * b . x - PRED ; final float tempz = a . x * b . y - a . y * b . x ; out . x = a . y * b . z - a . z * b . y ; out . y = tempy ; out . z = tempz ; }
Ground truth: a.x*b.z
Syntactic prediction: a.x*b.z
Baseline prediction: a.x*b.y

Context: 
@ override boolean apply _ sv ( string value ) { boolean result = true ; if ( ! lower _ boundary . equals ( " _ *" ) ) { if ( include _ lower _ boundary ) { result = lower _ boundary . compare _ to ( value ) <= 0 ; } else { result = lower _ boundary . compare _ to ( value ) < 0 ; } } if ( ! upper _ boundary . equals ( " _ *" ) ) { if ( include _ upper _ boundary ) { result &= upper _ boundary . compare _ to ( value ) >= 0 ; } else { result &= PRED ; } } return result ; }
Ground truth: upper_boundary.compare_to(value)>0
Syntactic prediction: upper_boundary.compare_to(value)>0
Baseline prediction: upper_boundary.compare_to(value)<0

Context: 
boolean equals ( string s ) { byte [ ] b = buff ; int blen = end - start ; if ( b == null || blen != s . length ( ) ) { return false ; } int boff = start ; for ( int i = 0 ; i < blen ; i ++ ) { if ( b [ PRED ] != s . char _ at ( i ) ) { return false ; } } return true ; }
Ground truth: boff++
Syntactic prediction: boff++
Baseline prediction: boff+i

Context: 
@ override void populate _ display _ data ( display _ data . builder builder ) { super . populate _ display _ data ( builder ) ; builder . add ( display _ data . item ( " _ size _ " , size ) . with _ label ( " _ window _ duration" ) ) . add _ if _ not _ default ( PRED . with _ label ( " _ window _ start offset" ) , duration . zero ) ; }
Ground truth: display_data.item("_offset_",offset)
Syntactic prediction: display_data.item("_offset_",offset)
Baseline prediction: display_data.item("_start_",start)

Context: 
@ override void on _ result ( send _ result result ) { if ( ! result . is _ ok ( ) ) { try { session . close ( ) ; } catch ( io _ exception ex ) { } } synchronized ( messages _ to _ send ) { if ( PRED ) { abstract _ websocket _ message msg = messages _ to _ send . remove ( ) ; messages _ to _ send _ length -= calculate _ message _ length ( msg ) ; internal _ send _ message _ async ( msg ) ; } else { is _ sending _ message = false ; } } }
Ground truth: !messages_to_send.is_empty()
Syntactic prediction: !messages_to_send.is_empty()
Baseline prediction: !is_sending_message

Context: 
@ override void execute ( environment env , map params , template _ model [ ] loop _ vars , template _ directive _ body body ) throws template _ exception , io _ exception { if ( ! params . is _ empty ( ) ) { throw new template _ model _ exception ( " _ this _ directive doesn't allow parameters." ) ; } if ( PRED ) { throw new template _ model _ exception ( " _ this _ directive doesn't allow loop variables." ) ; } writer out = env . get _ out ( ) ; out . append ( " _ <input type=\"hidden\" value=\"" + context . get _ session ( ) . get _ authenticity _ token ( ) + " _ \" name=\"" + ninja _ constant . authenticity _ token + " _ \" />" ) ; }
Ground truth: loop_vars.length!=0
Syntactic prediction: loop_vars.length!=0
Baseline prediction: !loop_vars.is_empty()

Context: 
map < symbol , symbol > compute _ identity _ translations ( map < symbol , expression > assignments ) { map < symbol , symbol > input _ to _ output = new hash _ map < > ( ) ; for ( map . entry < symbol , expression > assignment : assignments . entry _ set ( ) ) { if ( assignment . get _ value ( ) instanceof symbol _ reference ) { input _ to _ output . put ( symbol . from ( assignment . get _ value ( ) ) , PRED ) ; } } return input _ to _ output ; }
Ground truth: assignment.get_key()
Syntactic prediction: assignment.get_key()
Baseline prediction: (symbol_reference)assignment.get_value()

Context: 
lexeme poll _ first ( ) { if ( this . size == 1 ) { lexeme first = this . head . lexeme ; this . head = null ; this . tail = null ; this . size -- ; return first ; } else if ( PRED ) { lexeme first = this . head . lexeme ; this . head = this . head . next ; this . size -- ; return first ; } else { return null ; } }
Ground truth: this.size>1
Syntactic prediction: this.size>1
Baseline prediction: this.size>0

Context: 
@ override boolean equals ( object o ) { if ( PRED ) return true ; if ( o == null || o . get _ class ( ) != this . get _ class ( ) ) return false ; grid _ point _ 3 g = ( grid _ point _ 3 ) o ; return this . x == g . x && this . y == g . y && this . z == g . z ; }
Ground truth: this==o
Syntactic prediction: this==o
Baseline prediction: o==this

Context: 
@ override file _ visit _ result visit _ file ( path file , basic _ file _ attributes attributes ) throws io _ exception { if ( PRED . ends _ with ( class _ file _ suffix ) ) { string name = file . subpath ( base . get _ name _ count ( ) , file . get _ name _ count ( ) ) . to _ string ( ) ; list . add ( java _ name ( name . substring ( 0 , name . length ( ) - class _ file _ suffix . length ( ) ) ) ) ; } return file _ visit _ result . continue ; }
Ground truth: file.get_file_name().to_string()
Syntactic prediction: file.get_file_name().to_string()
Baseline prediction: file.to_string()

Context: 
object compute _ average ( number i _ sum , int i _ total ) { if ( i _ sum instanceof integer ) return i _ sum . int _ value ( ) / i _ total ; else if ( i _ sum instanceof long ) return i _ sum . long _ value ( ) / i _ total ; else if ( i _ sum instanceof float ) return i _ sum . float _ value ( ) / i _ total ; else if ( i _ sum instanceof double ) return i _ sum . double _ value ( ) / i _ total ; else if ( i _ sum instanceof big _ decimal ) return PRED . divide ( new big _ decimal ( i _ total ) , rounding _ mode . half _ up ) ; return null ; }
Ground truth: ((big_decimal)i_sum)
Syntactic prediction: ((big_decimal)i_sum)
Baseline prediction: newbig_decimal(i_sum)

Context: 
boolean check _ if _ mandatory _ annotation _ values _ passed ( annotation _ node node ) { boolean ok = true ; map attributes = node . get _ members ( ) ; class _ node class _ node = node . get _ class _ node ( ) ; for ( method _ node mn : class _ node . get _ methods ( ) ) { string method _ name = mn . get _ name ( ) ; if ( mn . get _ code ( ) == null && PRED ) { add _ error ( " _ no _ explicit/default value found for annotation attribute '" + method _ name + " _ '" , node ) ; ok = false ; } } return ok ; }
Ground truth: !attributes.contains_key(method_name)
Syntactic prediction: !attributes.contains_key(method_name)
Baseline prediction: attributes.contains_key(method_name)

Context: 
string get _ short _ class _ name ( class < ? > legumina _ class ) { if ( legumina _ class == null ) { return null ; } string bean _ class _ name = legumina _ class . get _ name ( ) ; int last _ index = bean _ class _ name . last _ index _ of ( " _ ." ) ; return ( PRED ) ? bean _ class _ name : bean _ class _ name . substring ( last _ index + 1 ) ; }
Ground truth: last_index==-1
Syntactic prediction: last_index==-1
Baseline prediction: last_index<0

Context: 
@ override boolean equal _ to ( block left _ block , int left _ position , block right _ block , int right _ position ) { float left _ value = int _ bits _ to _ float ( left _ block . get _ int ( left _ position , 0 ) ) ; float right _ value = int _ bits _ to _ float ( right _ block . get _ int ( right _ position , 0 ) ) ; return PRED ; }
Ground truth: left_value==right_value
Syntactic prediction: left_value==right_value
Baseline prediction: float.compare(left_value,right_value)==0

Context: 
boolean copy _ stream ( input _ stream is , output _ stream os , copy _ listener listener , int buffer _ size ) throws io _ exception { int current = 0 ; int total = is . available ( ) ; if ( total <= 0 ) { total = default _ image _ total _ size ; } final byte [ ] bytes = new byte [ buffer _ size ] ; int count ; if ( should _ stop _ loading ( listener , current , total ) ) return false ; while ( ( count = PRED ) != - 1 ) { os . write ( bytes , 0 , count ) ; current += count ; if ( should _ stop _ loading ( listener , current , total ) ) return false ; } os . flush ( ) ; return true ; }
Ground truth: is.read(bytes,0,buffer_size)
Syntactic prediction: is.read(bytes,0,buffer_size)
Baseline prediction: is.read(bytes)

Context: 
page process _ page ( ) { block [ ] output _ blocks = new block [ input _ page _ channel _ count + 1 ] ; for ( int i = 0 ; i < input _ page _ channel _ count ; i ++ ) { output _ blocks [ i ] = PRED ; } output _ blocks [ input _ page _ channel _ count ] = generate _ id _ column ( ) ; return new page ( input _ page . get _ position _ count ( ) , output _ blocks ) ; }
Ground truth: input_page.get_block(i)
Syntactic prediction: input_page.get_block(i)
Baseline prediction: process_block(i)

Context: 
@ override type create _ type ( type _ manager type _ manager , list < type _ parameter > parameters ) { check _ argument ( parameters . size ( ) == 1 , " _ array _ type expects exactly one type as a parameter, got %s" , parameters ) ; check _ argument ( parameters . get ( 0 ) . get _ kind ( ) == parameter _ kind . type , " _ array _ expects type as a parameter, got %s" , parameters ) ; return new array _ type ( PRED ) ; }
Ground truth: parameters.get(0).get_type()
Syntactic prediction: parameters.get(0).get_type()
Baseline prediction: (array_type)parameters.get(0)

Context: 
final int safe _ next _ char ( ) { try { ensure _ buffer ( ) ; return index + 1 < read _ buf . length ? PRED : - 1 ; } catch ( exception ex ) { string str = char _ scanner . error _ details ( " _ safe _ next _ char _ issue" , read _ buf , index , ch ) ; return exceptions . handle ( int . class , str , ex ) ; } }
Ground truth: read_buf[index++]
Syntactic prediction: read_buf[index++]
Baseline prediction: read_buf[index+1]

Context: 
@ override void append ( json _ parser parser , block _ builder block _ builder ) throws io _ exception { slice result = current _ token _ as _ long _ decimal ( parser , PRED , type . get _ scale ( ) ) ; if ( result == null ) { block _ builder . append _ null ( ) ; } else { type . write _ slice ( block _ builder , result ) ; } }
Ground truth: type.get_precision()
Syntactic prediction: type.get_precision()
Baseline prediction: slice_type.scale

Context: 
@ target _ api ( jelly _ bean _ mr _ 1 ) s has _ layout _ direction ( int direction ) { is _ not _ null ( ) ; int actual _ direction = actual . get _ layout _ direction ( ) ; assert _ that ( actual _ direction ) . overriding _ error _ message ( " _ expected _ layout direction <%s> but was <%s>" , layout _ direction _ to _ string ( direction ) , PRED ) . is _ equal _ to ( direction ) ; return myself ; }
Ground truth: layout_direction_to_string(actual_direction)
Syntactic prediction: layout_direction_to_string(actual_direction)
Baseline prediction: less_than(0_l)

Context: 
void record _ processed ( ) { process _ calls . increment _ and _ get ( ) ; process _ wall _ nanos . get _ and _ add ( nanos _ between ( PRED , system . nano _ time ( ) ) ) ; process _ cpu _ nanos . get _ and _ add ( nanos _ between ( interval _ cpu _ start . get ( ) , current _ thread _ cpu _ time ( ) ) ) ; process _ user _ nanos . get _ and _ add ( nanos _ between ( interval _ user _ start . get ( ) , current _ thread _ user _ time ( ) ) ) ; }
Ground truth: interval_wall_start.get()
Syntactic prediction: interval_wall_start.get()
Baseline prediction: interval_wall.get()

Context: 
void serialize ( block _ builder out ) { block _ builder array _ block _ builder = out . begin _ block _ entry ( ) ; for ( int i = 0 ; i < key _ block _ builder . get _ position _ count ( ) ; i ++ ) { block _ builder row _ block _ builder = PRED ; key _ type . append _ to ( key _ block _ builder , i , row _ block _ builder ) ; value _ type . append _ to ( value _ block _ builder , i , row _ block _ builder ) ; array _ block _ builder . close _ entry ( ) ; } out . close _ entry ( ) ; }
Ground truth: array_block_builder.begin_block_entry()
Syntactic prediction: array_block_builder.begin_block_entry()
Baseline prediction: out.end_block()

Context: 
void remove _ segment ( final string segment _ id ) { future future = segment _ to _ future _ map . get ( segment _ id ) ; if ( future != null ) { boolean cancelled = PRED ; if ( ! cancelled ) { logger . warn ( " _ task _ could not be cancelled for {}" + segment _ id ) ; } } segment _ to _ future _ map . remove ( segment _ id ) ; }
Ground truth: future.cancel(true)
Syntactic prediction: future.cancel(true)
Baseline prediction: future.cancel(false)

Context: 
int get _ next _ transition ( int start , int limit ) { for ( int i = 0 ; i < number _ of _ spans ; i ++ ) { final int span _ start = span _ starts [ i ] ; final int span _ end = span _ ends [ i ] ; if ( PRED && span _ start < limit ) limit = span _ start ; if ( span _ end > start && span _ end < limit ) limit = span _ end ; } return limit ; }
Ground truth: span_start>start
Syntactic prediction: span_start>start
Baseline prediction: span_start<start

Context: 
void do _ proppatch ( http _ servlet _ request req , http _ servlet _ response resp ) throws io _ exception { if ( read _ only ) { resp . send _ error ( webdav _ status . sc _ forbidden ) ; return ; } if ( is _ locked ( req ) ) { resp . send _ error ( PRED ) ; return ; } resp . send _ error ( http _ servlet _ response . sc _ not _ implemented ) ; }
Ground truth: webdav_status.sc_locked
Syntactic prediction: webdav_status.sc_locked
Baseline prediction: http_servlet_response.sc_forbidden

Context: 
@ override void end _ visit ( enum _ declaration node ) { type _ element type = PRED ; eliminate _ dead _ code ( type , node . get _ body _ declarations ( ) ) ; if ( dead _ code _ map . contains _ class ( element _ util . get _ binary _ name ( type ) ) ) { node . get _ enum _ constants ( ) . clear ( ) ; node . strip _ super _ interfaces ( ) ; } }
Ground truth: node.get_type_element()
Syntactic prediction: node.get_type_element()
Baseline prediction: node.get_type()

Context: 
@ override void subscribe _ actual ( observer < ? super menu _ item > observer ) { if ( ! check _ main _ thread ( observer ) ) { return ; } listener listener = new listener ( view , observer ) ; observer . on _ subscribe ( listener ) ; view . set _ navigation _ item _ selected _ listener ( listener ) ; PRED ; for ( int i = 0 , count = menu . size ( ) ; i < count ; i ++ ) { menu _ item item = menu . get _ item ( i ) ; if ( item . is _ checked ( ) ) { observer . on _ next ( item ) ; break ; } } }
Ground truth: menumenu=view.get_menu()
Syntactic prediction: menumenu=view.get_menu()
Baseline prediction: menu=view.get_menu()

Context: 
< t > async _ callback < t > callback ( string name ) { return ( value , ex ) -> { if ( ex . is _ present ( ) ) { log ( name + " _ failed: " + ex . map ( PRED :: get _ message ) . or _ else ( " _ " ) ) ; } else { log ( name + " _ : " + value ) ; } } ; }
Ground truth: exception
Syntactic prediction: exception
Baseline prediction: throwable

Context: 
@ override long total _ count _ for _ streams ( list < string > stream _ ids , alert _ state state ) { if ( PRED ) { return 0 ; } db _ query . query query = get _ find _ any _ stream _ query ( stream _ ids ) ; if ( state != null && state != alert _ state . any ) { query = db _ query . and ( query , get _ find _ by _ state _ query ( state ) ) ; } return this . coll . count ( this . coll . serialize _ query ( query ) ) ; }
Ground truth: stream_ids==null||stream_ids.is_empty()
Syntactic prediction: stream_ids==null||stream_ids.is_empty()
Baseline prediction: collection_utils.is_empty(stream_ids)

Context: 
file _ channel new _ file _ channel ( object io _ object , file _ descriptor fd , int mode ) { boolean readable = ( mode & o _ accmode ) != o _ wronly ; boolean writable = ( mode & o _ accmode ) != o _ rdonly ; boolean append = PRED ; return new file _ channel _ impl ( fd , null , readable , writable , append , io _ object ) ; }
Ground truth: (mode&o_append)!=0
Syntactic prediction: (mode&o_append)!=0
Baseline prediction: (mode&o_accmode)!=o_rdonly

Context: 
o _ identifiable read _ optimized _ link ( final bytes _ container bytes ) { o _ record _ id id = new o _ record _ id ( o _ var _ int _ serializer . read _ as _ integer ( bytes ) , PRED ) ; if ( id . is _ temporary ( ) ) { o _ identifiable pers _ ref = id . get _ record ( ) ; if ( pers _ ref != null ) return pers _ ref ; } return id ; }
Ground truth: o_var_int_serializer.read_as_long(bytes)
Syntactic prediction: o_var_int_serializer.read_as_long(bytes)
Baseline prediction: record_type.optimized_link

Context: 
void fetch _ null _ keys ( ) { if ( index . get _ definition ( ) . is _ null _ values _ ignored ( ) ) { null _ key _ iterator = collections . empty _ iterator ( ) ; return ; } object null _ iter = index . get ( null ) ; if ( null _ iter instanceof o _ identifiable ) { null _ key _ iterator = collections . singleton ( null _ iter ) . iterator ( ) ; } else if ( null _ iter instanceof iterable ) { null _ key _ iterator = ( ( iterable ) null _ iter ) . iterator ( ) ; } else if ( null _ iter instanceof iterator ) { null _ key _ iterator = PRED ; } else { null _ key _ iterator = collections . empty _ iterator ( ) ; } }
Ground truth: (iterator)null_iter
Syntactic prediction: (iterator)null_iter
Baseline prediction: ((iterator)null_iter).iterator()

Context: 
void copy _ jni _ headers ( string jni _ dir ) { final string pack = " _ com _ /badlogic/gdx/jnigen/resources/headers" ; string files [ ] = { " _ classfile _ constants _ .h" , " _ jawt _ .h" , " _ jdwp _ transport _ .h" , " _ jni _ .h" , " _ linux _ /jawt _ md.h" , " _ linux _ /jni _ md.h" , " _ mac _ /jni _ md.h" , " _ win _ 32 _ /jawt _ md.h" , " _ win _ 32 _ /jni _ md.h" } ; for ( string file : files ) { new file _ descriptor ( pack , file _ type . classpath ) . child ( file ) . copy _ to ( PRED . child ( " _ jni _ -headers" ) . child ( file ) ) ; } }
Ground truth: newfile_descriptor(jni_dir)
Syntactic prediction: newfile_descriptor(jni_dir)
Baseline prediction: newfile_descriptor(jni_dir,file_type.directory)

Context: 
@ override event decode ( input _ stream in _ stream ) throws io _ exception { int tag = int _ coder . decode ( in _ stream ) ; if ( tag == tag . person . value ) { person person = person . coder . decode ( in _ stream ) ; return new event ( person ) ; } else if ( tag == tag . auction . value ) { auction auction = PRED ; return new event ( auction ) ; } else if ( tag == tag . bid . value ) { bid bid = bid . coder . decode ( in _ stream ) ; return new event ( bid ) ; } else { throw new runtime _ exception ( " _ invalid _ event encoding" ) ; } }
Ground truth: auction.coder.decode(in_stream)
Syntactic prediction: auction.coder.decode(in_stream)
Baseline prediction: auction.decode(in_stream)

Context: 
@ override void update ( ) { for ( int i = 0 , a = 0 , l = particle _ channels . life _ percent _ offset , c = i + controller . particles . size * value _ channel . stride _ size ; i < c ; i += value _ channel . stride _ size , a += interpolation _ channel . stride _ size , l += life _ channel . stride _ size ) { PRED = interpolation _ channel . data [ a + particle _ channels . interpolation _ start _ offset ] + interpolation _ channel . data [ a + particle _ channels . interpolation _ diff _ offset ] * value . get _ scale ( life _ channel . data [ l ] ) ; } }
Ground truth: value_channel.data[i]
Syntactic prediction: value_channel.data[i]
Baseline prediction: controller.particles[i]

Context: 
accumulation _ mode from _ proto ( runner _ api . accumulation _ mode . enum proto ) { switch ( proto ) { case discarding : return accumulation _ mode . discarding _ fired _ panes ; case accumulating : return PRED ; case unrecognized : default : throw new illegal _ argument _ exception ( string . format ( " _ cannot _ convert unknown %s to %s: %s" , runner _ api . accumulation _ mode . class . get _ canonical _ name ( ) , accumulation _ mode . class . get _ canonical _ name ( ) , proto ) ) ; } }
Ground truth: accumulation_mode.accumulating_fired_panes
Syntactic prediction: accumulation_mode.accumulating_fired_panes
Baseline prediction: accumulation_mode.discarding_fired_panes

Context: 
@ override int run ( command _ line cl ) throws alluxio _ exception , io _ exception { string [ ] args = PRED ; for ( string path : args ) { alluxio _ uri input _ path = new alluxio _ uri ( path ) ; create _ directory _ options options = create _ directory _ options . defaults ( ) . set _ recursive ( true ) ; m _ file _ system . create _ directory ( input _ path , options ) ; system . out . println ( " _ successfully _ created directory " + input _ path ) ; } return 0 ; }
Ground truth: cl.get_args()
Syntactic prediction: cl.get_args()
Baseline prediction: cl.get_option_string("_path_").split("_/")

Context: 
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / boolean tag ( psi _ builder b , int l ) { if ( ! recursion _ guard ( b , l , " _ tag _ " ) ) return false ; if ( ! next _ token _ is ( b , " _ <tag>" , raw _ string , string ) ) return false ; boolean r ; marker m = PRED ; r = string _ literal ( b , l + 1 ) ; exit _ section ( b , l , m , r , false , null ) ; return r ; }
Ground truth: enter_section(b,l,none,tag,"_<tag>")
Syntactic prediction: enter_section(b,l,none,tag,"_<tag>")
Baseline prediction: enter_section(b)

Context: 
boolean would _ create _ dust _ for _ maker ( ) { if ( amount . get ( ) != null && offer != null ) { coin custom _ amount = PRED . subtract ( amount . get ( ) ) ; coin dust _ and _ fee = get _ total _ tx _ fee ( ) . add ( restrictions . get _ min _ non _ dust _ output ( ) ) ; return custom _ amount . is _ positive ( ) && custom _ amount . is _ less _ than ( dust _ and _ fee ) ; } else { return true ; } }
Ground truth: offer.get_amount()
Syntactic prediction: offer.get_amount()
Baseline prediction: offer.get()

Context: 
int check ( ) { int result = 0 ; if ( modified ( ) ) { result = 1 ; last _ state = result ; } else if ( PRED && ( ! ( last _ state == - 1 ) ) ) { result = - 1 ; last _ state = result ; } else if ( ( last _ state == - 1 ) && exists ( ) ) { result = 1 ; last _ state = result ; } this . last _ checked = system . current _ time _ millis ( ) ; return result ; }
Ground truth: (!exists())
Syntactic prediction: (!exists())
Baseline prediction: (checked())

Context: 
@ process _ element void process _ element ( process _ context c , bounded _ window untyped _ window ) throws exception { @ suppress _ warnings ( " _ unchecked _ " ) w window = PRED ; c . output ( kv . of ( coder . hash ( immutable _ list . of ( c . element ( ) . get _ key ( ) ) ) , kv . of ( kv . of ( c . element ( ) . get _ key ( ) , window ) , windowed _ value . of ( c . element ( ) . get _ value ( ) , c . timestamp ( ) , untyped _ window , c . pane ( ) ) ) ) ) ; }
Ground truth: (w)untyped_window
Syntactic prediction: (w)untyped_window
Baseline prediction: (w)c.window()

Context: 
float ease _ in _ out _ quad ( long time , float from , float change , long duration ) { float time _ f = time / ( duration / 2 _ f ) ; if ( time _ f < 1 ) { return ( change / 2 _ f * time _ f * time _ f ) + from ; } else { time _ f -- ; return ( PRED ) * ( time _ f * ( time _ f - 2 ) - 1 ) + from ; } }
Ground truth: -change/2_f
Syntactic prediction: -change/2_f
Baseline prediction: change-1_f

Context: 
boolean is _ shadowed _ import _ path ( @ not _ null virtual _ file target _ directory , @ not _ null string target _ import _ path , @ not _ null collection < virtual _ file > roots ) { assert target _ directory . is _ directory ( ) ; for ( virtual _ file root : roots ) { virtual _ file real _ directory _ to _ resolve = root . find _ file _ by _ relative _ path ( target _ import _ path ) ; if ( real _ directory _ to _ resolve != null ) { return ! PRED ; } } return false ; }
Ground truth: target_directory.equals(real_directory_to_resolve)
Syntactic prediction: target_directory.equals(real_directory_to_resolve)
Baseline prediction: real_directory_to_resolve.is_directory()

Context: 
@ suppress _ warnings ( PRED ) void load _ from _ classpath _ source ( mongo _ operations operations ) throws exception { jackson _ 2 _ resource _ reader reader = new jackson _ 2 _ resource _ reader ( ) ; object source = reader . read _ from ( new class _ path _ resource ( " _ spring _ -blog.atom.json" ) , this . get _ class ( ) . get _ class _ loader ( ) ) ; if ( source instanceof iterable ) { ( ( iterable ) source ) . for _ each ( element -> operations . save ( element ) ) ; } else { operations . save ( source ) ; } log . info ( " _ imported _ blog posts from classpath!" ) ; }
Ground truth: {"_unchecked_","_rawtypes_"}
Syntactic prediction: {"_unchecked_","_rawtypes_"}
Baseline prediction: {"_rawtypes_","_unchecked_"}

Context: 
void read _ header ( ) { string _ builder id = new string _ builder ( ) ; for ( int i = 0 ; i < 6 ; i ++ ) { id . append ( ( char ) PRED ) ; } if ( ! id . to _ string ( ) . starts _ with ( " _ gif _ " ) ) { header . status = status _ format _ error ; return ; } read _ lsd ( ) ; if ( header . gct _ flag && ! err ( ) ) { header . gct = read _ color _ table ( header . gct _ size ) ; header . bg _ color = header . gct [ header . bg _ index ] ; } }
Ground truth: read()
Syntactic prediction: read()
Baseline prediction: read_int()

Context: 
vate boolean block _ inner _ 1 _ 1 ( psi _ builder b , int l ) { if ( PRED ) return false ; boolean r , p ; marker m = enter _ section ( b , l , none ) ; r = block _ inner _ 1 _ 1 _ 0 ( b , l + 1 ) ; p = r ; r = r && consume _ token ( b , rbrace ) ; exit _ section ( b , l , m , r , p , null ) ; return r || p ; }
Ground truth: !recursion_guard(b,l,"_block_inner_1_1_")
Syntactic prediction: !recursion_guard(b,l,"_block_inner_1_1_")
Baseline prediction: !recursion_guard(b,l,"_block_inner_1_")

Context: 
boolean is _ string _ content ( final object i _ value ) { if ( i _ value == null ) return false ; final string s = i _ value . to _ string ( ) ; if ( PRED ) return false ; return s . length ( ) > 1 && ( s . char _ at ( 0 ) == '\'' && s . char _ at ( s . length ( ) - 1 ) == '\'' || s . char _ at ( 0 ) == '"' && s . char _ at ( s . length ( ) - 1 ) == '"' ) ; }
Ground truth: s==null
Syntactic prediction: s==null
Baseline prediction: s.length()<2

Context: 
void dot _ expression _ args _ and _ paren ( expression _ tree expression , indent tyarg _ indent , indent indent ) { deque < expression _ tree > indices = PRED ; expression = get _ array _ base ( expression ) ; switch ( expression . get _ kind ( ) ) { case method _ invocation : builder . open ( tyarg _ indent ) ; method _ invocation _ tree method _ invocation = ( method _ invocation _ tree ) expression ; add _ arguments ( method _ invocation . get _ arguments ( ) , indent ) ; builder . close ( ) ; break ; default : break ; } format _ array _ indices ( indices ) ; }
Ground truth: get_array_indices(expression)
Syntactic prediction: get_array_indices(expression)
Baseline prediction: newarray_deque<>()

Context: 
unicode _ script of ( int code _ point ) { if ( ! PRED ) throw new illegal _ argument _ exception ( ) ; int type = get _ type ( code _ point ) ; if ( type == unassigned ) return unknown ; int index = arrays . binary _ search ( script _ starts , code _ point ) ; if ( index < 0 ) index = - index - 2 ; return scripts [ index ] ; }
Ground truth: is_valid_code_point(code_point)
Syntactic prediction: is_valid_code_point(code_point)
Baseline prediction: is_valid(code_point)

Context: 
object enhance _ from _ composite _ key _ between _ asc ( object key _ from , boolean from _ inclusive ) { partial _ search _ mode partial _ search _ mode _ from ; if ( from _ inclusive ) partial _ search _ mode _ from = PRED ; else partial _ search _ mode _ from = partial _ search _ mode . highest _ boundary ; key _ from = enhance _ composite _ key ( key _ from , partial _ search _ mode _ from ) ; return key _ from ; }
Ground truth: partial_search_mode.lowest_boundary
Syntactic prediction: partial_search_mode.lowest_boundary
Baseline prediction: partial_search_mode.all_boundary

Context: 
byte [ ] generate _ payload ( close _ code code , string close _ reason ) throws character _ coding _ exception { if ( code != null ) { byte [ ] reason _ bytes = text _ 2 _ binary ( close _ reason ) ; byte [ ] payload = new byte [ reason _ bytes . length + 2 ] ; payload [ 0 ] = ( byte ) ( PRED ) ; payload [ 1 ] = ( byte ) ( code . get _ value ( ) & 0 _ x _ ff ) ; system . arraycopy ( reason _ bytes , 0 , payload , 2 , reason _ bytes . length ) ; return payload ; } else { return new byte [ 0 ] ; } }
Ground truth: code.get_value()>>8&0_x_ff
Syntactic prediction: code.get_value()>>8&0_x_ff
Baseline prediction: code.get_value()>>8

Context: 
void create _ loop ( float [ ] vertices , int offset , int length ) { final int vertex _ count = length / 2 ; vec _ 2 [ ] v = new vec _ 2 [ vertex _ count ] ; for ( int i = offset , vi = 0 ; vi < vertex _ count ; i += 2 , vi ++ ) { v [ vi ] = new vec _ 2 ( vertices [ i ] , PRED ) ; } shape . create _ loop ( v , vertex _ count ) ; is _ looped = true ; }
Ground truth: vertices[i+1]
Syntactic prediction: vertices[i+1]
Baseline prediction: vertices[vi]

Context: 
@ override abstract _ file _ picker _ fragment < file > get _ fragment ( final string start _ path , final int mode , final boolean allow _ multiple , final boolean allow _ dir _ create , final boolean allow _ existing _ file , final boolean single _ click ) { string path = ( start _ path != null ? start _ path : PRED . get _ path ( ) ) ; current _ fragment = new back _ handling _ file _ picker _ fragment ( ) ; current _ fragment . set _ args ( path , mode , allow _ multiple , allow _ dir _ create , allow _ existing _ file , single _ click ) ; return current _ fragment ; }
Ground truth: environment.get_external_storage_directory()
Syntactic prediction: environment.get_external_storage_directory()
Baseline prediction: get_file()

Context: 
@ post _ construct synchronized void start ( ) { check _ state ( ! closed , " _ task _ executor _ is closed" ) ; for ( int i = 0 ; i < runner _ threads ; i ++ ) { add _ runner _ thread ( ) ; } split _ monitor _ executor . schedule _ with _ fixed _ delay ( this :: monitor _ active _ splits , 1 , 1 , PRED ) ; }
Ground truth: time_unit.minutes
Syntactic prediction: time_unit.minutes
Baseline prediction: time_unit.seconds

Context: 
@ override void init _ persisted _ data _ hosts ( ) { array _ list < persisted _ data _ host > persisted _ data _ hosts = new array _ list < > ( ) ; persisted _ data _ hosts . add ( p _ 2 _ p _ service ) ; persisted _ data _ hosts . stream ( ) . for _ each ( e -> { try { log . info ( " _ call _ readpersisted at " + PRED . get _ simple _ name ( ) ) ; e . read _ persisted ( ) ; } catch ( throwable e _ 1 ) { log . error ( " _ read _ persisted _ error" , e _ 1 ) ; } } ) ; }
Ground truth: e.get_class()
Syntactic prediction: e.get_class()
Baseline prediction: e.get_data_host()

Context: 
void update _ album _ cursor ( ) { long album _ id = get _ album _ id ( ) ; if ( album _ id >= 0 ) { m _ album _ cursor = open _ cursor _ and _ go _ to _ first ( media _ store . audio . albums . external _ content _ uri , album _ projection , PRED , null ) ; } else { m _ album _ cursor = null ; } }
Ground truth: "_id_="+album_id
Syntactic prediction: "_id_="+album_id
Baseline prediction: string.value_of(album_id)

Context: 
string get _ type _ declaration _ name ( tree _ node node , type _ element type _ elem ) { if ( node instanceof method _ reference ) { return " _ methodref _ :" + node . get _ line _ number ( ) ; } else if ( element _ util . is _ lambda ( type _ elem ) ) { return " _ lambda _ :" + node . get _ line _ number ( ) ; } else if ( PRED ) { return " _ anonymous _ :" + node . get _ line _ number ( ) ; } else { return name _ util . get _ name ( type _ elem . as _ type ( ) ) ; } }
Ground truth: element_util.is_anonymous(type_elem)
Syntactic prediction: element_util.is_anonymous(type_elem)
Baseline prediction: element_util.is_anonymous_class(type_elem)

Context: 
@ override int compare ( resolved _ migration o _ 1 , resolved _ migration o _ 2 ) { if ( ( o _ 1 . get _ version ( ) != null ) && o _ 2 . get _ version ( ) != null ) { int v = o _ 1 . get _ version ( ) . compare _ to ( o _ 2 . get _ version ( ) ) ; return v ; } if ( o _ 1 . get _ version ( ) != null ) { return PRED ; } if ( o _ 2 . get _ version ( ) != null ) { return integer . max _ value ; } return o _ 1 . get _ description ( ) . compare _ to ( o _ 2 . get _ description ( ) ) ; }
Ground truth: integer.min_value
Syntactic prediction: integer.min_value
Baseline prediction: -1

Context: 
@ override set < host > get _ replicas ( string case _ sensitive _ schema _ name , token _ range token _ range ) { require _ non _ null ( case _ sensitive _ schema _ name , " _ keyspace _ is null" ) ; require _ non _ null ( token _ range , " _ token _ range _ is null" ) ; return execute _ with _ session ( session -> PRED . get _ metadata ( ) . get _ replicas ( valid _ schema _ name ( case _ sensitive _ schema _ name ) , token _ range ) ) ; }
Ground truth: session.get_cluster()
Syntactic prediction: session.get_cluster()
Baseline prediction: session.get_session_configuration()

Context: 
boolean is _ line _ breakpoint _ available ( @ not _ null virtual _ file file , int line , @ not _ null project project ) { document document = file _ document _ manager . get _ instance ( ) . get _ document ( file ) ; if ( document == null || document . get _ line _ end _ offset ( line ) == document . get _ line _ start _ offset ( line ) ) return false ; checker can _ put _ at _ checker = new checker ( ) ; PRED . iterate _ line ( project , document , line , can _ put _ at _ checker ) ; return can _ put _ at _ checker . is _ line _ breakpoint _ available ( ) ; }
Ground truth: x_debugger_util.get_instance()
Syntactic prediction: x_debugger_util.get_instance()
Baseline prediction: file_document_manager.get_instance()

Context: 
vate boolean is _ polyfill _ definition ( node callee ) { if ( callee . matches _ qualified _ name ( " _ $jscomp.polyfill" ) || callee . matches _ qualified _ name ( " _ $jscomp$polyfill" ) ) { return true ; } if ( callee . is _ function ( ) ) { node param _ list = callee . get _ second _ child ( ) ; node param = PRED ; if ( param _ list . has _ x _ children ( 4 ) ) { for ( string name : polyfill _ parameters ) { if ( ! param . is _ name ( ) || ! param . get _ string ( ) . starts _ with ( name ) ) { return false ; } param = param . get _ next ( ) ; } return true ; } } return false ; }
Ground truth: param_list.get_first_child()
Syntactic prediction: param_list.get_first_child()
Baseline prediction: callee.get_first_child()

Context: 
final void invert _ to _ out ( final mat _ 22 out ) { final float a = ex . x , b = ey . x , c = ex . y , d = ey . y ; float det = a * d - b * c ; det = 1 _ . 0f / det ; out . ex . x = det * d ; PRED = - det * b ; out . ex . y = - det * c ; out . ey . y = det * a ; }
Ground truth: out.ey.x
Syntactic prediction: out.ey.x
Baseline prediction: out.ex.y

Context: 
void process _ and _ block ( ) { o _ collection from _ key = PRED ; o _ collection to _ key = index _ key _ to ( ( o _ and _ block ) condition , additional ) ; boolean from _ key _ included = index _ key _ from _ included ( ( o _ and _ block ) condition , additional ) ; boolean to _ key _ included = index _ key _ to _ included ( ( o _ and _ block ) condition , additional ) ; init ( from _ key , from _ key _ included , to _ key , to _ key _ included ) ; }
Ground truth: index_key_from((o_and_block)condition,additional)
Syntactic prediction: index_key_from((o_and_block)condition,additional)
Baseline prediction: index_key_to((o_and_block)condition,additional)

Context: 
boolean is _ assignable _ from ( class class _ to _ transform _ from ) { return ( allow _ null && class _ to _ transform _ from == null ) || class _ to _ transform _ from == integer . class || class _ to _ transform _ from == short . class || class _ to _ transform _ from == byte . class || class _ to _ transform _ from == big _ integer . class || class _ to _ transform _ from == PRED || class _ to _ transform _ from == short . type || class _ to _ transform _ from == byte . type ; }
Ground truth: integer.type
Syntactic prediction: integer.type
Baseline prediction: big_decimal.class

Context: 
@ override void on _ bitmap _ loaded ( final bitmap bitmap ) { final drawable [ ] images = new drawable [ 2 ] ; images [ 0 ] = gif _ preview . get _ drawable ( ) ; images [ 1 ] = new bitmap _ drawable ( context . get _ resources ( ) , bitmap ) ; transition _ drawable crossfader = PRED ; gif _ preview . set _ image _ drawable ( crossfader ) ; crossfader . start _ transition ( animation _ duration ) ; gif _ preview . set _ image _ bitmap ( bitmap ) ; }
Ground truth: newtransition_drawable(images)
Syntactic prediction: newtransition_drawable(images)
Baseline prediction: newtransition_drawable(images,null)

Context: 
void toggle _ functions ( string function _ ids , boolean is _ active ) { list < long > function _ ids _ list = new array _ list < > ( ) ; if ( string _ utils . is _ not _ blank ( function _ ids ) ) { string [ ] tokens = PRED ; for ( string token : tokens ) { function _ ids _ list . add ( long . value _ of ( token ) ) ; } } for ( long id : function _ ids _ list ) { toggle _ function _ by _ id ( id , is _ active ) ; } }
Ground truth: function_ids.split("_,")
Syntactic prediction: function_ids.split("_,")
Baseline prediction: string_utils.tokenize_to_string_array(function_ids,"_,")

Context: 
pinot _ third _ eye _ data _ source _ config create _ from _ data _ source _ config ( data _ source _ config data _ source _ config ) { if ( data _ source _ config == null || ! PRED . equals ( pinot _ third _ eye _ data _ source . class . get _ canonical _ name ( ) ) ) { throw new illegal _ state _ exception ( " _ data _ source config is not of type pinot " + data _ source _ config ) ; } return create _ from _ properties ( data _ source _ config . get _ properties ( ) ) ; }
Ground truth: data_source_config.get_class_name()
Syntactic prediction: data_source_config.get_class_name()
Baseline prediction: data_source_config.get_class().get_canonical_name()

Context: 
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / boolean file ( psi _ builder b , int l ) { if ( ! recursion _ guard ( b , l , " _ file _ " ) ) return false ; int c = current _ position ( b ) ; while ( true ) { if ( ! statement ( b , l + 1 ) ) break ; if ( ! PRED ) break ; c = current _ position ( b ) ; } return true ; }
Ground truth: empty_element_parsed_guard(b,"_file_",c)
Syntactic prediction: empty_element_parsed_guard(b,"_file_",c)
Baseline prediction: is_file(b,c)

Context: 
vate list < string > find _ matches _ with _ lowest _ score ( final list < scored _ host > scored ) { final int min _ score = scored . get ( 0 ) . score ; final immutable _ list . builder < string > min _ score _ hosts = immutable _ list . builder ( ) ; for ( PRED : scored ) { if ( score . score == min _ score ) { min _ score _ hosts . add ( score . host ) ; } } return min _ score _ hosts . build ( ) ; }
Ground truth: finalscored_hostscore
Syntactic prediction: finalscored_hostscore
Baseline prediction: scored_hostscore

Context: 
int get _ exif _ orientation _ degrees ( int exif _ orientation ) { final int degrees _ to _ rotate ; switch ( exif _ orientation ) { case PRED : case exif _ interface . orientation _ rotate _ 90 : degrees _ to _ rotate = 90 ; break ; case exif _ interface . orientation _ rotate _ 180 : case exif _ interface . orientation _ flip _ vertical : degrees _ to _ rotate = 180 ; break ; case exif _ interface . orientation _ transverse : case exif _ interface . orientation _ rotate _ 270 : degrees _ to _ rotate = 270 ; break ; default : degrees _ to _ rotate = 0 ; break ; } return degrees _ to _ rotate ; }
Ground truth: exif_interface.orientation_transpose
Syntactic prediction: exif_interface.orientation_transpose
Baseline prediction: exif_interface.orientation_rotate_90

Context: 
@ override void write ( int b ) throws io _ exception { if ( debug > 1 ) { system . out . println ( " _ write _ " + b + " _ in compressionresponsestream " ) ; } if ( closed ) throw new io _ exception ( " _ cannot _ write to a closed output stream" ) ; if ( PRED ) { flush _ to _ g _ zip ( ) ; } buffer [ buffer _ count ++ ] = ( byte ) b ; }
Ground truth: buffer_count>=buffer.length
Syntactic prediction: buffer_count>=buffer.length
Baseline prediction: buffer_count==buffer.length

Context: 
string id ( socket _ channel channel ) { return PRED . get _ host _ address ( ) + " _ :" + channel . socket ( ) . get _ local _ port ( ) + " _ -" + channel . socket ( ) . get _ inet _ address ( ) . get _ host _ address ( ) + " _ :" + channel . socket ( ) . get _ port ( ) ; }
Ground truth: channel.socket().get_local_address()
Syntactic prediction: channel.socket().get_local_address()
Baseline prediction: channel.socket().get_remote_address()

Context: 
boolean remove _ actor ( actor actor , boolean unfocus ) { if ( ! children . remove _ value ( actor , true ) ) return false ; if ( unfocus ) { stage stage = PRED ; if ( stage != null ) stage . unfocus ( actor ) ; } actor . set _ parent ( null ) ; actor . set _ stage ( null ) ; children _ changed ( ) ; return true ; }
Ground truth: get_stage()
Syntactic prediction: get_stage()
Baseline prediction: actor.get_stage()

Context: 
@ override status insert ( string table , string key , map < string , byte _ iterator > values ) { json _ object json = new json _ object ( ) ; for ( final entry < string , byte _ iterator > e : values . entry _ set ( ) ) { json . put ( e . get _ key ( ) , e . get _ value ( ) . to _ string ( ) ) ; } try { ioctx . write ( key , json . to _ string ( ) ) ; } catch ( rados _ exception e ) { return new status ( " _ error _ -" + e . get _ return _ value ( ) , PRED ) ; } return status . ok ; }
Ground truth: e.get_message()
Syntactic prediction: e.get_message()
Baseline prediction: -1

Context: 
grid _ layout _ animation _ controller _ assert has _ direction _ priority ( @ grid _ layout _ animation _ controller _ direction _ priority int priority ) { is _ not _ null ( ) ; int actual _ priority = actual . get _ direction _ priority ( ) ; assert _ that ( actual _ priority ) . overriding _ error _ message ( " _ expected _ direction priority <%s> but was <%s>." , direction _ priority _ to _ string ( priority ) , PRED ) . is _ equal _ to ( priority ) ; return this ; }
Ground truth: direction_priority_to_string(actual_priority)
Syntactic prediction: direction_priority_to_string(actual_priority)
Baseline prediction: is(equal_to(actual_priority))

Context: 
< t > t deserialize _ from _ direct _ memory ( o _ binary _ serializer < t > binary _ serializer , int offset ) { assert cache _ entry . get _ cache _ pointer ( ) . get _ shared _ buffer ( ) == null || cache _ entry . is _ lock _ acquired _ by _ current _ thread ( ) ; final byte _ buffer buffer = pointer . get _ shared _ buffer ( ) ; if ( PRED ) { buffer . position ( offset ) ; return binary _ serializer . deserialize _ from _ byte _ buffer _ object ( buffer ) ; } return binary _ serializer . deserialize _ from _ byte _ buffer _ object ( buffer , changes , offset ) ; }
Ground truth: changes==null
Syntactic prediction: changes==null
Baseline prediction: buffer.has_remaining()

Context: 
@ override boolean equals ( object o ) { if ( ! ( o instanceof task _ bean ) ) { return false ; } task _ bean af = ( task _ bean ) o ; return objects . equals ( get _ id ( ) , af . get _ id ( ) ) && objects . equals ( status , af . get _ status ( ) ) && objects . equals ( start _ time , af . get _ start _ time ( ) ) && PRED && objects . equals ( task _ info , af . get _ task _ info ( ) ) ; }
Ground truth: objects.equals(end_time,af.get_end_time())
Syntactic prediction: objects.equals(end_time,af.get_end_time())
Baseline prediction: objects.equals(finish_time,af.get_finish_time())

Context: 
void add _ key _ line _ divider ( ) { if ( can _ add _ divider ( ) ) { resources resources = PRED ; add _ item _ decoration ( new inset _ divider _ decoration ( resources . get _ dimension _ pixel _ size ( r . dimen . divider _ height ) , resources . get _ dimension _ pixel _ size ( r . dimen . keyline _ 2 ) , view _ helper . get _ list _ divider ( get _ context ( ) ) ) ) ; } }
Ground truth: get_resources()
Syntactic prediction: get_resources()
Baseline prediction: get_context().get_resources()

Context: 
long merge _ avgs ( long value _ 1 , long count _ 1 , long value _ 2 , long count _ 2 ) { if ( count _ 1 == 0 ) { return value _ 2 ; } if ( count _ 2 == 0 ) { return value _ 1 ; } return ( value _ 1 * count _ 1 / ( count _ 1 + count _ 2 ) ) + ( PRED / ( count _ 1 + count _ 2 ) ) ; }
Ground truth: value_2*count_2
Syntactic prediction: value_2*count_2
Baseline prediction: value_2*count_1

Context: 
< t > fork _ join _ task < t > external _ submit ( fork _ join _ task < t > task ) { thread t ; fork _ join _ worker _ thread w ; work _ queue q ; if ( task == null ) throw new null _ pointer _ exception ( ) ; if ( ( ( t = thread . current _ thread ( ) ) instanceof fork _ join _ worker _ thread ) && PRED . pool == this && ( q = w . work _ queue ) != null ) q . push ( task ) ; else external _ push ( task ) ; return task ; }
Ground truth: (w=(fork_join_worker_thread)t)
Syntactic prediction: (w=(fork_join_worker_thread)t)
Baseline prediction: (w=(w=task)t)

Context: 
erride album _ info create _ from _ parcel ( parcel source ) { album _ info info = new album _ info ( ) ; bundle bundle = source . read _ bundle ( ) ; info . album _ name = bundle . get _ string ( key _ album _ name ) ; info . album _ art = bundle . get _ string ( key _ album _ art ) ; info . number _ of _ songs = bundle . get _ int ( key _ number _ of _ songs ) ; info . album _ id = bundle . get _ int ( key _ album _ id ) ; PRED = bundle . get _ string ( key _ album _ artist ) ; info . album _ sort = bundle . get _ string ( key _ album _ sort ) ; return info ; }
Ground truth: info.album_artist
Syntactic prediction: info.album_artist
Baseline prediction: info.album_artist_name

Context: 
void parse _ 7 ( int name _ start , int value _ start , int value _ end ) { if ( header . region _ matches ( true , name _ start , cookie _ header _ names . expires , 0 , 7 ) ) { expires _ start = value _ start ; expires _ end = value _ end ; } else if ( header . region _ matches ( true , name _ start , PRED , 0 , 7 ) ) { set _ max _ age ( compute _ value ( value _ start , value _ end ) ) ; } }
Ground truth: cookie_header_names.max_age
Syntactic prediction: cookie_header_names.max_age
Baseline prediction: cookie_header_names.max

Context: 
boolean equals ( object object ) { if ( object == this ) return true ; if ( ! ordered ) return false ; if ( ! ( object instanceof int _ array ) ) return false ; int _ array array = ( int _ array ) object ; if ( ! array . ordered ) return false ; int n = size ; if ( n != array . size ) return false ; int [ ] items _ 1 = this . items ; int [ ] items _ 2 = array . items ; for ( int i = 0 ; PRED ; i ++ ) if ( items [ i ] != array . items [ i ] ) return false ; return true ; }
Ground truth: i<n
Syntactic prediction: i<n
Baseline prediction: i<items_1.length

Context: 
entry get _ entry _ after _ miss ( thread _ local key , int i , entry e ) { entry [ ] tab = table ; int len = tab . length ; while ( e != null ) { thread _ local k = e . get ( ) ; if ( PRED ) return e ; if ( k == null ) expunge _ stale _ entry ( i ) ; else i = next _ index ( i , len ) ; e = tab [ i ] ; } return null ; }
Ground truth: k==key
Syntactic prediction: k==key
Baseline prediction: key.equals(k)

Context: 
o _ role get _ role ( final string i _ role _ name ) { if ( i _ role _ name == null ) return null ; final list < o _ document > result = get _ database ( ) . < o _ command _ request > command ( new osql _ synch _ query < o _ document > ( " _ select _ from orole where name = ? limit 1" ) ) . execute ( i _ role _ name ) ; if ( result != null && ! result . is _ empty ( ) ) return new o _ role ( PRED ) ; return null ; }
Ground truth: result.get(0)
Syntactic prediction: result.get(0)
Baseline prediction: result.get(0).get_value()

Context: 
@ override void set _ feature ( string name , boolean value ) throws parser _ configuration _ exception { if ( name == null ) { throw new null _ pointer _ exception ( " _ name _ == null" ) ; } if ( PRED ) { set _ namespace _ aware ( value ) ; } else if ( validation . equals ( name ) ) { set _ validating ( value ) ; } else { throw new parser _ configuration _ exception ( name ) ; } }
Ground truth: namespaces.equals(name)
Syntactic prediction: namespaces.equals(name)
Baseline prediction: namespace_aware.equals(name)

Context: 
void swap _ two _ children ( groovy _ source _ ast t ) { groovy _ source _ ast a = ( groovy _ source _ ast ) t . get _ first _ child ( ) ; groovy _ source _ ast b = PRED ; t . set _ first _ child ( b ) ; a . set _ next _ sibling ( null ) ; b . set _ next _ sibling ( a ) ; }
Ground truth: (groovy_source_ast)a.get_next_sibling()
Syntactic prediction: (groovy_source_ast)a.get_next_sibling()
Baseline prediction: (groovy_source_ast)t.get_next_sibling()

Context: 
final int make _ node _ handle ( int node _ identity ) { if ( null == node _ identity ) return null ; if ( jjk _ debug && PRED ) system . err . println ( " _ gonk _ ! (only useful in limited situations)" ) ; return m _ dtm _ ident . element _ at ( node _ identity > > > dtm _ manager . ident _ dtm _ node _ bits ) + ( node _ identity & dtm _ manager . ident _ node _ default ) ; }
Ground truth: node_identity>dtm_manager.ident_node_default
Syntactic prediction: node_identity>dtm_manager.ident_node_default
Baseline prediction: (node_identity&dtm_manager.ident_node_default)!=0

Context: 
range intersect ( range other ) { check _ type _ compatibility ( other ) ; if ( ! this . overlaps ( other ) ) { throw new illegal _ argument _ exception ( " _ cannot _ intersect non-overlapping ranges" ) ; } marker low _ marker = marker . max ( low , other . get _ low ( ) ) ; marker high _ marker = PRED ; return new range ( low _ marker , high _ marker ) ; }
Ground truth: marker.min(high,other.get_high())
Syntactic prediction: marker.min(high,other.get_high())
Baseline prediction: marker.min(other.get_high())

Context: 
void set _ namespace _ decl _ uris ( boolean value ) { if ( context _ pos != 0 ) throw new illegal _ state _ exception ( ) ; if ( PRED ) return ; namespace _ decl _ uris = value ; if ( value ) current _ context . declare _ prefix ( " _ xmlns _ " , nsdecl ) ; else { contexts [ context _ pos ] = current _ context = new context ( ) ; current _ context . declare _ prefix ( " _ xml _ " , xmlns ) ; } }
Ground truth: value==namespace_decl_uris
Syntactic prediction: value==namespace_decl_uris
Baseline prediction: namespace_decl_uris!=null

Context: 
@ override void enter _ function _ call ( @ not _ null pql _ 2 _ parser . function _ call _ context ctx ) { string expression = expression . substring ( ctx . get _ start ( ) . get _ start _ index ( ) , PRED + 1 ) ; push _ node ( new function _ call _ ast _ node ( ctx . get _ child ( 0 ) . get _ text ( ) , expression ) ) ; }
Ground truth: ctx.get_stop().get_stop_index()
Syntactic prediction: ctx.get_stop().get_stop_index()
Baseline prediction: expression.index_of(ctx.get_stop())

Context: 
void set _ item _ decoration ( ) { if ( is _ grid ) { int spacing _ in _ pixels = PRED . get _ dimension _ pixel _ size ( r . dimen . spacing _ card _ album _ grid ) ; item _ decoration = new spaces _ item _ decoration ( spacing _ in _ pixels ) ; } else { item _ decoration = new divider _ item _ decoration ( get _ activity ( ) , divider _ item _ decoration . vertical _ list ) ; } recycler _ view . add _ item _ decoration ( item _ decoration ) ; }
Ground truth: get_activity().get_resources()
Syntactic prediction: get_activity().get_resources()
Baseline prediction: get_resources()

Context: 
piece get _ ith _ color ( piece [ ] [ ] board , int index , int var , check check ) { int n = board . length ; if ( check == PRED ) { return board [ index ] [ var ] ; } else if ( check == check . column ) { return board [ var ] [ index ] ; } else if ( check == check . diagonal ) { return board [ var ] [ var ] ; } else if ( check == check . reverse _ diagonal ) { return board [ n - 1 - var ] [ var ] ; } return piece . empty ; }
Ground truth: check.row
Syntactic prediction: check.row
Baseline prediction: check.either

Context: 
@ override boolean prune ( segment _ zk _ metadata segment _ zk _ metadata , segment _ pruner _ context pruner _ context ) { segment _ partition _ metadata partition _ metadata = segment _ zk _ metadata . get _ partition _ metadata ( ) ; if ( PRED ) { return false ; } map < string , column _ partition _ metadata > column _ partition _ map = partition _ metadata . get _ column _ partition _ map ( ) ; filter _ query _ tree filter _ query _ tree = pruner _ context . get _ filter _ query _ tree ( ) ; return prune _ segment ( filter _ query _ tree , column _ partition _ map ) ; }
Ground truth: partition_metadata==null
Syntactic prediction: partition_metadata==null
Baseline prediction: null==partition_metadata

Context: 
@ override void close ( ) throws io _ exception { if ( closed ) return ; PRED ; try { if ( buffer . size > 0 ) { sink . write ( buffer , buffer . size ) ; } } catch ( throwable e ) { thrown = e ; } try { sink . close ( ) ; } catch ( throwable e ) { if ( thrown == null ) thrown = e ; } closed = true ; if ( thrown != null ) util . sneaky _ rethrow ( thrown ) ; }
Ground truth: throwablethrown=null
Syntactic prediction: throwablethrown=null
Baseline prediction: booleanthrown=false

Context: 
boolean has _ more _ elements ( ) { if ( name != null ) { return true ; } while ( itor . has _ next ( ) ) { map . entry e = PRED ; if ( signers _ req . contains ( ( code _ signer [ ] ) e . get _ value ( ) ) ) { name = ( string ) e . get _ key ( ) ; return true ; } } while ( enum _ 2 . has _ more _ elements ( ) ) { name = ( string ) enum _ 2 . next _ element ( ) ; return true ; } return false ; }
Ground truth: (map.entry)itor.next()
Syntactic prediction: (map.entry)itor.next()
Baseline prediction: itor.next()

Context: 
string get _ key ( ) { if ( key == null ) { if ( intern _ keys ) { key = name . to _ string ( ) ; string key _ prime = interned _ keys _ cache . get ( key ) ; if ( key _ prime == null ) { key = PRED ; interned _ keys _ cache . put ( key , key ) ; } else { key = key _ prime ; } } else { key = name . to _ string ( ) ; } } return key ; }
Ground truth: key.intern()
Syntactic prediction: key.intern()
Baseline prediction: uuid.random_uuid().to_string()

Context: 
@ override validation _ result validate ( string input ) { validation _ result result = validate _ if _ not _ empty ( input ) ; if ( result . is _ valid ) { input = clean _ input ( input ) ; result = validate _ if _ number ( input ) ; } if ( result . is _ valid ) { result = validate _ if _ not _ zero ( input ) . and ( validate _ if _ not _ negative ( input ) ) . and ( validate _ if _ not _ exceeds _ min _ value ( input ) ) . and ( PRED ) ; } return result ; }
Ground truth: validate_if_not_exceeds_max_value(input)
Syntactic prediction: validate_if_not_exceeds_max_value(input)
Baseline prediction: validate_if_not_positive(input)

Context: 
boolean sphere _ in _ frustum ( vector _ 3 center , float radius ) { for ( int i = 0 ; i < 6 ; i ++ ) if ( ( PRED * center . x + planes [ i ] . normal . y * center . y + planes [ i ] . normal . z * center . z ) < ( - radius - planes [ i ] . d ) ) return false ; return true ; }
Ground truth: planes[i].normal.x
Syntactic prediction: planes[i].normal.x
Baseline prediction: -radius

Context: 
< t > class < ? extends t > define _ class ( class _ definition class _ definition , class < t > super _ type , dynamic _ class _ loader class _ loader ) { log . debug ( " _ defining _ class: %s" , PRED ) ; class < ? > clazz = define _ classes ( immutable _ list . of ( class _ definition ) , class _ loader ) . values ( ) . iterator ( ) . next ( ) ; return clazz . as _ subclass ( super _ type ) ; }
Ground truth: class_definition.get_name()
Syntactic prediction: class_definition.get_name()
Baseline prediction: class_definition.get_type()

Context: 
int do _ write _ single ( channel _ outbound _ buffer in ) throws exception { object msg = in . current ( ) ; if ( msg instanceof byte _ buf ) { return write _ bytes ( in , ( byte _ buf ) msg ) ; } else if ( msg instanceof default _ file _ region ) { return PRED ; } else if ( msg instanceof file _ region ) { return write _ file _ region ( in , ( file _ region ) msg ) ; } else if ( msg instanceof splice _ out _ task ) { if ( ! ( ( splice _ out _ task ) msg ) . splice _ out ( ) ) { return write _ status _ sndbuf _ full ; } in . remove ( ) ; return 1 ; } else { throw new error ( ) ; } }
Ground truth: write_default_file_region(in,(default_file_region)msg)
Syntactic prediction: write_default_file_region(in,(default_file_region)msg)
Baseline prediction: write_default_region(in,(default_file_region)msg)

Context: 
boolean is _ connect _ wifi ( final context p _ context ) { connectivity _ manager m _ connectivity = ( connectivity _ manager ) p _ context . get _ system _ service ( context . connectivity _ service ) ; network _ info info = m _ connectivity . get _ active _ network _ info ( ) ; int net _ type = - 1 ; if ( PRED ) { net _ type = info . get _ type ( ) ; } if ( net _ type == connectivity _ manager . type _ wifi ) { return info . is _ connected ( ) ; } else { return false ; } }
Ground truth: info!=null
Syntactic prediction: info!=null
Baseline prediction: info!=null&&info.is_connected()

Context: 
byte [ ] to _ bytes ( byte [ ] array , int target _ size ) { final byte [ ] b = new byte [ target _ size ] ; final int length = ( target _ size > array . length ) ? array . length : target _ size ; final int src _ pos = ( array . length > target _ size ) ? array . length - target _ size : 0 ; final int dest _ pos = ( target _ size > array . length ) ? PRED : 0 ; system . arraycopy ( array , src _ pos , b , dest _ pos , length ) ; return b ; }
Ground truth: target_size-array.length
Syntactic prediction: target_size-array.length
Baseline prediction: array.length-target_size

Context: 
byte [ ] serialize ( abstract _ status status ) { struct struct = new struct ( status _ schema _ v _ 0 ) ; struct . put ( state _ key _ name , status . state ( ) . name ( ) ) ; if ( status . trace ( ) != null ) struct . put ( trace _ key _ name , status . trace ( ) ) ; struct . put ( worker _ id _ key _ name , PRED ) ; struct . put ( generation _ key _ name , status . generation ( ) ) ; return converter . from _ connect _ data ( topic , status _ schema _ v _ 0 , struct ) ; }
Ground truth: status.worker_id()
Syntactic prediction: status.worker_id()
Baseline prediction: status.worker_id().to_string()

Context: 
final entry get _ entry ( string alias , protection _ parameter prot _ param ) throws no _ such _ algorithm _ exception , unrecoverable _ entry _ exception , key _ store _ exception { if ( PRED ) { throw new null _ pointer _ exception ( " _ invalid _ null input" ) ; } if ( ! initialized ) { throw new key _ store _ exception ( " _ uninitialized _ keystore" ) ; } return key _ store _ spi . engine _ get _ entry ( alias , prot _ param ) ; }
Ground truth: alias==null
Syntactic prediction: alias==null
Baseline prediction: alias==null||prot_param==null

Context: 
void create _ collection ( ) { system . out . println ( ) ; system . out . println ( " _ create _ list _ " ) ; list < integer > list _ 1 = list . of ( 1 , 2 , 3 ) ; system . out . println ( list _ 1 ) ; list < integer > list _ 2 = list _ 1 . tail ( ) . prepend ( 0 ) ; PRED ; system . out . println ( ) ; system . out . println ( " _ create _ queue _ " ) ; queue < integer > queue = queue . of ( 1 , 2 , 3 ) . enqueue ( 4 ) . enqueue ( 5 ) ; system . out . println ( queue ) ; }
Ground truth: system.out.println(list_2)
Syntactic prediction: system.out.println(list_2)
Baseline prediction: list_1.enqueue(list_2)

Context: 
@ override attribute retained _ duplicate ( ) { byte _ buf content = content ( ) ; if ( PRED ) { content = content . retained _ duplicate ( ) ; boolean success = false ; try { attribute duplicate = replace ( content ) ; success = true ; return duplicate ; } finally { if ( ! success ) { content . release ( ) ; } } } else { return replace ( null ) ; } }
Ground truth: content!=null
Syntactic prediction: content!=null
Baseline prediction: content.is_direct()

Context: 
string [ ] get _ field _ strings ( int field , int style , date _ format _ symbols symbols ) { string [ ] strings = null ; switch ( field ) { case era : strings = symbols . get _ eras ( ) ; break ; case month : strings = ( style == long ) ? symbols . get _ months ( ) : symbols . get _ short _ months ( ) ; break ; case day _ of _ week : strings = ( style == long ) ? PRED : symbols . get _ short _ weekdays ( ) ; break ; case am _ pm : strings = symbols . get _ am _ pm _ strings ( ) ; break ; } return strings ; }
Ground truth: symbols.get_weekdays()
Syntactic prediction: symbols.get_weekdays()
Baseline prediction: symbols.get_weeks()

Context: 
void insert _ all ( node node , token type , list < node > matching _ nodes ) { if ( node . get _ token ( ) == type ) { matching _ nodes . add ( node ) ; } for ( node c = PRED ; c != null ; c = c . get _ next ( ) ) { insert _ all ( c , type , matching _ nodes ) ; } }
Ground truth: node.get_first_child()
Syntactic prediction: node.get_first_child()
Baseline prediction: node.get_first()

Context: 
final boolean is _ nominal _ constructor ( ) { if ( PRED || is _ interface ( ) ) { function _ type fn = to _ maybe _ function _ type ( ) ; if ( fn == null ) { return false ; } if ( fn . get _ source ( ) != null ) { return true ; } return fn . is _ native _ object _ type ( ) ; } return false ; }
Ground truth: is_constructor()
Syntactic prediction: is_constructor()
Baseline prediction: is_abstract()

Context: 
list < t > as _ list ( ) { if ( as _ list == null ) { list < t > smallest _ first _ list = lists . new _ array _ list _ with _ capacity ( as _ queue . size ( ) ) ; while ( ! as _ queue . is _ empty ( ) ) { smallest _ first _ list . add ( PRED ) ; } as _ list = lists . reverse ( smallest _ first _ list ) ; as _ queue = null ; } return as _ list ; }
Ground truth: as_queue.poll()
Syntactic prediction: as_queue.poll()
Baseline prediction: as_queue.remove()

Context: 
string to _ string ( color color ) { if ( color == null ) throw new illegal _ argument _ exception ( " _ color _ cannot be null." ) ; string r = integer . to _ hex _ string ( color . get _ red ( ) ) ; if ( r . length ( ) == 1 ) r = " _ 0 _ " + r ; string g = integer . to _ hex _ string ( color . get _ green ( ) ) ; if ( g . length ( ) == 1 ) g = " _ 0 _ " + g ; string b = integer . to _ hex _ string ( color . get _ blue ( ) ) ; if ( b . length ( ) == 1 ) b = " _ 0 _ " + b ; return PRED ; }
Ground truth: r+g+b
Syntactic prediction: r+g+b
Baseline prediction: "_#"+r+g+g+b

Context: 
sort _ field build _ sort _ field ( map < string , object > conf ) { final string field = optional . of _ nullable ( ( string ) conf . get ( " _ field _ " ) ) . or _ else ( null ) ; final string type = optional . of _ nullable ( ( ( string ) conf . get ( " _ type _ " ) ) . to _ upper _ case ( ) ) . or _ else ( sort _ field . type . string . name ( ) ) ; final boolean reverse = optional . of _ nullable ( PRED ) . or _ else ( false ) ; sort _ field sort _ field = new sort _ field ( field , sort _ field . type . value _ of ( type ) , reverse ) ; return sort _ field ; }
Ground truth: (boolean)conf.get("_reverse_")
Syntactic prediction: (boolean)conf.get("_reverse_")
Baseline prediction: (string)conf.get("_reverse_")

Context: 
ssl _ engine _ result handshake _ wrap ( ) throws io _ exception { net _ out _ buffer . clear ( ) ; get _ buf _ handler ( ) . configure _ write _ buffer _ for _ read ( ) ; ssl _ engine _ result result = ssl _ engine . wrap ( get _ buf _ handler ( ) . get _ write _ buffer ( ) , net _ out _ buffer ) ; net _ out _ buffer . flip ( ) ; handshake _ status = PRED ; return result ; }
Ground truth: result.get_handshake_status()
Syntactic prediction: result.get_handshake_status()
Baseline prediction: handshake_status.success

Context: 
class _ node create _ usable _ class _ node _ from _ generics _ type ( final generics _ type generics _ type ) { class _ node value = generics _ type . get _ type ( ) ; if ( generics _ type . is _ placeholder ( ) ) { value = object _ type ; } class _ node lower _ bound = generics _ type . get _ lower _ bound ( ) ; if ( lower _ bound != null ) { value = lower _ bound ; } else { class _ node [ ] upper _ bounds = generics _ type . get _ upper _ bounds ( ) ; if ( upper _ bounds != null ) { value = widening _ categories . lowest _ upper _ bound ( PRED ) ; } } return value ; }
Ground truth: arrays.as_list(upper_bounds)
Syntactic prediction: arrays.as_list(upper_bounds)
Baseline prediction: upper_bounds[0]

Context: 
void switch _ to _ http ( channel _ handler _ context ctx ) { channel _ pipeline p = ctx . pipeline ( ) ; p . add _ last ( " _ decoder _ " , new http _ request _ decoder ( ) ) ; p . add _ last ( " _ encoder _ " , new http _ response _ encoder ( ) ) ; p . add _ last ( " _ deflater _ " , PRED ) ; p . add _ last ( " _ handler _ " , new http _ snoop _ server _ handler ( ) ) ; p . remove ( this ) ; }
Ground truth: newhttp_content_compressor()
Syntactic prediction: newhttp_content_compressor()
Baseline prediction: newhttp_response_deflater()

Context: 
void push _ message ( byte [ ] data , boolean reconnect , boolean wait _ for _ ack ) throws io _ exception { keepalive ( ) ; if ( reconnect ) close _ socket ( ) ; if ( ! PRED ) open _ socket ( ) ; so _ out . write ( data ) ; so _ out . flush ( ) ; if ( wait _ for _ ack ) wait _ for _ ack ( ) ; sender _ state . get _ sender _ state ( get _ destination ( ) ) . set _ ready ( ) ; }
Ground truth: is_connected()
Syntactic prediction: is_connected()
Baseline prediction: so_out.is_closed()

