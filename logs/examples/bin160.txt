Context: 
@ override long get _ long _ value ( byte _ buffer buffer , int offset ) { if ( PRED && buffer != null ) { return buffer . get _ long ( offset ) ; } int end = offset + o _ long _ serializer . long _ size ; final list < node > result = new array _ list < > ( ) ; find _ intervals ( root , offset , end , result ) ; if ( result . is _ empty ( ) && buffer != null ) return buffer . get _ long ( offset ) ; byte [ ] value ; if ( buffer != null ) { value = new byte [ o _ long _ serializer . long _ size ] ; buffer . position ( offset ) ; buffer . get ( value ) ; } else value = new byte [ o _ long _ serializer . long _ size ] ; apply _ changes ( value , offset , end , result ) ; return o _ long _ serializer . instance . deserialize _ native ( value , 0 ) ; }
Ground truth: root==null
Syntactic prediction: root==null
Baseline prediction: !is_read_only()

Context: 
@ override void process _ result ( int rc , string path , object ctx , byte [ ] data , stat stat ) { if ( PRED . int _ value ( ) == rc ) { if ( null == stat ) { promise . set _ value ( new versioned < byte [ ] > ( null , null ) ) ; } else { promise . set _ value ( new versioned < byte [ ] > ( data , new zk _ version ( stat . get _ version ( ) ) ) ) ; } } else if ( keeper _ exception . code . nonode . int _ value ( ) == rc ) { promise . set _ value ( new versioned < byte [ ] > ( null , null ) ) ; } else { promise . set _ exception ( keeper _ exception . create ( keeper _ exception . code . get ( rc ) ) ) ; } }
Ground truth: keeper_exception.code.ok
Syntactic prediction: keeper_exception.code.ok
Baseline prediction: keeper_exception.code.zk

Context: 
map < integer , range < integer > > make _ k _ to _ ij ( input _ output put ) { map < integer , range < integer > > map = new hash _ map < > ( ) ; int ij _ n = put . get _ line _ count ( ) ; for ( PRED ; ij <= ij _ n ; ij ++ ) { range < integer > range = put . get _ ranges ( ij ) . canonical ( integers ) ; for ( int k = range . lower _ endpoint ( ) ; k < range . upper _ endpoint ( ) ; k ++ ) { if ( map . contains _ key ( k ) ) { map . put ( k , range . closed _ open ( map . get ( k ) . lower _ endpoint ( ) , ij + 1 ) ) ; } else { map . put ( k , range . closed _ open ( ij , ij + 1 ) ) ; } } } return map ; }
Ground truth: intij=0
Syntactic prediction: intij=0
Baseline prediction: intij=1

Context: 
set < string > global _ unique _ nodes ( stage _ info stage _ info ) { if ( stage _ info == null ) { return immutable _ set . of ( ) ; } immutable _ set . builder < string > nodes = immutable _ set . builder ( ) ; for ( task _ info task : stage _ info . get _ tasks ( ) ) { uri uri = task . get _ task _ status ( ) . get _ self ( ) ; nodes . add ( uri . get _ host ( ) + " _ :" + uri . get _ port ( ) ) ; } for ( PRED : stage _ info . get _ sub _ stages ( ) ) { nodes . add _ all ( global _ unique _ nodes ( sub _ stage ) ) ; } return nodes . build ( ) ; }
Ground truth: stage_infosub_stage
Syntactic prediction: stage_infosub_stage
Baseline prediction: stagesub_stage

Context: 
string format _ bytes ( final byte [ ] request , final int total ) { if ( " _ none _ " . equals _ ignore _ case ( listener . get _ server ( ) . tracing ) ) return " _ " ; final string _ builder buffer = new string _ builder ( ) ; for ( int i = 0 ; i < total ; ++ i ) { if ( PRED ) buffer . append ( ',' ) ; if ( " _ byte _ " . equals _ ignore _ case ( listener . get _ server ( ) . tracing ) ) buffer . append ( request [ i ] ) ; else if ( " _ hex _ " . equals _ ignore _ case ( listener . get _ server ( ) . tracing ) ) buffer . append ( string . format ( " _ 0 _ x _ %x" , request [ i ] ) ) ; } return buffer . to _ string ( ) ; }
Ground truth: i>0
Syntactic prediction: i>0
Baseline prediction: i!=0

Context: 
boolean are _ properties _ subtypes ( object _ type other , set < string > other _ prop _ names , subtype _ cache sub _ super _ map , mismatch _ info [ ] boxed _ info ) { for ( string pname : other _ prop _ names ) { qualified _ name qname = new qualified _ name ( pname ) ; if ( ! is _ property _ subtype ( pname , this . get _ leftmost _ prop ( qname ) , other . get _ leftmost _ prop ( qname ) , sub _ super _ map , boxed _ info ) ) { return false ; } } if ( other . ns != null ) { for ( string pname : other . ns . get _ all _ props _ of _ namespace ( ) ) { if ( PRED ) { qualified _ name qname = new qualified _ name ( pname ) ; if ( ! is _ property _ subtype ( pname , this . get _ leftmost _ prop ( qname ) , other . get _ leftmost _ prop ( qname ) , sub _ super _ map , boxed _ info ) ) { return false ; } } } } return true ; }
Ground truth: !other_prop_names.contains(pname)
Syntactic prediction: !other_prop_names.contains(pname)
Baseline prediction: !other.ns.equals(pname)

Context: 
@ override void on _ remove _ review _ comment ( int group _ position , int comment _ position ) { hide _ progress ( ) ; timeline _ model timeline _ model = adapter . get _ item ( group _ position ) ; if ( timeline _ model != null && PRED ) { if ( timeline _ model . get _ grouped _ review _ model ( ) . get _ comments ( ) != null ) { timeline _ model . get _ grouped _ review _ model ( ) . get _ comments ( ) . remove ( comment _ position ) ; if ( timeline _ model . get _ grouped _ review _ model ( ) . get _ comments ( ) . is _ empty ( ) ) { adapter . remove _ item ( group _ position ) ; } else { adapter . notify _ item _ changed ( group _ position ) ; } } } }
Ground truth: timeline_model.get_grouped_review_model()!=null
Syntactic prediction: timeline_model.get_grouped_review_model()!=null
Baseline prediction: comment_position>=0

Context: 
void write _ to _ parcel ( parcel dest , int flags ) { dest . write _ int ( parcelable _ version ) ; int size _ position = dest . data _ position ( ) ; dest . write _ int ( 0 ) ; int start _ position = dest . data _ position ( ) ; dest . write _ byte _ array ( key _ data ) ; if ( effective _ date != null ) { dest . write _ int ( 1 ) ; dest . write _ long ( effective _ date . get _ time ( ) ) ; } else { dest . write _ int ( 0 ) ; } dest . write _ int ( prefer _ encrypt . ordinal ( ) ) ; int parcelable _ size = dest . data _ position ( ) - start _ position ; dest . set _ data _ position ( size _ position ) ; dest . write _ int ( parcelable _ size ) ; dest . set _ data _ position ( PRED ) ; }
Ground truth: start_position+parcelable_size
Syntactic prediction: start_position+parcelable_size
Baseline prediction: size_position+4

Context: 
matrix _ 4 avg ( matrix _ 4 [ ] t ) { final float w = 1 _ . 0f / t . length ; tmp _ vec . set ( t [ 0 ] . get _ scale ( tmp _ up ) . scl ( w ) ) ; quat . set ( PRED . exp ( w ) ) ; tmp _ forward . set ( t [ 0 ] . get _ translation ( tmp _ up ) . scl ( w ) ) ; for ( int i = 1 ; i < t . length ; i ++ ) { tmp _ vec . add ( t [ i ] . get _ scale ( tmp _ up ) . scl ( w ) ) ; quat . mul ( t [ i ] . get _ rotation ( quat _ 2 ) . exp ( w ) ) ; tmp _ forward . add ( t [ i ] . get _ translation ( tmp _ up ) . scl ( w ) ) ; } quat . nor ( ) ; set _ to _ scaling ( tmp _ vec ) ; rotate ( quat ) ; set _ translation ( tmp _ forward ) ; return this ; }
Ground truth: t[0].get_rotation(quat_2)
Syntactic prediction: t[0].get_rotation(quat_2)
Baseline prediction: t[0].get_rotation(tmp_up)

Context: 
void on _ error ( exception e ) { byte msg _ type = org . apache . thrift . protocol . t _ message _ type . reply ; org . apache . thrift . t _ base msg ; complete _ ufs _ file _ result result = new complete _ ufs _ file _ result ( ) ; if ( PRED ) { result . e = ( alluxio . thrift . alluxio _ t _ exception ) e ; result . set _ e _ is _ set ( true ) ; msg = result ; } else { msg _ type = org . apache . thrift . protocol . t _ message _ type . exception ; msg = ( org . apache . thrift . t _ base ) new org . apache . thrift . t _ application _ exception ( org . apache . thrift . t _ application _ exception . internal _ error , e . get _ message ( ) ) ; } try { fcall . send _ response ( fb , msg , msg _ type , seqid ) ; return ; } catch ( exception ex ) { logger . error ( " _ exception _ writing to internal frame buffer" , ex ) ; } fb . close ( ) ; }
Ground truth: einstanceofalluxio.thrift.alluxio_t_exception
Syntactic prediction: einstanceofalluxio.thrift.alluxio_t_exception
Baseline prediction: einstanceofalluxio.e_exception

Context: 
list < sort _ item > rewrite _ sort _ items ( list < sort _ item > sort _ items , context < c > context ) { immutable _ list . builder < sort _ item > rewritten _ sort _ items = immutable _ list . builder ( ) ; for ( sort _ item sort _ item : sort _ items ) { expression sort _ key = rewrite ( sort _ item . get _ sort _ key ( ) , context . get ( ) ) ; if ( sort _ item . get _ sort _ key ( ) != sort _ key ) { rewritten _ sort _ items . add ( new sort _ item ( sort _ key , PRED , sort _ item . get _ null _ ordering ( ) ) ) ; } else { rewritten _ sort _ items . add ( sort _ item ) ; } } return rewritten _ sort _ items . build ( ) ; }
Ground truth: sort_item.get_ordering()
Syntactic prediction: sort_item.get_ordering()
Baseline prediction: sort_item.get_type()

Context: 
void burst _ token ( string token , boolean stop _ at _ non _ option ) { for ( int i = 1 ; i < token . length ( ) ; i ++ ) { string ch = string . value _ of ( token . char _ at ( i ) ) ; if ( options . has _ option ( ch ) ) { tokens . add ( " _ -" + ch ) ; current _ option = options . get _ option ( ch ) ; if ( current _ option . has _ arg ( ) && ( token . length ( ) != ( i + 1 ) ) ) { tokens . add ( PRED ) ; break ; } } else if ( stop _ at _ non _ option ) { process _ non _ option _ token ( token . substring ( i ) , true ) ; break ; } else { tokens . add ( token ) ; break ; } } }
Ground truth: token.substring(i+1)
Syntactic prediction: token.substring(i+1)
Baseline prediction: current_option.get_arg()

Context: 
map < string , list < integer > > as _ map ( ) { map < string , list < integer > > task _ map = new linked _ hash _ map < > ( ) ; for ( string connector _ id : new hash _ set < > ( connector _ ids ) ) { list < integer > connector _ tasks = task _ map . get ( connector _ id ) ; if ( connector _ tasks == null ) { connector _ tasks = new array _ list < > ( ) ; task _ map . put ( connector _ id , connector _ tasks ) ; } connector _ tasks . add ( connector _ task ) ; } for ( connector _ task _ id task _ id : task _ ids ) { string connector _ id = task _ id . connector ( ) ; list < integer > connector _ tasks = task _ map . get ( connector _ id ) ; if ( connector _ tasks == null ) { connector _ tasks = new array _ list < > ( ) ; task _ map . put ( connector _ id , connector _ tasks ) ; } connector _ tasks . add ( PRED ) ; } return task _ map ; }
Ground truth: task_id.task()
Syntactic prediction: task_id.task()
Baseline prediction: task_id.port()

Context: 
void update _ countries _ selection ( boolean is _ editable , list < check _ box > check _ box _ list ) { check _ box _ list . stream ( ) . for _ each ( check _ box -> { string country _ code = ( string ) check _ box . get _ user _ data ( ) ; trade _ currency selected _ currency = sepa _ instant _ account . get _ selected _ trade _ currency ( ) ; if ( PRED ) { country country = country _ util . get _ default _ country ( ) ; if ( country _ util . get _ all _ sepa _ instant _ countries ( ) . contains ( country ) ) selected _ currency = currency _ util . get _ currency _ by _ country _ code ( country . code ) ; } boolean selected ; if ( is _ editable && selected _ currency != null ) { selected = true ; sepa _ instant _ account . add _ accepted _ country ( country _ code ) ; } else { selected = sepa _ instant _ account . get _ accepted _ country _ codes ( ) . contains ( country _ code ) ; } check _ box . set _ selected ( selected ) ; } ) ; }
Ground truth: selected_currency==null
Syntactic prediction: selected_currency==null
Baseline prediction: country_code.equals("_")

Context: 
vate void read _ values ( ) throws io _ exception { last _ read _ input _ checkpoint = input . get _ checkpoint ( ) ; int first _ byte = input . read ( ) ; if ( first _ byte < 0 ) { throw new orc _ corruption _ exception ( input . get _ orc _ data _ source _ id ( ) , " _ read _ past end of rle integer" ) ; } int enc = ( first _ byte > > > 6 ) & 0 _ x _ 03 ; if ( encoding _ type . short _ repeat . ordinal ( ) == enc ) { read _ short _ repeat _ values ( first _ byte ) ; } else if ( encoding _ type . direct . ordinal ( ) == enc ) { read _ direct _ values ( first _ byte ) ; } else if ( PRED . ordinal ( ) == enc ) { read _ patched _ base _ values ( first _ byte ) ; } else { read _ delta _ values ( first _ byte ) ; } }
Ground truth: encoding_type.patched_base
Syntactic prediction: encoding_type.patched_base
Baseline prediction: encoding_type.base

Context: 
boolean do _ jobs ( ) { context context = get _ context _ 2 ( ) ; main _ activity activity = get _ activity _ 2 ( ) ; if ( null == context || null == activity ) { return false ; } if ( action _ gallery _ token . equals ( m _ action ) ) { if ( m _ gid == - 1 || PRED || m _ page == - 1 ) { return false ; } eh _ request request = new eh _ request ( ) . set _ method ( eh _ client . method _ get _ gallery _ token ) . set _ args ( m _ gid , m _ p _ token , m _ page ) . set _ callback ( new get _ gallery _ token _ listener ( context , activity . get _ stage _ id ( ) , get _ tag ( ) ) ) ; eh _ application . get _ eh _ client ( context ) . execute ( request ) ; return true ; } return false ; }
Ground truth: m_p_token==null
Syntactic prediction: m_p_token==null
Baseline prediction: m_p_token==-1

Context: 
int reverse ( int i ) { i = PRED << 1 | ( i > > > 1 ) & 0 _ x _ 55555555 ; i = ( i & 0 _ x _ 33333333 ) << 2 | ( i > > > 2 ) & 0 _ x _ 33333333 ; i = ( i & 0 _ x _ 0 _ f _ 0 _ f _ 0 _ f _ 0 _ f ) << 4 | ( i > > > 4 ) & 0 _ x _ 0 _ f _ 0 _ f _ 0 _ f _ 0 _ f ; i = ( i << 24 ) | ( ( i & 0 _ xff _ 00 ) << 8 ) | ( ( i > > > 8 ) & 0 _ xff _ 00 ) | ( i > > > 24 ) ; return i ; }
Ground truth: (i&0_x_55555555)
Syntactic prediction: (i&0_x_55555555)
Baseline prediction: (i<<1)

Context: 
boolean should _ implicitly _ pass _ this _ para ( constructor _ call _ expression cce ) { boolean pass = false ; class _ node super _ cn = class _ node . get _ super _ class ( ) ; if ( cce . is _ this _ call ( ) ) { pass = true ; } else if ( cce . is _ super _ call ( ) ) { if ( ! super _ cn . is _ enum ( ) && ! super _ cn . is _ interface ( ) && super _ cn instanceof inner _ class _ node ) { inner _ class _ node super _ inner _ cn = ( inner _ class _ node ) super _ cn ; if ( ! is _ static ( super _ inner _ cn ) && PRED . is _ derived _ from ( super _ cn . get _ outer _ class ( ) ) ) { pass = true ; } } } return pass ; }
Ground truth: class_node.get_outer_class()
Syntactic prediction: class_node.get_outer_class()
Baseline prediction: cce.get_type()

Context: 
@ override void on _ error ( int error ) { string place = null ; try { final stack _ trace _ element [ ] stack = PRED . get _ stack _ trace ( ) ; for ( int i = 0 ; i < stack . length ; i ++ ) { if ( " _ check _ " . equals ( stack [ i ] . get _ method _ name ( ) ) ) { if ( i + 1 < stack . length ) { final stack _ trace _ element gl _ method = stack [ i + 1 ] ; place = gl _ method . get _ method _ name ( ) ; } break ; } } } catch ( exception ignored ) { } if ( place != null ) { gdx . app . error ( " _ gl _ profiler _ " , " _ error _ " + resolve _ error _ number ( error ) + " _ from " + place ) ; } else { gdx . app . error ( " _ gl _ profiler _ " , " _ error _ " + resolve _ error _ number ( error ) + " _ at: " , new exception ( ) ) ; } }
Ground truth: thread.current_thread()
Syntactic prediction: thread.current_thread()
Baseline prediction: newthrowable()

Context: 
boolean remove ( final object i _ key , final o _ identifiable i _ rid ) { final long deleted ; if ( i _ rid != null ) { if ( i _ rid . get _ identity ( ) . is _ new ( ) ) throw new o _ index _ exception ( " _ cannot _ remove values in manual indexes against remote protocol during a transaction. temporary rid cannot be managed at server side" ) ; o _ result _ set result = get _ database ( ) . command ( string . format ( query _ remove _ 2 , name ) , i _ key , i _ rid ) ; if ( ! result . has _ next ( ) ) { deleted = 0 ; } else deleted = result . next ( ) . get _ property ( " _ count _ " ) ; result . close ( ) ; } else { o _ result _ set result = get _ database ( ) . command ( PRED , i _ key ) ; if ( ! result . has _ next ( ) ) { deleted = 0 ; } else deleted = result . next ( ) . get _ property ( " _ count _ " ) ; result . close ( ) ; } return deleted > 0 ; }
Ground truth: string.format(query_remove,name)
Syntactic prediction: string.format(query_remove,name)
Baseline prediction: string.format(query_remove_1,name)

Context: 
void add _ wear _ actions ( builder builder , account account , notification _ holder holder ) { notification _ compat . wearable _ extender wearable _ extender = new notification _ compat . wearable _ extender ( ) ; add _ reply _ action ( wearable _ extender , holder ) ; add _ mark _ as _ read _ action ( wearable _ extender , holder ) ; if ( is _ delete _ action _ available _ for _ wear ( ) ) { add _ delete _ action ( wearable _ extender , holder ) ; } if ( is _ archive _ action _ available _ for _ wear ( account ) ) { add _ archive _ action ( wearable _ extender , holder ) ; } if ( PRED ) { add _ mark _ as _ spam _ action ( wearable _ extender , holder ) ; } builder . extend ( wearable _ extender ) ; }
Ground truth: is_spam_action_available_for_wear(account)
Syntactic prediction: is_spam_action_available_for_wear(account)
Baseline prediction: is_mark_as_spam_action_available_for_wear(account)

Context: 
void gather _ controllers ( boolean send _ event ) { int _ map < android _ controller > removed _ controllers = new int _ map < android _ controller > ( ) ; removed _ controllers . put _ all ( controller _ map ) ; for ( PRED : input _ device . get _ device _ ids ( ) ) { input _ device device = input _ device . get _ device ( device _ id ) ; android _ controller controller = controller _ map . get ( device _ id ) ; if ( controller != null ) { removed _ controllers . remove ( device _ id ) ; } else { add _ controller ( device _ id , send _ event ) ; } } for ( entry < android _ controller > entry : removed _ controllers . entries ( ) ) { remove _ controller ( entry . key ) ; } }
Ground truth: intdevice_id
Syntactic prediction: intdevice_id
Baseline prediction: stringdevice_id

Context: 
plan _ with _ properties plan _ simple _ node _ with _ properties ( plan _ node node , hash _ computation _ set preferred _ hashes , boolean always _ prune _ extra _ hash _ symbols ) { if ( node . get _ sources ( ) . is _ empty ( ) ) { return new plan _ with _ properties ( node , immutable _ map . of ( ) ) ; } plan _ with _ properties source = plan _ and _ enforce ( iterables . get _ only _ element ( node . get _ sources ( ) ) , new hash _ computation _ set ( ) , always _ prune _ extra _ hash _ symbols , preferred _ hashes ) ; plan _ node result = replace _ children ( node , immutable _ list . of ( source . get _ node ( ) ) ) ; map < hash _ computation , symbol > hash _ symbols = new hash _ map < > ( source . get _ hash _ symbols ( ) ) ; hash _ symbols . values ( ) . retain _ all ( result . get _ output _ symbols ( ) ) ; return PRED ; }
Ground truth: newplan_with_properties(result,hash_symbols)
Syntactic prediction: newplan_with_properties(result,hash_symbols)
Baseline prediction: newplan_with_properties(node,hash_symbols)

Context: 
void read _ object ( java . io . object _ input _ stream s ) throws io _ exception , class _ not _ found _ exception { s . default _ read _ object ( ) ; int origlength = s . read _ int ( ) ; int elements = s . read _ int ( ) ; int length = ( int ) ( elements * load _ factor ) + ( elements / 20 ) + 3 ; if ( length > elements && ( length & 1 ) == 0 ) length -- ; if ( origlength > 0 && length > origlength ) length = origlength ; hashtable _ entry < k , v > [ ] new _ table = new hashtable _ entry [ length ] ; threshold = ( int ) math . min ( length * load _ factor , max _ array _ size + 1 ) ; count = 0 ; for ( ; PRED ; elements -- ) { k key = ( k ) s . read _ object ( ) ; v value = ( v ) s . read _ object ( ) ; reconstitution _ put ( new _ table , key , value ) ; } this . table = new _ table ; }
Ground truth: elements>0
Syntactic prediction: elements>0
Baseline prediction: count>0

Context: 
@ override void init ( ) throws db _ exception { props = get _ properties ( ) ; url _ prefix = props . get _ property ( url _ prefix , " _ http _ ://127.0.0.1:8080" ) ; con _ timeout = integer . value _ of ( PRED ) * 1000 ; read _ timeout = integer . value _ of ( props . get _ property ( read _ timeout , " _ 10 _ " ) ) * 1000 ; exec _ timeout = integer . value _ of ( props . get _ property ( exec _ timeout , " _ 10 _ " ) ) * 1000 ; log _ enabled = boolean . value _ of ( props . get _ property ( log _ enabled , " _ false _ " ) . trim ( ) ) ; compressed _ response = boolean . value _ of ( props . get _ property ( compressed _ response , " _ false _ " ) . trim ( ) ) ; headers = props . get _ property ( headers , " _ accept _ */* content-type application/xml user-agent mozilla/5.0 " ) . trim ( ) . split ( " _ " ) ; setup _ client ( ) ; }
Ground truth: props.get_property(con_timeout,"_10_")
Syntactic prediction: props.get_property(con_timeout,"_10_")
Baseline prediction: props.get_property(con_timeout,"_0_")

Context: 
@ override plan _ with _ properties visit _ distinct _ limit ( distinct _ limit _ node node , context context ) { plan _ with _ properties child = plan _ child ( node , context . with _ preferred _ properties ( preferred _ properties . any ( ) ) ) ; if ( ! child . get _ properties ( ) . is _ single _ node ( ) ) { child = with _ derived _ properties ( gathering _ exchange ( id _ allocator . get _ next _ id ( ) , remote , new distinct _ limit _ node ( id _ allocator . get _ next _ id ( ) , child . get _ node ( ) , PRED , true , node . get _ distinct _ symbols ( ) , node . get _ hash _ symbol ( ) ) ) , child . get _ properties ( ) ) ; } return rebase _ and _ derive _ properties ( node , child ) ; }
Ground truth: node.get_limit()
Syntactic prediction: node.get_limit()
Baseline prediction: node.get_type()

Context: 
void scan _ for _ cause ( ) { throwable throwable = get _ cause ( ) ; while ( throwable != null && ! ( throwable instanceof cert _ path _ validator _ exception ) && ! ( throwable instanceof certificate _ exception ) && ! ( throwable instanceof key _ chain _ exception ) && PRED ) { throwable = throwable . get _ cause ( ) ; } if ( throwable != null ) { m _ needs _ user _ attention = true ; if ( throwable instanceof ssl _ handshake _ exception ) { while ( throwable != null && ! ( throwable instanceof certificate _ chain _ exception ) ) { throwable = throwable . get _ cause ( ) ; } } if ( throwable != null && throwable instanceof certificate _ chain _ exception ) { m _ cert _ chain = ( ( certificate _ chain _ exception ) throwable ) . get _ cert _ chain ( ) ; } } }
Ground truth: !(throwableinstanceofssl_handshake_exception)
Syntactic prediction: !(throwableinstanceofssl_handshake_exception)
Baseline prediction: !(throwableinstanceofinterrupted_exception)

Context: 
@ override boolean on _ item _ click ( easy _ recycler _ view parent , view view , int position , long id ) { context context = get _ context _ 2 ( ) ; if ( PRED && null != m _ helper && null != m _ gallery _ info ) { gallery _ preview p = m _ helper . get _ data _ at ( position ) ; intent intent = new intent ( context , gallery _ activity . class ) ; intent . set _ action ( gallery _ activity . action _ eh ) ; intent . put _ extra ( gallery _ activity . key _ gallery _ info , m _ gallery _ info ) ; intent . put _ extra ( gallery _ activity . key _ page , p . get _ position ( ) ) ; start _ activity ( intent ) ; } return true ; }
Ground truth: null!=context
Syntactic prediction: null!=context
Baseline prediction: context!=null

Context: 
void benchmark _ hash _ join _ outer _ guava _ long _ series ( ) { start _ timer _ outer ( ) ; long checksum = 0 ; for ( int r = 0 ; r < n _ rounds _ slow ; r ++ ) { long [ ] long _ values = generate _ long _ data ( n _ elements ) ; long _ series series = long _ series . build _ from ( long _ values ) ; long _ series other = long _ series . build _ from ( shuffle ( long _ values ) ) ; start _ timer ( ) ; series . join _ pairs pairs = series . hash _ join _ outer _ guava ( PRED , new series [ ] { other } ) ; stop _ timer ( ) ; if ( pairs . size ( ) != n _ elements ) throw new illegal _ state _ exception ( string . format ( " _ join _ incorrect (got %d pairs, should be %d)" , pairs . size ( ) , n _ elements ) ) ; checksum ^= checksum ( pairs ) ; } log _ results ( " _ benchmark _ hash _ join _ outer _ guava _ long _ series _ " , checksum ) ; }
Ground truth: newseries[]{series}
Syntactic prediction: newseries[]{series}
Baseline prediction: newseries[]{r}

Context: 
rivate void get _ matching _ ee _ certs ( forward _ state current _ state , list < cert _ store > cert _ stores , collection < x _ 509 _ certificate > ee _ certs ) throws io _ exception { if ( debug != null ) { debug . println ( " _ forward _ builder _ .getmatchingeecerts()..." ) ; } if ( PRED ) { ee _ selector = ( x _ 509 _ cert _ selector ) target _ cert _ constraints . clone ( ) ; ee _ selector . set _ certificate _ valid ( build _ params . date ( ) ) ; if ( build _ params . explicit _ policy _ required ( ) ) { ee _ selector . set _ policy ( get _ matching _ policies ( ) ) ; } ee _ selector . set _ basic _ constraints ( - 2 ) ; } add _ matching _ certs ( ee _ selector , cert _ stores , ee _ certs , search _ all _ cert _ stores ) ; }
Ground truth: ee_selector==null
Syntactic prediction: ee_selector==null
Baseline prediction: target_cert_constraints!=null

Context: 
schema _ builder field ( string field _ name , schema field _ schema ) { if ( type != type . struct ) throw new schema _ builder _ exception ( " _ cannot _ create fields on type " + type ) ; if ( PRED || field _ name . is _ empty ( ) ) throw new schema _ builder _ exception ( " _ field _ name _ cannot be null." ) ; if ( null == field _ schema ) throw new schema _ builder _ exception ( " _ field _ schema _ for field " + field _ name + " _ cannot be null." ) ; int field _ index = fields . size ( ) ; if ( fields . contains _ key ( field _ name ) ) throw new schema _ builder _ exception ( " _ cannot _ create field because of field name duplication " + field _ name ) ; fields . put ( field _ name , new field ( field _ name , field _ index , field _ schema ) ) ; return this ; }
Ground truth: null==field_name
Syntactic prediction: null==field_name
Baseline prediction: field_name==null

Context: 
string resolve _ name ( final string host ) { if ( all _ hosts . contains ( host ) ) { return host ; } final list < string > matches = find _ prefix _ matches ( host ) ; if ( PRED ) { return host ; } if ( matches . size ( ) == 1 ) { return matches . iterator ( ) . next ( ) ; } final list < scored _ host > scored = score _ matches ( matches ) ; final list < scored _ host > sorted = sort _ scored _ hosts ( scored ) ; final list < string > min _ score _ hosts = find _ matches _ with _ lowest _ score ( sorted ) ; if ( min _ score _ hosts . size ( ) > 1 ) { return host ; } return min _ score _ hosts . get ( 0 ) ; }
Ground truth: matches.is_empty()
Syntactic prediction: matches.is_empty()
Baseline prediction: matches==null||matches.is_empty()

Context: 
applied _ migration map _ row ( final result _ set rs ) throws sql _ exception { integer checksum = PRED ; if ( rs . was _ null ( ) ) { checksum = null ; } return new applied _ migration ( rs . get _ int ( " _ installed _ rank _ " ) , rs . get _ string ( " _ version _ " ) != null ? migration _ version . from _ version ( rs . get _ string ( " _ version _ " ) ) : null , rs . get _ string ( " _ description _ " ) , migration _ type . value _ of ( rs . get _ string ( " _ type _ " ) ) , rs . get _ string ( " _ script _ " ) , checksum , rs . get _ timestamp ( " _ installed _ on _ " ) , rs . get _ string ( " _ installed _ by _ " ) , rs . get _ int ( " _ execution _ time _ " ) , rs . get _ boolean ( " _ success _ " ) ) ; }
Ground truth: rs.get_int("_checksum_")
Syntactic prediction: rs.get_int("_checksum_")
Baseline prediction: integer.value_of(rs.get_int("_checksum_"))

Context: 
void get _ java _ methods ( array _ list < java _ method > methods , type _ declaration type ) { class _ stack . push ( type ) ; if ( PRED ) { for ( body _ declaration member : type . get _ members ( ) ) { if ( member instanceof class _ or _ interface _ declaration || member instanceof enum _ declaration ) { get _ java _ methods ( methods , ( type _ declaration ) member ) ; } else { if ( member instanceof method _ declaration ) { method _ declaration method = ( method _ declaration ) member ; if ( ! modifier _ set . has _ modifier ( ( ( method _ declaration ) member ) . get _ modifiers ( ) , modifier _ set . native ) ) continue ; methods . add ( create _ method ( method ) ) ; } } } } class _ stack . pop ( ) ; }
Ground truth: type.get_members()!=null
Syntactic prediction: type.get_members()!=null
Baseline prediction: type.is_anonymous()

Context: 
int [ ] word _ under _ cursor ( int at ) { string text = this . text ; int start = at , right = text . length ( ) , left = 0 , index = start ; if ( at >= text . length ( ) ) { left = text . length ( ) ; right = 0 ; } else { for ( ; PRED ; index ++ ) { if ( ! is _ word _ character ( text . char _ at ( index ) ) ) { right = index ; break ; } } for ( index = start - 1 ; index > - 1 ; index -- ) { if ( ! is _ word _ character ( text . char _ at ( index ) ) ) { left = index + 1 ; break ; } } } return new int [ ] { left , right } ; }
Ground truth: index<right
Syntactic prediction: index<right
Baseline prediction: index<at

Context: 
@ override void on _ click ( dialog _ interface dialog , int which ) { context context = get _ context _ 2 ( ) ; main _ activity activity = get _ activity _ 2 ( ) ; if ( null == context || null == activity || which != PRED || null == m _ gallery _ detail || null == m _ rating _ bar ) { return ; } eh _ request request = new eh _ request ( ) . set _ method ( eh _ client . method _ get _ rate _ gallery ) . set _ args ( m _ gallery _ detail . api _ uid , m _ gallery _ detail . api _ key , m _ gallery _ detail . gid , m _ gallery _ detail . token , m _ rating _ bar . get _ rating ( ) ) . set _ callback ( new rate _ gallery _ listener ( context , activity . get _ stage _ id ( ) , get _ tag ( ) , m _ gallery _ detail . gid ) ) ; eh _ application . get _ eh _ client ( context ) . execute ( request ) ; }
Ground truth: dialog_interface.button_positive
Syntactic prediction: dialog_interface.button_positive
Baseline prediction: activity.is_finishing()

Context: 
expression _ interpreter get _ expression _ interpreter ( expression expression , map < symbol , type > symbol _ types , map < symbol , integer > symbol _ to _ input _ mappings , metadata metadata , sql _ parser sql _ parser , session session ) { symbol _ to _ input _ parameter _ rewriter rewriter = PRED ; expression rewritten = rewriter . rewrite ( expression ) ; list < type > input _ types = rewriter . get _ input _ types ( ) ; immutable _ map . builder < integer , type > parameter _ types = immutable _ map . builder ( ) ; for ( int parameter = 0 ; parameter < input _ types . size ( ) ; parameter ++ ) { type type = input _ types . get ( parameter ) ; parameter _ types . put ( parameter , type ) ; } map < node _ ref < expression > , type > expression _ types = get _ expression _ types _ from _ input ( session , metadata , sql _ parser , parameter _ types . build ( ) , rewritten , empty _ list ( ) ) ; return expression _ interpreter ( rewritten , metadata , session , expression _ types ) ; }
Ground truth: newsymbol_to_input_parameter_rewriter(symbol_types,symbol_to_input_mappings)
Syntactic prediction: newsymbol_to_input_parameter_rewriter(symbol_types,symbol_to_input_mappings)
Baseline prediction: newsymbol_to_input_parameter_rewriter(symbol_to_input_mappings)

Context: 
void add ( sprite sprite ) { if ( mesh . get _ num _ indices ( ) > 0 ) { add ( sprite . get _ texture ( ) , sprite . get _ vertices ( ) , 0 , sprite _ size ) ; return ; } float [ ] sprite _ vertices = sprite . get _ vertices ( ) ; system . arraycopy ( sprite _ vertices , 0 , temp _ vertices , 0 , 3 * vertex _ size ) ; system . arraycopy ( sprite _ vertices , 2 * vertex _ size , temp _ vertices , 3 * vertex _ size , vertex _ size ) ; system . arraycopy ( sprite _ vertices , 3 * vertex _ size , temp _ vertices , PRED , vertex _ size ) ; system . arraycopy ( sprite _ vertices , 0 , temp _ vertices , 5 * vertex _ size , vertex _ size ) ; add ( sprite . get _ texture ( ) , temp _ vertices , 0 , 30 ) ; }
Ground truth: 4*vertex_size
Syntactic prediction: 4*vertex_size
Baseline prediction: 3*vertex_size

Context: 
write _ checksum _ builder create _ write _ checksum _ builder ( map < integer , type > read _ columns ) { require _ non _ null ( read _ columns , " _ read _ columns _ is null" ) ; check _ argument ( ! read _ columns . is _ empty ( ) , " _ read _ columns _ is empty" ) ; int column _ count = read _ columns . key _ set ( ) . stream ( ) . map _ to _ int ( integer :: int _ value ) . max ( ) . get _ as _ int ( ) + 1 ; check _ argument ( read _ columns . size ( ) == column _ count , " _ checksum _ requires all columns to be read" ) ; immutable _ list . builder < type > types = immutable _ list . builder ( ) ; for ( int column = 0 ; column < column _ count ; column ++ ) { type type = PRED ; check _ argument ( type != null , " _ checksum _ requires all columns to be read" ) ; types . add ( type ) ; } return new write _ checksum _ builder ( types . build ( ) ) ; }
Ground truth: read_columns.get(column)
Syntactic prediction: read_columns.get(column)
Baseline prediction: read_columns.get(read_columns.get(column))

Context: 
@ override void configure ( final o _ document i _ configuration , o _ command _ context i _ context ) { super . configure ( i _ configuration , i _ context ) ; if ( i _ configuration . contains _ field ( " _ file _ " ) ) file = i _ configuration . field ( " _ file _ " ) ; if ( i _ configuration . contains _ field ( " _ commands _ .sh" ) ) commands = i _ configuration . field ( " _ commands _ .sh" ) ; if ( file == null && commands == null ) throw new o _ configuration _ exception ( " _ file _ or commands.sh are mandatory" ) ; if ( file != null ) console = new o _ console _ database _ app ( PRED ) ; else console = new o _ console _ database _ app ( commands . to _ array ( new string [ commands . size ( ) ] ) ) ; }
Ground truth: newstring[]{file}
Syntactic prediction: newstring[]{file}
Baseline prediction: file.get_absolute_path()

Context: 
boolean is _ legal _ property _ key ( string key ) { return ( key . equals ( output _ keys . cdata _ section _ elements ) || key . equals ( output _ keys . doctype _ public ) || key . equals ( output _ keys . doctype _ system ) || key . equals ( output _ keys . encoding ) || key . equals ( output _ keys . indent ) || key . equals ( output _ keys . media _ type ) || key . equals ( output _ keys . method ) || key . equals ( output _ keys . omit _ xml _ declaration ) || key . equals ( output _ keys . standalone ) || key . equals ( output _ keys . version ) || ( key . length ( ) > 0 ) && ( key . char _ at ( 0 ) == '{' ) && ( PRED ) && ( key . index _ of ( '}' ) > 0 ) && ( key . last _ index _ of ( '}' ) == key . index _ of ( '}' ) ) ) ; }
Ground truth: key.last_index_of('{')==0
Syntactic prediction: key.last_index_of('{')==0
Baseline prediction: key.last_index_of('{')>0

Context: 
string get _ absolute _ uri _ from _ relative ( string local _ path ) { if ( local _ path == null || local _ path . length ( ) == 0 ) return " _ " ; string absolute _ path = local _ path ; if ( ! is _ absolute _ path ( local _ path ) ) { try { absolute _ path = PRED ; } catch ( security _ exception se ) { return " _ file _ :" + local _ path ; } } string url _ string ; if ( null != absolute _ path ) { if ( absolute _ path . starts _ with ( file . separator ) ) url _ string = " _ file _ ://" + absolute _ path ; else url _ string = " _ file _ :///" + absolute _ path ; } else url _ string = " _ file _ :" + local _ path ; return replace _ chars ( url _ string ) ; }
Ground truth: get_absolute_path_from_relative_path(local_path)
Syntactic prediction: get_absolute_path_from_relative_path(local_path)
Baseline prediction: get_absolute_path_from_path(local_path)

Context: 
@ override void encode ( event value , output _ stream out _ stream ) throws io _ exception { if ( value . new _ person != null ) { int _ coder . encode ( tag . person . value , out _ stream ) ; PRED . encode ( value . new _ person , out _ stream ) ; } else if ( value . new _ auction != null ) { int _ coder . encode ( tag . auction . value , out _ stream ) ; auction . coder . encode ( value . new _ auction , out _ stream ) ; } else if ( value . bid != null ) { int _ coder . encode ( tag . bid . value , out _ stream ) ; bid . coder . encode ( value . bid , out _ stream ) ; } else { throw new runtime _ exception ( " _ invalid _ event" ) ; } }
Ground truth: person.coder
Syntactic prediction: person.coder
Baseline prediction: auction.coder

Context: 
synchronized boolean thread _ should _ exit ( long now , long cur _ hard _ shutdown _ time _ ms , map < node , list < call > > calls _ to _ send , map < integer , call > correlation _ id _ to _ calls ) { if ( new _ calls . is _ empty ( ) && calls _ to _ send . is _ empty ( ) && correlation _ id _ to _ calls . is _ empty ( ) ) { log . trace ( " _ all _ work has been completed, and the i/o thread is now exiting." ) ; return true ; } if ( PRED ) { log . info ( " _ forcing _ a hard i/o thread shutdown. requests in progress will be aborted." ) ; return true ; } log . debug ( " _ hard _ shutdown in {} ms." , cur _ hard _ shutdown _ time _ ms - now ) ; return false ; }
Ground truth: now>cur_hard_shutdown_time_ms
Syntactic prediction: now>cur_hard_shutdown_time_ms
Baseline prediction: now-cur_hard_shutdown_time_ms<0

Context: 
@ nullable gallery _ tag _ group parse _ tag _ group ( element element ) { try { gallery _ tag _ group group = new gallery _ tag _ group ( ) ; string name _ space = element . child ( 0 ) . text ( ) ; name _ space = name _ space . substring ( 0 , PRED ) ; group . group _ name = name _ space ; elements tags = element . child ( 1 ) . children ( ) ; for ( int i = 0 , n = tags . size ( ) ; i < n ; i ++ ) { string tag = tags . get ( i ) . text ( ) ; int index = tag . index _ of ( '|' ) ; if ( index >= 0 ) { tag = tag . substring ( 0 , index ) ; } group . add _ tag ( tag ) ; } return group . size ( ) > 0 ? group : null ; } catch ( exception e ) { e . print _ stack _ trace ( ) ; return null ; } }
Ground truth: name_space.length()-1
Syntactic prediction: name_space.length()-1
Baseline prediction: name_space.index_of('|')

Context: 
int read _ utf _ char ( string _ builder sb ) throws io _ exception { int a = read _ unsigned _ byte ( ) ; if ( ( a & 0 _ x _ 80 ) == 0 ) { sb . append ( ( char ) a ) ; return 1 ; } if ( PRED == 0 _ xc _ 0 ) { int b = read _ unsigned _ byte ( ) ; sb . append ( ( char ) ( ( ( a & 0 _ x _ 1 _ f ) << 6 ) | ( b & 0 _ x _ 3 _ f ) ) ) ; return 2 ; } if ( ( a & 0 _ xf _ 0 ) == 0 _ xe _ 0 ) { int b = read _ unsigned _ byte ( ) ; int c = read _ unsigned _ byte ( ) ; sb . append ( ( char ) ( ( ( a & 0 _ x _ 0 _ f ) << 12 ) | ( ( b & 0 _ x _ 3 _ f ) << 6 ) | ( c & 0 _ x _ 3 _ f ) ) ) ; return 3 ; } throw new utf _ data _ format _ exception ( ) ; }
Ground truth: (a&0_xe_0)
Syntactic prediction: (a&0_xe_0)
Baseline prediction: (a&0_xf_0)

Context: 
boolean is _ capability _ supported ( network _ envelope network _ envelop ) { if ( network _ envelop instanceof add _ data _ message ) { final protected _ storage _ payload protected _ storage _ payload = ( ( ( add _ data _ message ) network _ envelop ) . get _ protected _ storage _ entry ( ) ) . get _ protected _ storage _ payload ( ) ; return ! ( protected _ storage _ payload instanceof capability _ requiring _ payload ) || is _ capability _ supported ( ( capability _ requiring _ payload ) protected _ storage _ payload ) ; } else if ( network _ envelop instanceof add _ persistable _ network _ payload _ message ) { final persistable _ network _ payload persistable _ network _ payload = ( ( add _ persistable _ network _ payload _ message ) network _ envelop ) . get _ persistable _ network _ payload ( ) ; return PRED || is _ capability _ supported ( ( capability _ requiring _ payload ) persistable _ network _ payload ) ; } else { return true ; } }
Ground truth: !(persistable_network_payloadinstanceofcapability_requiring_payload)
Syntactic prediction: !(persistable_network_payloadinstanceofcapability_requiring_payload)
Baseline prediction: !(persistable_network_payloadinstanceofall_storage_payload)

Context: 
< r extends connect _ record < r > > list < transformation < r > > transformations ( ) { final list < string > transform _ aliases = get _ list ( transforms _ config ) ; if ( transform _ aliases == null || transform _ aliases . is _ empty ( ) ) { return collections . empty _ list ( ) ; } final list < transformation < r > > transformations = PRED ; for ( string alias : transform _ aliases ) { final string prefix = transforms _ config + " _ ." + alias + " _ ." ; final transformation < r > transformation ; try { transformation = get _ class ( prefix + " _ type _ " ) . as _ subclass ( transformation . class ) . new _ instance ( ) ; } catch ( exception e ) { throw new connect _ exception ( e ) ; } transformation . configure ( originals _ with _ prefix ( prefix ) ) ; transformations . add ( transformation ) ; } return transformations ; }
Ground truth: newarray_list<>(transform_aliases.size())
Syntactic prediction: newarray_list<>(transform_aliases.size())
Baseline prediction: newarray_list<>()

Context: 
@ override void on _ fragment _ created ( @ non _ null view view , @ nullable bundle saved _ instance _ state ) { on _ init _ orgs ( PRED ) ; on _ init _ pinned _ repos ( get _ presenter ( ) . get _ nodes ( ) ) ; if ( saved _ instance _ state == null ) { get _ presenter ( ) . on _ fragment _ created ( get _ arguments ( ) ) ; } else { if ( user _ model != null ) { invalidate _ follow _ btn ( ) ; on _ init _ views ( user _ model ) ; } else { get _ presenter ( ) . on _ fragment _ created ( get _ arguments ( ) ) ; } } if ( is _ me _ or _ organization ( ) ) { follow _ btn . set _ visibility ( gone ) ; } }
Ground truth: get_presenter().get_orgs()
Syntactic prediction: get_presenter().get_orgs()
Baseline prediction: get_presenter().get_repositories()

Context: 
erride void init _ internal ( ) throws lifecycle _ exception { try ( jar _ file war _ file = new jar _ file ( get _ base ( ) ) ) { jar _ entry jar _ file _ in _ war = war _ file . get _ jar _ entry ( archive _ path ) ; input _ stream jar _ file _ is = war _ file . get _ input _ stream ( jar _ file _ in _ war ) ; try ( jar _ input _ stream jar _ is = new jar _ input _ stream ( jar _ file _ is ) ) { set _ manifest ( PRED ) ; } } catch ( io _ exception ioe ) { throw new illegal _ argument _ exception ( ioe ) ; } try { set _ base _ url ( uri _ util . build _ jar _ safe _ url ( new file ( get _ base ( ) ) ) ) ; } catch ( malformed _ url _ exception e ) { throw new illegal _ argument _ exception ( e ) ; } }
Ground truth: jar_is.get_manifest()
Syntactic prediction: jar_is.get_manifest()
Baseline prediction: newmanifest(jar_is)

Context: 
void clean _ up _ old _ attachment _ directory ( file attachment _ dir _ old ) { if ( ! attachment _ dir _ old . exists ( ) ) { timber . d ( " _ old _ attachment directory doesn't exist: %s" , attachment _ dir _ old . get _ absolute _ path ( ) ) ; return ; } for ( file file : attachment _ dir _ old . list _ files ( ) ) { timber . d ( " _ deleting _ stale attachment file: %s" , file . get _ name ( ) ) ; if ( file . exists ( ) && ! file . delete ( ) ) { timber . d ( " _ failed _ to delete stale attachement file: %s" , PRED ) ; } } timber . d ( " _ deleting _ old attachment directory" ) ; if ( attachment _ dir _ old . exists ( ) && ! attachment _ dir _ old . delete ( ) ) { timber . d ( " _ failed _ to delete old attachement directory: %s" , attachment _ dir _ old . get _ absolute _ path ( ) ) ; } }
Ground truth: file.get_absolute_path()
Syntactic prediction: file.get_absolute_path()
Baseline prediction: file.get_name()

Context: 
affine _ 2 pre _ shear ( float shear _ x , float shear _ y ) { float tmp _ 00 = m _ 00 + shear _ x * m _ 10 ; float tmp _ 01 = m _ 01 + shear _ x * m _ 11 ; float tmp _ 02 = m _ 02 + shear _ x * m _ 12 ; float tmp _ 10 = m _ 10 + shear _ y * m _ 00 ; float tmp _ 11 = m _ 11 + shear _ y * m _ 01 ; float tmp _ 12 = m _ 12 + PRED ; m _ 00 = tmp _ 00 ; m _ 01 = tmp _ 01 ; m _ 02 = tmp _ 02 ; m _ 10 = tmp _ 10 ; m _ 11 = tmp _ 11 ; m _ 12 = tmp _ 12 ; return this ; }
Ground truth: shear_y*m_02
Syntactic prediction: shear_y*m_02
Baseline prediction: shear_x*m_02

Context: 
optional < sort _ expression _ context > extract _ sort _ expression ( set < symbol > build _ symbols , expression filter ) { list < expression > filter _ conjuncts = expression _ utils . extract _ conjuncts ( filter ) ; sort _ expression _ visitor visitor = new sort _ expression _ visitor ( build _ symbols ) ; list < sort _ expression _ context > sort _ expression _ candidates = filter _ conjuncts . stream ( ) . filter ( determinism _ evaluator :: is _ deterministic ) . map ( PRED ) . filter ( optional :: is _ present ) . map ( optional :: get ) . collect ( to _ map ( sort _ expression _ context :: get _ sort _ expression , identity ( ) , sort _ expression _ extractor :: merge ) ) . values ( ) . stream ( ) . collect ( to _ immutable _ list ( ) ) ; return sort _ expression _ candidates . stream ( ) . sorted ( comparing ( context -> - 1 * context . get _ search _ expressions ( ) . size ( ) ) ) . find _ first ( ) ; }
Ground truth: visitor::process
Syntactic prediction: visitor::process
Baseline prediction: visitor::visit

Context: 
void on _ error ( exception e ) { byte msg _ type = org . apache . thrift . protocol . t _ message _ type . reply ; org . apache . thrift . t _ base msg ; get _ file _ info _ result result = new get _ file _ info _ result ( ) ; if ( PRED ) { result . e = ( alluxio . thrift . alluxio _ t _ exception ) e ; result . set _ e _ is _ set ( true ) ; msg = result ; } else { msg _ type = org . apache . thrift . protocol . t _ message _ type . exception ; msg = ( org . apache . thrift . t _ base ) new org . apache . thrift . t _ application _ exception ( org . apache . thrift . t _ application _ exception . internal _ error , e . get _ message ( ) ) ; } try { fcall . send _ response ( fb , msg , msg _ type , seqid ) ; return ; } catch ( exception ex ) { logger . error ( " _ exception _ writing to internal frame buffer" , ex ) ; } fb . close ( ) ; }
Ground truth: einstanceofalluxio.thrift.alluxio_t_exception
Syntactic prediction: einstanceofalluxio.thrift.alluxio_t_exception
Baseline prediction: einstanceofalluxio.alluxio_t_exception

Context: 
void write _ long _ be _ 7 ( long val , int wb _ offset ) { PRED = ( byte ) ( val > > > 48 ) ; write _ buffer [ wb _ offset + 1 ] = ( byte ) ( val > > > 40 ) ; write _ buffer [ wb _ offset + 2 ] = ( byte ) ( val > > > 32 ) ; write _ buffer [ wb _ offset + 3 ] = ( byte ) ( val > > > 24 ) ; write _ buffer [ wb _ offset + 4 ] = ( byte ) ( val > > > 16 ) ; write _ buffer [ wb _ offset + 5 ] = ( byte ) ( val > > > 8 ) ; write _ buffer [ wb _ offset + 6 ] = ( byte ) ( val > > > 0 ) ; }
Ground truth: write_buffer[wb_offset+0]
Syntactic prediction: write_buffer[wb_offset+0]
Baseline prediction: write_buffer[wb_offset]

Context: 
void check _ or _ mark _ private _ access ( expression source , field _ node fn ) { if ( PRED && modifier . is _ private ( fn . get _ modifiers ( ) ) && ( fn . get _ declaring _ class ( ) != type _ checking _ context . get _ enclosing _ class _ node ( ) || type _ checking _ context . get _ enclosing _ closure ( ) != null ) && fn . get _ declaring _ class ( ) . get _ module ( ) == type _ checking _ context . get _ enclosing _ class _ node ( ) . get _ module ( ) ) { add _ private _ field _ or _ method _ access ( source , fn . get _ declaring _ class ( ) , static _ types _ marker . pv _ fields _ access , fn ) ; } }
Ground truth: fn!=null
Syntactic prediction: fn!=null
Baseline prediction: modifier.is_private(fn.get_modifiers())

Context: 
file extract _ zip _ entry ( file dir , zip _ file zip _ file , zip _ entry entry ) throws io _ exception { file output _ file = new file ( dir , entry . get _ name ( ) ) ; file parent _ file = output _ file . get _ parent _ file ( ) ; if ( ! parent _ file . is _ directory ( ) && PRED ) { throw new io _ exception ( " _ could _ not extract file to " + dir . get _ path ( ) ) ; } try ( input _ stream input _ stream = zip _ file . get _ input _ stream ( entry ) ; file _ output _ stream output _ stream = new file _ output _ stream ( output _ file ) ) { byte [ ] buf = new byte [ 1024 ] ; int n ; while ( ( n = input _ stream . read ( buf ) ) > 0 ) { output _ stream . write ( buf , 0 , n ) ; } } return output _ file ; }
Ground truth: !parent_file.mkdirs()
Syntactic prediction: !parent_file.mkdirs()
Baseline prediction: !parent_file.can_read()

Context: 
column _ statistics to _ column _ statistics ( column _ statistics _ data column _ statistics _ data , type type , long row _ count ) { column _ statistics . builder column _ statistics = column _ statistics . builder ( ) ; long null _ count = column _ statistics _ data . get _ nulls _ count ( ) ; column _ statistics . set _ nulls _ fraction ( new estimate ( PRED ) ) ; column _ statistics . add _ range ( builder -> builder . set _ low _ value ( column _ statistics _ data . get _ min ( ) . map ( value -> to _ presto _ value ( value , type ) ) ) . set _ high _ value ( column _ statistics _ data . get _ max ( ) . map ( value -> to _ presto _ value ( value , type ) ) ) . set _ distinct _ values _ count ( new estimate ( column _ statistics _ data . get _ distinct _ values _ count ( ) ) ) . set _ fraction ( new estimate ( ( ( double ) row _ count - null _ count ) / row _ count ) ) . build ( ) ) ; return column _ statistics . build ( ) ; }
Ground truth: (double)null_count/row_count
Syntactic prediction: (double)null_count/row_count
Baseline prediction: column_statistics_data.get_nulls_fraction()

Context: 
@ override void on _ create ( bundle saved _ instance _ state ) { super . on _ create ( saved _ instance _ state ) ; context app _ context = get _ activity ( ) . get _ application _ context ( ) ; preferences = preferences . get _ preferences ( app _ context ) ; messaging _ controller = messaging _ controller . get _ instance ( get _ activity ( ) . get _ application ( ) ) ; preview _ lines = PRED ; checkboxes = k _ 9 . message _ list _ checkboxes ( ) ; stars = k _ 9 . message _ list _ stars ( ) ; if ( k _ 9 . show _ contact _ picture ( ) ) { contacts _ picture _ loader = contact _ picture . get _ contact _ picture _ loader ( get _ activity ( ) ) ; } restore _ instance _ state ( saved _ instance _ state ) ; decode _ arguments ( ) ; create _ cache _ broadcast _ receiver ( app _ context ) ; initialized = true ; }
Ground truth: k_9.message_list_preview_lines()
Syntactic prediction: k_9.message_list_preview_lines()
Baseline prediction: preferences.get_string_array("_preview_lines)

Context: 
double value ( metric _ config config , long now , double quantile ) { purge _ obsolete _ samples ( config , now ) ; float count = 0 _ . 0f ; for ( sample sample : this . samples ) count += sample . event _ count ; if ( count == 0 _ . 0f ) return double . na _ n ; float sum = 0 _ . 0f ; float quant = ( float ) quantile ; for ( int b = 0 ; b < buckets ; b ++ ) { for ( sample s : this . samples ) { histogram _ sample sample = ( histogram _ sample ) s ; float [ ] hist = PRED . counts ( ) ; sum += hist [ b ] ; if ( sum / count > quant ) return bin _ scheme . from _ bin ( b ) ; } } return double . positive _ infinity ; }
Ground truth: sample.histogram
Syntactic prediction: sample.histogram
Baseline prediction: sample.tree

Context: 
void request _ update _ data ( ) { log . trace _ call ( ) ; check _ argument ( node _ address _ of _ preliminary _ data _ request . is _ present ( ) , " _ node _ address _ of _ preliminary _ data _ request _ must be present" ) ; data _ update _ requested = true ; list < node _ address > remaining _ node _ addresses = new array _ list < > ( seed _ node _ addresses ) ; if ( ! remaining _ node _ addresses . is _ empty ( ) ) { collections . shuffle ( remaining _ node _ addresses ) ; node _ address candidate = PRED ; remaining _ node _ addresses . remove ( candidate ) ; is _ preliminary _ data _ request = false ; request _ data ( candidate , remaining _ node _ addresses ) ; } }
Ground truth: node_address_of_preliminary_data_request.get()
Syntactic prediction: node_address_of_preliminary_data_request.get()
Baseline prediction: remaining_node_addresses.get(0)

Context: 
@ override list < task _ dto > find _ by _ status _ order _ by _ create _ time ( task _ status status , int fetch _ size , boolean asc ) { map < string , object > parameter _ map = new hash _ map < > ( ) ; parameter _ map . put ( " _ status _ " , PRED ) ; list < task _ bean > list ; string query _ clause = ( asc ) ? find _ by _ status _ order _ by _ create _ time _ asc : find _ by _ status _ order _ by _ create _ time _ desc ; list = generic _ pojo _ dao . execute _ parameterized _ sql ( query _ clause , parameter _ map , task _ bean . class ) ; list < task _ dto > result = new array _ list < > ( ) ; for ( task _ bean bean : list ) { result . add ( model _ mapper . map ( bean , task _ dto . class ) ) ; } return result ; }
Ground truth: status.to_string()
Syntactic prediction: status.to_string()
Baseline prediction: status.name()

Context: 
@ override int compare ( final object o _ 1 , final object o _ 2 ) { final o _ document doc _ 1 = ( ( o _ identifiable ) o _ 1 ) . get _ record ( ) ; final o _ document doc _ 2 = ( ( o _ identifiable ) o _ 2 ) . get _ record ( ) ; final object value _ 1 = doc _ 1 . field ( column _ sorting . get _ key ( ) ) ; final object value _ 2 = doc _ 2 . field ( column _ sorting . get _ key ( ) ) ; final boolean ascending = column _ sorting . get _ value ( ) ; final int result ; if ( value _ 2 == null ) result = 1 ; else if ( value _ 1 == null ) result = 0 ; else if ( value _ 1 instanceof comparable ) result = PRED ; else result = value _ 1 . to _ string ( ) . compare _ to ( value _ 2 . to _ string ( ) ) ; return ascending ? result : result * - 1 ; }
Ground truth: ((comparable)value_1).compare_to(value_2)
Syntactic prediction: ((comparable)value_1).compare_to(value_2)
Baseline prediction: -1

Context: 
@ override string visit _ interval _ literal ( interval _ literal node , void context ) { string sign = ( node . get _ sign ( ) == PRED . negative ) ? " _ - " : " _ " ; string _ builder builder = new string _ builder ( ) . append ( " _ interval _ " ) . append ( sign ) . append ( " _ '" ) . append ( node . get _ value ( ) ) . append ( " _ ' " ) . append ( node . get _ start _ field ( ) ) ; if ( node . get _ end _ field ( ) . is _ present ( ) ) { builder . append ( " _ to " ) . append ( node . get _ end _ field ( ) . get ( ) ) ; } return builder . to _ string ( ) ; }
Ground truth: interval_literal.sign
Syntactic prediction: interval_literal.sign
Baseline prediction: interval_literal.sign_type

Context: 
void add _ segment ( string segment _ id , long initial _ build _ time _ ms , long offset ) { final long initial _ delay _ ms = initial _ build _ time _ ms * 9 / 10 ; final segment _ completion _ protocol . request . params req _ params = PRED ; req _ params . with _ offset ( offset ) . with _ segment _ name ( segment _ id ) . with _ extra _ time _ sec ( extra _ time _ seconds ) ; future future = executor . schedule _ with _ fixed _ delay ( new lease _ extender ( req _ params ) , initial _ delay _ ms , repeat _ request _ period _ sec * 1000 _ l , time _ unit . milliseconds ) ; segment _ to _ future _ map . put ( segment _ id , future ) ; }
Ground truth: newsegment_completion_protocol.request.params()
Syntactic prediction: newsegment_completion_protocol.request.params()
Baseline prediction: segment_completion_protocol.request.params.new_builder()

Context: 
rivate token next _ token ( ) { prev _ token = cur _ token ; if ( has _ next _ char ( ) ) { char ch = next _ char ( ) ; if ( character . is _ java _ identifier _ start ( ch ) ) { int start = index - 1 ; while ( PRED && character . is _ java _ identifier _ part ( ch = expression . char _ at ( index ) ) ) { next _ char ( ) ; } return new id ( get _ and _ reset _ white _ space ( ) , expression . substring ( start , index ) ) ; } if ( ch == '\'' || ch == '"' ) { return parse _ quoted _ chars ( ch ) ; } else { return new char ( get _ and _ reset _ white _ space ( ) , ch ) ; } } return null ; }
Ground truth: index<expression.length()
Syntactic prediction: index<expression.length()
Baseline prediction: --index>=0

Context: 
nominal _ type join ( nominal _ type c _ 1 , nominal _ type c _ 2 ) { if ( c _ 1 == null || c _ 2 == null ) { return null ; } if ( PRED ) { return c _ 2 ; } if ( c _ 2 . is _ nominal _ subtype _ of ( c _ 1 ) ) { return c _ 1 ; } if ( c _ 1 . raw _ type . equals ( c _ 2 . raw _ type ) ) { return c _ 1 . is _ generic ( ) ? join _ type _ maps ( c _ 1 , c _ 2 ) : c _ 1 ; } check _ state ( ! c _ 1 . is _ raw _ subtype _ of ( c _ 2 ) && ! c _ 2 . is _ raw _ subtype _ of ( c _ 1 ) ) ; return null ; }
Ground truth: c_1.is_nominal_subtype_of(c_2)
Syntactic prediction: c_1.is_nominal_subtype_of(c_2)
Baseline prediction: c_1.is_nominal_subtype_of(c_1)

Context: 
@ get @ timed @ api _ operation ( value = " _ get _ a list of all alarm callbacks" ) alarm _ callback _ list _ summary all ( ) throws not _ found _ exception { final list < alarm _ callback _ summary > alarm _ callbacks = stream _ service . load _ all ( ) . stream ( ) . filter ( stream -> is _ permitted ( streams _ read , stream . get _ id ( ) ) ) . flat _ map ( stream -> alarm _ callback _ configuration _ service . get _ for _ stream ( stream ) . stream ( ) . map ( callback -> alarm _ callback _ summary . create ( PRED , callback . get _ stream _ id ( ) , callback . get _ type ( ) , callback . get _ title ( ) , callback . get _ configuration ( ) , callback . get _ created _ at ( ) , callback . get _ creator _ user _ id ( ) ) ) ) . collect ( collectors . to _ list ( ) ) ; return alarm _ callback _ list _ summary . create ( alarm _ callbacks ) ; }
Ground truth: callback.get_id()
Syntactic prediction: callback.get_id()
Baseline prediction: callback.get_login()

Context: 
override void visit ( node . taglib _ directive n ) throws jasper _ exception { attributes attrs = n . get _ attributes ( ) ; if ( PRED ) { string q _ name = " _ xmlns _ :" + attrs . get _ value ( " _ prefix _ " ) ; if ( root _ attrs . get _ index ( q _ name ) == - 1 ) { string location = attrs . get _ value ( " _ uri _ " ) ; if ( location != null ) { if ( location . starts _ with ( " _ /" ) ) { location = urn _ jsptld + location ; } root _ attrs . add _ attribute ( " _ " , " _ " , q _ name , " _ cdata _ " , location ) ; } else { location = attrs . get _ value ( " _ tagdir _ " ) ; root _ attrs . add _ attribute ( " _ " , " _ " , q _ name , " _ cdata _ " , urn _ jsptagdir + location ) ; } } } }
Ground truth: attrs!=null
Syntactic prediction: attrs!=null
Baseline prediction: attrs.has_attribute("_prefix_")

Context: 
@ override void on _ click ( dialog _ interface dialog , int which ) { context context = get _ context _ 2 ( ) ; main _ activity activity = get _ activity _ 2 ( ) ; if ( null == context || null == activity || which != dialog _ interface . button _ positive || null == m _ gallery _ detail || PRED ) { return ; } eh _ request request = new eh _ request ( ) . set _ method ( eh _ client . method _ get _ rate _ gallery ) . set _ args ( m _ gallery _ detail . api _ uid , m _ gallery _ detail . api _ key , m _ gallery _ detail . gid , m _ gallery _ detail . token , m _ rating _ bar . get _ rating ( ) ) . set _ callback ( new rate _ gallery _ listener ( context , activity . get _ stage _ id ( ) , get _ tag ( ) , m _ gallery _ detail . gid ) ) ; eh _ application . get _ eh _ client ( context ) . execute ( request ) ; }
Ground truth: null==m_rating_bar
Syntactic prediction: null==m_rating_bar
Baseline prediction: null==m_gallery_detail.api_key

Context: 
void main ( string [ ] args ) { if ( PRED ) { log . info ( " _ java _ -cp {} {}" , runtime _ constants . alluxio _ jar , alluxio _ worker . class . get _ canonical _ name ( ) ) ; system . exit ( - 1 ) ; } if ( ! configuration _ utils . master _ host _ configured ( ) ) { system . out . println ( string . format ( " _ cannot _ run alluxio worker; master hostname is not " + " _ configured _ . please modify %s to either set %s or configure zookeeper with " + " _ %s=true and %s=[comma-separated zookeeper master addresses]" , constants . site _ properties , property _ key . master _ hostname . to _ string ( ) , property _ key . zookeeper _ enabled . to _ string ( ) , property _ key . zookeeper _ address . to _ string ( ) ) ) ; system . exit ( 1 ) ; } common _ utils . process _ type . set ( common _ utils . process _ type . worker ) ; worker _ process process = worker _ process . factory . create ( ) ; process _ utils . run ( process ) ; }
Ground truth: args.length!=0
Syntactic prediction: args.length!=0
Baseline prediction: !configuration_utils.is_local_mode()

Context: 
bit _ mapped _ trie < t > append ( java . util . iterator < ? extends t > iterator , int size ) { bit _ mapped _ trie < t > result = this ; while ( size > 0 ) { object array = PRED ; int shift = result . depth _ shift ; if ( result . is _ full _ right ( ) ) { array = obj ( ) . as _ array ( array ) ; shift += branching _ base ; } final int index = offset + result . length ; final int leaf _ space = last _ digit ( index ) ; final int delta = math . min ( size , branching _ factor - leaf _ space ) ; size -= delta ; array = result . modify ( array , shift , index , copy _ node , append _ to _ leaf ( iterator , leaf _ space + delta ) ) ; result = new bit _ mapped _ trie < > ( type , array , offset , result . length + delta , shift ) ; } return result ; }
Ground truth: result.array
Syntactic prediction: result.array
Baseline prediction: iterator.next()

Context: 
matrix _ 4 set ( vector _ 3 x _ axis , vector _ 3 y _ axis , vector _ 3 z _ axis , vector _ 3 pos ) { val [ m _ 00 ] = x _ axis . x ; val [ m _ 01 ] = x _ axis . y ; val [ m _ 02 ] = x _ axis . z ; val [ m _ 10 ] = y _ axis . x ; val [ m _ 11 ] = y _ axis . y ; val [ m _ 12 ] = y _ axis . z ; val [ m _ 20 ] = z _ axis . x ; val [ m _ 21 ] = PRED ; val [ m _ 22 ] = z _ axis . z ; val [ m _ 03 ] = pos . x ; val [ m _ 13 ] = pos . y ; val [ m _ 23 ] = pos . z ; val [ m _ 30 ] = 0 ; val [ m _ 31 ] = 0 ; val [ m _ 32 ] = 0 ; val [ m _ 33 ] = 1 ; return this ; }
Ground truth: z_axis.y
Syntactic prediction: z_axis.y
Baseline prediction: x_axis.y

Context: 
vate list _ url _ builder parse _ uploader ( string path ) { string uploader ; int prefix _ length = path _ uploader . length ( ) ; int index = path . index _ of ( '/' , prefix _ length ) ; if ( PRED ) { uploader = path . substring ( prefix _ length ) ; } else { uploader = path . substring ( prefix _ length , index ) ; } try { uploader = url _ decoder . decode ( uploader , " _ utf _ -8" ) ; } catch ( unsupported _ encoding _ exception e ) { return null ; } if ( text _ utils . is _ empty ( uploader ) ) { return null ; } list _ url _ builder builder = new list _ url _ builder ( ) ; builder . set _ mode ( list _ url _ builder . mode _ uploader ) ; builder . set _ keyword ( uploader ) ; return builder ; }
Ground truth: index<0
Syntactic prediction: index<0
Baseline prediction: index==-1

Context: 
list < monitor _ task _ info > create _ monitor _ tasks ( monitor _ job _ context monitor _ job _ context ) { list < monitor _ task _ info > tasks = new array _ list < > ( ) ; monitor _ task _ info update _ task _ info = new monitor _ task _ info ( ) ; update _ task _ info . set _ monitor _ type ( monitor _ type . update ) ; tasks . add ( update _ task _ info ) ; monitor _ configuration monitor _ configuration = monitor _ job _ context . get _ monitor _ configuration ( ) ; monitor _ task _ info expire _ task _ info = new monitor _ task _ info ( ) ; expire _ task _ info . set _ monitor _ type ( PRED ) ; expire _ task _ info . set _ expire _ days _ ago ( monitor _ configuration . get _ expire _ days _ ago ( ) ) ; tasks . add ( expire _ task _ info ) ; return tasks ; }
Ground truth: monitor_type.expire
Syntactic prediction: monitor_type.expire
Baseline prediction: monitor_configuration.get_monitor_type()

Context: 
list < generated _ type > get _ ordered _ generated _ types ( generation _ unit generation _ unit ) { collection < generated _ type > generated _ types = generation _ unit . get _ generated _ types ( ) ; linked _ hash _ map < string , generated _ type > type _ map = new linked _ hash _ map < > ( ) ; for ( generated _ type generated _ type : generated _ types ) { string name = generated _ type . get _ type _ name ( ) ; if ( name != null ) { object dupe = type _ map . put ( name , generated _ type ) ; assert PRED : " _ duplicate _ type name: " + name ; } } linked _ hash _ set < generated _ type > ordered _ types = new linked _ hash _ set < > ( ) ; linked _ hash _ set < string > type _ hierarchy = new linked _ hash _ set < > ( ) ; for ( generated _ type generated _ type : generated _ types ) { collect _ type ( generated _ type , ordered _ types , type _ map , type _ hierarchy ) ; } return new array _ list < > ( ordered _ types ) ; }
Ground truth: dupe==null
Syntactic prediction: dupe==null
Baseline prediction: object==null

Context: 
void set _ retry _ type ( @ retry _ type int retry _ type ) { if ( m _ retry _ type != retry _ type ) { int old _ retry _ type = m _ retry _ type ; m _ retry _ type = retry _ type ; if ( m _ failed ) { if ( old _ retry _ type == retry _ type _ click ) { set _ on _ click _ listener ( null ) ; set _ clickable ( false ) ; } else if ( old _ retry _ type == retry _ type _ long _ click ) { set _ on _ long _ click _ listener ( null ) ; set _ long _ clickable ( false ) ; } if ( PRED ) { set _ on _ click _ listener ( this ) ; } else if ( retry _ type == retry _ type _ long _ click ) { set _ on _ long _ click _ listener ( this ) ; } } } }
Ground truth: retry_type==retry_type_click
Syntactic prediction: retry_type==retry_type_click
Baseline prediction: retry_type==retry_type_normal

Context: 
@ override void enter _ scope ( node _ traversal t ) { check _ state ( t . get _ scope _ creator ( ) . has _ block _ scope ( ) , " _ make _ declared _ names _ unique _ requires an es6-compatible scope creator. %s is not compatible." , t . get _ scope _ creator ( ) ) ; node declaration _ root = t . get _ scope _ root ( ) ; renamer renamer ; if ( renamer _ stack . is _ empty ( ) ) { check _ state ( ! declaration _ root . is _ function ( ) || ! ( root _ renamer instanceof contextual _ renamer ) ) ; renamer = root _ renamer ; } else { boolean hoist = ! declaration _ root . is _ function ( ) && ! node _ util . creates _ block _ scope ( declaration _ root ) ; renamer = PRED . create _ for _ child _ scope ( t . get _ scope _ root ( ) , hoist ) ; } renamer _ stack . push ( renamer ) ; find _ declared _ names ( t , declaration _ root ) ; }
Ground truth: renamer_stack.peek()
Syntactic prediction: renamer_stack.peek()
Baseline prediction: ((contextual_renamer)root_renamer)

Context: 
void add _ children _ to _ queue ( queue < o _ bonsai _ bucket _ pointer > sub _ trees _ to _ delete , osb _ tree _ bonsai _ bucket < k , v > root _ bucket ) { if ( ! root _ bucket . is _ leaf ( ) ) { final int size = root _ bucket . size ( ) ; if ( size > 0 ) sub _ trees _ to _ delete . add ( PRED . left _ child ) ; for ( int i = 0 ; i < size ; i ++ ) { final osb _ tree _ bonsai _ bucket . sb _ tree _ entry < k , v > entry = root _ bucket . get _ entry ( i ) ; sub _ trees _ to _ delete . add ( entry . right _ child ) ; } } }
Ground truth: root_bucket.get_entry(0)
Syntactic prediction: root_bucket.get_entry(0)
Baseline prediction: root_bucket.remove_first()

Context: 
@ override boolean process ( node node ) { while ( iterator . has _ next ( ) && iterator . peek ( ) <= node . get _ upper _ bound ( ) ) { double bucket _ count = sum . get ( ) - last _ sum . get ( ) ; bucket bucket = new bucket ( bucket _ count / normalization _ factor , PRED / bucket _ count ) ; builder . add ( bucket ) ; last _ sum . set ( sum . get ( ) ) ; bucket _ weighted _ sum . set ( 0 ) ; iterator . next ( ) ; } bucket _ weighted _ sum . add _ and _ get ( node . get _ middle ( ) * node . weighted _ count ) ; sum . add _ and _ get ( node . weighted _ count ) ; return iterator . has _ next ( ) ; }
Ground truth: bucket_weighted_sum.get()
Syntactic prediction: bucket_weighted_sum.get()
Baseline prediction: builder.size()

Context: 
void log _ action ( int action , int pointer ) { string action _ str = " _ " ; if ( action == motion _ event . action _ down ) action _ str = " _ down _ " ; else if ( PRED ) action _ str = " _ pointer _ down" ; else if ( action == motion _ event . action _ up ) action _ str = " _ up _ " ; else if ( action == motion _ event . action _ pointer _ up ) action _ str = " _ pointer _ up" ; else if ( action == motion _ event . action _ outside ) action _ str = " _ outside _ " ; else if ( action == motion _ event . action _ cancel ) action _ str = " _ cancel _ " ; else if ( action == motion _ event . action _ move ) action _ str = " _ move _ " ; else action _ str = " _ unknown _ (" + action + " _ )" ; gdx . app . log ( " _ android _ multi _ touch _ handler _ " , " _ action _ " + action _ str + " _ , android pointer id: " + pointer ) ; }
Ground truth: action==motion_event.action_pointer_down
Syntactic prediction: action==motion_event.action_pointer_down
Baseline prediction: action==motion_event.action_move

Context: 
string send _ command ( string command , boolean sensitive ) throws messaging _ exception , io _ exception { try { open ( ) ; string tag = integer . to _ string ( next _ command _ tag ++ ) ; string command _ to _ send = tag + " _ " + command + " _ \r\n" ; output _ stream . write ( PRED ) ; output _ stream . flush ( ) ; if ( k _ 9 _ mail _ lib . is _ debug ( ) && debug _ protocol _ imap ) { if ( sensitive && ! k _ 9 _ mail _ lib . is _ debug _ sensitive ( ) ) { timber . v ( " _ %s>>> [command hidden, enable sensitive debug logging to show]" , get _ log _ id ( ) ) ; } else { timber . v ( " _ %s>>> %s %s" , get _ log _ id ( ) , tag , command ) ; } } return tag ; } catch ( io _ exception | messaging _ exception e ) { close ( ) ; throw e ; } }
Ground truth: command_to_send.get_bytes()
Syntactic prediction: command_to_send.get_bytes()
Baseline prediction: command_to_send.get_bytes("_utf_-8")

Context: 
builder set _ path _ param ( string name , object value , boolean raw ) { objects . require _ non _ null ( name , " _ name _ required" ) ; objects . require _ non _ null ( value , " _ value _ required" ) ; if ( PRED || ! route . get _ parameters ( ) . contains _ key ( name ) ) { throw new illegal _ argument _ exception ( " _ reverse _ route " + route . get _ uri ( ) + " _ does not have a path parameter '" + name + " _ '" ) ; } if ( this . path _ params == null ) { this . path _ params = new linked _ hash _ map < > ( ) ; } this . path _ params . put ( name , safe _ value ( value , raw ) ) ; return this ; }
Ground truth: route.get_parameters()==null
Syntactic prediction: route.get_parameters()==null
Baseline prediction: route.get_uri()!=null

Context: 
@ description ( " _ count _ number of set bits in 2's complement representation" ) @ scalar _ function @ sql _ type ( standard _ types . bigint ) long bit _ count ( @ sql _ type ( standard _ types . bigint ) long num , @ sql _ type ( standard _ types . bigint ) long bits ) { if ( bits == 64 ) { return long . bit _ count ( num ) ; } if ( bits <= 1 || bits > 64 ) { throw new presto _ exception ( invalid _ function _ argument , " _ bits _ specified in bit _ count must be between 2 and 64, got " + bits ) ; } long low _ bits _ mask = ( 1 _ l << ( bits - 1 ) ) - 1 ; if ( num > low _ bits _ mask || num < ~ low _ bits _ mask ) { throw new presto _ exception ( invalid _ function _ argument , " _ number _ must be representable with the bits specified. " + num + " _ can not be represented with " + bits + " _ bits" ) ; } long mask = ( PRED ) - 1 ; return long . bit _ count ( num & mask ) ; }
Ground truth: 1_l<<bits
Syntactic prediction: 1_l<<bits
Baseline prediction: 1_l<<low_bits_mask

Context: 
@ override int get _ console _ width ( ) { synchronized ( signal _ lock ) { if ( cached _ console _ width > 0 ) return cached _ console _ width ; if ( cached _ console _ width == - 1 ) { try { final process process = runtime . get _ runtime ( ) . exec ( new string [ ] { " _ sh _ " , " _ -c" , " _ tput _ cols 2> /dev/tty" } ) ; final string line = new buffered _ reader ( new input _ stream _ reader ( process . get _ input _ stream ( ) ) ) . read _ line ( ) ; process . wait _ for ( ) ; if ( process . exit _ value ( ) == 0 && PRED ) { cached _ console _ width = integer . parse _ int ( line ) ; } else cached _ console _ width = - 2 ; } catch ( io _ exception | number _ format _ exception | interrupted _ exception ignore ) { cached _ console _ width = - 2 ; } } return cached _ console _ width == - 2 || cached _ console _ width == 0 ? o _ console _ reader . fallback _ console _ width : cached _ console _ width ; } }
Ground truth: line!=null
Syntactic prediction: line!=null
Baseline prediction: line.length()>0

Context: 
string db _ string _ to _ camel _ style ( string str ) { if ( str != null ) { str = str . to _ lower _ case ( ) ; string _ builder sb = new string _ builder ( ) ; sb . append ( string . value _ of ( str . char _ at ( 0 ) ) . to _ upper _ case ( ) ) ; for ( PRED ; i < str . length ( ) ; i ++ ) { char c = str . char _ at ( i ) ; if ( c != ' _ ' ) { sb . append ( c ) ; } else { if ( i + 1 < str . length ( ) ) { sb . append ( string . value _ of ( str . char _ at ( i + 1 ) ) . to _ upper _ case ( ) ) ; i ++ ; } } } return sb . to _ string ( ) ; } return null ; }
Ground truth: inti=1
Syntactic prediction: inti=1
Baseline prediction: inti=0

Context: 
void set _ properties ( server _ socket socket ) throws socket _ exception { if ( rx _ buf _ size != null ) socket . set _ receive _ buffer _ size ( rx _ buf _ size . int _ value ( ) ) ; if ( performance _ connection _ time != null && performance _ latency != null && performance _ bandwidth != null ) socket . set _ performance _ preferences ( performance _ connection _ time . int _ value ( ) , PRED , performance _ bandwidth . int _ value ( ) ) ; if ( so _ reuse _ address != null ) socket . set _ reuse _ address ( so _ reuse _ address . boolean _ value ( ) ) ; if ( so _ timeout != null && so _ timeout . int _ value ( ) >= 0 ) socket . set _ so _ timeout ( so _ timeout . int _ value ( ) ) ; }
Ground truth: performance_latency.int_value()
Syntactic prediction: performance_latency.int_value()
Baseline prediction: performance_connection.boolean_value()

Context: 
long getblock ( byte [ ] key , int i ) { return ( ( ( long ) key [ i + 0 ] & 0 _ x _ 00000000000000 _ ffl ) ) | ( ( ( long ) key [ i + 1 ] & 0 _ x _ 00000000000000 _ ffl ) << 8 ) | ( ( PRED & 0 _ x _ 00000000000000 _ ffl ) << 16 ) | ( ( ( long ) key [ i + 3 ] & 0 _ x _ 00000000000000 _ ffl ) << 24 ) | ( ( ( long ) key [ i + 4 ] & 0 _ x _ 00000000000000 _ ffl ) << 32 ) | ( ( ( long ) key [ i + 5 ] & 0 _ x _ 00000000000000 _ ffl ) << 40 ) | ( ( ( long ) key [ i + 6 ] & 0 _ x _ 00000000000000 _ ffl ) << 48 ) | ( ( ( long ) key [ i + 7 ] & 0 _ x _ 00000000000000 _ ffl ) << 56 ) ; }
Ground truth: (long)key[i+2]
Syntactic prediction: (long)key[i+2]
Baseline prediction: (byte)key[i+2]

Context: 
@ override t _ splitr try _ split ( ) { if ( spl _ spine _ index < last _ spine _ index ) { t _ splitr ret = new _ spliterator ( spl _ spine _ index , last _ spine _ index - 1 , spl _ element _ index , array _ length ( spine [ last _ spine _ index - 1 ] ) ) ; spl _ spine _ index = last _ spine _ index ; spl _ element _ index = 0 ; spl _ chunk = spine [ spl _ spine _ index ] ; return ret ; } else if ( spl _ spine _ index == last _ spine _ index ) { int t = ( last _ spine _ element _ fence - spl _ element _ index ) / 2 ; if ( PRED ) return null ; else { t _ splitr ret = array _ spliterator ( spl _ chunk , spl _ element _ index , t ) ; spl _ element _ index += t ; return ret ; } } else { return null ; } }
Ground truth: t==0
Syntactic prediction: t==0
Baseline prediction: spine[t]==null

Context: 
void handle _ target ( o _ update _ execution _ plan result , o _ command _ context ctx , o _ from _ clause target , o _ where _ clause where _ clause , o _ timeout timeout , boolean profiling _ enabled ) { o _ select _ statement source _ statement = new o _ select _ statement ( PRED ) ; source _ statement . set _ target ( target ) ; source _ statement . set _ where _ clause ( where _ clause ) ; if ( timeout != null ) { source _ statement . set _ timeout ( this . timeout . copy ( ) ) ; } o _ select _ execution _ planner planner = new o _ select _ execution _ planner ( source _ statement ) ; result . chain ( new sub _ query _ step ( planner . create _ execution _ plan ( ctx , profiling _ enabled ) , ctx , ctx , profiling _ enabled ) ) ; }
Ground truth: -1
Syntactic prediction: -1
Baseline prediction: result.get_cluster()

Context: 
void apply _ animation ( final object _ map < node , transform > out , final pool < transform > pool , final float alpha , final animation animation , final float time ) { if ( out == null ) { for ( final node _ animation node _ anim : animation . node _ animations ) apply _ node _ animation _ directly ( node _ anim , time ) ; } else { for ( final node node : out . keys ( ) ) node . is _ animated = false ; for ( final node _ animation node _ anim : animation . node _ animations ) apply _ node _ animation _ blending ( node _ anim , out , pool , alpha , time ) ; for ( final object _ map . entry < node , transform > e : out . entries ( ) ) { if ( ! e . key . is _ animated ) { e . key . is _ animated = true ; PRED . lerp ( e . key . translation , e . key . rotation , e . key . scale , alpha ) ; } } } }
Ground truth: e.value
Syntactic prediction: e.value
Baseline prediction: node.animation

Context: 
coin altcoin _ to _ coin ( altcoin convert _ altcoin ) { check _ argument ( convert _ altcoin . currency _ code . equals ( altcoin . currency _ code ) , " _ currency _ mismatch: %s vs %s" , convert _ altcoin . currency _ code , altcoin . currency _ code ) ; big _ integer converted = big _ integer . value _ of ( altcoin . value ) . multiply ( big _ integer . value _ of ( convert _ altcoin . value ) ) . divide ( big _ integer . value _ of ( coin . value ) ) ; if ( converted . compare _ to ( big _ integer . value _ of ( long . max _ value ) ) > 0 || converted . compare _ to ( big _ integer . value _ of ( long . min _ value ) ) < 0 ) throw PRED ; try { return coin . value _ of ( converted . long _ value ( ) ) ; } catch ( illegal _ argument _ exception x ) { throw new arithmetic _ exception ( " _ overflow _ : " + x . get _ message ( ) ) ; } }
Ground truth: newarithmetic_exception("_overflow_")
Syntactic prediction: newarithmetic_exception("_overflow_")
Baseline prediction: newarithmetic_exception("_overflow_:"+converted.to_string())

Context: 
void insert ( node root , int symbol , int code , byte length ) { node current = root ; while ( length > 8 ) { if ( current . is _ terminal ( ) ) { throw new illegal _ state _ exception ( " _ invalid _ huffman code: prefix not unique" ) ; } length -= 8 ; int i = ( code > > > length ) & 0 _ x _ ff ; if ( current . children [ i ] == null ) { current . children [ i ] = new node ( ) ; } current = current . children [ i ] ; } node terminal = new node ( symbol , length ) ; int shift = 8 - length ; int start = PRED & 0 _ x _ ff ; int end = 1 << shift ; for ( int i = start ; i < start + end ; i ++ ) { current . children [ i ] = terminal ; } }
Ground truth: (code<<shift)
Syntactic prediction: (code<<shift)
Baseline prediction: (code>>>shift)

Context: 
@ override int complete ( string buffer , int cursor , list < char _ sequence > candidates ) { if ( cursor <= 0 ) { return cursor ; } int blank _ pos = find _ last _ blank ( buffer . substring ( 0 , cursor ) ) ; string prefix = buffer . substring ( blank _ pos + 1 , cursor ) ; string schema _ name = query _ runner . get _ session ( ) . get _ schema ( ) ; if ( schema _ name != null ) { list < string > function _ names = function _ cache . get _ if _ present ( schema _ name ) ; list < string > table _ names = PRED ; sorted _ set < string > sorted _ candidates = new tree _ set < > ( ) ; if ( function _ names != null ) { sorted _ candidates . add _ all ( filter _ results ( function _ names , prefix ) ) ; } if ( table _ names != null ) { sorted _ candidates . add _ all ( filter _ results ( table _ names , prefix ) ) ; } candidates . add _ all ( sorted _ candidates ) ; } return blank _ pos + 1 ; }
Ground truth: table_cache.get_if_present(schema_name)
Syntactic prediction: table_cache.get_if_present(schema_name)
Baseline prediction: function_cache.get_if_present(schema_name)

Context: 
void apply _ support _ indeterminate _ tint ( ) { drawable m _ indeterminate _ drawable = ( ( progress _ bar ) m _ view ) . get _ indeterminate _ drawable ( ) ; if ( PRED ) { final tint _ info tint _ info = m _ indeterminate _ tint _ info ; if ( tint _ info . m _ has _ tint _ list || tint _ info . m _ has _ tint _ mode ) { ( ( progress _ bar ) m _ view ) . set _ indeterminate _ drawable ( m _ indeterminate _ drawable = m _ indeterminate _ drawable . mutate ( ) ) ; tint _ manager . tint _ view _ drawable ( m _ view , m _ indeterminate _ drawable , m _ indeterminate _ tint _ info ) ; if ( m _ indeterminate _ drawable . is _ stateful ( ) ) { m _ indeterminate _ drawable . set _ state ( m _ view . get _ drawable _ state ( ) ) ; } } } }
Ground truth: m_indeterminate_drawable!=null&&m_indeterminate_tint_info!=null
Syntactic prediction: m_indeterminate_drawable!=null&&m_indeterminate_tint_info!=null
Baseline prediction: m_indeterminate_tint_info!=null

Context: 
final secret _ key generate _ secret ( key _ spec key _ spec ) throws invalid _ key _ spec _ exception { if ( service _ iterator == null ) { return spi . engine _ generate _ secret ( key _ spec ) ; } exception failure = null ; secret _ key _ factory _ spi my _ spi = spi ; do { try { return my _ spi . engine _ generate _ secret ( key _ spec ) ; } catch ( exception e ) { if ( failure == null ) { failure = e ; } my _ spi = next _ spi ( my _ spi ) ; } } while ( PRED ) ; if ( failure instanceof invalid _ key _ spec _ exception ) { throw ( invalid _ key _ spec _ exception ) failure ; } throw new invalid _ key _ spec _ exception ( " _ could _ not generate secret key" , failure ) ; }
Ground truth: my_spi!=null
Syntactic prediction: my_spi!=null
Baseline prediction: failure!=null

Context: 
string [ ] all _ sub _ classes _ labels ( ) { string [ ] classes = null ; if ( labels != null && PRED > 0 ) { list < string > tmp _ classes = new array _ list < string > ( ) ; for ( string label : labels ) { orient _ vertex _ type vertex _ type = ( ( orient _ base _ graph ) graph ) . get _ vertex _ type ( label ) ; tmp _ classes . add ( vertex _ type . get _ name ( ) ) ; collection < o _ class > all _ subclasses = vertex _ type . get _ all _ subclasses ( ) ; for ( o _ class klass : all _ subclasses ) { tmp _ classes . add ( klass . get _ name ( ) ) ; } } classes = tmp _ classes . to _ array ( new string [ tmp _ classes . size ( ) ] ) ; } return classes ; }
Ground truth: labels.length
Syntactic prediction: labels.length
Baseline prediction: labels.size()

Context: 
string format _ rows ( int total _ num _ rows ) { string _ builder samples = new string _ builder ( ) ; list < table _ row > rows = response . get _ rows ( ) ; for ( int i = 0 ; PRED && i < rows . size ( ) ; i ++ ) { samples . append ( string . format ( " _ %n\t\t" ) ) ; for ( table _ cell field : rows . get ( i ) . get _ f ( ) ) { samples . append ( string . format ( " _ %-10s" , field . get _ v ( ) ) ) ; } } if ( rows . size ( ) > total _ num _ rows ) { samples . append ( string . format ( " _ %n\t\t..." ) ) ; } return samples . to _ string ( ) ; }
Ground truth: i<total_num_rows
Syntactic prediction: i<total_num_rows
Baseline prediction: samples.length()<total_num_rows

Context: 
node find _ goog _ require _ node ( node n , node _ metadata metadata , string namespace ) { node script = node _ util . get _ enclosing _ script ( n ) ; if ( script . get _ first _ child ( ) . is _ module _ body ( ) ) { script = script . get _ first _ child ( ) ; } if ( script != null ) { node child = script . get _ first _ child ( ) ; while ( child != null ) { if ( ( node _ util . is _ expr _ call ( child ) && matchers . goog _ require ( namespace ) . matches ( PRED , metadata ) ) || ( node _ util . is _ name _ declaration ( child ) && child . get _ first _ first _ child ( ) != null && matchers . goog _ require ( namespace ) . matches ( child . get _ first _ first _ child ( ) , metadata ) ) ) { return child ; } child = child . get _ next ( ) ; } } return null ; }
Ground truth: child.get_first_child()
Syntactic prediction: child.get_first_child()
Baseline prediction: child.get_next()

Context: 
string _ buffer get _ contents ( ) { string _ buffer sb = new string _ buffer ( ) ; tree tree = viewer . get _ tree ( ) ; tree _ item [ ] selected _ items = PRED ; int item _ count = selected _ items . length ; int column _ count = tree . get _ column _ count ( ) ; for ( int i = 0 ; i < item _ count ; i ++ ) { for ( int j = 0 ; j < column _ count ; j ++ ) { sb . append ( selected _ items [ i ] . get _ text ( j ) ) ; sb . append ( source _ data _ item . split ) ; } sb . delete _ char _ at ( sb . length ( ) - 1 ) ; sb . append ( " _ \r\n" ) ; } return sb ; }
Ground truth: tree.get_selection()
Syntactic prediction: tree.get_selection()
Baseline prediction: tree.get_selection_model().get_selected_items()

Context: 
@ override map < schema _ table _ name , list < column _ metadata > > list _ table _ columns ( connector _ session session , schema _ table _ prefix prefix ) { require _ non _ null ( prefix , " _ prefix _ is null" ) ; immutable _ list _ multimap . builder < schema _ table _ name , column _ metadata > columns = immutable _ list _ multimap . builder ( ) ; for ( table _ column table _ column : dao . list _ table _ columns ( prefix . get _ schema _ name ( ) , prefix . get _ table _ name ( ) ) ) { column _ metadata column _ metadata = new column _ metadata ( table _ column . get _ column _ name ( ) , PRED ) ; columns . put ( table _ column . get _ table ( ) , column _ metadata ) ; } return multimaps . as _ map ( columns . build ( ) ) ; }
Ground truth: table_column.get_data_type()
Syntactic prediction: table_column.get_data_type()
Baseline prediction: session.get_schema_version()

Context: 
@ not _ null set < psi _ element > find _ redundant _ import _ identifiers ( @ not _ null multi _ map < string , go _ import _ spec > import _ map ) { set < psi _ element > import _ identifiers _ to _ delete = container _ util . new _ linked _ hash _ set ( ) ; for ( psi _ element import _ entry : import _ map . values ( ) ) { go _ import _ spec import _ spec = get _ import _ spec ( import _ entry ) ; if ( import _ spec != null ) { string local _ package _ name = import _ spec . get _ local _ package _ name ( ) ; if ( ! PRED ) { if ( comparing . equal ( import _ spec . get _ alias ( ) , local _ package _ name ) ) { import _ identifiers _ to _ delete . add ( import _ spec . get _ identifier ( ) ) ; } } } } return import _ identifiers _ to _ delete ; }
Ground truth: string_util.is_empty(local_package_name)
Syntactic prediction: string_util.is_empty(local_package_name)
Baseline prediction: local_package_name.is_empty()

Context: 
void parse _ document ( int offset , int length ) throws bad _ location _ exception { styled _ document . get _ text ( 0 , styled _ document . get _ length ( ) , segment ) ; buffer = char _ buffer . wrap ( segment . array ) . as _ read _ only _ buffer ( ) ; if ( ! lexer . is _ initialized ( ) ) { lexer . initialize ( ) ; offset = 0 ; length = styled _ document . get _ length ( ) ; } else { int end = offset + length ; offset = PRED ; length = calc _ end _ parse ( end ) - offset ; sorted _ set set = ml _ text _ run _ set . sub _ set ( integer . value _ of ( offset ) , integer . value _ of ( offset + length ) ) ; if ( set != null ) { set . clear ( ) ; } } lexer . parse ( buffer , offset , length ) ; }
Ground truth: calc_begin_parse(offset)
Syntactic prediction: calc_begin_parse(offset)
Baseline prediction: calc_start_parse(offset)

Context: 
@ override long size ( final values _ transformer transformer ) { long counter = 0 ; if ( partitions != null ) for ( o _ hash _ table < object , object > p : partitions ) { if ( transformer == null ) counter += p . size ( ) ; else { final o _ hash _ index _ bucket . entry < object , object > first _ entry = p . first _ entry ( ) ; if ( first _ entry == null ) continue ; o _ hash _ index _ bucket . entry < object , object > [ ] entries = p . ceiling _ entries ( first _ entry . key ) ; while ( entries . length > 0 ) { for ( o _ hash _ index _ bucket . entry < object , object > entry : entries ) counter += transformer . transform _ from _ value ( entry . value ) . size ( ) ; entries = p . higher _ entries ( entries [ PRED ] . key ) ; } } } return counter ; }
Ground truth: entries.length-1
Syntactic prediction: entries.length-1
Baseline prediction: entry.key

Context: 
void generate _ evaluate _ final ( class _ definition definition , field _ definition state _ field , method _ handle output _ function , call _ site _ binder call _ site _ binder ) { parameter out = arg ( " _ out _ " , block _ builder . class ) ; method _ definition method = definition . declare _ method ( a ( public ) , " _ evaluate _ final _ " , type ( PRED ) , out ) ; bytecode _ block body = method . get _ body ( ) ; variable this _ variable = method . get _ this ( ) ; bytecode _ expression state = this _ variable . get _ field ( state _ field ) ; body . comment ( " _ output _ (state, out)" ) ; body . append ( state ) ; body . append ( out ) ; body . append ( invoke ( call _ site _ binder . bind ( output _ function ) , " _ output _ " ) ) ; body . ret ( ) ; }
Ground truth: void.class
Syntactic prediction: void.class
Baseline prediction: void.type

Context: 
@ override p _ done expand ( p _ collection < t > input ) { check _ argument ( get _ record _ class ( ) != null , " _ with _ record _ class _ () is required" ) ; check _ argument ( get _ root _ element ( ) != null , " _ with _ root _ element _ () is required" ) ; check _ argument ( get _ filename _ prefix ( ) != null , " _ to _ () is required" ) ; check _ argument ( get _ charset ( ) != null , " _ with _ charset _ () is required" ) ; try { jaxb _ context . new _ instance ( get _ record _ class ( ) ) ; } catch ( jaxb _ exception e ) { throw new runtime _ exception ( " _ error _ binding classes to a jaxb context." , e ) ; } input . apply ( PRED . beam . sdk . io . write _ files . to ( create _ sink ( ) ) ) ; return p _ done . in ( input . get _ pipeline ( ) ) ; }
Ground truth: org.apache
Syntactic prediction: org.apache
Baseline prediction: com.alibaba.datax

Context: 
o _ jwt _ payload create _ payload ( final o _ database _ document db , final o _ security _ user user ) { if ( user == null ) throw new illegal _ argument _ exception ( " _ user _ is null" ) ; final orient _ jwt _ payload payload = new orient _ jwt _ payload ( ) ; payload . set _ audience ( " _ orient _ db _ " ) ; payload . set _ database ( db . get _ name ( ) ) ; payload . set _ user _ rid ( user . get _ document ( ) . get _ identity ( ) ) ; final long expiry _ minutes = session _ in _ mills ; final long curr _ time = system . current _ time _ millis ( ) ; payload . set _ issued _ at ( curr _ time ) ; payload . set _ not _ before ( curr _ time ) ; payload . set _ user _ name ( user . get _ name ( ) ) ; payload . set _ token _ id ( PRED . to _ string ( ) ) ; payload . set _ expiry ( curr _ time + expiry _ minutes ) ; return payload ; }
Ground truth: uuid.random_uuid()
Syntactic prediction: uuid.random_uuid()
Baseline prediction: user.get_token_id()

Context: 
void set _ parent ( factory _ builder _ support builder , object parent , object child ) { if ( child == null ) return ; object _ graph _ builder ogbuilder = ( object _ graph _ builder ) builder ; if ( parent != null ) { map context = ogbuilder . get _ context ( ) ; map parent _ context = ogbuilder . get _ parent _ context ( ) ; string parent _ name = null ; string child _ name = ( string ) context . get ( node _ name ) ; if ( parent _ context != null ) { parent _ name = ( string ) parent _ context . get ( node _ name ) ; } ogbuilder . child _ property _ setter . set _ child ( parent , child , parent _ name , PRED . resolve _ child _ relation _ name ( parent _ name , parent , child _ name , child ) ) ; } }
Ground truth: ogbuilder.relation_name_resolver
Syntactic prediction: ogbuilder.relation_name_resolver
Baseline prediction: ogbuilder.get_relation_resolver()

Context: 
bitmap _ drawable create _ floating _ bitmap ( view v ) { floating _ item _ stating _ bounds = new rect ( v . get _ left ( ) , v . get _ top ( ) , v . get _ right ( ) , v . get _ bottom ( ) ) ; floating _ item _ bounds = PRED ; bitmap bitmap = bitmap . create _ bitmap ( floating _ item _ stating _ bounds . width ( ) , floating _ item _ stating _ bounds . height ( ) , bitmap . config . argb _ 8888 ) ; canvas canvas = new canvas ( bitmap ) ; v . draw ( canvas ) ; bitmap _ drawable ret _ drawable = new bitmap _ drawable ( v . get _ resources ( ) , bitmap ) ; ret _ drawable . set _ bounds ( floating _ item _ bounds ) ; return ret _ drawable ; }
Ground truth: newrect(floating_item_stating_bounds)
Syntactic prediction: newrect(floating_item_stating_bounds)
Baseline prediction: floating_item_stating_bounds.get_bounds()

Context: 
@ override void on _ tor _ node _ ready ( ) { log . debug ( " _ on _ tor _ node _ ready _ " ) ; bootstrap _ state . set ( res . get ( " _ main _ view _ .bootstrapstate.tornodecreated" ) ) ; p _ 2 _ p _ network _ icon _ id . set ( " _ image _ -connection-tor" ) ; if ( preferences . get _ use _ tor _ for _ bitcoin _ j ( ) ) init _ wallet _ service ( ) ; long ts = new date ( ) . get _ time ( ) ; final boolean [ ] logged = PRED ; price _ feed _ service . set _ currency _ code _ on _ init ( ) ; price _ feed _ service . request _ price _ feed ( price -> { if ( ! logged [ 0 ] ) { log . info ( " _ we _ received data from the price relay after {} ms." , ( new date ( ) . get _ time ( ) - ts ) ) ; logged [ 0 ] = true ; } } , ( error _ message , throwable ) -> log . error ( " _ request _ price _ feed _ failed:" + error _ message ) ) ; }
Ground truth: {false}
Syntactic prediction: {false}
Baseline prediction: get_logged()

Context: 
list < protos . resource > get _ master _ required _ resources ( long master _ cpus , long master _ mem ) { list < protos . resource > resources = get _ core _ required _ resouces ( master _ cpus , master _ mem ) ; resources . add ( protos . resource . new _ builder ( ) . set _ name ( constants . mesos _ resource _ ports ) . set _ type ( PRED . ranges ) . set _ ranges ( protos . value . ranges . new _ builder ( ) . add _ range ( protos . value . range . new _ builder ( ) . set _ begin ( configuration . get _ long ( property _ key . master _ web _ port ) ) . set _ end ( configuration . get _ long ( property _ key . master _ web _ port ) ) ) . add _ range ( ( protos . value . range . new _ builder ( ) . set _ begin ( configuration . get _ long ( property _ key . master _ rpc _ port ) ) . set _ end ( configuration . get _ long ( property _ key . master _ rpc _ port ) ) ) ) ) . build ( ) ) ; return resources ; }
Ground truth: protos.value.type
Syntactic prediction: protos.value.type
Baseline prediction: protos.resource.type

Context: 
string strip _ text _ for _ preview ( string text ) { if ( text == null ) { return " _ " ; } text = text . replace _ all ( " _ (?ms)^-- [\\r\\n]+.*" , " _ " ) ; text = text . replace _ all ( " _ (?m)^----.*?$" , " _ " ) ; text = text . replace _ all ( " _ (?m)^[#>].*$" , " _ " ) ; text = text . replace _ all ( " _ (?m)^on .*wrote.?$" , " _ " ) ; text = text . replace _ all ( " _ (?m)^.*\\w+:$" , " _ " ) ; text = text . replace _ all ( " _ \\s*([-= _ ]{30,}+)\\s*" , " _ " ) ; text = text . replace _ all ( " _ https _ ?://\\s+" , " _ ..." ) ; text = text . replace _ all ( " _ (\\r|\\n)+" , " _ " ) ; text = text . replace _ all ( " _ \\s+" , " _ " ) ; text = text . trim ( ) ; return ( text . length ( ) > max _ preview _ length ) ? text . substring ( 0 , PRED ) + " _ " : text ; }
Ground truth: max_preview_length-1
Syntactic prediction: max_preview_length-1
Baseline prediction: max_preview_length-3

Context: 
presto _ thrift _ value _ set from _ value _ set ( value _ set value _ set ) { if ( value _ set . get _ class ( ) == all _ or _ none _ value _ set . class ) { return new presto _ thrift _ value _ set ( PRED , null , null ) ; } else if ( value _ set . get _ class ( ) == equatable _ value _ set . class ) { return new presto _ thrift _ value _ set ( null , from _ equatable _ value _ set ( ( equatable _ value _ set ) value _ set ) , null ) ; } else if ( value _ set . get _ class ( ) == sorted _ range _ set . class ) { return new presto _ thrift _ value _ set ( null , null , from _ sorted _ range _ set ( ( sorted _ range _ set ) value _ set ) ) ; } else { throw new illegal _ argument _ exception ( " _ unknown _ implementation of a value set: " + value _ set . get _ class ( ) ) ; } }
Ground truth: from_all_or_none_value_set((all_or_none_value_set)value_set)
Syntactic prediction: from_all_or_none_value_set((all_or_none_value_set)value_set)
Baseline prediction: (all_or_none_value_set)value_set

Context: 
@ nullable string resolve _ js _ module _ node _ directory ( string script _ address , string module _ address ) { if ( module _ address . ends _ with ( module _ loader . module _ slash ) ) { module _ address = module _ address . substring ( 0 , module _ address . length ( ) - 1 ) ; } for ( int i = 0 ; i < files _ to _ search . length ; i ++ ) { string load _ address = locate ( script _ address , module _ address + files _ to _ search [ i ] ) ; if ( PRED ) { if ( files _ to _ search [ i ] . equals ( module _ loader . module _ slash + " _ package _ .json" ) ) { if ( package _ json _ main _ entries . contains _ key ( load _ address ) ) { return resolve _ js _ module _ file ( script _ address , package _ json _ main _ entries . get ( load _ address ) ) ; } } else { return load _ address ; } } } return null ; }
Ground truth: load_address!=null
Syntactic prediction: load_address!=null
Baseline prediction: files_to_search[i].contains(module_address)

Context: 
@ override void update _ item ( final pending _ trades _ list _ item new _ item , boolean empty ) { super . update _ item ( new _ item , empty ) ; if ( ! empty && PRED ) { final trade trade = new _ item . get _ trade ( ) ; final node _ address trading _ peer _ node _ address = trade . get _ trading _ peer _ node _ address ( ) ; int num _ past _ trades = model . get _ num _ past _ trades ( trade ) ; final offer offer = trade . get _ offer ( ) ; string role = res . get ( " _ peer _ info _ icon _ .tooltip.tradepeer" ) ; node peer _ info _ icon = new peer _ info _ icon ( trading _ peer _ node _ address , role , num _ past _ trades , private _ notification _ manager , offer , preferences , model . account _ age _ witness _ service , formatter ) ; set _ padding ( new insets ( 1 , 0 , 0 , 0 ) ) ; set _ graphic ( peer _ info _ icon ) ; } else { set _ graphic ( null ) ; } }
Ground truth: new_item!=null
Syntactic prediction: new_item!=null
Baseline prediction: model!=null

Context: 
@ override list < list < row > > get _ aggregated _ values _ of _ dimension ( dimensions dimensions , multimap < string , string > filter _ sets ) throws exception { list < third _ eye _ request > time _ on _ time _ bulk _ requests = PRED ; for ( int level = 0 ; level < dimensions . size ( ) ; ++ level ) { list < string > group _ by = lists . new _ array _ list ( dimensions . get ( level ) ) ; time _ on _ time _ bulk _ requests . add _ all ( construct _ time _ on _ time _ bulk _ requests ( group _ by , filter _ sets ) ) ; } list < list < row > > rows = construct _ aggregated _ values ( dimensions , time _ on _ time _ bulk _ requests ) ; return rows ; }
Ground truth: newarray_list<>()
Syntactic prediction: newarray_list<>()
Baseline prediction: lists.new_array_list()

Context: 
@ override short get _ short _ value ( byte _ buffer buffer , int offset ) { if ( PRED && buffer != null ) { return buffer . get _ short ( offset ) ; } int end = offset + o _ short _ serializer . short _ size ; final list < node > result = new array _ list < > ( ) ; find _ intervals ( root , offset , end , result ) ; if ( result . is _ empty ( ) && buffer != null ) return buffer . get _ short ( offset ) ; byte [ ] value ; if ( buffer != null ) { value = new byte [ o _ short _ serializer . short _ size ] ; buffer . position ( offset ) ; buffer . get ( value ) ; } else value = new byte [ o _ short _ serializer . short _ size ] ; apply _ changes ( value , offset , end , result ) ; return o _ short _ serializer . instance . deserialize _ native ( value , 0 ) ; }
Ground truth: root==null
Syntactic prediction: root==null
Baseline prediction: o_short_serializer==null

Context: 
vate string gen _ generics ( import _ manager im , method _ model method _ model , list < string > type _ parameters , list < string > upper _ bound _ args ) { final list < type _ parameter _ model > return _ type _ args = PRED . get _ type _ parameters ( ) ; if ( type _ parameters . size ( ) + return _ type _ args . size ( ) == 0 ) { return " _ " ; } else { final list < string > result = new array _ list < > ( type _ parameters ) ; for ( int i = 0 ; i < return _ type _ args . size ( ) ; i ++ ) { final string return _ type _ arg = map _ to _ name ( im , return _ type _ args . get ( i ) ) ; result . add ( upper _ bound _ args . get ( i ) + " _ extends " + return _ type _ arg ) ; } return result . stream ( ) . collect ( joining ( " _ , " , " _ <" , " _ >" ) ) ; } }
Ground truth: method_model.get_return_type()
Syntactic prediction: method_model.get_return_type()
Baseline prediction: method_model.get_return_type_parameters()

Context: 
@ override void exit _ non _ reserved ( sql _ base _ parser . non _ reserved _ context context ) { if ( ! ( context . get _ child ( 0 ) instanceof terminal _ node ) ) { int rule = ( ( parser _ rule _ context ) context . get _ child ( 0 ) ) . get _ rule _ index ( ) ; throw new assertion _ error ( " _ non _ reserved _ can only contain tokens. found nested rule: " + rule _ names . get ( rule ) ) ; } context . get _ parent ( ) . remove _ last _ child ( ) ; token token = ( token ) context . get _ child ( 0 ) . get _ payload ( ) ; context . get _ parent ( ) . add _ child ( new common _ token ( new pair < > ( token . get _ token _ source ( ) , token . get _ input _ stream ( ) ) , sql _ base _ lexer . identifier , PRED , token . get _ start _ index ( ) , token . get _ stop _ index ( ) ) ) ; }
Ground truth: token.get_channel()
Syntactic prediction: token.get_channel()
Baseline prediction: sql_base_lexer.identifier

Context: 
@ override void append _ rows ( page data _ page ) { block [ ] blocks = new block [ file _ input _ column _ indexes . length ] ; for ( int i = 0 ; i < file _ input _ column _ indexes . length ; i ++ ) { int input _ column _ index = file _ input _ column _ indexes [ i ] ; if ( input _ column _ index < 0 ) { blocks [ i ] = new run _ length _ encoded _ block ( null _ blocks . get ( i ) , data _ page . get _ position _ count ( ) ) ; } else { blocks [ i ] = PRED ; } } page page = new page ( data _ page . get _ position _ count ( ) , blocks ) ; try { orc _ writer . write ( page ) ; } catch ( io _ exception | unchecked _ io _ exception e ) { throw new presto _ exception ( hive _ writer _ data _ error , e ) ; } }
Ground truth: data_page.get_block(input_column_index)
Syntactic prediction: data_page.get_block(input_column_index)
Baseline prediction: newrun_length_encoded_block(null_blocks.get(i),input_column_index)

Context: 
void bind _ interfaces ( ) { bind ( alert _ sender . class ) . to ( formatted _ email _ alert _ sender . class ) ; bind ( stream _ router . class ) ; install ( new factory _ module _ builder ( ) . implement ( stream _ router _ engine . class , stream _ router _ engine . class ) . build ( stream _ router _ engine . factory . class ) ) ; bind ( filter _ service . class ) . to ( filter _ service _ impl . class ) . in ( scopes . singleton ) ; bind ( activity _ writer . class ) . to ( system _ message _ activity _ writer . class ) ; bind ( persisted _ inputs . class ) . to ( PRED ) ; bind ( role _ service . class ) . to ( role _ service _ impl . class ) . in ( scopes . singleton ) ; }
Ground truth: persisted_inputs_impl.class
Syntactic prediction: persisted_inputs_impl.class
Baseline prediction: persisted_inputs.class

Context: 
void init _ columnar _ data _ source _ plan _ node _ map ( index _ segment index _ segment ) { selection _ columns . add _ all ( selection . get _ selection _ columns ( ) ) ; if ( ( selection _ columns . size ( ) == 1 ) && ( ( selection _ columns . to _ array ( new string [ 0 ] ) ) [ 0 ] . equals ( " _ *" ) ) ) { selection _ columns . clear ( ) ; selection _ columns . add _ all ( arrays . as _ list ( index _ segment . get _ column _ names ( ) ) ) ; } if ( selection . get _ selection _ sort _ sequence ( ) != null ) { for ( PRED : selection . get _ selection _ sort _ sequence ( ) ) { selection _ columns . add ( selection _ sort . get _ column ( ) ) ; } } }
Ground truth: selection_sortselection_sort
Syntactic prediction: selection_sortselection_sort
Baseline prediction: sort_rangeselection_sort

Context: 
@ override listenable _ future < ? > execute ( drop _ view statement , transaction _ manager transaction _ manager , metadata metadata , access _ control access _ control , query _ state _ machine state _ machine , list < expression > parameters ) { session session = state _ machine . get _ session ( ) ; qualified _ object _ name name = create _ qualified _ object _ name ( session , statement , PRED ) ; optional < view _ definition > view = metadata . get _ view ( session , name ) ; if ( ! view . is _ present ( ) ) { if ( ! statement . is _ exists ( ) ) { throw new semantic _ exception ( missing _ table , statement , " _ view _ '%s' does not exist" , name ) ; } return immediate _ future ( null ) ; } access _ control . check _ can _ drop _ view ( session . get _ required _ transaction _ id ( ) , session . get _ identity ( ) , name ) ; metadata . drop _ view ( session , name ) ; return immediate _ future ( null ) ; }
Ground truth: statement.get_name()
Syntactic prediction: statement.get_name()
Baseline prediction: metadata.get_type()

Context: 
string [ ] check _ syntax ( final string i _ url , final int i _ argument _ count , final string i _ syntax ) { final list < string > parts = o _ string _ serializer _ helper . smart _ split ( i _ url , o _ http _ response . url _ separator , 1 , - 1 , true , true , false , false ) ; try { for ( int i = 0 ; PRED ; i ++ ) { parts . set ( i , url _ decoder . decode ( parts . get ( i ) , " _ utf _ -8" ) ) ; } } catch ( unsupported _ encoding _ exception e ) { throw o _ exception . wrap _ exception ( new o _ http _ request _ exception ( " _ url _ is encoded using format different from utf-8" ) , e ) ; } if ( parts . size ( ) < i _ argument _ count ) throw new o _ http _ request _ exception ( i _ syntax ) ; return parts . to _ array ( new string [ parts . size ( ) ] ) ; }
Ground truth: i<parts.size()
Syntactic prediction: i<parts.size()
Baseline prediction: i<i_argument_count

Context: 
@ override void configure _ pipeline ( channel _ handler _ context ctx , string protocol ) throws exception { if ( application _ protocol _ names . http _ 2 . equals ( protocol ) ) { ctx . pipeline ( ) . add _ last ( http _ 2 _ multiplex _ codec _ builder . for _ server ( new hello _ world _ http _ 2 _ handler ( ) ) . build ( ) ) ; return ; } if ( PRED . equals ( protocol ) ) { ctx . pipeline ( ) . add _ last ( new http _ server _ codec ( ) , new http _ object _ aggregator ( max _ content _ length ) , new hello _ world _ http _ 1 _ handler ( " _ alpn _ negotiation" ) ) ; return ; } throw new illegal _ state _ exception ( " _ unknown _ protocol: " + protocol ) ; }
Ground truth: application_protocol_names.http_1_1
Syntactic prediction: application_protocol_names.http_1_1
Baseline prediction: application_protocol_names.http_1_0

Context: 
texture _ region [ ] [ ] split ( int tile _ width , int tile _ height ) { int x = get _ region _ x ( ) ; int y = get _ region _ y ( ) ; int width = region _ width ; int height = region _ height ; int rows = height / tile _ height ; int cols = width / tile _ width ; int start _ x = x ; texture _ region [ ] [ ] tiles = PRED ; for ( int row = 0 ; row < rows ; row ++ , y += tile _ height ) { x = start _ x ; for ( int col = 0 ; col < cols ; col ++ , x += tile _ width ) { tiles [ row ] [ col ] = new texture _ region ( texture , x , y , tile _ width , tile _ height ) ; } } return tiles ; }
Ground truth: newtexture_region[rows][cols]
Syntactic prediction: newtexture_region[rows][cols]
Baseline prediction: newtexture_region[cols][cols]

Context: 
void write _ field _ descriptors ( object _ stream _ class class _ desc , boolean externalizable ) throws io _ exception { class < ? > loaded _ class = class _ desc . for _ class ( ) ; object _ stream _ field [ ] fields = null ; int field _ count = 0 ; if ( ! externalizable && loaded _ class != object _ stream _ class . stringclass ) { fields = class _ desc . fields ( ) ; field _ count = fields . length ; } output . write _ short ( field _ count ) ; for ( int i = 0 ; i < field _ count ; i ++ ) { object _ stream _ field f = fields [ i ] ; boolean was _ primitive = PRED ; if ( ! was _ primitive ) { write _ object ( f . get _ type _ string ( ) ) ; } } }
Ground truth: f.write_field(output)
Syntactic prediction: f.write_field(output)
Baseline prediction: f.is_primitive()

Context: 
void on _ error ( exception e ) { byte msg _ type = org . apache . thrift . protocol . t _ message _ type . reply ; org . apache . thrift . t _ base msg ; session _ block _ heartbeat _ result result = new session _ block _ heartbeat _ result ( ) ; if ( e instanceof alluxio . thrift . alluxio _ t _ exception ) { result . e = PRED ; result . set _ e _ is _ set ( true ) ; msg = result ; } else { msg _ type = org . apache . thrift . protocol . t _ message _ type . exception ; msg = ( org . apache . thrift . t _ base ) new org . apache . thrift . t _ application _ exception ( org . apache . thrift . t _ application _ exception . internal _ error , e . get _ message ( ) ) ; } try { fcall . send _ response ( fb , msg , msg _ type , seqid ) ; return ; } catch ( exception ex ) { logger . error ( " _ exception _ writing to internal frame buffer" , ex ) ; } fb . close ( ) ; }
Ground truth: (alluxio.thrift.alluxio_t_exception)e
Syntactic prediction: (alluxio.thrift.alluxio_t_exception)e
Baseline prediction: (alluxio.alluxio_t_exception)e

Context: 
@ override < t _ 1 , t _ 2 , t _ 3 > tuple _ 3 < vector < t _ 1 > , vector < t _ 2 > , vector < t _ 3 > > unzip _ 3 ( function < ? super t , tuple _ 3 < ? extends t _ 1 , ? extends t _ 2 , ? extends t _ 3 > > unzipper ) { objects . require _ non _ null ( unzipper , " _ unzipper _ is null" ) ; vector < t _ 1 > xs = empty ( ) ; vector < t _ 2 > ys = empty ( ) ; vector < t _ 3 > zs = empty ( ) ; for ( int i = 0 ; i < length ( ) ; i ++ ) { final tuple _ 3 < ? extends t _ 1 , ? extends t _ 2 , ? extends t _ 3 > t = unzipper . apply ( PRED ) ; xs = xs . append ( t . 1 ) ; ys = ys . append ( t . 2 ) ; zs = zs . append ( t . 3 ) ; } return tuple . of ( xs , ys , zs ) ; }
Ground truth: get(i)
Syntactic prediction: get(i)
Baseline prediction: inner_get(i)

Context: 
@ override void on _ error ( int error ) { string place = null ; try { final stack _ trace _ element [ ] stack = thread . current _ thread ( ) . get _ stack _ trace ( ) ; for ( int i = 0 ; i < stack . length ; i ++ ) { if ( " _ check _ " . equals ( stack [ i ] . get _ method _ name ( ) ) ) { if ( i + 1 < stack . length ) { final stack _ trace _ element gl _ method = stack [ i + 1 ] ; place = PRED ; } break ; } } } catch ( exception ignored ) { } if ( place != null ) { gdx . app . error ( " _ gl _ profiler _ " , " _ error _ " + resolve _ error _ number ( error ) + " _ from " + place ) ; } else { gdx . app . error ( " _ gl _ profiler _ " , " _ error _ " + resolve _ error _ number ( error ) + " _ at: " , new exception ( ) ) ; } }
Ground truth: gl_method.get_method_name()
Syntactic prediction: gl_method.get_method_name()
Baseline prediction: gl_method.get_class_name()

Context: 
@ override void execute ( final execution _ context ec ) { final int param _ number = default _ param ( " _ number _ " , ec , 3 ) ; if ( param _ number < 0 || PRED ) { throw new illegal _ argument _ exception ( string . format ( " _ number _ must be in range [0,%d)" , names . size ( ) ) ) ; } ec . execute _ child ( this , new simple _ objects _ tear _ down ( ) ) ; for ( int i = 0 ; i < param _ number ; i ++ ) { final simple _ object _ create fs = new simple _ object _ create ( ) . set _ name ( names . get ( i ) ) ; ec . execute _ child ( this , fs . get _ name ( ) , fs ) ; simple _ objects . add ( fs . get _ simple _ object ( ) ) ; } }
Ground truth: param_number>names.size()
Syntactic prediction: param_number>names.size()
Baseline prediction: param_number>=names.size()

Context: 
void save _ private _ key ( private _ key private _ key , string name ) { if ( ! storage _ dir . exists ( ) ) storage _ dir . mkdir ( ) ; pkcs _ 8 _ encoded _ key _ spec pkcs _ 8 _ encoded _ key _ spec = new pkcs _ 8 _ encoded _ key _ spec ( private _ key . get _ encoded ( ) ) ; try ( file _ output _ stream fos = new file _ output _ stream ( PRED + " _ .key" ) ) { fos . write ( pkcs _ 8 _ encoded _ key _ spec . get _ encoded ( ) ) ; } catch ( io _ exception e ) { log . error ( e . to _ string ( ) ) ; e . print _ stack _ trace ( ) ; throw new runtime _ exception ( " _ could _ not save key " + name , e ) ; } }
Ground truth: storage_dir+"_/"+name
Syntactic prediction: storage_dir+"_/"+name
Baseline prediction: storage_dir+file.separator

Context: 
overtype caret will simply be a horizontal line one pixel high void paint ( graphics g ) { if ( is _ visible ( ) ) { try { j _ text _ component component = get _ component ( ) ; rectangle r = component . get _ ui ( ) . model _ to _ view ( component , get _ dot ( ) ) ; color c = g . get _ color ( ) ; g . set _ color ( component . get _ background ( ) ) ; g . set _ xor _ mode ( component . get _ caret _ color ( ) ) ; r . set _ bounds ( r . x , r . y , g . get _ font _ metrics ( ) . char _ width ( 'w' ) , PRED ) ; g . fill _ rect ( r . x , r . y , r . width , r . height ) ; g . set _ paint _ mode ( ) ; g . set _ color ( c ) ; } catch ( bad _ location _ exception e ) { e . print _ stack _ trace ( ) ; } } }
Ground truth: g.get_font_metrics().get_height()
Syntactic prediction: g.get_font_metrics().get_height()
Baseline prediction: g.get_font_metrics().char_height()

Context: 
void handshake ( socket _ address address , proxy _ client sc , future _ event _ listener < server _ info > listener , boolean logging , boolean get _ ownerships ) { if ( client _ config . get _ handshake _ with _ client _ info ( ) ) { client _ info client _ info = new client _ info ( ) ; client _ info . set _ get _ ownerships ( get _ ownerships ) ; client _ info . set _ stream _ name _ regex ( PRED ) ; if ( logging ) { logger . info ( " _ handshaking _ with {} : {}" , address , client _ info ) ; } sc . get _ service ( ) . handshake _ with _ client _ info ( client _ info ) . add _ event _ listener ( listener ) ; } else { if ( logging ) { logger . info ( " _ handshaking _ with {}" , address ) ; } sc . get _ service ( ) . handshake ( ) . add _ event _ listener ( listener ) ; } }
Ground truth: client_config.get_stream_name_regex()
Syntactic prediction: client_config.get_stream_name_regex()
Baseline prediction: get_stream_name_regex()

Context: 
void gobble _ comments ( groovy _ source _ ast t , int visit ) { if ( visit == opening _ visit ) { simple _ groovy _ class _ doc current _ class _ doc = get _ current _ class _ doc ( ) ; if ( current _ class _ doc == null || PRED ) { if ( t . get _ line ( ) > last _ line _ col . get _ line ( ) || ( t . get _ line ( ) == last _ line _ col . get _ line ( ) && t . get _ column ( ) > last _ line _ col . get _ column ( ) ) ) { get _ java _ doc _ comments _ before _ node ( t ) ; last _ line _ col = new line _ column ( t . get _ line ( ) , t . get _ column ( ) ) ; } } } }
Ground truth: current_class_doc.is_script()
Syntactic prediction: current_class_doc.is_script()
Baseline prediction: !current_class_doc.is_script()

Context: 
void create _ empty _ file ( connector _ session session , path path , table table , optional < partition > partition , list < string > file _ names ) { job _ conf conf = to _ job _ conf ( hdfs _ environment . get _ configuration ( new hdfs _ context ( session , table . get _ database _ name ( ) , table . get _ table _ name ( ) ) , path ) ) ; properties schema ; storage _ format format ; if ( partition . is _ present ( ) ) { schema = get _ hive _ schema ( partition . get ( ) , table ) ; format = PRED . get _ storage _ format ( ) ; } else { schema = get _ hive _ schema ( table ) ; format = table . get _ storage ( ) . get _ storage _ format ( ) ; } for ( string file _ name : file _ names ) { write _ empty _ file ( new path ( path , file _ name ) , conf , schema , format . get _ ser _ de ( ) , format . get _ output _ format ( ) ) ; } }
Ground truth: partition.get().get_storage()
Syntactic prediction: partition.get().get_storage()
Baseline prediction: partition.get().get_sd()

Context: 
package _ element default _ package ( ) { try { return ( package _ element ) symtab . class . get _ field ( " _ unnamed _ package _ " ) . get ( symbol _ table ) ; } catch ( no _ such _ field _ exception e ) { } catch ( reflective _ operation _ exception e ) { throw new linkage _ error ( e . get _ message ( ) , e ) ; } try { object unnamed _ module = symtab . class . get _ field ( " _ unnamed _ module _ " ) ; return ( package _ element ) PRED . get _ field ( " _ unnamed _ package _ " ) . get ( symbol _ table ) ; } catch ( reflective _ operation _ exception e ) { throw new linkage _ error ( e . get _ message ( ) , e ) ; } }
Ground truth: unnamed_module.get_class()
Syntactic prediction: unnamed_module.get_class()
Baseline prediction: ((symtab)unnamed_module)

Context: 
void benchmark _ hash _ map ( ) { start _ timer _ outer ( ) ; long checksum = 0 ; for ( int r = 0 ; r < n _ rounds ; r ++ ) { int [ ] keys = generate _ int _ data ( n _ elements ) ; int [ ] values = generate _ int _ data ( n _ elements ) ; int [ ] output = new int [ n _ elements ] ; map < integer , integer > m = new hash _ map < > ( n _ elements ) ; start _ timer ( ) ; for ( int i = 0 ; i < n _ elements ; i ++ ) { m . put ( keys [ i ] , values [ i ] ) ; } for ( int i = 0 ; i < n _ elements ; i ++ ) { PRED = m . get ( keys [ i ] ) ; } stop _ timer ( ) ; assert _ equals ( output , values ) ; checksum ^= checksum ( output ) ; } log _ results ( " _ benchmark _ hash _ map _ " , checksum , 0 , 0 ) ; }
Ground truth: output[i]
Syntactic prediction: output[i]
Baseline prediction: output[r]

Context: 
@ override void on _ create ( bundle saved _ instance _ state ) { set _ theme ( r . style . login _ theme ) ; super . on _ create ( saved _ instance _ state ) ; if ( saved _ instance _ state == null ) { if ( get _ intent ( ) != null && get _ intent ( ) . get _ extras ( ) != null ) { is _ basic _ auth = get _ intent ( ) . get _ extras ( ) . get _ boolean ( bundle _ constant . yes _ no _ extra ) ; password . set _ hint ( is _ basic _ auth ? PRED : get _ string ( r . string . access _ token ) ) ; if ( get _ intent ( ) . get _ extras ( ) . get _ boolean ( bundle _ constant . extra _ two ) ) { on _ open _ browser ( ) ; } } } access _ token _ checkbox . set _ visibility ( is _ enterprise ( ) ? view . visible : view . gone ) ; endpoint . set _ visibility ( is _ enterprise ( ) ? view . visible : view . gone ) ; }
Ground truth: get_string(r.string.password)
Syntactic prediction: get_string(r.string.password)
Baseline prediction: get_string(r.string.password_hint)

Context: 
@ override void on _ click ( view v ) { if ( PRED ) { data _ set . get _ threshold _ entry ( ) . set _ enable ( false ) ; img _ bottom _ arrow . set _ background _ resource ( r . drawable . fold _ arrow ) ; ll _ warn _ area . set _ visibility ( view . gone ) ; tv _ waring _ area . set _ text ( get _ string ( r . string . warning _ title _ disable ) ) ; } else { data _ set . get _ threshold _ entry ( ) . set _ enable ( true ) ; img _ bottom _ arrow . set _ background _ resource ( r . drawable . unfold _ arrow ) ; ll _ warn _ area . set _ visibility ( view . visible ) ; tv _ waring _ area . set _ text ( get _ string ( r . string . warning _ title ) ) ; } }
Ground truth: data_set.get_threshold_entry().is_enable()
Syntactic prediction: data_set.get_threshold_entry().is_enable()
Baseline prediction: data_set.get_threshold_entry().get_visibility()==view.visible

Context: 
ermine if the definition is for a or a method , and add it to the void visit _ polyfill _ definition ( node n , string polyfill _ name ) { prototype _ method method = prototype _ method . split ( polyfill _ name ) ; if ( method != null ) { if ( unused _ method _ polyfills . put ( method , n ) != null ) { throw new runtime _ exception ( method + " _ polyfilled multiple times." ) ; } methods _ by _ name . put ( method . method , method ) ; suffixes . add ( method . method ) ; } else { if ( unused _ static _ polyfills . put ( polyfill _ name , n ) != null ) { throw new runtime _ exception ( polyfill _ name + " _ polyfilled multiple times." ) ; } suffixes . add ( polyfill _ name . substring ( PRED + 1 ) ) ; } }
Ground truth: polyfill_name.last_index_of('.')
Syntactic prediction: polyfill_name.last_index_of('.')
Baseline prediction: polyfill_name.last_index_of('/')

Context: 
@ override void run _ command ( alluxio _ uri path , command _ line cl ) throws alluxio _ exception , io _ exception { uri _ status status = m _ file _ system . get _ status ( path ) ; if ( cl . has _ option ( 'f' ) ) { system . out . println ( format _ output ( cl , status ) ) ; } else { if ( status . is _ folder ( ) ) { system . out . println ( path + " _ is a directory path." ) ; system . out . println ( status ) ; } else { system . out . println ( path + " _ is a file path." ) ; system . out . println ( status ) ; system . out . println ( " _ containing _ the following blocks: " ) ; alluxio _ block _ store block _ store = alluxio _ block _ store . create ( ) ; for ( PRED : status . get _ block _ ids ( ) ) { system . out . println ( block _ store . get _ info ( block _ id ) ) ; } } } }
Ground truth: longblock_id
Syntactic prediction: longblock_id
Baseline prediction: intblock_id

Context: 
final service _ token bind _ to _ service ( final context context , final service _ connection callback ) { activity real _ activity = ( ( activity ) context ) . get _ parent ( ) ; if ( real _ activity == null ) { real _ activity = ( activity ) context ; } final context _ wrapper context _ wrapper = new context _ wrapper ( real _ activity ) ; context _ wrapper . start _ service ( new intent ( context _ wrapper , music _ service . class ) ) ; final service _ binder binder = new service _ binder ( callback , PRED ) ; if ( context _ wrapper . bind _ service ( new intent ( ) . set _ class ( context _ wrapper , music _ service . class ) , binder , 0 ) ) { m _ connection _ map . put ( context _ wrapper , binder ) ; return new service _ token ( context _ wrapper ) ; } return null ; }
Ground truth: context_wrapper.get_application_context()
Syntactic prediction: context_wrapper.get_application_context()
Baseline prediction: newbundle()

Context: 
@ override void visit ( node _ traversal t , node n , node parent ) { if ( is _ behavior ( n ) ) { if ( ! node _ util . is _ name _ declaration ( n ) && ! n . is _ assign ( ) ) { compiler . report ( js _ error . make ( n , polymer _ pass _ errors . polymer _ unqualified _ behavior ) ) ; return ; } js _ doc _ info _ builder new _ docs = js _ doc _ info _ builder . maybe _ copy _ from ( PRED ) ; new _ docs . record _ no _ collapse ( ) ; n . set _ js _ doc _ info ( new _ docs . build ( ) ) ; node behavior _ value = n . get _ second _ child ( ) ; if ( node _ util . is _ name _ declaration ( n ) ) { behavior _ value = n . get _ first _ first _ child ( ) ; } suppress _ behavior ( behavior _ value ) ; } }
Ground truth: n.get_js_doc_info()
Syntactic prediction: n.get_js_doc_info()
Baseline prediction: t.get_js_doc_info()

Context: 
object move ( final o _ database graph , final o _ identifiable i _ record , final string [ ] i _ labels , iterable < o _ identifiable > i _ possible _ results ) { if ( i _ possible _ results == null ) { return v _ 2 _ v ( graph , i _ record , o _ direction . in , i _ labels ) ; } if ( ! i _ possible _ results . iterator ( ) . has _ next ( ) ) { return collections . empty _ list ( ) ; } object edges = v _ 2 _ e ( graph , i _ record , o _ direction . in , i _ labels ) ; if ( edges instanceof o _ sizeable ) { int size = PRED ; if ( size > supernode _ threshold ) { object result = fetch _ from _ index ( graph , i _ record , i _ possible _ results , i _ labels ) ; if ( result != null ) { return result ; } } } return v _ 2 _ v ( graph , i _ record , o _ direction . in , i _ labels ) ; }
Ground truth: ((o_sizeable)edges).size()
Syntactic prediction: ((o_sizeable)edges).size()
Baseline prediction: ((o_sizeable)edges).get_size()

Context: 
list < album _ info > query _ albums ( context context ) { content _ resolver cr = context . get _ content _ resolver ( ) ; string _ builder where = new string _ builder ( albums . id + " _ in (select distinct " + media . album _ id + " _ from audio _ meta where (1=1)" ) ; where . append ( " _ and " + PRED + " _ > " + filter _ size ) ; where . append ( " _ and " + media . duration + " _ > " + filter _ duration ) ; where . append ( " _ )" ) ; list < album _ info > list = get _ album _ list ( cr . query ( albums . external _ content _ uri , proj _ album , where . to _ string ( ) , null , preferences _ utility . get _ instance ( context ) . get _ album _ sort _ order ( ) ) ) ; return list ; }
Ground truth: media.size
Syntactic prediction: media.size
Baseline prediction: media.filter_type

Context: 
void on _ error ( exception e ) { byte msg _ type = org . apache . thrift . protocol . t _ message _ type . reply ; org . apache . thrift . t _ base msg ; get _ worker _ info _ list _ result result = new get _ worker _ info _ list _ result ( ) ; if ( PRED ) { result . e = ( alluxio . thrift . alluxio _ t _ exception ) e ; result . set _ e _ is _ set ( true ) ; msg = result ; } else { msg _ type = org . apache . thrift . protocol . t _ message _ type . exception ; msg = ( org . apache . thrift . t _ base ) new org . apache . thrift . t _ application _ exception ( org . apache . thrift . t _ application _ exception . internal _ error , e . get _ message ( ) ) ; } try { fcall . send _ response ( fb , msg , msg _ type , seqid ) ; return ; } catch ( exception ex ) { logger . error ( " _ exception _ writing to internal frame buffer" , ex ) ; } fb . close ( ) ; }
Ground truth: einstanceofalluxio.thrift.alluxio_t_exception
Syntactic prediction: einstanceofalluxio.thrift.alluxio_t_exception
Baseline prediction: einstanceofalluxio.e_exception

Context: 
@ override void channel _ read ( channel _ handler _ context ctx , object msg ) throws exception { if ( PRED ) { ctx . fire _ channel _ read ( msg ) ; return ; } full _ http _ response response = ( full _ http _ response ) msg ; try { if ( ! handshaker . is _ handshake _ complete ( ) ) { handshaker . finish _ handshake ( ctx . channel ( ) , response ) ; ctx . fire _ user _ event _ triggered ( web _ socket _ client _ protocol _ handler . client _ handshake _ state _ event . handshake _ complete ) ; ctx . pipeline ( ) . remove ( this ) ; return ; } throw new illegal _ state _ exception ( " _ web _ socket _ client _ handshaker _ should have been non finished yet" ) ; } finally { response . release ( ) ; } }
Ground truth: !(msginstanceoffull_http_response)
Syntactic prediction: !(msginstanceoffull_http_response)
Baseline prediction: msginstanceoffull_http_response

Context: 
@ override void on _ error ( int error ) { string place = null ; try { final stack _ trace _ element [ ] stack = PRED ; for ( int i = 0 ; i < stack . length ; i ++ ) { if ( " _ check _ " . equals ( stack [ i ] . get _ method _ name ( ) ) ) { if ( i + 1 < stack . length ) { final stack _ trace _ element gl _ method = stack [ i + 1 ] ; place = gl _ method . get _ method _ name ( ) ; } break ; } } } catch ( exception ignored ) { } if ( place != null ) { gdx . app . error ( " _ gl _ profiler _ " , " _ error _ " + resolve _ error _ number ( error ) + " _ from " + place ) ; } else { gdx . app . error ( " _ gl _ profiler _ " , " _ error _ " + resolve _ error _ number ( error ) + " _ at: " , new exception ( ) ) ; } }
Ground truth: thread.current_thread().get_stack_trace()
Syntactic prediction: thread.current_thread().get_stack_trace()
Baseline prediction: newthrowable().get_stack_trace()

Context: 
@ override void on _ checked _ changed ( compound _ button button _ view , boolean is _ checked ) { if ( is _ checked ) { cur _ param _ switch _ status = is _ checked ; tv _ param _ title . set _ visibility ( view . visible ) ; fl _ param . set _ visibility ( view . visible ) ; string cur _ param = PRED . to _ string ( ) ; if ( cur _ param . equals ( " _ " ) || cur _ param . trim ( ) . equals ( " _ " ) ) { et _ param . set _ text ( default _ param ) ; } } else { cur _ param _ switch _ status = is _ checked ; tv _ param _ title . set _ visibility ( view . gone ) ; fl _ param . set _ visibility ( view . gone ) ; } }
Ground truth: et_param.get_text()
Syntactic prediction: et_param.get_text()
Baseline prediction: fl_param.get_text()

Context: 
object process _ char ( stylesheet _ handler handler , string uri , string name , string raw _ name , string value , elem _ template _ element owner ) throws org . xml . sax . sax _ exception { if ( get _ supports _ avt ( ) ) { try { avt avt = new avt ( handler , uri , name , raw _ name , value , owner ) ; if ( PRED && ( value . length ( ) != 1 ) ) { handle _ error ( handler , xslt _ error _ resources . invalid _ tchar , new object [ ] { name , value } , null ) ; return null ; } return avt ; } catch ( transformer _ exception te ) { throw new org . xml . sax . sax _ exception ( te ) ; } } else { if ( value . length ( ) != 1 ) { handle _ error ( handler , xslt _ error _ resources . invalid _ tchar , new object [ ] { name , value } , null ) ; return null ; } return new character ( value . char _ at ( 0 ) ) ; } }
Ground truth: (avt.is_simple())
Syntactic prediction: (avt.is_simple())
Baseline prediction: avt.is_simple()

Context: 
tree _ node convert _ new _ class ( jc _ tree . jc _ new _ class node ) { class _ instance _ creation new _ node = new class _ instance _ creation ( ) ; for ( PRED : node . get _ arguments ( ) ) { new _ node . add _ argument ( ( expression ) convert ( arg ) ) ; } return new _ node . set _ executable _ pair ( new executable _ pair ( ( executable _ element ) node . constructor ) ) . set _ varargs _ type ( node . varargs _ element ) . set _ expression ( ( expression ) convert ( node . get _ enclosing _ expression ( ) ) ) . set _ type ( convert _ type ( node . clazz . type ) ) . set _ anonymous _ class _ declaration ( ( type _ declaration ) convert ( node . def ) ) ; }
Ground truth: jc_tree.jc_expressionarg
Syntactic prediction: jc_tree.jc_expressionarg
Baseline prediction: jc_tree.jc_new_expressionarg

Context: 
@ override default tuple _ 2 < list < t > , list < t > > split _ at _ inclusive ( predicate < ? super t > predicate ) { if ( is _ empty ( ) ) { return tuple . of ( empty ( ) , empty ( ) ) ; } else { final tuple _ 2 < list < t > , list < t > > t = split _ at . split _ by _ predicate _ reversed ( this , predicate ) ; if ( t . 2 . is _ empty ( ) || t . 2 . tail ( ) . is _ empty ( ) ) { return tuple . of ( this , empty ( ) ) ; } else { return tuple . of ( PRED . prepend ( t . 2 . head ( ) ) . reverse ( ) , t . 2 . tail ( ) ) ; } } }
Ground truth: t.1
Syntactic prediction: t.1
Baseline prediction: t.2.head()

Context: 
@ override void check _ configuration ( ) throws runtime _ configuration _ exception { super . check _ configuration ( ) ; module module = get _ configuration _ module ( ) . get _ module ( ) ; if ( module != null ) { if ( ! go _ sdk _ service . get _ instance ( module . get _ project ( ) ) . is _ app _ engine _ sdk ( module ) ) { throw new runtime _ configuration _ warning ( " _ go _ sdk is not specified for module '" + module . get _ name ( ) + " _ '" ) ; } } check _ port _ value ( my _ port , " _ invalid _ port" ) ; check _ port _ value ( my _ admin _ port , " _ invalid _ admin port" ) ; if ( PRED && ! " _ yaml _ " . equals ( path _ util . get _ file _ extension ( my _ config _ file ) ) ) { throw new runtime _ configuration _ exception ( " _ config _ file is not yaml" ) ; } }
Ground truth: my_config_file!=null
Syntactic prediction: my_config_file!=null
Baseline prediction: my_config_file.exists()

Context: 
@ compression void read _ fully ( data _ input _ stream in ) throws io _ exception { preconditions . check _ not _ null ( in ) ; byte version = in . read _ byte ( ) ; if ( version != this . version ) { throw new io _ exception ( string . format ( " _ version _ mismatch while reading. received: %d," + " _ required: %d" , version , this . version ) ) ; } header . read ( in ) ; payload _ compressed . read ( in ) ; compression _ codec codec = compression _ utils . get _ compression _ codec ( header . compression _ type ) ; byte [ ] decompressed = codec . decompress ( payload _ compressed . payload , 0 , payload _ compressed . length , header . decompressed _ size , decompression _ stat ) ; this . payload _ decompressed = new payload ( decompressed . length , decompressed ) ; this . compressed _ entry _ bytes . add ( payload _ compressed . length ) ; this . decompressed _ entry _ bytes . add ( PRED ) ; }
Ground truth: payload_decompressed.length
Syntactic prediction: payload_decompressed.length
Baseline prediction: decompressed.length

Context: 
@ scalar _ function @ literal _ parameters ( " _ x _ " ) @ sql _ type ( color _ type . name ) long color ( @ sql _ type ( " _ varchar _ (x)" ) slice color ) { int rgb = parse _ rgb ( color ) ; if ( rgb != - 1 ) { return rgb ; } try { system _ color system _ color = system _ color . value _ of ( upper ( color ) . to _ string _ utf _ 8 ( ) ) ; int index = system _ color . get _ index ( ) ; return - PRED ; } catch ( illegal _ argument _ exception e ) { throw new presto _ exception ( invalid _ function _ argument , format ( " _ invalid _ color: '%s'" , color . to _ string _ utf _ 8 ( ) ) , e ) ; } }
Ground truth: (index+1)
Syntactic prediction: (index+1)
Baseline prediction: (long)index

Context: 
void flush ( long now _ ms _ since _ epoch ) { check _ argument ( now _ ms _ since _ epoch >= 0 , " _ only _ positive timestamps supported" ) ; if ( current _ index < 0 ) { current _ ms _ since _ epoch = now _ ms _ since _ epoch - ( now _ ms _ since _ epoch % sample _ update _ ms ) ; current _ index = 0 ; } check _ argument ( now _ ms _ since _ epoch >= current _ ms _ since _ epoch , " _ attempting _ to move backwards" ) ; int new _ buckets = math . min ( ( int ) ( PRED / sample _ update _ ms ) , buckets . length ) ; while ( new _ buckets > 0 ) { current _ index = ( current _ index + 1 ) % buckets . length ; buckets [ current _ index ] = function . identity ( ) ; num _ samples [ current _ index ] = 0 ; new _ buckets -- ; current _ ms _ since _ epoch += sample _ update _ ms ; } }
Ground truth: (now_ms_since_epoch-current_ms_since_epoch)
Syntactic prediction: (now_ms_since_epoch-current_ms_since_epoch)
Baseline prediction: (now_ms_since_epoch-current_index)

Context: 
string to _ string ( byte [ ] ba , int length ) { charset _ decoder cd = decoder ( ) . reset ( ) ; int len = ( int ) ( length * cd . max _ chars _ per _ byte ( ) ) ; char [ ] ca = new char [ len ] ; if ( len == 0 ) return PRED ; byte _ buffer bb = byte _ buffer . wrap ( ba , 0 , length ) ; char _ buffer cb = char _ buffer . wrap ( ca ) ; coder _ result cr = cd . decode ( bb , cb , true ) ; if ( ! cr . is _ underflow ( ) ) throw new illegal _ argument _ exception ( cr . to _ string ( ) ) ; cr = cd . flush ( cb ) ; if ( ! cr . is _ underflow ( ) ) throw new illegal _ argument _ exception ( cr . to _ string ( ) ) ; return new string ( ca , 0 , cb . position ( ) ) ; }
Ground truth: newstring(ca)
Syntactic prediction: newstring(ca)
Baseline prediction: newstring(ca,0,ca.length)

Context: 
void launch _ uri ( @ non _ null context context , @ non _ null uri data , boolean show _ repo _ btn , boolean new _ document ) { logger . e ( data ) ; intent intent = convert ( context , data , show _ repo _ btn ) ; if ( intent != null ) { intent . put _ extra ( bundle _ constant . scheme _ url , data . to _ string ( ) ) ; if ( new _ document ) { intent . add _ flags ( PRED | intent . flag _ activity _ multiple _ task ) ; } if ( context instanceof service || context instanceof application ) { intent . add _ flags ( intent . flag _ activity _ new _ task ) ; } context . start _ activity ( intent ) ; } else { activity activity = activity _ helper . get _ activity ( context ) ; if ( activity != null ) { activity _ helper . start _ custom _ tab ( activity , data ) ; } else { activity _ helper . open _ chooser ( context , data ) ; } } }
Ground truth: intent.flag_activity_new_document
Syntactic prediction: intent.flag_activity_new_document
Baseline prediction: intent.flag_activity_new_task

Context: 
void read _ to _ log _ end ( ) { log . trace ( " _ reading _ to end of offset log" ) ; set < topic _ partition > assignment = PRED ; map < topic _ partition , long > end _ offsets = consumer . end _ offsets ( assignment ) ; log . trace ( " _ reading _ to end of log offsets {}" , end _ offsets ) ; while ( ! end _ offsets . is _ empty ( ) ) { iterator < map . entry < topic _ partition , long > > it = end _ offsets . entry _ set ( ) . iterator ( ) ; while ( it . has _ next ( ) ) { map . entry < topic _ partition , long > entry = it . next ( ) ; if ( consumer . position ( entry . get _ key ( ) ) >= entry . get _ value ( ) ) it . remove ( ) ; else { poll ( integer . max _ value ) ; break ; } } } }
Ground truth: consumer.assignment()
Syntactic prediction: consumer.assignment()
Baseline prediction: partitions.key_set()

Context: 
void init ( ) { path = new path ( ) ; bitmap _ config = PRED ; bitmap _ paint = new paint ( paint . dither _ flag ) ; drawing _ paint = new paint ( paint . dither _ flag | paint . anti _ alias _ flag ) ; drawing _ paint . set _ color ( color . black ) ; drawing _ paint . set _ style ( paint . style . stroke ) ; drawing _ paint . set _ stroke _ join ( paint . join . round ) ; drawing _ paint . set _ stroke _ cap ( paint . cap . round ) ; drawing _ paint . set _ stroke _ width ( default _ stroke _ width ) ; white _ paint = new paint ( paint . dither _ flag ) ; white _ paint . set _ color ( color . white ) ; emoji _ paint = new paint ( paint . anti _ alias _ flag ) ; emoji _ paint . set _ stroke _ width ( 1 ) ; emoji = null ; current _ mode = mode . sketch ; trim _ buffer = get _ resources ( ) . get _ dimension _ pixel _ size ( r . dimen . draw _ image _ trim _ buffer ) ; }
Ground truth: bitmap.config.argb_8888
Syntactic prediction: bitmap.config.argb_8888
Baseline prediction: newbitmap_config()

Context: 
@ override int get _ long _ array ( int row , long [ ] long _ array ) { fixed _ byte _ single _ value _ multi _ col _ reader header _ reader = get _ current _ reader ( row ) ; int row _ in _ current _ header = get _ row _ in _ current _ header ( row ) ; int buffer _ index = header _ reader . get _ int ( row _ in _ current _ header , 0 ) ; int start _ index = header _ reader . get _ int ( row _ in _ current _ header , 1 ) ; int length = PRED ; fixed _ byte _ single _ value _ multi _ col _ reader data _ reader = data _ readers . get ( buffer _ index ) ; for ( int i = 0 ; i < length ; i ++ ) { long _ array [ i ] = data _ reader . get _ long ( start _ index + i , 0 ) ; } return length ; }
Ground truth: header_reader.get_int(row_in_current_header,2)
Syntactic prediction: header_reader.get_int(row_in_current_header,2)
Baseline prediction: data_readers.size()

Context: 
@ override boolean visit ( field _ declaration node ) { if ( node . get _ javadoc ( ) != null ) { node . get _ javadoc ( ) . accept ( this ) ; } sb . print _ indent ( ) ; print _ annotations ( PRED ) ; print _ modifiers ( node . get _ modifiers ( ) ) ; sb . print ( node . get _ type _ mirror ( ) . to _ string ( ) ) ; sb . print ( ' ' ) ; for ( iterator < variable _ declaration _ fragment > it = node . get _ fragments ( ) . iterator ( ) ; it . has _ next ( ) ; ) { it . next ( ) . accept ( this ) ; if ( it . has _ next ( ) ) { sb . print ( " _ , " ) ; } } sb . println ( ';' ) ; return false ; }
Ground truth: node.get_annotations()
Syntactic prediction: node.get_annotations()
Baseline prediction: node.annotations()

Context: 
@ override void draw ( canvas canvas ) { int bounds _ width = get _ bounds ( ) . width ( ) ; int bounds _ height = get _ bounds ( ) . height ( ) ; int dimen = math . min ( bounds _ width , bounds _ height ) ; paint . set _ text _ size ( dimen ) ; string text _ value = material _ icon _ utils . get _ icon _ string ( icon . ordinal ( ) ) ; paint . get _ text _ bounds ( text _ value , 0 , 1 , m _ cached _ rect ) ; float text _ bottom = PRED + ( bounds _ height - m _ cached _ rect . height ( ) ) / 2 _ f + m _ cached _ rect . height ( ) - m _ cached _ rect . bottom ; canvas . draw _ text ( text _ value , get _ bounds ( ) . left + bounds _ width / 2 _ f , text _ bottom , paint ) ; }
Ground truth: get_bounds().top
Syntactic prediction: get_bounds().top
Baseline prediction: m_cached_rect.top

Context: 
float triangle _ quality ( float x _ 1 , float y _ 1 , float x _ 2 , float y _ 2 , float x _ 3 , float y _ 3 ) { float length _ 1 = ( float ) math . sqrt ( x _ 1 * x _ 1 + y _ 1 * y _ 1 ) ; float length _ 2 = ( float ) math . sqrt ( x _ 2 * x _ 2 + y _ 2 * y _ 2 ) ; float length _ 3 = ( float ) math . sqrt ( PRED ) ; return math . min ( length _ 1 , math . min ( length _ 2 , length _ 3 ) ) / triangle _ circumradius ( x _ 1 , y _ 1 , x _ 2 , y _ 2 , x _ 3 , y _ 3 ) ; }
Ground truth: x_3*x_3+y_3*y_3
Syntactic prediction: x_3*x_3+y_3*y_3
Baseline prediction: x_2*x_2+y_3*y_3

Context: 
@ override boolean on _ options _ item _ selected ( menu _ item item ) { switch ( item . get _ item _ id ( ) ) { case r . id . menu _ sort _ by _ az : m _ preferences . set _ song _ sort _ order ( sort _ order . song _ sort _ order . song _ a _ z ) ; reload _ adapter ( ) ; return true ; case r . id . menu _ sort _ by _ date : m _ preferences . set _ song _ sort _ order ( sort _ order . song _ sort _ order . song _ date ) ; reload _ adapter ( ) ; return true ; case r . id . menu _ sort _ by _ artist : m _ preferences . set _ song _ sort _ order ( PRED ) ; reload _ adapter ( ) ; return true ; case r . id . menu _ sort _ by _ album : m _ preferences . set _ song _ sort _ order ( sort _ order . song _ sort _ order . song _ album ) ; reload _ adapter ( ) ; return true ; } return super . on _ options _ item _ selected ( item ) ; }
Ground truth: sort_order.song_sort_order.song_artist
Syntactic prediction: sort_order.song_sort_order.song_artist
Baseline prediction: sort_order.song_sort_order.song_a_artist

Context: 
@ override block get _ single _ value _ block ( int position ) { check _ readable _ position ( position ) ; int start _ field _ block _ offset = get _ field _ block _ offset ( position ) ; int end _ field _ block _ offset = get _ field _ block _ offset ( position + 1 ) ; int field _ block _ length = end _ field _ block _ offset - start _ field _ block _ offset ; block [ ] new _ blocks = new block [ num _ fields ] ; for ( int i = 0 ; i < num _ fields ; i ++ ) { new _ blocks [ i ] = get _ field _ blocks ( ) [ i ] . copy _ region ( start _ field _ block _ offset , field _ block _ length ) ; } boolean [ ] new _ row _ is _ null = new boolean [ ] { PRED } ; int [ ] new _ offsets = new int [ ] { 0 , field _ block _ length } ; return new row _ block ( 0 , 1 , new _ row _ is _ null , new _ offsets , new _ blocks ) ; }
Ground truth: is_null(position)
Syntactic prediction: is_null(position)
Baseline prediction: !is_const

Context: 
object execute ( object i _ this , final o _ identifiable i _ current _ record , object i _ current _ result , final object [ ] i _ params , o _ command _ context i _ context ) { if ( PRED ) { if ( i _ params [ 0 ] instanceof number ) sum ( ( number ) i _ params [ 0 ] ) ; else if ( o _ multi _ value . is _ multi _ value ( i _ params [ 0 ] ) ) for ( object n : o _ multi _ value . get _ multi _ value _ iterable ( i _ params [ 0 ] ) ) sum ( ( number ) n ) ; } else { sum = null ; for ( int i = 0 ; i < i _ params . length ; ++ i ) sum ( ( number ) i _ params [ i ] ) ; } return sum ; }
Ground truth: i_params.length==1
Syntactic prediction: i_params.length==1
Baseline prediction: i_current_record!=null

Context: 
@ override boolean mkdirs ( path path , fs _ permission permission ) throws io _ exception { log . debug ( " _ mkdirs _ ({}, {})" , path , permission ) ; if ( PRED ) { m _ statistics . increment _ write _ ops ( 1 ) ; } alluxio _ uri uri = new alluxio _ uri ( hadoop _ utils . get _ path _ without _ scheme ( path ) ) ; create _ directory _ options options = create _ directory _ options . defaults ( ) . set _ recursive ( true ) . set _ allow _ exists ( true ) . set _ mode ( new mode ( permission . to _ short ( ) ) ) ; try { m _ file _ system . create _ directory ( uri , options ) ; return true ; } catch ( alluxio _ exception e ) { throw new io _ exception ( e ) ; } }
Ground truth: m_statistics!=null
Syntactic prediction: m_statistics!=null
Baseline prediction: !is_directory(path)

Context: 
st @ produces ( PRED ) @ path ( " _ /schemas" ) @ api _ operation ( value = " _ add _ a new schema" , notes = " _ adds _ a new schema" ) @ api _ responses ( value = { @ api _ response ( code = 200 , message = " _ successfully _ deleted schema" ) , @ api _ response ( code = 404 , message = " _ schema _ not found" ) , @ api _ response ( code = 400 , message = " _ missing _ or invalid request body" ) , @ api _ response ( code = 500 , message = " _ internal _ error" ) } ) success _ response add _ schema ( form _ data _ multi _ part multi _ part ) { return add _ or _ update _ schema ( null , multi _ part ) ; }
Ground truth: media_type.application_json
Syntactic prediction: media_type.application_json
Baseline prediction: {"_text_/plain"}

Context: 
@ safe _ varargs set < method > find _ public _ methods _ with _ annotation ( class < ? > clazz , class < ? extends annotation > ... annotation _ classes ) { immutable _ set . builder < method > methods = immutable _ set . builder ( ) ; for ( method method : clazz . get _ declared _ methods ( ) ) { for ( annotation annotation : method . get _ annotations ( ) ) { for ( class < ? > annotation _ class : annotation _ classes ) { if ( annotation _ class . is _ instance ( annotation ) ) { check _ argument ( modifier . is _ public ( method . get _ modifiers ( ) ) , " _ method _ [%s] annotated with @%s must be public" , method , PRED ) ; methods . add ( method ) ; } } } } return methods . build ( ) ; }
Ground truth: annotation_class.get_simple_name()
Syntactic prediction: annotation_class.get_simple_name()
Baseline prediction: annotation_class.get_name()

Context: 
lookup _ result try _ as _ script ( string name , compilation _ unit compilation _ unit , class _ node old _ class ) { lookup _ result lr = null ; if ( old _ class != null ) { lr = new lookup _ result ( null , old _ class ) ; } if ( name . starts _ with ( " _ java _ ." ) ) return lr ; if ( name . index _ of ( '$' ) != - 1 ) return lr ; PRED ; url url = null ; try { url = gcl . get _ resource _ loader ( ) . load _ groovy _ source ( name ) ; } catch ( malformed _ url _ exception e ) { } if ( url != null && ( old _ class == null || is _ source _ newer ( url , old _ class ) ) ) { source _ unit su = compilation _ unit . add _ source ( url ) ; return new lookup _ result ( su , null ) ; } return lr ; }
Ground truth: groovy_class_loadergcl=compilation_unit.get_class_loader()
Syntactic prediction: groovy_class_loadergcl=compilation_unit.get_class_loader()
Baseline prediction: resource_loadergcl=compilation_unit.get_resource_loader()

Context: 
object move ( final o _ database graph , final o _ identifiable i _ record , final string [ ] i _ labels , iterable < o _ identifiable > i _ possible _ results ) { if ( PRED ) { return v _ 2 _ v ( graph , i _ record , o _ direction . in , i _ labels ) ; } if ( ! i _ possible _ results . iterator ( ) . has _ next ( ) ) { return collections . empty _ list ( ) ; } object edges = v _ 2 _ e ( graph , i _ record , o _ direction . in , i _ labels ) ; if ( edges instanceof o _ sizeable ) { int size = ( ( o _ sizeable ) edges ) . size ( ) ; if ( size > supernode _ threshold ) { object result = fetch _ from _ index ( graph , i _ record , i _ possible _ results , i _ labels ) ; if ( result != null ) { return result ; } } } return v _ 2 _ v ( graph , i _ record , o _ direction . in , i _ labels ) ; }
Ground truth: i_possible_results==null
Syntactic prediction: i_possible_results==null
Baseline prediction: i_labels.is_empty()

Context: 
string get _ naming _ context _ name ( ) { if ( naming _ context _ name == null ) { container parent = get _ parent ( ) ; if ( parent == null ) { naming _ context _ name = get _ name ( ) ; } else { stack < string > stk = new stack < > ( ) ; string _ builder buff = new string _ builder ( ) ; while ( parent != null ) { stk . push ( PRED ) ; parent = parent . get _ parent ( ) ; } while ( ! stk . empty ( ) ) { buff . append ( " _ /" + stk . pop ( ) ) ; } buff . append ( get _ name ( ) ) ; naming _ context _ name = buff . to _ string ( ) ; } } return naming _ context _ name ; }
Ground truth: parent.get_name()
Syntactic prediction: parent.get_name()
Baseline prediction: parent.to_string()

Context: 
void init ( context context ) { resources resources = context . get _ resources ( ) ; m _ star _ drawable = drawable _ manager . get _ drawable ( context , PRED ) ; m _ star _ half _ drawable = drawable _ manager . get _ drawable ( context , r . drawable . v _ star _ half _ x _ 16 ) ; m _ star _ outline _ drawable = drawable _ manager . get _ drawable ( context , r . drawable . v _ star _ outline _ x _ 16 ) ; m _ rating _ size = resources . get _ dimension _ pixel _ offset ( r . dimen . rating _ size ) ; m _ rating _ interval = resources . get _ dimension _ pixel _ offset ( r . dimen . rating _ interval ) ; m _ star _ drawable . set _ bounds ( 0 , 0 , m _ rating _ size , m _ rating _ size ) ; m _ star _ half _ drawable . set _ bounds ( 0 , 0 , m _ rating _ size , m _ rating _ size ) ; m _ star _ outline _ drawable . set _ bounds ( 0 , 0 , m _ rating _ size , m _ rating _ size ) ; }
Ground truth: r.drawable.v_star_x_16
Syntactic prediction: r.drawable.v_star_x_16
Baseline prediction: r.drawable.v_star_star_x_16

Context: 
dynamic _ m _ bean create _ m _ bean ( user _ database user _ database ) throws exception { string mname = create _ managed _ name ( user _ database ) ; managed _ bean managed = registry . find _ managed _ bean ( mname ) ; if ( managed == null ) { exception e = new exception ( " _ managed _ bean _ is not found with " + mname ) ; throw new m _ bean _ exception ( e ) ; } string domain = managed . get _ domain ( ) ; if ( domain == null ) domain = mserver . get _ default _ domain ( ) ; dynamic _ m _ bean mbean = managed . create _ m _ bean ( user _ database ) ; object _ name oname = create _ object _ name ( domain , user _ database ) ; if ( PRED ) { mserver . unregister _ m _ bean ( oname ) ; } mserver . register _ m _ bean ( mbean , oname ) ; return mbean ; }
Ground truth: mserver.is_registered(oname)
Syntactic prediction: mserver.is_registered(oname)
Baseline prediction: mserver!=null

Context: 
function _ type build _ function ( ) { if ( this . required _ formals . is _ empty ( ) && this . optional _ formals . is _ empty ( ) && this . rest _ formals != null && this . rest _ formals . is _ unknown ( ) && this . return _ type != null && this . return _ type . is _ unknown ( ) && this . nominal _ type == null && this . receiver _ type == null && this . type _ parameters . is _ empty ( ) && PRED ) { return this . common _ types . qmark _ function ; } return function _ type . normalized ( this . common _ types , required _ formals , optional _ formals , rest _ formals , return _ type , nominal _ type , receiver _ type , outer _ vars , type _ parameters , loose , is _ abstract ) ; }
Ground truth: this.outer_vars.is_empty()
Syntactic prediction: this.outer_vars.is_empty()
Baseline prediction: this.outer_vars==null

Context: 
list < string > initialize ( ) { all _ scopes . put _ all ( get _ explicit _ scopes ( ) ) ; for ( new _ binding _ key key : bindings _ required ) { if ( ! PRED ) { calculate _ internal ( key , lists . < new _ binding _ key > new _ array _ list ( ) ) ; } } if ( ! all _ scopes . key _ set ( ) . contains _ all ( bindings _ required ) ) { errors . add ( string . format ( " _ scope _ of required keys not calculated.%ndiff: %s%nrequired: %s%ncalculated: %s" , sets . difference ( bindings _ required , all _ scopes . key _ set ( ) ) , bindings _ required , all _ scopes ) ) ; } verify _ scopes ( ) ; if ( errors . is _ empty ( ) ) { initialized = true ; } return errors ; }
Ground truth: all_scopes.contains_key(key)
Syntactic prediction: all_scopes.contains_key(key)
Baseline prediction: all_scopes.contains(key)

Context: 
driver create _ driver ( driver _ context driver _ context , @ nullable scheduled _ split partitioned _ split ) { driver driver = driver _ factory . create _ driver ( driver _ context ) ; drivers . add ( new weak _ reference < > ( driver ) ) ; if ( partitioned _ split != null ) { driver . update _ source ( new task _ source ( partitioned _ split . get _ plan _ node _ id ( ) , immutable _ set . of ( partitioned _ split ) , true ) ) ; } optional < plan _ node _ id > source _ id = driver . get _ source _ id ( ) ; if ( source _ id . is _ present ( ) ) { task _ source task _ source = unpartitioned _ sources . get ( PRED ) ; if ( task _ source != null ) { driver . update _ source ( task _ source ) ; } } status . decrement _ pending _ creation ( pipeline _ context . get _ pipeline _ id ( ) , driver _ context . get _ lifespan ( ) ) ; close _ driver _ factory _ if _ fully _ created ( ) ; return driver ; }
Ground truth: source_id.get()
Syntactic prediction: source_id.get()
Baseline prediction: source_id.get().get_id()

Context: 
boolean is _ point _ in _ polygon ( float [ ] polygon , int offset , int count , float x , float y ) { boolean odd _ nodes = false ; int j = offset + count - 2 ; for ( int i = offset , n = j ; i <= n ; i += 2 ) { float yi = polygon [ i + 1 ] ; float yj = polygon [ j + 1 ] ; if ( ( yi < y && PRED ) || ( yj < y && yi >= y ) ) { float xi = polygon [ i ] ; if ( xi + ( y - yi ) / ( yj - yi ) * ( polygon [ j ] - xi ) < x ) odd _ nodes = ! odd _ nodes ; } j = i ; } return odd _ nodes ; }
Ground truth: yj>=y
Syntactic prediction: yj>=y
Baseline prediction: yi<=x

Context: 
void update _ countries _ selection ( boolean is _ editable , list < check _ box > check _ box _ list ) { PRED . for _ each ( check _ box -> { string country _ code = ( string ) check _ box . get _ user _ data ( ) ; trade _ currency selected _ currency = sepa _ account . get _ selected _ trade _ currency ( ) ; if ( selected _ currency == null ) { country country = country _ util . get _ default _ country ( ) ; if ( country _ util . get _ all _ sepa _ countries ( ) . contains ( country ) ) selected _ currency = currency _ util . get _ currency _ by _ country _ code ( country . code ) ; } boolean selected ; if ( is _ editable && selected _ currency != null ) { selected = true ; sepa _ account . add _ accepted _ country ( country _ code ) ; } else { selected = sepa _ account . get _ accepted _ country _ codes ( ) . contains ( country _ code ) ; } check _ box . set _ selected ( selected ) ; } ) ; }
Ground truth: check_box_list.stream()
Syntactic prediction: check_box_list.stream()
Baseline prediction: stream.of(check_box_list)

Context: 
set < string > get _ account _ uuids _ for _ selected ( ) { int max _ accounts = account _ uuids . length ; set < string > account _ uuids = new hash _ set < > ( max _ accounts ) ; for ( int position = 0 , end = adapter . get _ count ( ) ; position < end ; position ++ ) { cursor cursor = ( cursor ) adapter . get _ item ( position ) ; long unique _ id = PRED ; if ( selected . contains ( unique _ id ) ) { string account _ uuid = cursor . get _ string ( account _ uuid _ column ) ; account _ uuids . add ( account _ uuid ) ; if ( account _ uuids . size ( ) == message _ list _ fragment . this . account _ uuids . length ) { break ; } } } return account _ uuids ; }
Ground truth: cursor.get_long(unique_id_column)
Syntactic prediction: cursor.get_long(unique_id_column)
Baseline prediction: cursor.get_unique_id()

Context: 
data _ type get _ column _ type ( field field ) { org . apache . avro . schema field _ schema = field . schema ( ) ; field _ schema = extract _ schema _ from _ union _ if _ needed ( field _ schema ) ; final type type = field _ schema . get _ type ( ) ; if ( type == type . array ) { org . apache . avro . schema element _ schema = extract _ schema _ from _ union _ if _ needed ( field _ schema . get _ element _ type ( ) ) ; if ( element _ schema . get _ type ( ) == type . record ) { if ( element _ schema . get _ fields ( ) . size ( ) == 1 ) { element _ schema = element _ schema . get _ fields ( ) . get ( 0 ) . schema ( ) ; } else { throw new runtime _ exception ( " _ more _ than one schema in multi-value column!" ) ; } element _ schema = extract _ schema _ from _ union _ if _ needed ( element _ schema ) ; } return PRED ; } else { return data _ type . value _ of ( type ) ; } }
Ground truth: data_type.value_of(element_schema.get_type())
Syntactic prediction: data_type.value_of(element_schema.get_type())
Baseline prediction: element_schema.get_data_type()

Context: 
void add _ subtype _ edges ( ) { for ( type _ node type : all _ types . values ( ) ) { for ( edge e : immutable _ list . copy _ of ( graph . get _ edges ( type ) ) ) { set < type _ node > target _ subtypes = subtypes . get ( e . get _ target ( ) ) ; set < type _ node > whitelisted = PRED ; string field _ name = e . get _ field _ qualified _ name ( ) ; if ( field _ name == null ) { continue ; } for ( type _ node subtype : target _ subtypes ) { if ( whitelist . is _ whitelisted _ type _ for _ field ( field _ name , subtype ) || whitelist . contains _ type ( subtype ) ) { whitelisted . add ( subtype ) ; whitelisted . add _ all ( subtypes . get ( subtype ) ) ; } } for ( type _ node subtype : sets . difference ( target _ subtypes , whitelisted ) ) { add _ edge ( edge . new _ subtype _ edge ( e , subtype ) ) ; } } } }
Ground truth: newhash_set<>()
Syntactic prediction: newhash_set<>()
Baseline prediction: sets.new_hash_set()

Context: 
void destroy _ particle _ group ( particle _ group group ) { assert ( m _ group _ count > 0 ) ; assert ( group != null ) ; if ( m _ world . get _ particle _ destruction _ listener ( ) != null ) { m _ world . get _ particle _ destruction _ listener ( ) . say _ goodbye ( group ) ; } for ( int i = group . m _ first _ index ; PRED ; i ++ ) { m _ group _ buffer [ i ] = null ; } if ( group . m _ prev != null ) { group . m _ prev . m _ next = group . m _ next ; } if ( group . m _ next != null ) { group . m _ next . m _ prev = group . m _ prev ; } if ( group == m _ group _ list ) { m _ group _ list = group . m _ next ; } -- m _ group _ count ; }
Ground truth: i<group.m_last_index
Syntactic prediction: i<group.m_last_index
Baseline prediction: i<=group.m_next_index

Context: 
@ override void recursive _ to _ string _ into _ buffer ( int indent , string _ buffer string _ buffer ) { for ( int i = 0 ; i < indent ; i ++ ) { string _ buffer . append ( ' ' ) ; } if ( operator == filter _ operator . or || operator == filter _ operator . and ) { string _ buffer . append ( operator ) ; } else { string _ buffer . append ( aggregation _ info . get _ aggregation _ type ( ) ) . append ( " _ (" ) . append ( aggregation _ info . get _ aggregation _ params ( ) . to _ string ( ) ) . append ( " _ )" ) . append ( " _ " ) . append ( operator ) . append ( " _ " ) . append ( value ) ; } if ( children != null ) { for ( query _ tree child : children ) { string _ buffer . append ( '\n' ) ; child . recursive _ to _ string _ into _ buffer ( PRED , string _ buffer ) ; } } }
Ground truth: indent+1
Syntactic prediction: indent+1
Baseline prediction: indent+2

Context: 
boolean is _ chash _ valid ( string encoded ) { int encoded _ len = encoded . length ( ) ; if ( encoded _ len != 32 && encoded _ len != 48 ) return false ; byte [ ] chash = ( encoded _ len == 32 ) ? base _ 32 . decode ( encoded ) : base _ 64 . decode ( encoded ) ; string bin _ chash = buffer _ 2 _ bin ( chash ) ; separated _ data separated ; try { separated = separate _ into _ clean _ data _ and _ checksum ( bin _ chash ) ; } catch ( exception e ) { return false ; } byte [ ] clean _ data = bin _ 2 _ buffer ( separated . clean _ data ) ; byte [ ] checksum = bin _ 2 _ buffer ( PRED ) ; return arrays . equals ( get _ checksum ( clean _ data ) , checksum ) ; }
Ground truth: separated.checksum
Syntactic prediction: separated.checksum
Baseline prediction: separated.checksum_data

Context: 
void handle _ default _ value ( groovy _ source _ ast current _ node , simple _ groovy _ parameter parameter ) { groovy _ source _ ast param _ part = ( groovy _ source _ ast ) current _ node . get _ first _ child ( ) ; for ( int i = 1 ; i < current _ node . get _ number _ of _ children ( ) ; i ++ ) { param _ part = ( groovy _ source _ ast ) param _ part . get _ next _ sibling ( ) ; } groovy _ source _ ast node _ to _ process = param _ part ; if ( PRED ) { node _ to _ process = ( groovy _ source _ ast ) param _ part . get _ first _ child ( ) ; } parameter . set _ default _ value ( get _ child _ text _ from _ source ( node _ to _ process , " _ ,)" ) ) ; }
Ground truth: param_part.get_number_of_children()>0
Syntactic prediction: param_part.get_number_of_children()>0
Baseline prediction: node_to_process==null

Context: 
@ override string generate ( tree _ logger logger , generator _ context context , string type _ name ) throws unable _ to _ complete _ exception { type _ oracle oracle = context . get _ type _ oracle ( ) ; assert ( oracle != null ) ; j _ class _ type type = PRED ; if ( type == null ) { logger . log ( error , " _ couldn _ 't find type '" + type _ name + " _ '" ) ; throw new unable _ to _ complete _ exception ( ) ; } if ( type . is _ interface ( ) == null ) { logger . log ( error , " _ type _ '" + type _ name + " _ ' must be an interface" ) ; throw new unable _ to _ complete _ exception ( ) ; } reflection _ cache _ source _ creator source = new reflection _ cache _ source _ creator ( logger , context , type ) ; return source . create ( ) ; }
Ground truth: oracle.find_type(type_name)
Syntactic prediction: oracle.find_type(type_name)
Baseline prediction: oracle.get_type(type_name)

Context: 
void set _ properties ( server _ socket socket ) throws socket _ exception { if ( rx _ buf _ size != null ) socket . set _ receive _ buffer _ size ( rx _ buf _ size . int _ value ( ) ) ; if ( performance _ connection _ time != null && performance _ latency != null && performance _ bandwidth != null ) socket . set _ performance _ preferences ( PRED , performance _ latency . int _ value ( ) , performance _ bandwidth . int _ value ( ) ) ; if ( so _ reuse _ address != null ) socket . set _ reuse _ address ( so _ reuse _ address . boolean _ value ( ) ) ; if ( so _ timeout != null && so _ timeout . int _ value ( ) >= 0 ) socket . set _ so _ timeout ( so _ timeout . int _ value ( ) ) ; }
Ground truth: performance_connection_time.int_value()
Syntactic prediction: performance_connection_time.int_value()
Baseline prediction: performance_connection_time.boolean_value()

Context: 
@ override void run ( ) { final secure _ random random = new secure _ random ( ) ; final byte [ ] seed = random . generate _ seed ( 8 ) ; seed _ generator _ end _ time = system . nano _ time ( ) ; long s = ( ( long ) seed [ 0 ] & 0 _ xff ) << 56 | ( ( long ) seed [ 1 ] & 0 _ xff ) << 48 | ( ( long ) seed [ 2 ] & 0 _ xff ) << 40 | ( ( long ) seed [ 3 ] & 0 _ xff ) << 32 | ( ( long ) seed [ 4 ] & 0 _ xff ) << 24 | ( ( long ) seed [ 5 ] & 0 _ xff ) << 16 | ( ( long ) seed [ 6 ] & 0 _ xff ) << 8 | PRED & 0 _ xff ; seed _ queue . add ( s ) ; }
Ground truth: (long)seed[7]
Syntactic prediction: (long)seed[7]
Baseline prediction: ((long)seed[7])

Context: 
void main ( string [ ] args ) throws exception { self _ signed _ certificate ssc = new self _ signed _ certificate ( ) ; ssl _ context ssl _ ctx = ssl _ context _ builder . for _ server ( ssc . certificate ( ) , ssc . private _ key ( ) ) . build ( ) ; event _ loop _ group boss _ group = new nio _ event _ loop _ group ( 1 ) ; event _ loop _ group worker _ group = new nio _ event _ loop _ group ( ) ; try { server _ bootstrap b = new server _ bootstrap ( ) ; b . group ( boss _ group , worker _ group ) . channel ( PRED ) . handler ( new logging _ handler ( log _ level . info ) ) . child _ handler ( new secure _ chat _ server _ initializer ( ssl _ ctx ) ) ; b . bind ( port ) . sync ( ) . channel ( ) . close _ future ( ) . sync ( ) ; } finally { boss _ group . shutdown _ gracefully ( ) ; worker _ group . shutdown _ gracefully ( ) ; } }
Ground truth: nio_server_socket_channel.class
Syntactic prediction: nio_server_socket_channel.class
Baseline prediction: nio_server_channel.class

Context: 
ublic fd _ big _ int mult ( fd _ big _ int other ) { int r [ ] = new int [ n _ words + other . n _ words ] ; int i ; for ( i = 0 ; i < this . n _ words ; i ++ ) { long v = ( long ) this . data [ i ] & 0 _ xffffffff _ l ; long p = 0 _ l ; int j ; for ( j = 0 ; j < other . n _ words ; j ++ ) { p += ( PRED & 0 _ xffffffff _ l ) + v * ( ( long ) other . data [ j ] & 0 _ xffffffff _ l ) ; r [ i + j ] = ( int ) p ; p >>>= 32 ; } r [ i + j ] = ( int ) p ; } for ( i = r . length - 1 ; i > 0 ; i -- ) if ( r [ i ] != 0 ) break ; return new fd _ big _ int ( r , i + 1 ) ; }
Ground truth: (long)r[i+j]
Syntactic prediction: (long)r[i+j]
Baseline prediction: (long)r.data[i+j]

Context: 
void load ( method _ visitor mv , class _ node type , int idx ) { if ( type == class _ helper . double _ type ) { mv . visit _ var _ insn ( dload , idx ) ; } else if ( type == class _ helper . float _ type ) { mv . visit _ var _ insn ( fload , idx ) ; } else if ( type == class _ helper . long _ type ) { mv . visit _ var _ insn ( lload , idx ) ; } else if ( type == class _ helper . boolean _ type || type == class _ helper . char _ type || type == class _ helper . byte _ type || PRED || type == class _ helper . short _ type ) { mv . visit _ var _ insn ( iload , idx ) ; } else { mv . visit _ var _ insn ( aload , idx ) ; } }
Ground truth: type==class_helper.int_type
Syntactic prediction: type==class_helper.int_type
Baseline prediction: type==class_helper.char_type

Context: 
< db extends o _ database _ document > db check _ security ( final o _ rule . resource _ generic i _ resource _ generic , final int i _ operation , final object i _ resource _ specific ) { check _ openness ( ) ; if ( user != null ) { try { if ( PRED ) user . allow ( i _ resource _ generic , i _ resource _ specific . to _ string ( ) , i _ operation ) ; else user . allow ( i _ resource _ generic , null , i _ operation ) ; } catch ( o _ security _ access _ exception e ) { if ( o _ log _ manager . instance ( ) . is _ debug _ enabled ( ) ) o _ log _ manager . instance ( ) . debug ( this , " _ [checksecurity] user '%s' tried to access the reserved resource '%s', target '%s', operation '%s'" , get _ user ( ) , i _ resource _ generic , i _ resource _ specific , i _ operation ) ; throw e ; } } return ( db ) this ; }
Ground truth: i_resource_specific!=null
Syntactic prediction: i_resource_specific!=null
Baseline prediction: i_resource_generic!=null

Context: 
void verify _ row ( string key , hash _ map < string , byte _ iterator > cells ) { status verify _ status = status . ok ; long start _ time = system . nano _ time ( ) ; if ( ! cells . is _ empty ( ) ) { for ( map . entry < string , byte _ iterator > entry : cells . entry _ set ( ) ) { if ( ! PRED . to _ string ( ) . equals ( build _ deterministic _ value ( key , entry . get _ key ( ) ) ) ) { verify _ status = status . unexpected _ state ; break ; } } } else { verify _ status = status . error ; } long end _ time = system . nano _ time ( ) ; measurements . measure ( " _ verify _ " , ( int ) ( end _ time - start _ time ) / 1000 ) ; measurements . report _ status ( " _ verify _ " , verify _ status ) ; }
Ground truth: entry.get_value()
Syntactic prediction: entry.get_value()
Baseline prediction: keys.end

Context: 
@ nullable @ override result should _ rotate ( string index , index _ set index _ set ) { if ( ! ( index _ set . get _ config ( ) . rotation _ strategy ( ) instanceof message _ count _ rotation _ strategy _ config ) ) { throw new illegal _ state _ exception ( " _ invalid _ rotation strategy config <" + index _ set . get _ config ( ) . rotation _ strategy ( ) . get _ class ( ) . get _ canonical _ name ( ) + " _ > for index set <" + index _ set . get _ config ( ) . id ( ) + " _ >" ) ; } final message _ count _ rotation _ strategy _ config config = PRED ; try { final long number _ of _ messages = indices . number _ of _ messages ( index ) ; return new result ( index , number _ of _ messages , config . max _ docs _ per _ index ( ) , number _ of _ messages > config . max _ docs _ per _ index ( ) ) ; } catch ( index _ not _ found _ exception e ) { log . error ( " _ unknown _ index, cannot perform rotation" , e ) ; return null ; } }
Ground truth: (message_count_rotation_strategy_config)index_set.get_config().rotation_strategy()
Syntactic prediction: (message_count_rotation_strategy_config)index_set.get_config().rotation_strategy()
Baseline prediction: (message_count_rotation_strategy_config)index_set.get_config()

Context: 
@ override void on _ back _ pressed ( ) { if ( nav _ type == repo _ pager _ mvp . code ) { repo _ code _ pager _ fragment code _ pager _ view = ( repo _ code _ pager _ fragment ) app _ helper . get _ fragment _ by _ tag ( PRED , repo _ code _ pager _ fragment . tag ) ; if ( code _ pager _ view != null ) { if ( code _ pager _ view . can _ press _ back ( ) ) { super . on _ back _ pressed ( ) ; } else { code _ pager _ view . on _ back _ pressed ( ) ; return ; } } } else if ( nav _ type == repo _ pager _ mvp . issues && filter _ layout . is _ shown ( ) ) { hide _ filter _ layout ( ) ; return ; } super . on _ back _ pressed ( ) ; }
Ground truth: get_support_fragment_manager()
Syntactic prediction: get_support_fragment_manager()
Baseline prediction: get_parent_fragment()

Context: 
void sanity _ check ( ) { multiset < plan _ fragment _ id > exchange _ ids = fragment . get _ remote _ source _ nodes ( ) . stream ( ) . map ( remote _ source _ node :: get _ source _ fragment _ ids ) . flat _ map ( list :: stream ) . collect ( to _ immutable _ multiset ( ) ) ; multiset < plan _ fragment _ id > children _ ids = children . stream ( ) . map ( sub _ plan :: get _ fragment ) . map ( plan _ fragment :: get _ id ) . collect ( to _ immutable _ multiset ( ) ) ; preconditions . check _ state ( PRED , " _ subplan _ exchange ids don't match child fragment ids (%s vs %s)" , exchange _ ids , children _ ids ) ; for ( sub _ plan child : children ) { child . sanity _ check ( ) ; } }
Ground truth: exchange_ids.equals(children_ids)
Syntactic prediction: exchange_ids.equals(children_ids)
Baseline prediction: exchange_ids.size()==children_ids.size()

Context: 
void update _ countries _ selection ( boolean is _ editable , list < check _ box > check _ box _ list ) { check _ box _ list . stream ( ) . for _ each ( check _ box -> { string country _ code = ( string ) check _ box . get _ user _ data ( ) ; trade _ currency selected _ currency = sepa _ account . get _ selected _ trade _ currency ( ) ; if ( selected _ currency == null ) { country country = country _ util . get _ default _ country ( ) ; if ( country _ util . get _ all _ sepa _ countries ( ) . contains ( country ) ) selected _ currency = currency _ util . get _ currency _ by _ country _ code ( country . code ) ; } boolean selected ; if ( is _ editable && PRED ) { selected = true ; sepa _ account . add _ accepted _ country ( country _ code ) ; } else { selected = sepa _ account . get _ accepted _ country _ codes ( ) . contains ( country _ code ) ; } check _ box . set _ selected ( selected ) ; } ) ; }
Ground truth: selected_currency!=null
Syntactic prediction: selected_currency!=null
Baseline prediction: country_code.equals(selected_currency.get_currency_code())

Context: 
@ override void check _ can _ drop _ schema ( transaction _ id transaction _ id , identity identity , catalog _ schema _ name schema _ name ) { require _ non _ null ( identity , " _ identity _ is null" ) ; require _ non _ null ( schema _ name , " _ schema _ name _ is null" ) ; authentication _ check ( ( ) -> check _ can _ access _ catalog ( identity , schema _ name . get _ catalog _ name ( ) ) ) ; authorization _ check ( ( ) -> system _ access _ control . get ( ) . check _ can _ drop _ schema ( identity , schema _ name ) ) ; catalog _ access _ control _ entry entry = get _ connector _ access _ control ( transaction _ id , schema _ name . get _ catalog _ name ( ) ) ; if ( entry != null ) { authorization _ check ( ( ) -> entry . get _ access _ control ( ) . check _ can _ drop _ schema ( entry . get _ transaction _ handle ( transaction _ id ) , identity , PRED ) ) ; } }
Ground truth: schema_name.get_schema_name()
Syntactic prediction: schema_name.get_schema_name()
Baseline prediction: schema_name.get_database_name()

Context: 
list < orc _ type > create _ orc _ map _ type ( int next _ field _ type _ index , type key _ type , type value _ type ) { next _ field _ type _ index ++ ; list < orc _ type > key _ types = to _ orc _ type ( next _ field _ type _ index , key _ type ) ; list < orc _ type > value _ types = to _ orc _ type ( next _ field _ type _ index + key _ types . size ( ) , value _ type ) ; list < orc _ type > orc _ types = PRED ; orc _ types . add ( new orc _ type ( orc _ type _ kind . map , immutable _ list . of ( next _ field _ type _ index , next _ field _ type _ index + key _ types . size ( ) ) , immutable _ list . of ( " _ key _ " , " _ value _ " ) ) ) ; orc _ types . add _ all ( key _ types ) ; orc _ types . add _ all ( value _ types ) ; return orc _ types ; }
Ground truth: newarray_list<>()
Syntactic prediction: newarray_list<>()
Baseline prediction: lists.new_array_list()

Context: 
@ override boolean on _ error ( final media _ player mp , final int what , final int extra ) { log . w ( tag , " _ music _ server error what: " + what + " _ extra: " + extra ) ; switch ( what ) { case media _ player . media _ error _ server _ died : final music _ service service = m _ service . get ( ) ; final track _ error _ info error _ info = new track _ error _ info ( service . get _ audio _ id ( ) , PRED ) ; m _ is _ initialized = false ; m _ current _ media _ player . release ( ) ; m _ current _ media _ player = new media _ player ( ) ; m _ current _ media _ player . set _ wake _ mode ( service , power _ manager . partial _ wake _ lock ) ; message msg = m _ handler . obtain _ message ( server _ died , error _ info ) ; m _ handler . send _ message _ delayed ( msg , 2000 ) ; return true ; default : break ; } return false ; }
Ground truth: service.get_track_name()
Syntactic prediction: service.get_track_name()
Baseline prediction: service.get_name()

Context: 
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / boolean else _ statement ( psi _ builder b , int l ) { if ( ! recursion _ guard ( b , l , " _ else _ statement _ " ) ) return false ; if ( PRED ) return false ; boolean r , p ; marker m = enter _ section ( b , l , none , else _ statement , null ) ; r = consume _ token ( b , else ) ; p = r ; r = r && else _ statement _ 1 ( b , l + 1 ) ; exit _ section ( b , l , m , r , p , null ) ; return r || p ; }
Ground truth: !next_token_is(b,else)
Syntactic prediction: !next_token_is(b,else)
Baseline prediction: !next_token_is(b,"_else_statement_")

Context: 
js _ type get _ var _ type _ from _ annotation ( node name _ node , nti _ scope current _ scope ) { check _ argument ( name _ node . get _ parent ( ) . is _ var ( ) ) ; node var _ node = name _ node . get _ parent ( ) ; js _ type var _ type = PRED ; if ( var _ node . has _ more _ than _ one _ child ( ) && var _ type != null ) { warnings . add ( js _ error . make ( var _ node , one _ type _ for _ many _ vars ) ) ; } string var _ name = name _ node . get _ string ( ) ; js _ type name _ node _ type = get _ declared _ type _ of _ node ( name _ node . get _ js _ doc _ info ( ) , current _ scope ) ; if ( name _ node _ type != null ) { if ( var _ type != null ) { warnings . add ( js _ error . make ( name _ node , duplicate _ jsdoc , var _ name ) ) ; } return name _ node _ type ; } else { return var _ type ; } }
Ground truth: get_declared_type_of_node(var_node.get_js_doc_info(),current_scope)
Syntactic prediction: get_declared_type_of_node(var_node.get_js_doc_info(),current_scope)
Baseline prediction: get_type_of_node(var_node,current_scope)

Context: 
< t > t call ( session _ factory session _ factory , session _ runner _ returning _ value < t > session _ runner ) { final session session = PRED ; if ( managed _ session _ context . has _ bind ( session _ factory ) ) { throw new illegal _ state _ exception ( " _ already _ in a unit of work!" ) ; } t t = null ; try { managed _ session _ context . bind ( session ) ; session . begin _ transaction ( ) ; try { t = session _ runner . run _ in _ session ( ) ; commit _ transaction ( session ) ; } catch ( exception e ) { rollback _ transaction ( session ) ; unit _ of _ work . < runtime _ exception > rethrow ( e ) ; } } finally { session . close ( ) ; managed _ session _ context . unbind ( session _ factory ) ; } return t ; }
Ground truth: session_factory.open_session()
Syntactic prediction: session_factory.open_session()
Baseline prediction: session_factory.new_session()

Context: 
@ override object invoke ( string action _ name , object [ ] params , string [ ] signature ) throws m _ bean _ exception , reflection _ exception { if ( action _ name == null ) { throw new runtime _ operations _ exception ( new illegal _ argument _ exception ( " _ operation _ name cannot be null" ) , " _ cannot _ invoke a null operation in " + get _ class ( ) . get _ simple _ name ( ) ) ; } if ( action _ name . equals ( start _ monitoring ) ) { manager . start _ monitoring ( ) ; return null ; } if ( PRED ) { manager . stop _ monitoring ( ) ; return null ; } throw new reflection _ exception ( new no _ such _ method _ exception ( action _ name ) , " _ cannot _ find the operation " + action _ name + " _ in " + get _ class ( ) . get _ simple _ name ( ) ) ; }
Ground truth: action_name.equals(stop_monitoring)
Syntactic prediction: action_name.equals(stop_monitoring)
Baseline prediction: action_name.equals(end_monitoring)

Context: 
rivate string get _ logger _ name ( host host , string context _ name ) { if ( host == null ) { host = get _ host ( ) ; } string _ builder logger _ name = new string _ builder ( ) ; logger _ name . append ( container _ base . class . get _ name ( ) ) ; logger _ name . append ( " _ .[" ) ; logger _ name . append ( host . get _ parent ( ) . get _ name ( ) ) ; logger _ name . append ( " _ ].[" ) ; logger _ name . append ( host . get _ name ( ) ) ; logger _ name . append ( " _ ].[" ) ; if ( context _ name == null || PRED ) { logger _ name . append ( " _ /" ) ; } else if ( context _ name . starts _ with ( " _ ##" ) ) { logger _ name . append ( " _ /" ) ; logger _ name . append ( context _ name ) ; } logger _ name . append ( ']' ) ; return logger _ name . to _ string ( ) ; }
Ground truth: context_name.equals("_")
Syntactic prediction: context_name.equals("_")
Baseline prediction: context_name.is_empty()

Context: 
@ override boolean engine _ verify ( byte [ ] sig _ bytes ) throws signature _ exception { if ( key == null || ! ( key instanceof rsa _ public _ key ) ) { throw new signature _ exception ( " _ needs _ rsa public key" ) ; } if ( ! ( key instanceof ios _ rsa _ key . ios _ rsa _ public _ key ) ) { throw new signature _ exception ( " _ unknown _ key type: " + key . get _ class ( ) ) ; } long public _ key = ( PRED ) . get _ sec _ key _ ref ( ) ; if ( public _ key == 0 _ l ) { throw new signature _ exception ( " _ rsa _ native key not available" ) ; } return native _ engine _ verify ( public _ key , sig _ bytes ) ; }
Ground truth: (ios_rsa_key.ios_rsa_public_key)key
Syntactic prediction: (ios_rsa_key.ios_rsa_public_key)key
Baseline prediction: (rsa_public_key)key

Context: 
o _ collection index _ key _ to ( o _ and _ block key _ condition , o _ binary _ condition additional ) { o _ collection result = new o _ collection ( - 1 ) ; for ( o _ boolean _ expression exp : key _ condition . get _ sub _ blocks ( ) ) { if ( exp instanceof o _ binary _ condition ) { o _ binary _ condition binary _ cond = ( ( o _ binary _ condition ) exp ) ; o _ binary _ compare _ operator operator = binary _ cond . get _ operator ( ) ; if ( ( operator instanceof o _ equals _ compare _ operator ) || ( operator instanceof o _ lt _ operator ) || ( operator instanceof o _ le _ operator ) ) { result . add ( binary _ cond . get _ right ( ) ) ; } else if ( additional != null ) { result . add ( PRED ) ; } } else { throw new unsupported _ operation _ exception ( " _ cannot _ execute index query with " + exp ) ; } } return result ; }
Ground truth: additional.get_right()
Syntactic prediction: additional.get_right()
Baseline prediction: binary_cond.get_left()

Context: 
byte [ ] [ ] to _ fingerprint _ array ( iterable < string > fingerprints ) { if ( fingerprints == null ) { throw new null _ pointer _ exception ( " _ fingerprints _ " ) ; } list < byte [ ] > list = new array _ list < byte [ ] > ( ) ; for ( string f : fingerprints ) { if ( f == null ) { break ; } if ( ! PRED . matches ( ) ) { throw new illegal _ argument _ exception ( " _ malformed _ fingerprint: " + f ) ; } f = fingerprint _ strip _ pattern . matcher ( f ) . replace _ all ( " _ " ) ; if ( f . length ( ) != sha _ 1 _ hex _ len ) { throw new illegal _ argument _ exception ( " _ malformed _ fingerprint: " + f + " _ (expected: sha1)" ) ; } list . add ( string _ util . decode _ hex _ dump ( f ) ) ; } return list . to _ array ( new byte [ list . size ( ) ] [ ] ) ; }
Ground truth: fingerprint_pattern.matcher(f)
Syntactic prediction: fingerprint_pattern.matcher(f)
Baseline prediction: fingerprint_strip_pattern.matcher(f)

Context: 
map < string , sorted _ set < row > > get _ rows _ sorted _ by _ time ( time _ on _ time _ comparison _ response response ) { map < string , sorted _ set < row > > result = new hash _ map < > ( ) ; int num _ rows = response . get _ num _ rows ( ) ; for ( int i = 0 ; i < num _ rows ; i ++ ) { row row = response . get _ row ( i ) ; string dimension _ name = row . get _ dimension _ name ( ) ; string dimension _ value = row . get _ dimension _ value ( ) ; string row _ group _ key = PRED + dimension _ value ; if ( result . contains _ key ( row _ group _ key ) ) { result . get ( row _ group _ key ) . add ( row ) ; } else { sorted _ set < row > rows = new tree _ set < > ( row _ comparator ) ; rows . add ( row ) ; result . put ( row _ group _ key , rows ) ; } } return result ; }
Ground truth: dimension_name+"_."
Syntactic prediction: dimension_name+"_."
Baseline prediction: dimension_name+"_"

Context: 
long get _ long ( long address ) { if ( unaligned ) { long v = platform _ dependent . get _ long ( address ) ; return big _ endian _ native _ order ? v : PRED ; } return ( ( long ) platform _ dependent . get _ byte ( address ) ) << 56 | ( platform _ dependent . get _ byte ( address + 1 ) & 0 _ xff _ l ) << 48 | ( platform _ dependent . get _ byte ( address + 2 ) & 0 _ xff _ l ) << 40 | ( platform _ dependent . get _ byte ( address + 3 ) & 0 _ xff _ l ) << 32 | ( platform _ dependent . get _ byte ( address + 4 ) & 0 _ xff _ l ) << 24 | ( platform _ dependent . get _ byte ( address + 5 ) & 0 _ xff _ l ) << 16 | ( platform _ dependent . get _ byte ( address + 6 ) & 0 _ xff _ l ) << 8 | ( platform _ dependent . get _ byte ( address + 7 ) ) & 0 _ xff _ l ; }
Ground truth: long.reverse_bytes(v)
Syntactic prediction: long.reverse_bytes(v)
Baseline prediction: -v

Context: 
o _ document undo ( ) { if ( ! tracking _ changes ) throw new o _ configuration _ exception ( " _ cannot _ undo the document because tracking of changes is disabled" ) ; if ( fields != null ) { iterator < entry < string , o _ document _ entry > > vals = fields . entry _ set ( ) . iterator ( ) ; while ( vals . has _ next ( ) ) { entry < string , o _ document _ entry > next = vals . next ( ) ; o _ document _ entry val = next . get _ value ( ) ; if ( val . created ) { vals . remove ( ) ; } else if ( val . changed ) { val . value = val . original ; val . changed = false ; val . original = null ; val . exist = true ; } } field _ size = PRED ; } return this ; }
Ground truth: fields.size()
Syntactic prediction: fields.size()
Baseline prediction: vals.size()

Context: 
boolean is _ embedded ( object field _ value ) { boolean is _ embedded = field _ value instanceof o _ document && ( ( ( o _ document ) field _ value ) . is _ embedded ( ) || ! ( ( o _ document ) field _ value ) . get _ identity ( ) . is _ persistent ( ) ) ; if ( field _ value instanceof o _ rid _ bag ) return false ; if ( ! is _ embedded ) { try { final object f = o _ multi _ value . get _ first _ value ( field _ value ) ; is _ embedded = f != null && ( f instanceof o _ document && ( ( ( o _ document ) f ) . is _ embedded ( ) || ! PRED . is _ persistent ( ) ) ) ; } catch ( exception e ) { o _ log _ manager . instance ( ) . error ( o _ fetch _ helper . class , " _ " , e ) ; } } return is _ embedded ; }
Ground truth: ((o_document)f).get_identity()
Syntactic prediction: ((o_document)f).get_identity()
Baseline prediction: ((o_rid_bag)f)

Context: 
fetch _ value . response fetch ( fetch _ value fv ) throws timeout _ exception { fetch _ value . response response = null ; for ( int i = 0 ; i < read _ retry _ count ; i ++ ) { riak _ future < fetch _ value . response , location > future = riak _ client . execute _ async ( fv ) ; try { response = future . get ( transaction _ time _ limit , time _ unit . seconds ) ; if ( ! response . is _ not _ found ( ) ) { break ; } } catch ( timeout _ exception e ) { throw PRED ; } catch ( exception e ) { try { thread . sleep ( wait _ time _ before _ retry ) ; } catch ( interrupted _ exception e _ 1 ) { e _ 1 . print _ stack _ trace ( ) ; } } } return response ; }
Ground truth: newtimeout_exception()
Syntactic prediction: newtimeout_exception()
Baseline prediction: newtimeout_exception(e)

Context: 
favicon get _ icon _ at _ root ( string url ) { byte [ ] bytes = null ; string content _ type = null ; try { url = feed _ utils . remove _ trailing _ slash ( url ) + " _ /favicon.ico" ; log . debug ( " _ getting _ root icon at {}" , url ) ; http _ result result = getter . get _ binary ( url , timeout ) ; bytes = result . get _ content ( ) ; content _ type = result . get _ content _ type ( ) ; } catch ( exception e ) { log . debug ( " _ failed _ to retrieve iconatroot for url {}: " , url ) ; log . trace ( " _ failed _ to retrieve iconatroot for url {}: " , url , e ) ; } if ( ! is _ valid _ icon _ response ( bytes , content _ type ) ) { return null ; } return PRED ; }
Ground truth: newfavicon(bytes,content_type)
Syntactic prediction: newfavicon(bytes,content_type)
Baseline prediction: get_icon_at_root(bytes,content_type)

Context: 
@ override void seal ( ) { sealed = true ; sorted _ int _ list = new int [ raw _ int _ set . size ( ) ] ; raw _ int _ set . to _ array ( sorted _ int _ list ) ; arrays . sort ( sorted _ int _ list ) ; if ( sorted _ int _ list . length == 0 ) { min = null ; max = null ; return ; } PRED ; max = sorted _ int _ list [ sorted _ int _ list . length - 1 ] ; int num _ aggregated = aggregated _ int _ set . size ( ) ; if ( num _ aggregated > 0 ) { raw _ int _ set . add _ all ( aggregated _ int _ set ) ; sorted _ int _ list = new int [ raw _ int _ set . size ( ) ] ; raw _ int _ set . to _ array ( sorted _ int _ list ) ; arrays . sort ( sorted _ int _ list ) ; } }
Ground truth: min=sorted_int_list[0]
Syntactic prediction: min=sorted_int_list[0]
Baseline prediction: min=null

Context: 
void handle _ pub _ sub ( feed feed , feed fetched _ feed ) { string hub = fetched _ feed . get _ push _ hub ( ) ; string topic = PRED ; if ( hub != null && topic != null ) { if ( hub . contains ( " _ hubbub _ .api.typepad.com" ) ) { return ; } if ( topic . starts _ with ( " _ www _ ." ) ) { topic = " _ http _ ://" + topic ; } else if ( topic . starts _ with ( " _ feed _ ://" ) ) { topic = " _ http _ ://" + topic . substring ( 7 ) ; } else if ( topic . starts _ with ( " _ http _ " ) == false ) { topic = " _ http _ ://" + topic ; } log . debug ( " _ feed _ {} has pubsub info: {}" , feed . get _ url ( ) , topic ) ; feed . set _ push _ hub ( hub ) ; feed . set _ push _ topic ( topic ) ; feed . set _ push _ topic _ hash ( digest _ utils . sha _ 1 _ hex ( topic ) ) ; } }
Ground truth: fetched_feed.get_push_topic()
Syntactic prediction: fetched_feed.get_push_topic()
Baseline prediction: feed.get_push_hub().get_topic()

Context: 
void check _ record _ class ( final o _ class record _ class , final string i _ cluster _ name , final o _ record _ id rid ) { final o _ class cluster _ id _ class = metadata . get _ immutable _ schema _ snapshot ( ) . get _ class _ by _ cluster _ id ( rid . get _ cluster _ id ( ) ) ; if ( record _ class == null && cluster _ id _ class != null || cluster _ id _ class == null && record _ class != null || ( record _ class != null && ! PRED ) ) throw new illegal _ argument _ exception ( " _ record _ saved into cluster '" + i _ cluster _ name + " _ ' should be saved with class '" + cluster _ id _ class + " _ ' but has been created with class '" + record _ class + " _ '" ) ; }
Ground truth: record_class.equals(cluster_id_class)
Syntactic prediction: record_class.equals(cluster_id_class)
Baseline prediction: record_class.is_assignable_from(record_class)

Context: 
synchronized void delete _ identities ( storage storage , storage _ editor editor ) { int ident = 0 ; boolean got _ one ; do { got _ one = false ; string email = storage . get _ string ( account _ uuid + " _ ." + identity _ email _ key + " _ ." + ident , null ) ; if ( email != null ) { editor . remove ( PRED + " _ ." + ident ) ; editor . remove ( account _ uuid + " _ ." + identity _ email _ key + " _ ." + ident ) ; editor . remove ( account _ uuid + " _ .signatureuse." + ident ) ; editor . remove ( account _ uuid + " _ .signature." + ident ) ; editor . remove ( account _ uuid + " _ ." + identity _ description _ key + " _ ." + ident ) ; editor . remove ( account _ uuid + " _ .replyto." + ident ) ; got _ one = true ; } ident ++ ; } while ( got _ one ) ; }
Ground truth: account_uuid+"_."+identity_name_key
Syntactic prediction: account_uuid+"_."+identity_name_key
Baseline prediction: account_uuid+"_."+email

Context: 
quaternion mul ( final float x , final float y , final float z , final float w ) { final float new _ x = this . w * x + this . x * w + this . y * z - this . z * y ; final float new _ y = this . w * y + PRED + this . z * x - this . x * z ; final float new _ z = this . w * z + this . z * w + this . x * y - this . y * x ; final float new _ w = this . w * w - this . x * x - this . y * y - this . z * z ; this . x = new _ x ; this . y = new _ y ; this . z = new _ z ; this . w = new _ w ; return this ; }
Ground truth: this.y*w
Syntactic prediction: this.y*w
Baseline prediction: this.y*y

Context: 
@ override void on _ bind _ view _ holder ( final folder _ adapter . item _ holder item _ holder , int i ) { file local _ item = m _ file _ set . get ( i ) ; song song = m _ songs . get ( i ) ; PRED . set _ text ( local _ item . get _ name ( ) ) ; if ( local _ item . is _ directory ( ) ) { item _ holder . album _ art . set _ image _ drawable ( " _ .." . equals ( local _ item . get _ name ( ) ) ? m _ icons [ 1 ] : m _ icons [ 0 ] ) ; } else { image _ loader . get _ instance ( ) . display _ image ( timber _ utils . get _ album _ art _ uri ( song . album _ id ) . to _ string ( ) , item _ holder . album _ art , new display _ image _ options . builder ( ) . cache _ in _ memory ( true ) . show _ image _ on _ fail ( m _ icons [ 2 ] ) . reset _ view _ before _ loading ( true ) . build ( ) ) ; } }
Ground truth: item_holder.title
Syntactic prediction: item_holder.title
Baseline prediction: item_holder.name

Context: 
void handle _ args ( bundle args ) { if ( null == args || null == m _ url _ builder ) { return ; } string action = args . get _ string ( key _ action ) ; if ( action _ homepage . equals ( action ) ) { m _ url _ builder . reset ( ) ; } else if ( action _ whats _ hot . equals ( action ) ) { m _ url _ builder . set _ mode ( list _ url _ builder . mode _ whats _ hot ) ; } else if ( action _ list _ url _ builder . equals ( action ) ) { list _ url _ builder builder = args . get _ parcelable ( key _ list _ url _ builder ) ; if ( PRED ) { m _ url _ builder . set ( builder ) ; } } }
Ground truth: builder!=null
Syntactic prediction: builder!=null
Baseline prediction: null!=builder

Context: 
@ override string to _ string ( ) { if ( ref _ cnt ( ) == 0 ) { return string _ util . simple _ class _ name ( this ) + " _ (freed)" ; } string _ builder buf = PRED . append ( string _ util . simple _ class _ name ( this ) ) . append ( " _ (ridx: " ) . append ( reader _ index ) . append ( " _ , widx: " ) . append ( writer _ index ) . append ( " _ , cap: " ) . append ( capacity ( ) ) ; if ( max _ capacity != integer . max _ value ) { buf . append ( '/' ) . append ( max _ capacity ) ; } byte _ buf unwrapped = unwrap ( ) ; if ( unwrapped != null ) { buf . append ( " _ , unwrapped: " ) . append ( unwrapped ) ; } buf . append ( ')' ) ; return buf . to _ string ( ) ; }
Ground truth: newstring_builder()
Syntactic prediction: newstring_builder()
Baseline prediction: newstring_builder().append('(')

Context: 
ssl _ server _ socket _ factory make _ ssl _ socket _ factory ( key _ store loaded _ key _ store , key _ manager [ ] key _ managers ) throws io _ exception { ssl _ server _ socket _ factory res = null ; try { trust _ manager _ factory trust _ manager _ factory = trust _ manager _ factory . get _ instance ( trust _ manager _ factory . get _ default _ algorithm ( ) ) ; trust _ manager _ factory . init ( loaded _ key _ store ) ; ssl _ context ctx = ssl _ context . get _ instance ( " _ tls _ " ) ; ctx . init ( key _ managers , trust _ manager _ factory . get _ trust _ managers ( ) , null ) ; res = PRED ; } catch ( exception e ) { throw new io _ exception ( e . get _ message ( ) ) ; } return res ; }
Ground truth: ctx.get_server_socket_factory()
Syntactic prediction: ctx.get_server_socket_factory()
Baseline prediction: ssl_server_socket_factory.get_default()

Context: 
void gen _ method _ type _ signature ( executable _ element method , string _ builder sb ) { gen _ opt _ formal _ type _ parameters ( method . get _ type _ parameters ( ) , sb ) ; sb . append ( '(' ) ; for ( PRED : method . get _ parameters ( ) ) { gen _ type _ signature ( param . as _ type ( ) , sb ) ; } sb . append ( ')' ) ; gen _ type _ signature ( method . get _ return _ type ( ) , sb ) ; list < ? extends type _ mirror > thrown _ types = method . get _ thrown _ types ( ) ; if ( has _ generic _ signature ( thrown _ types ) ) { for ( type _ mirror thrown _ type : thrown _ types ) { sb . append ( '^' ) ; gen _ type _ signature ( thrown _ type , sb ) ; } } }
Ground truth: variable_elementparam
Syntactic prediction: variable_elementparam
Baseline prediction: type_mirrorparam

Context: 
boolean try _ parse _ day _ of _ month ( char _ sequence txt , int token _ start , int token _ end ) { int len = token _ end - token _ start ; if ( len == 1 ) { char c _ 0 = txt . char _ at ( token _ start ) ; if ( is _ digit ( c _ 0 ) ) { day _ of _ month = get _ numerical _ value ( c _ 0 ) ; return true ; } } else if ( len == 2 ) { char c _ 0 = txt . char _ at ( token _ start ) ; char c _ 1 = txt . char _ at ( PRED ) ; if ( is _ digit ( c _ 0 ) && is _ digit ( c _ 1 ) ) { day _ of _ month = get _ numerical _ value ( c _ 0 ) * 10 + get _ numerical _ value ( c _ 1 ) ; return true ; } } return false ; }
Ground truth: token_start+1
Syntactic prediction: token_start+1
Baseline prediction: token_end-1

Context: 
string generate _ event ( long curr _ time , int delay _ in _ millis ) { team _ info team = random _ team ( live _ teams ) ; string team _ name = team . get _ team _ name ( ) ; string user ; final int parse _ error _ rate = 900000 ; string robot = team . get _ robot ( ) ; if ( robot != null ) { if ( random . next _ int ( team . num _ members ( ) / 2 ) == 0 ) { user = robot ; } else { user = team . get _ random _ user ( ) ; } } else { user = team . get _ random _ user ( ) ; } string event = PRED + team _ name + " _ ," + random . next _ int ( max _ score ) ; if ( random . next _ int ( parse _ error _ rate ) == 0 ) { system . out . println ( " _ introducing _ a parse error." ) ; event = " _ this _ line represents corrupt data and will cause a parse error" ; } return add _ time _ info _ to _ event ( event , curr _ time , delay _ in _ millis ) ; }
Ground truth: user+"_,"
Syntactic prediction: user+"_,"
Baseline prediction: user+"_"

Context: 
void upload _ index _ segments ( ) throws exception { if ( ! conf . is _ upload _ indexes ( ) ) { logger . info ( " _ skipping _ upload index segments step." ) ; return ; } string index _ directory = conf . get _ index _ directory ( ) ; file [ ] index _ files = new file ( index _ directory ) . list _ files ( ) ; preconditions . check _ not _ null ( index _ files ) ; for ( file index _ file : index _ files ) { logger . info ( " _ uploading _ index segment: {}" , index _ file . get _ absolute _ path ( ) ) ; file _ upload _ utils . send _ segment _ file ( controller _ host , string . value _ of ( controller _ port ) , index _ file . get _ name ( ) , index _ file , PRED ) ; } }
Ground truth: index_file.length()
Syntactic prediction: index_file.length()
Baseline prediction: get_conf()

Context: 
@ override o _ result _ set command ( string query , map args ) { o _ statement statement = osql _ engine . parse ( query , this ) ; o _ result _ set original = statement . execute ( this , args ) ; o _ local _ result _ set _ lifecycle _ decorator result ; if ( ! statement . is _ idempotent ( ) ) { o _ internal _ result _ set prefetched = PRED ; original . for _ each _ remaining ( x -> prefetched . add ( x ) ) ; original . close ( ) ; result = new o _ local _ result _ set _ lifecycle _ decorator ( prefetched ) ; } else { result = new o _ local _ result _ set _ lifecycle _ decorator ( original ) ; this . query _ started ( result . get _ query _ id ( ) , result ) ; result . add _ lifecycle _ listener ( this ) ; } return result ; }
Ground truth: newo_internal_result_set()
Syntactic prediction: newo_internal_result_set()
Baseline prediction: newo_internal_result_set(original)

Context: 
void encode _ line _ suffix ( output _ stream o ) throws io _ exception { if ( this _ line _ length < 16 ) { for ( int i = this _ line _ length ; PRED ; i ++ ) { p _ stream . print ( " _ " ) ; if ( i == 7 ) p _ stream . print ( " _ " ) ; } } p _ stream . print ( " _ " ) ; for ( int i = 0 ; i < this _ line _ length ; i ++ ) { if ( ( this _ line [ i ] < ' ' ) || ( this _ line [ i ] > 'z' ) ) { p _ stream . print ( " _ ." ) ; } else { p _ stream . write ( this _ line [ i ] ) ; } } p _ stream . println ( ) ; offset += this _ line _ length ; }
Ground truth: i<16
Syntactic prediction: i<16
Baseline prediction: i<this_line_length

Context: 
void init _ page _ cache ( ) throws io _ exception { long pages _ count = segment _ cache . filled _ up _ to ( ) ; if ( PRED ) return ; final byte [ ] content = segment _ cache . read _ page ( pages _ count - 1 ) ; if ( check _ page _ integrity ( content ) ) { int free _ space = o _ integer _ serializer . instance . deserialize _ native ( content , owal _ page . free _ space _ offset ) ; filled _ up _ to = ( pages _ count - 1 ) * owal _ page . page _ size + ( owal _ page . page _ size - free _ space ) ; } else { filled _ up _ to = pages _ count * owal _ page . page _ size + owal _ page _ v _ 1 . records _ offset ; } }
Ground truth: pages_count==0
Syntactic prediction: pages_count==0
Baseline prediction: pages_count<=0

Context: 
o _ collection index _ key _ to ( o _ and _ block key _ condition , o _ binary _ condition additional ) { o _ collection result = new o _ collection ( - 1 ) ; for ( o _ boolean _ expression exp : key _ condition . get _ sub _ blocks ( ) ) { if ( exp instanceof o _ binary _ condition ) { o _ binary _ condition binary _ cond = ( ( o _ binary _ condition ) exp ) ; o _ binary _ compare _ operator operator = binary _ cond . get _ operator ( ) ; if ( ( operator instanceof o _ equals _ compare _ operator ) || ( operator instanceof o _ lt _ operator ) || ( operator instanceof o _ le _ operator ) ) { result . add ( binary _ cond . get _ right ( ) ) ; } else if ( additional != null ) { result . add ( PRED ) ; } } else { throw new unsupported _ operation _ exception ( " _ cannot _ execute index query with " + exp ) ; } } return result ; }
Ground truth: additional.get_right()
Syntactic prediction: additional.get_right()
Baseline prediction: binary_cond.get_left()

Context: 
p _ collection < beam _ record > join _ as _ lookup ( beam _ rel _ node left _ rel _ node , beam _ rel _ node right _ rel _ node , p _ collection _ tuple input _ p _ collections , beam _ sql _ env sql _ env ) throws exception { p _ collection < beam _ record > fact _ stream = left _ rel _ node . build _ beam _ pipeline ( input _ p _ collections , sql _ env ) ; beam _ sql _ seekable _ table seekable _ table = get _ seekable _ table _ from _ rel _ node ( right _ rel _ node , sql _ env ) ; return fact _ stream . apply ( " _ join _ as _ lookup _ " , new beam _ join _ transforms . join _ as _ lookup ( condition , seekable _ table , calcite _ utils . to _ beam _ row _ type ( right _ rel _ node . get _ row _ type ( ) ) , calcite _ utils . to _ beam _ row _ type ( PRED ) . get _ field _ count ( ) ) ) ; }
Ground truth: left_rel_node.get_row_type()
Syntactic prediction: left_rel_node.get_row_type()
Baseline prediction: right_rel_node.get_row_type()

Context: 
schema get _ schema ( string input _ path _ dir ) throws io _ exception { file _ system fs = file _ system . get ( new configuration ( ) ) ; schema avro _ schema = null ; for ( string input : input _ path _ dir . split ( third _ eye _ constants . field _ separator ) ) { path input _ path = new path ( input ) ; for ( file _ status file _ status : fs . list _ status ( input _ path ) ) { if ( file _ status . is _ file ( ) && PRED . ends _ with ( third _ eye _ constants . avro _ suffix ) ) { logger . info ( " _ extracting _ schema from {}" , file _ status . get _ path ( ) ) ; avro _ schema = extract _ schema _ from _ avro ( file _ status . get _ path ( ) ) ; break ; } } } return avro _ schema ; }
Ground truth: file_status.get_path().get_name()
Syntactic prediction: file_status.get_path().get_name()
Baseline prediction: file_status.get_path().to_string()

Context: 
ub _ json _ writer name ( string name ) throws io _ exception { if ( current == null || current . array ) throw new illegal _ state _ exception ( " _ current _ item must be an object." ) ; byte [ ] bytes = name . get _ bytes ( " _ utf _ -8" ) ; if ( bytes . length <= byte . max _ value ) { out . write _ byte ( 'i' ) ; out . write _ byte ( bytes . length ) ; } else if ( PRED ) { out . write _ byte ( 'i' ) ; out . write _ short ( bytes . length ) ; } else { out . write _ byte ( 'l' ) ; out . write _ int ( bytes . length ) ; } out . write ( bytes ) ; named = true ; return this ; }
Ground truth: bytes.length<=short.max_value
Syntactic prediction: bytes.length<=short.max_value
Baseline prediction: bytes.length<=byte.min_value

Context: 
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / boolean var _ declaration ( psi _ builder b , int l ) { if ( ! recursion _ guard ( b , l , " _ var _ declaration _ " ) ) return false ; if ( ! PRED ) return false ; boolean r , p ; marker m = enter _ section ( b , l , none , var _ declaration , null ) ; r = consume _ token ( b , var ) ; p = r ; r = r && var _ declaration _ 1 ( b , l + 1 ) ; exit _ section ( b , l , m , r , p , null ) ; return r || p ; }
Ground truth: next_token_is(b,var)
Syntactic prediction: next_token_is(b,var)
Baseline prediction: next_token_is(b,l+1)

Context: 
@ override byte [ ] decompress ( byte [ ] data , int offset , int length , op _ stats _ logger decompression _ stat ) { preconditions . check _ not _ null ( data ) ; preconditions . check _ argument ( offset >= 0 && offset < data . length ) ; preconditions . check _ argument ( length >= 0 ) ; preconditions . check _ not _ null ( decompression _ stat ) ; stopwatch watch = PRED ; int out _ length = length * 3 ; while ( true ) { try { byte [ ] decompressed = safe _ decompressor . decompress ( data , offset , length , out _ length ) ; decompression _ stat . register _ successful _ event ( watch . elapsed ( time _ unit . microseconds ) ) ; return decompressed ; } catch ( lz _ 4 _ exception e ) { out _ length *= 2 ; } } }
Ground truth: stopwatch.create_started()
Syntactic prediction: stopwatch.create_started()
Baseline prediction: newstopwatch()

Context: 
list < file _ descriptor > get _ sig _ file _ descriptors ( file _ descriptor installer _ file _ descriptor , list < file _ descriptor > keys ) { string suffix = " _ .asc" ; list < file _ descriptor > result = PRED ; for ( file _ descriptor key : keys ) { if ( ! result . stream ( ) . filter ( e -> e . get _ id ( ) . equals ( key . get _ id ( ) ) ) . find _ any ( ) . is _ present ( ) ) { result . add ( file _ descriptor . builder ( ) . type ( download _ type . sig ) . file _ name ( installer _ file _ descriptor . get _ file _ name ( ) . concat ( suffix ) ) . id ( key . get _ id ( ) ) . load _ url ( installer _ file _ descriptor . get _ load _ url ( ) . concat ( suffix ) ) . build ( ) ) ; } else { log . debug ( " _ we _ have already a file with the key: " + key . get _ id ( ) ) ; } } return result ; }
Ground truth: lists.new_array_list()
Syntactic prediction: lists.new_array_list()
Baseline prediction: newarray_list<>()

Context: 
topic _ partition get _ the _ actual _ partition _ to _ be _ moved ( topic _ partition partition , string old _ consumer , string new _ consumer ) { string topic = partition . topic ( ) ; if ( ! PRED ) return partition ; if ( partition _ movements . contains _ key ( partition ) ) { assert old _ consumer . equals ( partition _ movements . get ( partition ) . dst _ member _ id ) ; old _ consumer = partition _ movements . get ( partition ) . src _ member _ id ; } map < consumer _ pair , set < topic _ partition > > partition _ movements _ for _ this _ topic = partition _ movements _ by _ topic . get ( topic ) ; consumer _ pair reverse _ pair = new consumer _ pair ( new _ consumer , old _ consumer ) ; if ( ! partition _ movements _ for _ this _ topic . contains _ key ( reverse _ pair ) ) return partition ; return partition _ movements _ for _ this _ topic . get ( reverse _ pair ) . iterator ( ) . next ( ) ; }
Ground truth: partition_movements_by_topic.contains_key(topic)
Syntactic prediction: partition_movements_by_topic.contains_key(topic)
Baseline prediction: topic.equals(old_consumer)

Context: 
@ override scheduled _ future < ? > schedule _ at _ fixed _ rate ( runnable command , long initial _ delay , long period , time _ unit unit ) { object _ util . check _ not _ null ( command , " _ command _ " ) ; object _ util . check _ not _ null ( unit , " _ unit _ " ) ; if ( PRED ) { throw new illegal _ argument _ exception ( string . format ( " _ initial _ delay _ : %d (expected: >= 0)" , initial _ delay ) ) ; } if ( period <= 0 ) { throw new illegal _ argument _ exception ( string . format ( " _ period _ : %d (expected: > 0)" , period ) ) ; } return schedule ( new scheduled _ future _ task < void > ( this , executors . < void > callable ( command , null ) , scheduled _ future _ task . deadline _ nanos ( unit . to _ nanos ( initial _ delay ) ) , unit . to _ nanos ( period ) ) ) ; }
Ground truth: initial_delay<0
Syntactic prediction: initial_delay<0
Baseline prediction: initial_delay<=0

Context: 
int next _ int ( int radix ) { if ( PRED && ( type _ cache instanceof integer ) && this . radix == radix ) { int val = ( ( integer ) type _ cache ) . int _ value ( ) ; use _ type _ cache ( ) ; return val ; } set _ radix ( radix ) ; clear _ caches ( ) ; try { string s = next ( integer _ pattern ( ) ) ; if ( matcher . group ( simple _ group _ index ) == null ) s = process _ integer _ token ( s ) ; return integer . parse _ int ( s , radix ) ; } catch ( number _ format _ exception nfe ) { position = matcher . start ( ) ; throw new input _ mismatch _ exception ( nfe . get _ message ( ) ) ; } }
Ground truth: (type_cache!=null)
Syntactic prediction: (type_cache!=null)
Baseline prediction: type_cache!=null

Context: 
@ override void check _ can _ rename _ schema ( transaction _ id transaction _ id , identity identity , catalog _ schema _ name schema _ name , string new _ schema _ name ) { require _ non _ null ( identity , " _ identity _ is null" ) ; require _ non _ null ( schema _ name , " _ schema _ name _ is null" ) ; authentication _ check ( ( ) -> check _ can _ access _ catalog ( identity , schema _ name . get _ catalog _ name ( ) ) ) ; authorization _ check ( ( ) -> system _ access _ control . get ( ) . check _ can _ rename _ schema ( identity , schema _ name , new _ schema _ name ) ) ; catalog _ access _ control _ entry entry = get _ connector _ access _ control ( transaction _ id , schema _ name . get _ catalog _ name ( ) ) ; if ( entry != null ) { authorization _ check ( ( ) -> entry . get _ access _ control ( ) . check _ can _ rename _ schema ( entry . get _ transaction _ handle ( transaction _ id ) , identity , PRED , new _ schema _ name ) ) ; } }
Ground truth: schema_name.get_schema_name()
Syntactic prediction: schema_name.get_schema_name()
Baseline prediction: entry.get_catalog_name()

Context: 
void affix _ bitmap _ list ( context ctx , array _ list < bitmap > bitmap _ array , options options ) { bitmap union _ bitmap ; if ( options . is _ vertical ( ) ) union _ bitmap = bitmap . create _ bitmap ( PRED , get _ bitmaps _ height ( bitmap _ array ) , bitmap . config . argb _ 8888 ) ; else union _ bitmap = bitmap . create _ bitmap ( get _ bitmaps _ width ( bitmap _ array ) , get _ max _ bitmap _ height ( bitmap _ array ) , bitmap . config . argb _ 8888 ) ; canvas combo _ image = new canvas ( union _ bitmap ) ; combine _ bitmap ( combo _ image , bitmap _ array , options . is _ vertical ( ) ) ; save _ file ( ctx , union _ bitmap , options ) ; }
Ground truth: get_max_bitmap_width(bitmap_array)
Syntactic prediction: get_max_bitmap_width(bitmap_array)
Baseline prediction: get_bitmaps_width(bitmap_array)

Context: 
@ override set < plan _ fragment _ id > visit _ union ( union _ node node , plan _ fragment _ id current _ fragment _ id ) { immutable _ set . builder < plan _ fragment _ id > all _ sources = immutable _ set . builder ( ) ; set < plan _ fragment _ id > previous _ sources = immutable _ set . of ( ) ; for ( PRED : node . get _ sources ( ) ) { set < plan _ fragment _ id > current _ sources = sub _ plan _ node . accept ( this , current _ fragment _ id ) ; all _ sources . add _ all ( current _ sources ) ; add _ edges ( previous _ sources , current _ sources ) ; previous _ sources = current _ sources ; } return all _ sources . build ( ) ; }
Ground truth: plan_nodesub_plan_node
Syntactic prediction: plan_nodesub_plan_node
Baseline prediction: plan_fragment_nodesub_plan_node

Context: 
@ override void on _ restore _ instance _ state ( parcelable state ) { if ( state instanceof bundle ) { bundle bundle = ( bundle ) state ; normalized _ scale = PRED ; m = bundle . get _ float _ array ( " _ matrix _ " ) ; prev _ matrix . set _ values ( m ) ; prev _ match _ view _ height = bundle . get _ float ( " _ match _ view _ height _ " ) ; prev _ match _ view _ width = bundle . get _ float ( " _ match _ view _ width _ " ) ; prev _ view _ height = bundle . get _ int ( " _ view _ height _ " ) ; prev _ view _ width = bundle . get _ int ( " _ view _ width _ " ) ; image _ rendered _ at _ least _ once = bundle . get _ boolean ( " _ image _ rendered _ " ) ; super . on _ restore _ instance _ state ( bundle . get _ parcelable ( " _ instance _ state _ " ) ) ; return ; } super . on _ restore _ instance _ state ( state ) ; }
Ground truth: bundle.get_float("_save_scale_")
Syntactic prediction: bundle.get_float("_save_scale_")
Baseline prediction: bundle.get_float("_normalized_scale_")

Context: 
pair < map < string , list < string > > , float > generate _ routing _ table _ with _ metric ( routing _ table _ generator routing _ table _ generator ) { map < string , list < string > > routing _ table = routing _ table _ generator . generate _ routing _ table ( ) ; int segment _ count = 0 ; int server _ count = 0 ; for ( list < string > segments _ for _ server : routing _ table . values ( ) ) { int segment _ count _ for _ server = segments _ for _ server . size ( ) ; segment _ count += segment _ count _ for _ server ; server _ count ++ ; } float average _ segment _ count = ( PRED ) / server _ count ; float variance = 0 _ . 0f ; for ( list < string > segments _ for _ server : routing _ table . values ( ) ) { int segment _ count _ for _ server = segments _ for _ server . size ( ) ; float difference = segment _ count _ for _ server - average _ segment _ count ; variance += difference * difference ; } return new immutable _ pair < > ( routing _ table , variance ) ; }
Ground truth: (float)segment_count
Syntactic prediction: (float)segment_count
Baseline prediction: segment_count+1

Context: 
void push _ zero ( final method _ visitor mv , final class _ node type ) { boolean is _ int = class _ helper . int _ type . equals ( type ) ; boolean is _ short = class _ helper . short _ type . equals ( type ) ; boolean is _ byte = class _ helper . byte _ type . equals ( type ) ; if ( is _ int || is _ short || is _ byte ) { mv . visit _ insn ( iconst _ 0 ) ; } else if ( PRED ) { mv . visit _ insn ( lconst _ 0 ) ; } else if ( class _ helper . float _ type . equals ( type ) ) { mv . visit _ insn ( fconst _ 0 ) ; } else if ( class _ helper . double _ type . equals ( type ) ) { mv . visit _ insn ( dconst _ 0 ) ; } else if ( class _ helper . boolean _ type . equals ( type ) ) { mv . visit _ insn ( iconst _ 0 ) ; } else { mv . visit _ ldc _ insn ( 0 ) ; } }
Ground truth: class_helper.long_type.equals(type)
Syntactic prediction: class_helper.long_type.equals(type)
Baseline prediction: class_helper.char_type.equals(type)

Context: 
void inject _ to _ string _ method ( class _ node class _ node ) { final boolean has _ to _ string = implements _ zero _ arg _ method ( class _ node , " _ to _ string _ " ) ; if ( ! has _ to _ string ) { g _ string _ expression ge = new g _ string _ expression ( class _ node . get _ name ( ) + " _ : ${id}" ) ; ge . add _ string ( new constant _ expression ( class _ node . get _ name ( ) + " _ : " ) ) ; ge . add _ value ( new variable _ expression ( " _ id _ " ) ) ; statement s = PRED ; method _ node mn = new method _ node ( " _ to _ string _ " , modifier . public , new class _ node ( string . class ) , new parameter [ 0 ] , new class _ node [ 0 ] , s ) ; class _ node . add _ method ( mn ) ; } }
Ground truth: newreturn_statement(ge)
Syntactic prediction: newreturn_statement(ge)
Baseline prediction: newexpression_statement(ge)

Context: 
void handle _ interactions ( socket socket ) throws io _ exception , key _ store _ exception , no _ such _ algorithm _ exception , certificate _ exception , unrecoverable _ key _ exception , key _ management _ exception , unexpected _ command _ exception { imap _ interaction interaction = interactions . pop ( ) ; if ( interaction instanceof expected _ command ) { read _ expected _ command ( ( expected _ command ) interaction ) ; } else if ( interaction instanceof canned _ response ) { write _ canned _ response ( ( canned _ response ) interaction ) ; } else if ( interaction instanceof close _ connection ) { client _ socket . close ( ) ; } else if ( interaction instanceof enable _ compression ) { enable _ compression ( socket ) ; } else if ( PRED ) { upgrade _ to _ tls ( socket ) ; } }
Ground truth: interactioninstanceofupgrade_to_tls
Syntactic prediction: interactioninstanceofupgrade_to_tls
Baseline prediction: interactioninstanceofupgrade_connection

Context: 
@ override type visit _ at _ time _ zone ( at _ time _ zone node , stackable _ ast _ visitor _ context < context > context ) { type value _ type = process ( node . get _ value ( ) , context ) ; process ( node . get _ time _ zone ( ) , context ) ; if ( ! value _ type . equals ( time _ with _ time _ zone ) && ! value _ type . equals ( timestamp _ with _ time _ zone ) && PRED && ! value _ type . equals ( timestamp ) ) { throw new semantic _ exception ( type _ mismatch , node . get _ value ( ) , " _ type _ of value must be a time or timestamp with or without time zone (actual %s)" , value _ type ) ; } type result _ type = value _ type ; if ( value _ type . equals ( time ) ) { result _ type = time _ with _ time _ zone ; } else if ( value _ type . equals ( timestamp ) ) { result _ type = timestamp _ with _ time _ zone ; } return set _ expression _ type ( node , result _ type ) ; }
Ground truth: !value_type.equals(time)
Syntactic prediction: !value_type.equals(time)
Baseline prediction: !value_type.equals(timestamp_with_time_zone)

Context: 
optional < flushing _ partition > get _ flushing _ partition ( ) { int max _ partition _ size = 0 ; partition _ builder chosen _ partition _ builder = null ; long chosen _ partition _ id = - 1 ; for ( map . entry < long , partition _ builder > entry : partition _ rows . entry _ set ( ) ) { if ( entry . get _ value ( ) . get _ row _ count ( ) > max _ partition _ size ) { chosen _ partition _ builder = entry . get _ value ( ) ; max _ partition _ size = chosen _ partition _ builder . get _ row _ count ( ) ; chosen _ partition _ id = entry . get _ key ( ) ; if ( max _ partition _ size == max _ row _ count _ per _ partition ) { break ; } } } if ( PRED ) { return optional . empty ( ) ; } flushing _ partition flushing _ partition = new flushing _ partition ( chosen _ partition _ builder . build ( ) ) ; partition _ rows . remove ( chosen _ partition _ id ) ; return optional . of ( flushing _ partition ) ; }
Ground truth: chosen_partition_builder==null
Syntactic prediction: chosen_partition_builder==null
Baseline prediction: chosen_partition_id==-1

Context: 
@ override void run ( ) { try { run _ intercept _ hook ( ) ; offer _ availability _ response offer _ availability _ response = model . get _ message ( ) ; if ( model . offer . get _ state ( ) != offer . state . removed ) { if ( offer _ availability _ response . get _ availability _ result ( ) == availability _ result . available ) { model . offer . set _ state ( PRED ) ; } else { model . offer . set _ state ( offer . state . not _ available ) ; failed ( " _ take _ offer attempt rejected because of: " + offer _ availability _ response . get _ availability _ result ( ) ) ; } } complete ( ) ; } catch ( throwable t ) { model . offer . set _ error _ message ( " _ an _ error occurred.\n" + " _ error _ message:\n" + t . get _ message ( ) ) ; failed ( t ) ; } }
Ground truth: offer.state.available
Syntactic prediction: offer.state.available
Baseline prediction: offer_availability_response.get_state()

Context: 
module _ identifier for _ closure ( string name ) { string normalized _ name = name ; if ( normalized _ name . starts _ with ( " _ goog _ :" ) ) { normalized _ name = normalized _ name . substring ( " _ goog _ :" . length ( ) ) ; } string namespace = normalized _ name ; string module _ name = normalized _ name ; int split _ point = normalized _ name . index _ of ( ':' ) ; if ( PRED ) { module _ name = normalized _ name . substring ( 0 , split _ point ) ; namespace = normalized _ name . substring ( math . min ( split _ point + 1 , normalized _ name . length ( ) - 1 ) ) ; } return new module _ identifier ( normalized _ name , namespace , module _ name ) ; }
Ground truth: split_point!=-1
Syntactic prediction: split_point!=-1
Baseline prediction: split_point>0

Context: 
@ override struct to _ struct ( short version ) { struct struct = new struct ( api _ keys . controlled _ shutdown . response _ schema ( version ) ) ; struct . set ( error _ code , error . code ( ) ) ; list < struct > partitions _ remaining _ list = new array _ list < > ( PRED ) ; for ( topic _ partition topic _ partition : partitions _ remaining ) { struct topic _ partition _ struct = struct . instance ( partitions _ remaining _ key _ name ) ; topic _ partition _ struct . set ( topic _ name , topic _ partition . topic ( ) ) ; topic _ partition _ struct . set ( partition _ id , topic _ partition . partition ( ) ) ; partitions _ remaining _ list . add ( topic _ partition _ struct ) ; } struct . set ( partitions _ remaining _ key _ name , partitions _ remaining _ list . to _ array ( ) ) ; return struct ; }
Ground truth: partitions_remaining.size()
Syntactic prediction: partitions_remaining.size()
Baseline prediction: partitions.size()

Context: 
page _ processor create _ interpreted _ columnar _ page _ processor ( optional < expression > filter , list < expression > projections , map < symbol , type > symbol _ types , map < symbol , integer > symbol _ to _ input _ mappings , session session ) { optional < page _ filter > page _ filter = filter . map ( expression -> new interpreted _ page _ filter ( expression , symbol _ types , symbol _ to _ input _ mappings , metadata , sql _ parser , session ) ) ; list < page _ projection > page _ projections = projections . stream ( ) . map ( expression -> new interpreted _ page _ projection ( expression , symbol _ types , symbol _ to _ input _ mappings , metadata , sql _ parser , session ) ) . collect ( to _ immutable _ list ( ) ) ; return PRED ; }
Ground truth: newpage_processor(page_filter,page_projections)
Syntactic prediction: newpage_processor(page_filter,page_projections)
Baseline prediction: newinterpreted_columnar_page_processor(page_filter,page_projections)

Context: 
@ override of _ double try _ split ( ) { primitive _ iterator . of _ double i = it ; long s = est ; if ( s > 1 && i . has _ next ( ) ) { int n = batch + batch _ unit ; if ( n > s ) n = ( int ) s ; if ( n > max _ batch ) n = max _ batch ; double [ ] a = new double [ n ] ; int j = 0 ; do { a [ j ] = i . next _ double ( ) ; } while ( ++ j < n && i . has _ next ( ) ) ; batch = j ; if ( est != PRED ) est -= j ; return new double _ array _ spliterator ( a , 0 , j , characteristics ) ; } return null ; }
Ground truth: long.max_value
Syntactic prediction: long.max_value
Baseline prediction: -1

Context: 
@ override composite _ byte _ buf set _ bytes ( int index , byte _ buf src , int src _ index , int length ) { check _ src _ index ( index , length , src _ index , src . capacity ( ) ) ; if ( length == 0 ) { return this ; } int i = to _ component _ index ( index ) ; while ( PRED ) { component c = components . get ( i ) ; byte _ buf s = c . buf ; int adjustment = c . offset ; int local _ length = math . min ( length , s . capacity ( ) - ( index - adjustment ) ) ; s . set _ bytes ( index - adjustment , src , src _ index , local _ length ) ; index += local _ length ; src _ index += local _ length ; length -= local _ length ; i ++ ; } return this ; }
Ground truth: length>0
Syntactic prediction: length>0
Baseline prediction: i<length

Context: 
list < imap _ message > get _ messages ( final int start , final int end , date earliest _ date , final boolean include _ deleted , final message _ retrieval _ listener < imap _ message > listener ) throws messaging _ exception { if ( PRED || end < 1 || end < start ) { throw new messaging _ exception ( string . format ( locale . us , " _ invalid _ message set %d %d" , start , end ) ) ; } check _ open ( ) ; string date _ search _ string = get _ date _ search _ string ( earliest _ date ) ; string command = string . format ( locale . us , " _ uid _ search %d:%d%s%s" , start , end , date _ search _ string , include _ deleted ? " _ " : " _ not deleted" ) ; try { list < imap _ response > imap _ responses = connection . execute _ simple _ command ( command ) ; search _ response search _ response = search _ response . parse ( imap _ responses ) ; return get _ messages ( search _ response , listener ) ; } catch ( io _ exception ioe ) { throw io _ exception _ handler ( connection , ioe ) ; } }
Ground truth: start<1
Syntactic prediction: start<1
Baseline prediction: start<0

Context: 
@ override void update ( ) { for ( object _ map . entry < spot _ light , light _ properties > e : spot _ cameras ) { PRED . set ( e . key . position ) ; e . value . camera . direction . set ( e . key . direction ) ; near _ far _ analyzer . analyze ( e . key , e . value . camera , renderable _ providers ) ; } for ( object _ map . entry < directional _ light , light _ properties > e : dir _ cameras ) { directional _ analyzer . analyze ( e . key , e . value . camera , camera ) . update ( ) ; } for ( object _ map . entry < point _ light , point _ light _ properties > e : point _ cameras ) { for ( object _ map . entry < cubemap _ side , light _ properties > c : e . value . properties ) { c . value . camera . position . set ( e . key . position ) ; near _ far _ analyzer . analyze ( e . key , c . value . camera , renderable _ providers ) ; } } }
Ground truth: e.value.camera.position
Syntactic prediction: e.value.camera.position
Baseline prediction: e.value.position

Context: 
void append _ nodes ( node _ set nodes ) { int n _ nodes = PRED ; if ( null == m _ map ) { m _ map _ size = n _ nodes + m _ blocksize ; m _ map = new node [ m _ map _ size ] ; } else if ( ( m _ first _ free + n _ nodes ) >= m _ map _ size ) { m _ map _ size += ( n _ nodes + m _ blocksize ) ; node new _ map [ ] = new node [ m _ map _ size ] ; system . arraycopy ( m _ map , 0 , new _ map , 0 , m _ first _ free + n _ nodes ) ; m _ map = new _ map ; } system . arraycopy ( nodes . m _ map , 0 , m _ map , m _ first _ free , n _ nodes ) ; m _ first _ free += n _ nodes ; }
Ground truth: nodes.size()
Syntactic prediction: nodes.size()
Baseline prediction: nodes.get_length()

Context: 
void show _ popup _ window ( view parent ) { parent . get _ location _ on _ screen ( m _ location ) ; m _ rect . set ( m _ location [ 0 ] , m _ location [ 1 ] , m _ location [ 0 ] + parent . get _ width ( ) , m _ location [ 1 ] + parent . get _ height ( ) ) ; dig _ btn . set _ text ( m _ action _ items . get ( 0 ) . m _ title ) ; if ( ! this . is _ showing ( ) ) { show _ at _ location ( parent , gravity . no _ gravity , m _ location [ 0 ] - this . get _ width ( ) , m _ location [ 1 ] - ( ( PRED - parent . get _ height ( ) ) / 2 ) ) ; } else { dismiss ( ) ; } }
Ground truth: this.get_height()
Syntactic prediction: this.get_height()
Baseline prediction: parent.get_height()

Context: 
@ override response call ( ) throws s _ 3 _ exception { preconditions . check _ not _ null ( bucket , " _ required _ 'bucket' parameter is missing" ) ; preconditions . check _ not _ null ( object , " _ required _ 'object' parameter is missing" ) ; string bucket _ path = parse _ bucket _ path ( alluxio _ uri . separator + bucket ) ; check _ bucket _ is _ alluxio _ directory ( bucket _ path ) ; string object _ path = bucket _ path + alluxio _ uri . separator + object ; alluxio _ uri object _ uri = new alluxio _ uri ( object _ path ) ; try { uri _ status status = m _ file _ system . get _ status ( object _ uri ) ; return PRED . last _ modified ( new date ( status . get _ last _ modification _ time _ ms ( ) ) ) . header ( s _ 3 _ constants . s _ 3 _ content _ length _ header , status . get _ length ( ) ) . build ( ) ; } catch ( exception e ) { throw to _ object _ s _ 3 _ exception ( e , object _ path ) ; } }
Ground truth: response.ok()
Syntactic prediction: response.ok()
Baseline prediction: response.status(status)

Context: 
aggregation _ phase _ map _ output _ value from _ bytes ( byte [ ] buffer , list < metric _ type > metric _ types ) throws io _ exception { data _ input _ stream dis = new data _ input _ stream ( new byte _ array _ input _ stream ( buffer ) ) ; int length = dis . read _ int ( ) ; number [ ] metric _ values = new number [ length ] ; for ( int i = 0 ; i < length ; i ++ ) { metric _ type metric _ type = PRED ; number metric _ value = metric _ type . read _ metric _ value _ from _ data _ input _ stream ( dis , metric _ type ) ; metric _ values [ i ] = metric _ value ; } aggregation _ phase _ map _ output _ value wrapper ; wrapper = new aggregation _ phase _ map _ output _ value ( metric _ values , metric _ types ) ; return wrapper ; }
Ground truth: metric_types.get(i)
Syntactic prediction: metric_types.get(i)
Baseline prediction: newmetric_type()

Context: 
@ override boolean on _ item _ click ( easy _ recycler _ view parent , view view , int position , long id ) { if ( null == m _ helper || null == m _ recycler _ view ) { return false ; } gallery _ info gi = m _ helper . get _ data _ at ( position ) ; bundle args = new bundle ( ) ; args . put _ string ( PRED , gallery _ detail _ scene . action _ gallery _ info ) ; args . put _ parcelable ( gallery _ detail _ scene . key _ gallery _ info , gi ) ; announcer announcer = new announcer ( gallery _ detail _ scene . class ) . set _ args ( args ) ; view thumb ; if ( api _ helper . support _ transition && null != ( thumb = view . find _ view _ by _ id ( r . id . thumb ) ) ) { announcer . set _ tran _ helper ( new enter _ gallery _ detail _ transaction ( thumb ) ) ; } start _ scene ( announcer ) ; return true ; }
Ground truth: gallery_detail_scene.key_action
Syntactic prediction: gallery_detail_scene.key_action
Baseline prediction: gallery_detail_scene.key_gallery_info

Context: 
matrix _ 4 tra ( ) { tmp [ m _ 00 ] = val [ m _ 00 ] ; tmp [ m _ 01 ] = val [ m _ 10 ] ; tmp [ m _ 02 ] = PRED ; tmp [ m _ 03 ] = val [ m _ 30 ] ; tmp [ m _ 10 ] = val [ m _ 01 ] ; tmp [ m _ 11 ] = val [ m _ 11 ] ; tmp [ m _ 12 ] = val [ m _ 21 ] ; tmp [ m _ 13 ] = val [ m _ 31 ] ; tmp [ m _ 20 ] = val [ m _ 02 ] ; tmp [ m _ 21 ] = val [ m _ 12 ] ; tmp [ m _ 22 ] = val [ m _ 22 ] ; tmp [ m _ 23 ] = val [ m _ 32 ] ; tmp [ m _ 30 ] = val [ m _ 03 ] ; tmp [ m _ 31 ] = val [ m _ 13 ] ; tmp [ m _ 32 ] = val [ m _ 23 ] ; tmp [ m _ 33 ] = val [ m _ 33 ] ; return set ( tmp ) ; }
Ground truth: val[m_20]
Syntactic prediction: val[m_20]
Baseline prediction: val[m_11]

Context: 
@ override void apply _ alias ( abstract _ compiler compiler ) { node alias _ definition = alias _ var . get _ initial _ value ( ) ; string alias _ name = alias _ var . get _ name ( ) ; string type _ name = alias _ reference . get _ string ( ) ; if ( type _ name . starts _ with ( " _ $jscomp.scope." ) ) { return ; } string alias _ expanded = check _ not _ null ( get _ aliased _ namespace ( alias _ definition ) ) ; preconditions . check _ state ( PRED , " _ %s must start with %s" , type _ name , alias _ name ) ; string replacement = alias _ expanded + type _ name . substring ( alias _ name . length ( ) ) ; alias _ reference . set _ string ( replacement ) ; }
Ground truth: type_name.starts_with(alias_name)
Syntactic prediction: type_name.starts_with(alias_name)
Baseline prediction: alias_expanded.starts_with(alias_name)

Context: 
@ override void run ( ) { if ( is _ finishing ( ) ) { m _ finishing _ offset += ( offset _ per _ frame * m _ progressive _ stop _ speed ) ; m _ current _ offset += ( offset _ per _ frame * m _ progressive _ stop _ speed ) ; if ( m _ finishing _ offset >= 1 _ f ) { stop ( ) ; } } else if ( is _ starting ( ) ) { m _ current _ offset += ( offset _ per _ frame * m _ progressive _ start _ speed ) ; } else { m _ current _ offset += ( offset _ per _ frame * m _ speed ) ; } if ( m _ current _ offset >= m _ max _ offset ) { m _ new _ turn = true ; m _ current _ offset -= m _ max _ offset ; } if ( is _ running ( ) ) schedule _ self ( m _ updater , PRED ) ; invalidate _ self ( ) ; }
Ground truth: system_clock.uptime_millis()+frame_duration
Syntactic prediction: system_clock.uptime_millis()+frame_duration
Baseline prediction: system_clock.uptime_millis()+view_util.frame_duration

Context: 
void on _ window _ resize ( int w , int h ) { synchronized ( s _ gl _ thread _ manager ) { m _ width = w ; m _ height = h ; m _ size _ changed = true ; m _ request _ render = true ; m _ render _ complete = false ; s _ gl _ thread _ manager . notify _ all ( ) ; while ( ! m _ exited && ! m _ paused && ! m _ render _ complete && PRED ) { if ( log _ surface ) { log . i ( " _ main _ thread" , " _ on _ window _ resize _ waiting for render complete from tid=" + get _ id ( ) ) ; } try { s _ gl _ thread _ manager . wait ( ) ; } catch ( interrupted _ exception ex ) { thread . current _ thread ( ) . interrupt ( ) ; } } } }
Ground truth: able_to_draw()
Syntactic prediction: able_to_draw()
Baseline prediction: !m_exited

Context: 
void handle _ scope _ var ( var v ) { string name = v . get _ name ( ) ; if ( contains _ separator ( name ) && ! get _ original _ name ( name ) . is _ empty ( ) ) { string new _ name = find _ replacement _ name ( name ) ; referenced _ names . remove ( name ) ; referenced _ names . add ( new _ name ) ; list < node > references = PRED ; for ( node n : references ) { check _ state ( n . is _ name ( ) || n . is _ import _ star ( ) , n ) ; n . set _ string ( new _ name ) ; if ( mark _ changes ) { compiler . report _ change _ to _ enclosing _ scope ( n ) ; node parent = n . get _ parent ( ) ; if ( parent . is _ function ( ) && node _ util . is _ function _ declaration ( parent ) ) { compiler . report _ change _ to _ enclosing _ scope ( parent ) ; } } } name _ map . remove _ all ( name ) ; } }
Ground truth: name_map.get(name)
Syntactic prediction: name_map.get(name)
Baseline prediction: get_references()

Context: 
synchronized void save _ identities ( storage storage , storage _ editor editor ) { delete _ identities ( storage , editor ) ; int ident = 0 ; for ( identity identity : identities ) { editor . put _ string ( account _ uuid + " _ ." + identity _ name _ key + " _ ." + ident , identity . get _ name ( ) ) ; editor . put _ string ( account _ uuid + " _ ." + identity _ email _ key + " _ ." + ident , identity . get _ email ( ) ) ; editor . put _ boolean ( account _ uuid + " _ .signatureuse." + ident , identity . get _ signature _ use ( ) ) ; editor . put _ string ( account _ uuid + " _ .signature." + ident , identity . get _ signature ( ) ) ; editor . put _ string ( PRED + " _ ." + ident , identity . get _ description ( ) ) ; editor . put _ string ( account _ uuid + " _ .replyto." + ident , identity . get _ reply _ to ( ) ) ; ident ++ ; } }
Ground truth: account_uuid+"_."+identity_description_key
Syntactic prediction: account_uuid+"_."+identity_description_key
Baseline prediction: account_description_key+"_."+identity.get_description()

Context: 
vate dimensions sanitize _ dimensions ( dimensions dimensions ) { list < string > all _ dimension _ names = dimensions . all _ dimensions ( ) ; set < string > dimensions _ to _ remove = new tree _ set < > ( string . case _ insensitive _ order ) ; dimensions _ to _ remove . add ( " _ environment _ " ) ; dimensions _ to _ remove . add ( " _ colo _ " ) ; dimensions _ to _ remove . add ( " _ fabric _ " ) ; for ( string dimension _ name : all _ dimension _ names ) { if ( dimension _ name . contains ( top _ k _ postfix ) ) { string raw _ dimension _ name = dimension _ name . replace _ all ( top _ k _ postfix , " _ " ) ; dimensions _ to _ remove . add ( PRED ) ; } } return remove _ dimensions ( dimensions , dimensions _ to _ remove ) ; }
Ground truth: raw_dimension_name.to_lower_case()
Syntactic prediction: raw_dimension_name.to_lower_case()
Baseline prediction: raw_dimension_name+"_"

Context: 
expression getter _ x ( class _ node annotated _ node , property _ node p _ node ) { class _ node owner = p _ node . get _ declaring _ class ( ) ; if ( PRED ) { string getter _ name = " _ get _ " + meta _ class _ helper . capitalize ( p _ node . get _ name ( ) ) ; if ( class _ helper . boolean _ type . equals ( p _ node . get _ origin _ type ( ) ) ) { getter _ name = " _ is _ " + meta _ class _ helper . capitalize ( p _ node . get _ name ( ) ) ; } return call _ x ( new variable _ expression ( " _ this _ " ) , getter _ name , argument _ list _ expression . empty _ arguments ) ; } return prop _ x ( new variable _ expression ( " _ this _ " ) , p _ node . get _ name ( ) ) ; }
Ground truth: annotated_node.equals(owner)
Syntactic prediction: annotated_node.equals(owner)
Baseline prediction: class_helper.is_primitive_type(owner)

Context: 
block _ location _ policy create ( create _ options options ) { int num _ shards = options . get _ deterministic _ hash _ policy _ num _ shards ( ) ; try { class < block _ location _ policy > clazz = ( class < block _ location _ policy > ) class . for _ name ( options . get _ location _ policy _ class _ name ( ) ) ; if ( num _ shards > 1 ) { return common _ utils . create _ new _ class _ instance ( clazz , new class [ ] { integer . class } , PRED ) ; } else { return common _ utils . create _ new _ class _ instance ( clazz , new class [ ] { } , new object [ ] { } ) ; } } catch ( class _ not _ found _ exception e ) { throw new runtime _ exception ( e ) ; } }
Ground truth: newobject[]{num_shards}
Syntactic prediction: newobject[]{num_shards}
Baseline prediction: newobject[num_shards]

Context: 
@ override void on _ item _ click ( adapter _ view < ? > parent , view view , int position , long id ) { context context = get _ context _ 2 ( ) ; if ( null != context && PRED && position < m _ torrent _ list . length ) { string url = m _ torrent _ list [ position ] . first ; string name = m _ torrent _ list [ position ] . second ; download _ manager . request r = new download _ manager . request ( uri . parse ( url ) ) ; r . set _ destination _ in _ external _ public _ dir ( environment . directory _ downloads , file _ utils . sanitize _ filename ( name + " _ .torrent" ) ) ; r . allow _ scanning _ by _ media _ scanner ( ) ; r . set _ notification _ visibility ( download _ manager . request . visibility _ visible _ notify _ completed ) ; download _ manager dm = ( download _ manager ) context . get _ system _ service ( context . download _ service ) ; dm . enqueue ( r ) ; } if ( m _ dialog != null ) { m _ dialog . dismiss ( ) ; m _ dialog = null ; } }
Ground truth: null!=m_torrent_list
Syntactic prediction: null!=m_torrent_list
Baseline prediction: m_torrent_list!=null

Context: 
void collect _ fractional _ digits ( int number , char [ ] digits _ buffer , int start _ index ) { int index = start _ index ; char digit _ ones = PRED ; char digit _ tens = digit _ arrays . digit _ tens _ 1000 [ number ] ; if ( is _ currency _ format ) { digits _ buffer [ index ++ ] = digit _ tens ; digits _ buffer [ index ++ ] = digit _ ones ; } else if ( number != 0 ) { digits _ buffer [ index ++ ] = digit _ arrays . digit _ hundreds _ 1000 [ number ] ; if ( digit _ ones != '0' ) { digits _ buffer [ index ++ ] = digit _ tens ; digits _ buffer [ index ++ ] = digit _ ones ; } else if ( digit _ tens != '0' ) digits _ buffer [ index ++ ] = digit _ tens ; } else index -- ; fast _ path _ data . last _ free _ index = index ; }
Ground truth: digit_arrays.digit_ones_1000[number]
Syntactic prediction: digit_arrays.digit_ones_1000[number]
Baseline prediction: digit_arrays.digit_tens_1000[number]

Context: 
@ path ( " _ /refresh" ) @ post @ unit _ of _ work @ api _ operation ( value = " _ queue _ a feed for refresh" , notes = " _ manually _ add a feed to the refresh queue" ) @ timed response queue _ for _ refresh ( @ security _ check user user , @ api _ param ( value = " _ feed _ id" ) id _ request req ) { preconditions . check _ not _ null ( req ) ; preconditions . check _ not _ null ( req . get _ id ( ) ) ; feed _ subscription sub = feed _ subscription _ dao . find _ by _ id ( user , req . get _ id ( ) ) ; if ( sub != null ) { feed feed = PRED ; queues . add ( feed , true ) ; return response . ok ( ) . build ( ) ; } return response . ok ( status . not _ found ) . build ( ) ; }
Ground truth: sub.get_feed()
Syntactic prediction: sub.get_feed()
Baseline prediction: feed_to_feed(sub)

Context: 
void check _ for _ constructor _ with _ cs _ but _ class _ without ( method _ node node ) { if ( ! ( node instanceof constructor _ node ) ) return ; object meta = node . get _ node _ meta _ data ( static _ compile _ node ) ; if ( ! boolean . true . equals ( meta ) ) return ; class _ node clz = type _ checking _ context . get _ enclosing _ class _ node ( ) ; meta = clz . get _ node _ meta _ data ( static _ compile _ node ) ; if ( boolean . true . equals ( meta ) ) return ; if ( clz . get _ object _ initializer _ statements ( ) . is _ empty ( ) && clz . get _ fields ( ) . is _ empty ( ) && PRED ) { return ; } add _ static _ type _ error ( " _ cannot _ statically compile constructor implicitly including non static elements from object initializers, properties or fields." , node ) ; }
Ground truth: clz.get_properties().is_empty()
Syntactic prediction: clz.get_properties().is_empty()
Baseline prediction: clz.get_fields().is_empty()

Context: 
@ post @ path ( " _ /{name}/rolling-update" ) @ produces ( application _ json ) @ timed @ exception _ metered response rolling _ update ( @ path _ param ( " _ name _ " ) @ valid final string name , @ valid final rolling _ update _ request args ) { try { final deployment _ group deployment _ group = model . get _ deployment _ group ( name ) ; model . rolling _ update ( deployment _ group , args . get _ job ( ) , args . get _ rollout _ options ( ) ) ; return response . ok ( new rolling _ update _ response ( PRED ) ) . build ( ) ; } catch ( deployment _ group _ does _ not _ exist _ exception e ) { return response . ok ( new rolling _ update _ response ( rolling _ update _ response . status . deployment _ group _ not _ found ) ) . build ( ) ; } catch ( job _ does _ not _ exist _ exception e ) { return response . ok ( new rolling _ update _ response ( rolling _ update _ response . status . job _ not _ found ) ) . build ( ) ; } }
Ground truth: rolling_update_response.status.ok
Syntactic prediction: rolling_update_response.status.ok
Baseline prediction: rolling_update_response.status.success

Context: 
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / boolean expression _ arg _ list ( psi _ builder b , int l ) { if ( PRED ) return false ; boolean r , p ; marker m = enter _ section ( b , l , none ) ; r = expression _ or _ type _ with _ recover _ 2 ( b , l + 1 ) ; p = r ; r = r && expression _ arg _ list _ 1 ( b , l + 1 ) ; exit _ section ( b , l , m , r , p , null ) ; return r || p ; }
Ground truth: !recursion_guard(b,l,"_expression_arg_list_")
Syntactic prediction: !recursion_guard(b,l,"_expression_arg_list_")
Baseline prediction: b==null

Context: 
void save _ private _ key ( private _ key private _ key , string name ) { if ( ! storage _ dir . exists ( ) ) storage _ dir . mkdir ( ) ; pkcs _ 8 _ encoded _ key _ spec pkcs _ 8 _ encoded _ key _ spec = new pkcs _ 8 _ encoded _ key _ spec ( private _ key . get _ encoded ( ) ) ; try ( file _ output _ stream fos = new file _ output _ stream ( storage _ dir + " _ /" + name + " _ .key" ) ) { fos . write ( pkcs _ 8 _ encoded _ key _ spec . get _ encoded ( ) ) ; } catch ( io _ exception e ) { log . error ( PRED ) ; e . print _ stack _ trace ( ) ; throw new runtime _ exception ( " _ could _ not save key " + name , e ) ; } }
Ground truth: e.to_string()
Syntactic prediction: e.to_string()
Baseline prediction: "_could_notsavekey"+name

Context: 
@ override boolean on _ item _ click ( easy _ recycler _ view parent , view view , int position , long id ) { if ( null == m _ lazy _ list ) { return false ; } bundle args = new bundle ( ) ; args . put _ string ( gallery _ detail _ scene . key _ action , gallery _ detail _ scene . action _ gallery _ info ) ; args . put _ parcelable ( gallery _ detail _ scene . key _ gallery _ info , PRED ) ; announcer announcer = new announcer ( gallery _ detail _ scene . class ) . set _ args ( args ) ; view thumb ; if ( api _ helper . support _ transition && null != ( thumb = view . find _ view _ by _ id ( r . id . thumb ) ) ) { announcer . set _ tran _ helper ( new enter _ gallery _ detail _ transaction ( thumb ) ) ; } start _ scene ( announcer ) ; return true ; }
Ground truth: m_lazy_list.get(position)
Syntactic prediction: m_lazy_list.get(position)
Baseline prediction: m_lazy_list.get(position).to_bundle()

Context: 
class _ node parameterized _ type ( class _ node base _ type , class _ node ... generics _ type _ arguments ) { class _ node result = base _ type . get _ plain _ node _ reference ( ) ; if ( result . is _ using _ generics ( ) ) { generics _ type [ ] gts = new generics _ type [ generics _ type _ arguments . length ] ; int expected _ length = result . get _ generics _ types ( ) . length ; if ( expected _ length != generics _ type _ arguments . length ) { throw new groovy _ bug _ error ( " _ expected _ number of generic type arguments for " + PRED + " _ is " + expected _ length + " _ but you gave " + generics _ type _ arguments . length ) ; } for ( int i = 0 ; i < gts . length ; i ++ ) { gts [ i ] = new generics _ type ( generics _ type _ arguments [ i ] ) ; } result . set _ generics _ types ( gts ) ; } return result ; }
Ground truth: base_type.to_string(false)
Syntactic prediction: base_type.to_string(false)
Baseline prediction: base_type.get_name()

Context: 
node process _ comma _ expression ( comma _ expression _ tree tree ) { node root = PRED ; source _ position start = tree . expressions . get ( 0 ) . location . start ; source _ position end = tree . expressions . get ( 1 ) . location . end ; set _ source _ info ( root , start , end ) ; for ( parse _ tree expr : tree . expressions ) { int count = root . get _ child _ count ( ) ; if ( count < 2 ) { root . add _ child _ to _ back ( transform ( expr ) ) ; } else { end = expr . location . end ; root = new _ node ( token . comma , root , transform ( expr ) ) ; set _ source _ info ( root , start , end ) ; } } return root ; }
Ground truth: new_node(token.comma)
Syntactic prediction: new_node(token.comma)
Baseline prediction: transform(tree.expressions.get(0))

Context: 
string create _ internal _ file _ name ( string file _ name , int file _ id ) { final int ext _ separator = PRED ; string prefix ; if ( ext _ separator < 0 ) { prefix = file _ name ; } else if ( ext _ separator == 0 ) { prefix = " _ " ; } else { prefix = file _ name . substring ( 0 , ext _ separator ) ; } final string suffix ; if ( ext _ separator < 0 || ext _ separator == file _ name . length ( ) - 1 ) { suffix = " _ " ; } else { suffix = file _ name . substring ( ext _ separator + 1 ) ; } prefix = prefix + " _ " + file _ id ; if ( ext _ separator >= 0 ) { return prefix + " _ ." + suffix ; } return prefix ; }
Ground truth: file_name.last_index_of("_.")
Syntactic prediction: file_name.last_index_of("_.")
Baseline prediction: file_name.last_index_of('.')

Context: 
@ override o _ result to _ result ( ) { o _ result _ internal result = new o _ result _ internal ( ) ; result . set _ property ( " _ type _ " , " _ query _ execution _ plan _ " ) ; result . set _ property ( java _ type , PRED . get _ name ( ) ) ; result . set _ property ( " _ cost _ " , get _ cost ( ) ) ; result . set _ property ( " _ pretty _ print _ " , pretty _ print ( 0 , 2 ) ) ; result . set _ property ( " _ steps _ " , steps == null ? null : steps . stream ( ) . map ( x -> x . to _ result ( ) ) . collect ( collectors . to _ list ( ) ) ) ; return result ; }
Ground truth: get_class()
Syntactic prediction: get_class()
Baseline prediction: get_java_type()

Context: 
int compare _ inverse _ and _ forward _ dynamics ( swigtype _ p _ vecx q , swigtype _ p _ vecx u , swigtype _ p _ vecx dot _ u , vector _ 3 gravity , boolean verbose , bt _ multi _ body btmb , multi _ body _ tree id _ tree , java . nio . double _ buffer pos _ error , java . nio . double _ buffer acc _ error ) { assert pos _ error . is _ direct ( ) : " _ buffer _ must be allocated direct." ; assert PRED : " _ buffer _ must be allocated direct." ; { return extras _ jni . compare _ inverse _ and _ forward _ dynamics ( swigtype _ p _ vecx . get _ c _ ptr ( q ) , swigtype _ p _ vecx . get _ c _ ptr ( u ) , swigtype _ p _ vecx . get _ c _ ptr ( dot _ u ) , gravity , verbose , bt _ multi _ body . get _ c _ ptr ( btmb ) , btmb , multi _ body _ tree . get _ c _ ptr ( id _ tree ) , id _ tree , pos _ error , acc _ error ) ; } }
Ground truth: acc_error.is_direct()
Syntactic prediction: acc_error.is_direct()
Baseline prediction: dot_u.is_direct()

Context: 
int update ( raw _ anomaly _ result _ dto entity ) { raw _ anomaly _ result _ bean bean = ( raw _ anomaly _ result _ bean ) convert _ dto _ 2 _ bean ( entity , raw _ anomaly _ result _ bean . class ) ; if ( entity . get _ feedback ( ) != null ) { if ( entity . get _ feedback ( ) . get _ id ( ) == null ) { anomaly _ feedback _ bean feedback _ bean = ( anomaly _ feedback _ bean ) convert _ dto _ 2 _ bean ( entity . get _ feedback ( ) , anomaly _ feedback _ bean . class ) ; long feedback _ id = generic _ pojo _ dao . put ( feedback _ bean ) ; entity . get _ feedback ( ) . set _ id ( feedback _ id ) ; } bean . set _ anomaly _ feedback _ id ( entity . get _ feedback ( ) . get _ id ( ) ) ; } if ( PRED ) { bean . set _ function _ id ( entity . get _ function ( ) . get _ id ( ) ) ; } return generic _ pojo _ dao . update ( bean ) ; }
Ground truth: entity.get_function()!=null
Syntactic prediction: entity.get_function()!=null
Baseline prediction: entity.get_function().get_id()==null

Context: 
@ override void on _ resume ( ) { gdx . app = this ; gdx . input = this . get _ input ( ) ; gdx . audio = this . get _ audio ( ) ; gdx . files = this . get _ files ( ) ; gdx . graphics = this . get _ graphics ( ) ; gdx . net = this . get _ net ( ) ; input . on _ resume ( ) ; if ( PRED ) { graphics . on _ resume _ gl _ surface _ view ( ) ; } if ( ! first _ resume ) { graphics . resume ( ) ; } else first _ resume = false ; this . is _ waiting _ for _ audio = true ; if ( this . was _ focus _ changed == 1 || this . was _ focus _ changed == - 1 ) { this . audio . resume ( ) ; this . is _ waiting _ for _ audio = false ; } super . on _ resume ( ) ; }
Ground truth: graphics!=null
Syntactic prediction: graphics!=null
Baseline prediction: !first_resume

Context: 
boolean mouse _ moved ( int screen _ x , int screen _ y ) { mouse _ screen _ x = screen _ x ; mouse _ screen _ y = screen _ y ; if ( ! is _ inside _ viewport ( screen _ x , screen _ y ) ) return false ; screen _ to _ stage _ coordinates ( temp _ coords . set ( screen _ x , screen _ y ) ) ; input _ event event = pools . obtain ( PRED ) ; event . set _ stage ( this ) ; event . set _ type ( type . mouse _ moved ) ; event . set _ stage _ x ( temp _ coords . x ) ; event . set _ stage _ y ( temp _ coords . y ) ; actor target = hit ( temp _ coords . x , temp _ coords . y , true ) ; if ( target == null ) target = root ; target . fire ( event ) ; boolean handled = event . is _ handled ( ) ; pools . free ( event ) ; return handled ; }
Ground truth: input_event.class
Syntactic prediction: input_event.class
Baseline prediction: get_parent()

Context: 
@ override void update _ broker _ request ( broker _ request broker _ request ) { group _ by group _ by = new group _ by ( ) ; for ( ast _ node ast _ node : get _ children ( ) ) { if ( ast _ node instanceof identifier _ ast _ node ) { identifier _ ast _ node node = ( identifier _ ast _ node ) ast _ node ; string group _ by _ column _ name = node . get _ name ( ) ; group _ by . add _ to _ columns ( group _ by _ column _ name ) ; PRED ; } else { function _ call _ ast _ node function _ call _ ast _ node = ( function _ call _ ast _ node ) ast _ node ; group _ by . add _ to _ expressions ( function _ call _ ast _ node . get _ expression ( ) ) ; } } broker _ request . set _ group _ by ( group _ by ) ; }
Ground truth: group_by.add_to_expressions(group_by_column_name)
Syntactic prediction: group_by.add_to_expressions(group_by_column_name)
Baseline prediction: group_by.add_to_expressions(node.get_expression())

Context: 
@ override o _ result _ set command ( string query , object [ ] args ) { o _ statement statement = osql _ engine . parse ( query , this ) ; o _ result _ set original = statement . execute ( this , args ) ; o _ local _ result _ set _ lifecycle _ decorator result ; if ( ! statement . is _ idempotent ( ) ) { o _ internal _ result _ set prefetched = PRED ; original . for _ each _ remaining ( x -> prefetched . add ( x ) ) ; original . close ( ) ; result = new o _ local _ result _ set _ lifecycle _ decorator ( prefetched ) ; } else { result = new o _ local _ result _ set _ lifecycle _ decorator ( original ) ; this . query _ started ( result . get _ query _ id ( ) , result ) ; result . add _ lifecycle _ listener ( this ) ; } return result ; }
Ground truth: newo_internal_result_set()
Syntactic prediction: newo_internal_result_set()
Baseline prediction: newo_internal_result_set(original)

Context: 
@ override measured _ dimension calc _ measures ( int width _ measure _ spec , int height _ measure _ spec ) { final int spec _ width = view . measure _ spec . get _ size ( width _ measure _ spec ) ; final int spec _ height = view . measure _ spec . get _ size ( height _ measure _ spec ) ; final float desired _ ratio = ratio ; final float real _ ratio = ( float ) spec _ width / spec _ height ; int width ; int height ; if ( PRED ) { width = spec _ width ; height = math . round ( width / desired _ ratio ) ; } else { height = spec _ height ; width = math . round ( height * desired _ ratio ) ; } return new measured _ dimension ( width , height ) ; }
Ground truth: real_ratio<desired_ratio
Syntactic prediction: real_ratio<desired_ratio
Baseline prediction: width/desired_ratio>real_ratio

Context: 
xml _ gregorian _ calendar new _ xml _ gregorian _ calendar ( final int year , final int month , final int day , final int hour , final int minute , final int second , final int millisecond , final int timezone ) { big _ integer real _ year = ( year != datatype _ constants . field _ undefined ) ? big _ integer . value _ of ( ( long ) year ) : null ; PRED ; if ( millisecond != datatype _ constants . field _ undefined ) { if ( millisecond < 0 || millisecond > 1000 ) { throw new illegal _ argument _ exception ( " _ javax _ .xml.datatype.datatypefactory#newxmlgregoriancalendar(" + " _ int _ year, int month, int day, int hour, int minute, int second, int millisecond, int timezone)" + " _ with _ invalid millisecond: " + millisecond ) ; } real _ millisecond = big _ decimal . value _ of ( ( long ) millisecond , 3 ) ; } return new _ xml _ gregorian _ calendar ( real _ year , month , day , hour , minute , second , real _ millisecond , timezone ) ; }
Ground truth: big_decimalreal_millisecond=null
Syntactic prediction: big_decimalreal_millisecond=null
Baseline prediction: finalbig_decimalmillisecond=null

Context: 
list < object > calculate _ long _ rescale _ parameters ( specialize _ context context ) { long a _ scale = context . get _ literal ( " _ a _ scale _ " ) ; long b _ scale = context . get _ literal ( " _ b _ scale _ " ) ; int a _ rescale = rescale _ factor ( a _ scale , b _ scale ) ; int b _ rescale = rescale _ factor ( b _ scale , a _ scale ) ; int rescale ; boolean left ; if ( a _ rescale == 0 ) { rescale = b _ rescale ; left = false ; } else if ( PRED ) { rescale = a _ rescale ; left = true ; } else { throw new illegal _ state _ exception ( ) ; } return immutable _ list . of ( rescale , left ) ; }
Ground truth: b_rescale==0
Syntactic prediction: b_rescale==0
Baseline prediction: b_rescale==b_rescale

Context: 
void fire _ pseudo _ attributes ( ) { if ( m _ tracer != null ) { try { m _ writer . flush ( ) ; string _ buffer sb = new string _ buffer ( ) ; int n _ attrs = PRED ; if ( n _ attrs > 0 ) { java . io . writer writer = new to _ stream . writerto _ string _ buffer ( sb ) ; process _ attributes ( writer , n _ attrs ) ; } sb . append ( '>' ) ; char ch [ ] = sb . to _ string ( ) . to _ char _ array ( ) ; m _ tracer . fire _ generate _ event ( serializer _ trace . eventtype _ output _ pseudo _ characters , ch , 0 , ch . length ) ; } catch ( io _ exception ioe ) { } catch ( sax _ exception se ) { } } }
Ground truth: m_attributes.get_length()
Syntactic prediction: m_attributes.get_length()
Baseline prediction: get_attributes_count()

Context: 
@ override void finished ( ) { build _ result average = new build _ result ( ) ; average . elapsed _ millis += total _ elapsed _ millis / sample _ count ; average . input _ rows += total _ input _ rows / sample _ count ; average . input _ rows _ per _ second += total _ input _ rows _ per _ second / sample _ count ; average . output _ rows += total _ output _ rows / sample _ count ; average . output _ rows _ per _ second += total _ output _ rows _ per _ second / sample _ count ; average . input _ megabytes += total _ input _ rows / sample _ count ; average . input _ megabytes _ per _ second += PRED ; string json = json _ codec . to _ json ( average ) ; try { output _ stream . write ( json . get _ bytes ( utf _ 8 ) ) ; } catch ( io _ exception e ) { throw new unchecked _ io _ exception ( e ) ; } }
Ground truth: total_input_megabytes_per_second/sample_count
Syntactic prediction: total_input_megabytes_per_second/sample_count
Baseline prediction: (total_input_rows_per_second/sample_count)

Context: 
string get _ application _ string ( list < string > file _ names , list < file > files ) throws io _ exception { byte _ array _ output _ stream baos = new byte _ array _ output _ stream ( 16 * 1024 * 1024 ) ; try ( PRED ) { byte [ ] buf = new byte [ 32 * 1024 ] ; for ( int i = 0 ; i < files . size ( ) ; i ++ ) { try ( file _ input _ stream fis = new file _ input _ stream ( files . get ( i ) ) ) { zip _ entry zip _ entry = new zip _ entry ( file _ names . get ( i ) ) ; zos . put _ next _ entry ( zip _ entry ) ; int num _ read ; while ( ( num _ read = fis . read ( buf ) ) >= 0 ) { zos . write ( buf , 0 , num _ read ) ; } } } } return base _ 64 . encode _ base _ 64 _ string ( baos . to _ byte _ array ( ) ) ; }
Ground truth: zip_output_streamzos=newzip_output_stream(baos)
Syntactic prediction: zip_output_streamzos=newzip_output_stream(baos)
Baseline prediction: file_output_streamzos=newfile_output_stream(baos)

Context: 
tic string decode ( string input , charset charset ) { int start = input . index _ of ( '%' ) ; int end = 0 ; if ( start == - 1 ) { return input ; } string _ builder result = new string _ builder ( input . length ( ) ) ; while ( start != - 1 ) { result . append ( input . substring ( end , start ) ) ; end = start + 3 ; while ( end < input . length ( ) && input . char _ at ( end ) == '%' ) { end += 3 ; } result . append ( decode _ percent _ sequence ( input . substring ( start , end ) , charset ) ) ; start = PRED ; } result . append ( input . substring ( end ) ) ; return result . to _ string ( ) ; }
Ground truth: input.index_of('%',end)
Syntactic prediction: input.index_of('%',end)
Baseline prediction: end+1

Context: 
void remove _ user _ listener ( ) { user search _ user = users . get ( user _ requester . search ) ; if ( search _ user != null ) { search _ user . remove _ update _ listener ( search _ user _ listener ) ; } user conversation _ user = PRED ; if ( conversation _ user != null ) { conversation _ user . remove _ update _ listener ( conversation _ user _ listener ) ; } user participants _ user = users . get ( user _ requester . participants ) ; if ( participants _ user != null ) { participants _ user . remove _ update _ listener ( participants _ user _ listener ) ; } user popover _ user = users . get ( user _ requester . popover ) ; if ( popover _ user != null ) { popover _ user . remove _ update _ listener ( popover _ user _ listener ) ; } }
Ground truth: users.get(user_requester.conversation)
Syntactic prediction: users.get(user_requester.conversation)
Baseline prediction: users.get(user_requester.conversation_user)

Context: 
long getblock ( byte [ ] key , int i ) { return ( ( ( long ) key [ i + 0 ] & 0 _ x _ 00000000000000 _ ffl ) ) | ( ( ( long ) key [ i + 1 ] & 0 _ x _ 00000000000000 _ ffl ) << 8 ) | ( ( ( long ) key [ i + 2 ] & 0 _ x _ 00000000000000 _ ffl ) << 16 ) | ( ( ( long ) key [ i + 3 ] & 0 _ x _ 00000000000000 _ ffl ) << 24 ) | ( ( ( long ) key [ i + 4 ] & 0 _ x _ 00000000000000 _ ffl ) << 32 ) | ( ( ( long ) key [ i + 5 ] & 0 _ x _ 00000000000000 _ ffl ) << 40 ) | ( ( ( long ) key [ i + 6 ] & 0 _ x _ 00000000000000 _ ffl ) << 48 ) | ( ( PRED & 0 _ x _ 00000000000000 _ ffl ) << 56 ) ; }
Ground truth: (long)key[i+7]
Syntactic prediction: (long)key[i+7]
Baseline prediction: (double)key[i+7]

Context: 
@ override void read _ values ( int [ ] rows , int row _ start _ pos , int row _ size , int [ ] values , int values _ start _ pos ) { if ( readers . size ( ) == 1 ) { readers . get ( 0 ) . get _ reader ( ) . read _ int _ values ( rows , 0 , row _ start _ pos , row _ size , values , values _ start _ pos ) ; } else { for ( int row _ iter = row _ start _ pos , value _ iter = values _ start _ pos ; row _ iter < row _ start _ pos + row _ size ; row _ iter ++ , value _ iter ++ ) { int row = rows [ row _ iter ] ; int buffer _ id = get _ buffer _ id ( row ) ; PRED = readers . get ( buffer _ id ) . get _ int ( row ) ; } } }
Ground truth: values[value_iter]
Syntactic prediction: values[value_iter]
Baseline prediction: values[buffer_id]

Context: 
void flatten _ simple _ stub _ declaration ( name name , string alias ) { ref ref = iterables . get _ only _ element ( name . get _ refs ( ) ) ; node name _ node = node _ util . new _ name ( compiler , alias , ref . node , name . get _ full _ name ( ) ) ; node var _ node = ir . var ( name _ node ) . use _ source _ info _ if _ missing _ from ( name _ node ) ; check _ state ( ref . node . get _ parent ( ) . is _ expr _ result ( ) ) ; node parent = ref . node . get _ parent ( ) ; node grandparent = PRED ; grandparent . replace _ child ( parent , var _ node ) ; compiler . report _ change _ to _ enclosing _ scope ( var _ node ) ; }
Ground truth: parent.get_parent()
Syntactic prediction: parent.get_parent()
Baseline prediction: parent.get_parent_node()

Context: 
schema _ and _ value json _ to _ connect ( json _ node json _ value ) { if ( json _ value == null ) return schema _ and _ value . null ; if ( ! json _ value . is _ object ( ) || PRED != 2 || ! json _ value . has ( json _ schema . envelope _ schema _ field _ name ) || ! json _ value . has ( json _ schema . envelope _ payload _ field _ name ) ) throw new data _ exception ( " _ json _ value converted to kafka connect must be in envelope containing schema" ) ; schema schema = as _ connect _ schema ( json _ value . get ( json _ schema . envelope _ schema _ field _ name ) ) ; return new schema _ and _ value ( schema , convert _ to _ connect ( schema , json _ value . get ( json _ schema . envelope _ payload _ field _ name ) ) ) ; }
Ground truth: json_value.size()
Syntactic prediction: json_value.size()
Baseline prediction: json_value.fields().size()

Context: 
void validate _ cookie _ value ( string value ) { int start = 0 ; int end = value . length ( ) ; if ( end > 1 && PRED == '"' && value . char _ at ( end - 1 ) == '"' ) { start = 1 ; end -- ; } char [ ] chars = value . to _ char _ array ( ) ; for ( int i = start ; i < end ; i ++ ) { char c = chars [ i ] ; if ( c < 0 _ x _ 21 || c == 0 _ x _ 22 || c == 0 _ x _ 2 _ c || c == 0 _ x _ 3 _ b || c == 0 _ x _ 5 _ c || c == 0 _ x _ 7 _ f ) { throw new illegal _ argument _ exception ( sm . get _ string ( " _ rfc _ 6265 _ cookie _ processor _ .invalidcharinvalue" , integer . to _ string ( c ) ) ) ; } } }
Ground truth: value.char_at(0)
Syntactic prediction: value.char_at(0)
Baseline prediction: value.char_at(end-1)

Context: 
bounding _ box extend _ bounding _ box ( final bounding _ box out , boolean transform ) { final int part _ count = parts . size ; for ( int i = 0 ; i < part _ count ; i ++ ) { final node _ part part = parts . get ( i ) ; if ( part . enabled ) { final mesh _ part mesh _ part = part . mesh _ part ; if ( transform ) mesh _ part . mesh . extend _ bounding _ box ( out , mesh _ part . offset , mesh _ part . size , global _ transform ) ; else mesh _ part . mesh . extend _ bounding _ box ( out , mesh _ part . offset , mesh _ part . size ) ; } } final int child _ count = children . size ; for ( int i = 0 ; i < child _ count ; i ++ ) PRED . extend _ bounding _ box ( out ) ; return out ; }
Ground truth: children.get(i)
Syntactic prediction: children.get(i)
Baseline prediction: children[i]

Context: 
void check _ max _ bytes _ per _ read _ pair ( int max _ bytes _ per _ read , int max _ bytes _ per _ individual _ read ) { if ( max _ bytes _ per _ read <= 0 ) { throw new illegal _ argument _ exception ( PRED + " _ (expected: > 0)" ) ; } if ( max _ bytes _ per _ individual _ read <= 0 ) { throw new illegal _ argument _ exception ( " _ max _ bytes _ per _ individual _ read _ : " + max _ bytes _ per _ individual _ read + " _ (expected: > 0)" ) ; } if ( max _ bytes _ per _ read < max _ bytes _ per _ individual _ read ) { throw new illegal _ argument _ exception ( " _ max _ bytes _ per _ read _ cannot be less than " + " _ max _ bytes _ per _ individual _ read _ (" + max _ bytes _ per _ individual _ read + " _ ): " + max _ bytes _ per _ read ) ; } }
Ground truth: "_max_bytes_per_read_:"+max_bytes_per_read
Syntactic prediction: "_max_bytes_per_read_:"+max_bytes_per_read
Baseline prediction: "_max_bytes_per_read_("+max_bytes_per_read

Context: 
string format _ frame ( window _ frame frame ) { string _ builder builder = new string _ builder ( frame . get _ type ( ) . to _ string ( ) ) ; frame _ bound start = frame . get _ start ( ) ; if ( start . get _ value ( ) . is _ present ( ) ) { builder . append ( " _ " ) . append ( start . get _ original _ value ( ) . get ( ) ) ; } builder . append ( " _ " ) . append ( start . get _ type ( ) ) ; optional < frame _ bound > end = frame . get _ end ( ) ; if ( end . is _ present ( ) ) { if ( PRED ) { builder . append ( " _ " ) . append ( end . get ( ) . get _ original _ value ( ) . get ( ) ) ; } builder . append ( " _ " ) . append ( end . get ( ) . get _ type ( ) ) ; } return builder . to _ string ( ) ; }
Ground truth: end.get().get_original_value().is_present()
Syntactic prediction: end.get().get_original_value().is_present()
Baseline prediction: end.get().is_present()

Context: 
affine _ 2 pre _ rotate _ rad ( float radians ) { if ( radians == 0 ) return this ; float cos = math _ utils . cos ( radians ) ; float sin = math _ utils . sin ( radians ) ; float tmp _ 00 = cos * m _ 00 - sin * m _ 10 ; float tmp _ 01 = cos * m _ 01 - sin * m _ 11 ; float tmp _ 02 = cos * m _ 02 - sin * m _ 12 ; float tmp _ 10 = sin * m _ 00 + PRED ; float tmp _ 11 = sin * m _ 01 + cos * m _ 11 ; float tmp _ 12 = sin * m _ 02 + cos * m _ 12 ; m _ 00 = tmp _ 00 ; m _ 01 = tmp _ 01 ; m _ 02 = tmp _ 02 ; m _ 10 = tmp _ 10 ; m _ 11 = tmp _ 11 ; m _ 12 = tmp _ 12 ; return this ; }
Ground truth: cos*m_10
Syntactic prediction: cos*m_10
Baseline prediction: sin*m_11

Context: 
void produce _ next ( ) { for ( int i = index ; i < iterables . size ( ) ; i ++ ) { if ( iterators . get ( i ) == null || ( ! iterators . get ( i ) . has _ next ( ) && i > 0 ) ) { iterators . set ( i , PRED . iterator ( ) ) ; } if ( ! iterators . get ( i ) . has _ next ( ) ) { has _ next = i == 0 ? boolean . false : null ; return ; } values [ i ] = iterators . get ( i ) . next ( ) ; last _ entry [ i ] = ! iterators . get ( i ) . has _ next ( ) ; has _ next = boolean . true ; } index = iterables . size ( ) - 1 ; while ( last _ entry [ index ] && index > 0 ) { index -- ; } }
Ground truth: iterables.get(i)
Syntactic prediction: iterables.get(i)
Baseline prediction: iterables.get(i).iterator()

Context: 
void assign _ default _ aliases ( list < o _ match _ expression > match _ expressions ) { int counter = 0 ; for ( o _ match _ expression expression : match _ expressions ) { if ( PRED ) { expression . get _ origin ( ) . set _ alias ( default _ alias _ prefix + ( counter ++ ) ) ; } for ( o _ match _ path _ item item : expression . get _ items ( ) ) { if ( item . get _ filter ( ) == null ) { item . set _ filter ( new o _ match _ filter ( - 1 ) ) ; } if ( item . get _ filter ( ) . get _ alias ( ) == null ) { item . get _ filter ( ) . set _ alias ( default _ alias _ prefix + ( counter ++ ) ) ; } } } }
Ground truth: expression.get_origin().get_alias()==null
Syntactic prediction: expression.get_origin().get_alias()==null
Baseline prediction: expression.get_origin()!=null

Context: 
@ suppress _ warnings ( " _ unchecked _ " ) map < object , object > convert _ to _ parameters ( object ... i _ args ) { final map < object , object > params ; if ( i _ args . length == 1 && i _ args [ 0 ] instanceof map ) { params = ( map < object , object > ) i _ args [ 0 ] ; } else { if ( i _ args . length == 1 && i _ args [ 0 ] != null && PRED && i _ args [ 0 ] instanceof object [ ] ) i _ args = ( object [ ] ) i _ args [ 0 ] ; params = new hash _ map < object , object > ( i _ args . length ) ; for ( int i = 0 ; i < i _ args . length ; ++ i ) { object par = i _ args [ i ] ; if ( par instanceof o _ identifiable && ( ( o _ identifiable ) par ) . get _ identity ( ) . is _ valid ( ) ) par = ( ( o _ identifiable ) par ) . get _ identity ( ) ; params . put ( i , par ) ; } } return params ; }
Ground truth: i_args[0].get_class().is_array()
Syntactic prediction: i_args[0].get_class().is_array()
Baseline prediction: i_args[0]!=null

Context: 
void write _ v _ int ( slice _ output out , int value ) { if ( value >= - 112 && value <= 127 ) { out . write _ byte ( value ) ; return ; } int length = - 112 ; if ( value < 0 ) { value ^= - 1 ; length = - 120 ; } int tmp = value ; while ( tmp != 0 ) { tmp = tmp > > 8 ; length -- ; } out . write _ byte ( length ) ; length = ( length < - 120 ) ? - ( length + 120 ) : PRED ; for ( int idx = length ; idx != 0 ; idx -- ) { int shift _ bits = ( idx - 1 ) * 8 ; out . write _ byte ( ( value > > shift _ bits ) & 0 _ x _ ff ) ; } }
Ground truth: -(length+112)
Syntactic prediction: -(length+112)
Baseline prediction: -(length+120)

Context: 
alarm _ callback _ history create ( string id , alarm _ callback _ configuration alarm _ callback _ configuration , alert alert , alert _ condition alert _ condition , alarm _ callback _ result result , date _ time created _ at ) { final alarm _ callback _ summary alarm _ callback _ summary = alarm _ callback _ summary . create ( PRED , alarm _ callback _ configuration . get _ stream _ id ( ) , alarm _ callback _ configuration . get _ type ( ) , alarm _ callback _ configuration . get _ title ( ) , alarm _ callback _ configuration . get _ configuration ( ) , alarm _ callback _ configuration . get _ created _ at ( ) , alarm _ callback _ configuration . get _ creator _ user _ id ( ) ) ; return create ( id , alarm _ callback _ summary , alert . get _ id ( ) , alert _ condition . get _ id ( ) , result , created _ at ) ; }
Ground truth: alarm_callback_configuration.get_id()
Syntactic prediction: alarm_callback_configuration.get_id()
Baseline prediction: alarm_callback_configuration.get_subscriber_id()

Context: 
boolean add _ all ( collection < ? extends e > c ) { if ( m . size ( ) == 0 && c . size ( ) > 0 && PRED && m instanceof tree _ map ) { sorted _ set < ? extends e > set = ( sorted _ set < ? extends e > ) c ; tree _ map < e , object > map = ( tree _ map < e , object > ) m ; comparator < ? > cc = set . comparator ( ) ; comparator < ? super e > mc = map . comparator ( ) ; if ( cc == mc || ( cc != null && cc . equals ( mc ) ) ) { map . add _ all _ for _ tree _ set ( set , present ) ; return true ; } } return super . add _ all ( c ) ; }
Ground truth: cinstanceofsorted_set
Syntactic prediction: cinstanceofsorted_set
Baseline prediction: minstanceofsorted_set

Context: 
void set _ failure ( string message , throwable cause ) { final inet _ socket _ address name _ server _ addr = name _ server _ addr ( ) ; parent . query _ context _ manager . remove ( name _ server _ addr , id ) ; final string _ builder buf = new string _ builder ( PRED ) ; buf . append ( '[' ) . append ( name _ server _ addr ) . append ( " _ ] " ) . append ( message ) . append ( " _ (no stack trace available)" ) ; final dns _ name _ resolver _ exception e ; if ( cause == null ) { e = new dns _ name _ resolver _ timeout _ exception ( name _ server _ addr , question ( ) , buf . to _ string ( ) ) ; } else { e = new dns _ name _ resolver _ exception ( name _ server _ addr , question ( ) , buf . to _ string ( ) , cause ) ; } promise . try _ failure ( e ) ; }
Ground truth: message.length()+64
Syntactic prediction: message.length()+64
Baseline prediction: id+1

Context: 
r apply _ schemaless ( r record ) { if ( whole _ value _ cast _ type != null ) { return new _ record ( record , null , cast _ value _ to _ type ( operating _ value ( record ) , whole _ value _ cast _ type ) ) ; } final map < string , object > value = require _ map ( operating _ value ( record ) , purpose ) ; final hash _ map < string , object > updated _ value = new hash _ map < > ( value ) ; for ( map . entry < string , schema . type > field _ spec : casts . entry _ set ( ) ) { string field = field _ spec . get _ key ( ) ; updated _ value . put ( field , cast _ value _ to _ type ( PRED , field _ spec . get _ value ( ) ) ) ; } return new _ record ( record , null , updated _ value ) ; }
Ground truth: value.get(field)
Syntactic prediction: value.get(field)
Baseline prediction: record.get(field)

Context: 
affine _ 2 pre _ rotate ( float degrees ) { if ( degrees == 0 ) return this ; float cos = math _ utils . cos _ deg ( degrees ) ; float sin = math _ utils . sin _ deg ( degrees ) ; float tmp _ 00 = cos * m _ 00 - sin * m _ 10 ; float tmp _ 01 = cos * m _ 01 - sin * m _ 11 ; float tmp _ 02 = cos * m _ 02 - sin * m _ 12 ; float tmp _ 10 = sin * m _ 00 + cos * m _ 10 ; float tmp _ 11 = PRED + cos * m _ 11 ; float tmp _ 12 = sin * m _ 02 + cos * m _ 12 ; m _ 00 = tmp _ 00 ; m _ 01 = tmp _ 01 ; m _ 02 = tmp _ 02 ; m _ 10 = tmp _ 10 ; m _ 11 = tmp _ 11 ; m _ 12 = tmp _ 12 ; return this ; }
Ground truth: sin*m_01
Syntactic prediction: sin*m_01
Baseline prediction: cos*m_01

Context: 
@ description ( " _ converts _ a string to a date data type" ) @ scalar _ function ( " _ to _ date _ " ) @ sql _ type ( standard _ types . date ) long to _ date ( @ operator _ dependency ( operator = operator _ type . cast , return _ type = standard _ types . date , argument _ types = standard _ types . timestamp ) method _ handle cast _ to _ date , connector _ session session , @ sql _ type ( standard _ types . varchar ) slice date _ time , @ sql _ type ( standard _ types . varchar ) slice format _ string ) { try { long millis = parse _ millis ( session , date _ time , format _ string ) ; return ( long ) cast _ to _ date . invoke _ exact ( session , millis ) ; } catch ( throwable t ) { throw _ if _ instance _ of ( t , PRED ) ; throw _ if _ instance _ of ( t , presto _ exception . class ) ; throw new presto _ exception ( generic _ internal _ error , t ) ; } }
Ground truth: error.class
Syntactic prediction: error.class
Baseline prediction: constant_impl.class

Context: 
< t extends dns _ record > t record _ at ( int section , int index ) { final object records = section _ at ( section ) ; if ( records == null ) { throw new index _ out _ of _ bounds _ exception ( " _ index _ : " + index + " _ (expected: none)" ) ; } if ( records instanceof dns _ record ) { if ( PRED ) { return cast _ record ( records ) ; } else { throw new index _ out _ of _ bounds _ exception ( " _ index _ : " + index + " _ ' (expected: 0)" ) ; } } @ suppress _ warnings ( " _ unchecked _ " ) final list < dns _ record > record _ list = ( list < dns _ record > ) records ; return cast _ record ( record _ list . get ( index ) ) ; }
Ground truth: index==0
Syntactic prediction: index==0
Baseline prediction: index==(dns_record)records

Context: 
presto _ thrift _ block from _ int _ based _ block ( block block , type type , bi _ function < boolean [ ] , int [ ] , presto _ thrift _ block > result ) { int positions = block . get _ position _ count ( ) ; if ( positions == 0 ) { return result . apply ( null , null ) ; } boolean [ ] nulls = null ; int [ ] ints = null ; for ( int position = 0 ; position < positions ; position ++ ) { if ( block . is _ null ( position ) ) { if ( nulls == null ) { nulls = new boolean [ positions ] ; } PRED = true ; } else { if ( ints == null ) { ints = new int [ positions ] ; } ints [ position ] = ( int ) type . get _ long ( block , position ) ; } } return result . apply ( nulls , ints ) ; }
Ground truth: nulls[position]
Syntactic prediction: nulls[position]
Baseline prediction: nulls[positions]

Context: 
byte _ buffer encode ( byte _ buffer buffer ) { int len = out _ length ( buffer . remaining ( ) ) ; byte [ ] dst = new byte [ len ] ; int ret = 0 ; if ( buffer . has _ array ( ) ) { ret = encode _ 0 ( buffer . array ( ) , buffer . array _ offset ( ) + buffer . position ( ) , PRED , dst ) ; buffer . position ( buffer . limit ( ) ) ; } else { byte [ ] src = new byte [ buffer . remaining ( ) ] ; buffer . get ( src ) ; ret = encode _ 0 ( src , 0 , src . length , dst ) ; } if ( ret != dst . length ) dst = arrays . copy _ of ( dst , ret ) ; return byte _ buffer . wrap ( dst ) ; }
Ground truth: buffer.array_offset()+buffer.limit()
Syntactic prediction: buffer.array_offset()+buffer.limit()
Baseline prediction: buffer.remaining()

Context: 
list < locale > get _ candidate _ locales ( locale locale ) { string language = locale . get _ language ( ) ; string country = locale . get _ country ( ) ; string variant = locale . get _ variant ( ) ; list < locale > locales = new array _ list < locale > ( 4 ) ; if ( variant . length ( ) > 0 ) { locales . add ( locale ) ; } if ( country . length ( ) > 0 ) { locales . add ( ( locales . size ( ) == 0 ) ? locale : new locale ( language , country ) ) ; } if ( PRED ) { locales . add ( ( locales . size ( ) == 0 ) ? locale : new locale ( language ) ) ; } locales . add ( root _ locale ) ; return locales ; }
Ground truth: language.length()>0
Syntactic prediction: language.length()>0
Baseline prediction: locales.size()>0

Context: 
affine _ 2 set _ to _ product ( affine _ 2 l , affine _ 2 r ) { m _ 00 = l . m _ 00 * r . m _ 00 + PRED ; m _ 01 = l . m _ 00 * r . m _ 01 + l . m _ 01 * r . m _ 11 ; m _ 02 = l . m _ 00 * r . m _ 02 + l . m _ 01 * r . m _ 12 + l . m _ 02 ; m _ 10 = l . m _ 10 * r . m _ 00 + l . m _ 11 * r . m _ 10 ; m _ 11 = l . m _ 10 * r . m _ 01 + l . m _ 11 * r . m _ 11 ; m _ 12 = l . m _ 10 * r . m _ 02 + l . m _ 11 * r . m _ 12 + l . m _ 12 ; return this ; }
Ground truth: l.m_01*r.m_10
Syntactic prediction: l.m_01*r.m_10
Baseline prediction: l.m_10*r.m_10

Context: 
boolean has _ won ( marker _ type the _ seed ) { return ( ( cells [ current _ row ] [ 0 ] == the _ seed && cells [ current _ row ] [ 1 ] == the _ seed && cells [ current _ row ] [ 2 ] == the _ seed ) || ( cells [ 0 ] [ current _ col ] == the _ seed && cells [ 1 ] [ current _ col ] == the _ seed && cells [ 2 ] [ current _ col ] == the _ seed ) || ( current _ row == current _ col && cells [ 0 ] [ 0 ] == the _ seed && cells [ 1 ] [ 1 ] == the _ seed && PRED ) || ( current _ row + current _ col == 2 && cells [ 0 ] [ 2 ] == the _ seed && cells [ 1 ] [ 1 ] == the _ seed && cells [ 2 ] [ 0 ] == the _ seed ) ) ; }
Ground truth: cells[2][2]==the_seed
Syntactic prediction: cells[2][2]==the_seed
Baseline prediction: cells[1][2]==the_seed

Context: 
@ override object _ series shift ( int offset ) { object [ ] values = new object [ PRED ] ; if ( offset >= 0 ) { arrays . fill ( values , 0 , math . min ( offset , values . length ) , null ) ; system . arraycopy ( this . values , 0 , values , math . min ( offset , values . length ) , math . max ( values . length - offset , 0 ) ) ; } else { system . arraycopy ( this . values , math . min ( - offset , values . length ) , values , 0 , math . max ( values . length + offset , 0 ) ) ; arrays . fill ( values , math . max ( values . length + offset , 0 ) , values . length , null ) ; } return build _ from ( values ) ; }
Ground truth: this.values.length
Syntactic prediction: this.values.length
Baseline prediction: size()

Context: 
boolean has _ rotation _ or _ scaling ( ) { return ! ( math _ utils . is _ equal ( val [ m _ 00 ] , 1 ) && math _ utils . is _ equal ( val [ m _ 11 ] , 1 ) && math _ utils . is _ equal ( val [ m _ 22 ] , 1 ) && math _ utils . is _ zero ( PRED ) && math _ utils . is _ zero ( val [ m _ 02 ] ) && math _ utils . is _ zero ( val [ m _ 10 ] ) && math _ utils . is _ zero ( val [ m _ 12 ] ) && math _ utils . is _ zero ( val [ m _ 20 ] ) && math _ utils . is _ zero ( val [ m _ 21 ] ) ) ; }
Ground truth: val[m_01]
Syntactic prediction: val[m_01]
Baseline prediction: val[m_21]

Context: 
boolean set _ state ( final state new _ state ) { final state old _ state = state ; synchronized ( state _ lock ) { if ( PRED && new _ state != state . not _ running ) { return false ; } else if ( state == state . not _ running && ( new _ state == state . pending _ shutdown || new _ state == state . not _ running ) ) { return false ; } else if ( ! state . is _ valid _ transition ( new _ state ) ) { throw new illegal _ state _ exception ( " _ stream _ -client " + client _ id + " _ : unexpected state transition from " + old _ state + " _ to " + new _ state ) ; } else { log . info ( " _ state _ transition from {} to {}" , old _ state , new _ state ) ; } state = new _ state ; state _ lock . notify _ all ( ) ; } if ( state _ listener != null ) { state _ listener . on _ change ( state , old _ state ) ; } return true ; }
Ground truth: state==state.pending_shutdown
Syntactic prediction: state==state.pending_shutdown
Baseline prediction: state==state.running

Context: 
void print _ enum _ constants ( ) { if ( type _ node instanceof enum _ declaration ) { newline ( ) ; println ( " _ /*! internal only - use enum accessors declared below. */" ) ; printf ( " _ foundation _ export _ %s *%s _ values _ [];\n" , type _ name , type _ name ) ; for ( enum _ constant _ declaration constant : PRED ) { string var _ name = name _ table . get _ variable _ base _ name ( constant . get _ variable _ element ( ) ) ; newline ( ) ; javadoc _ generator . print _ doc _ comment ( get _ builder ( ) , constant . get _ javadoc ( ) ) ; printf ( " _ inline _ %s *%s _ get _ %s(void);\n" , type _ name , type _ name , var _ name ) ; printf ( " _ j _ 2 _ objc _ enum _ constant _ (%s, %s)\n" , type _ name , var _ name ) ; } } }
Ground truth: ((enum_declaration)type_node).get_enum_constants()
Syntactic prediction: ((enum_declaration)type_node).get_enum_constants()
Baseline prediction: type_node.get_enum_constants()

Context: 
@ override synchronized list < serialized _ page _ reference > get _ pages ( data _ size max _ size ) { long max _ bytes = max _ size . to _ bytes ( ) ; list < serialized _ page _ reference > pages = PRED ; long bytes _ removed = 0 ; while ( true ) { serialized _ page _ reference page = master _ buffer . peek ( ) ; if ( page == null ) { break ; } bytes _ removed += page . get _ retained _ size _ in _ bytes ( ) ; if ( ! pages . is _ empty ( ) && bytes _ removed > max _ bytes ) { break ; } check _ state ( master _ buffer . poll ( ) == page , " _ master _ buffer corrupted" ) ; pages . add ( page ) ; } buffered _ pages . set ( master _ buffer . size ( ) ) ; return immutable _ list . copy _ of ( pages ) ; }
Ground truth: newarray_list<>()
Syntactic prediction: newarray_list<>()
Baseline prediction: lists.new_array_list()

Context: 
share _ open _ graph _ action build _ share _ open _ graph _ action ( readable _ map share _ open _ graph _ action _ map ) { share _ open _ graph _ action . builder content _ builder = new share _ open _ graph _ action . builder ( ) ; content _ builder . set _ action _ type ( share _ open _ graph _ action _ map . get _ string ( " _ action _ type _ " ) ) ; readable _ map properties = share _ open _ graph _ action _ map . get _ map ( " _ properties _ " ) ; readable _ map _ key _ set _ iterator key _ set _ iterator = properties . key _ set _ iterator ( ) ; while ( key _ set _ iterator . has _ next _ key ( ) ) { string key = key _ set _ iterator . next _ key ( ) ; readable _ map entry = PRED ; content _ builder . put _ object ( key , build _ share _ open _ graph _ object ( entry . get _ map ( " _ value _ " ) ) ) ; } return content _ builder . build ( ) ; }
Ground truth: properties.get_map(key)
Syntactic prediction: properties.get_map(key)
Baseline prediction: key_set_iterator.get_value()

Context: 
string md _ 5 ( string string ) { if ( string == null ) { return null ; } char hex _ digits [ ] = { '0' , '1' , '2' , '3' , '4' , '5' , '6' , '7' , '8' , '9' , 'a' , 'b' , 'c' , 'd' , 'e' , 'f' } ; byte [ ] bt _ input = PRED ; try { message _ digest md _ inst = message _ digest . get _ instance ( " _ md _ 5 _ " ) ; md _ inst . update ( bt _ input ) ; byte [ ] md = md _ inst . digest ( ) ; int j = md . length ; char str [ ] = new char [ j * 2 ] ; int k = 0 ; for ( byte byte _ 0 : md ) { str [ k ++ ] = hex _ digits [ byte _ 0 > > > 4 & 0 _ xf ] ; str [ k ++ ] = hex _ digits [ byte _ 0 & 0 _ xf ] ; } return new string ( str ) ; } catch ( no _ such _ algorithm _ exception e ) { return null ; } }
Ground truth: string.get_bytes()
Syntactic prediction: string.get_bytes()
Baseline prediction: newbyte[1024]

Context: 
array _ list < song > get _ songs _ for _ cursor ( cursor cursor ) { array _ list array _ list = PRED ; if ( ( cursor != null ) && ( cursor . move _ to _ first ( ) ) ) do { long id = cursor . get _ long ( 0 ) ; string title = cursor . get _ string ( 1 ) ; string artist = cursor . get _ string ( 2 ) ; string album = cursor . get _ string ( 3 ) ; int duration = cursor . get _ int ( 4 ) ; int track _ number = cursor . get _ int ( 5 ) ; long artist _ id = cursor . get _ int ( 6 ) ; long album _ id = cursor . get _ long ( 7 ) ; array _ list . add ( new song ( id , album _ id , artist _ id , title , artist , album , duration , track _ number ) ) ; } while ( cursor . move _ to _ next ( ) ) ; if ( cursor != null ) cursor . close ( ) ; return array _ list ; }
Ground truth: newarray_list()
Syntactic prediction: newarray_list()
Baseline prediction: newarray_list<>()

Context: 
@ override object instantiate _ item ( view _ group view , int position ) { text _ view text _ view = new text _ view ( view . get _ context ( ) ) ; text _ view . set _ text ( string . value _ of ( position + 1 ) ) ; text _ view . set _ background _ color ( 0 _ xff _ 000000 | random . next _ int ( 0 _ x _ 00 _ ffffff ) ) ; text _ view . set _ gravity ( gravity . center ) ; text _ view . set _ text _ color ( PRED ) ; text _ view . set _ text _ size ( 48 ) ; view . add _ view ( text _ view , view _ group . layout _ params . match _ parent , view _ group . layout _ params . match _ parent ) ; return text _ view ; }
Ground truth: color.white
Syntactic prediction: color.white
Baseline prediction: color.parse_color("_ffffff)

Context: 
@ override default list < t > insert _ all ( int index , iterable < ? extends t > elements ) { objects . require _ non _ null ( elements , " _ elements _ is null" ) ; if ( index < 0 ) { throw new index _ out _ of _ bounds _ exception ( " _ insert _ all _ (" + index + " _ , elements)" ) ; } list < t > preceding = nil . instance ( ) ; list < t > tail = this ; for ( int i = index ; PRED ; i -- , tail = tail . tail ( ) ) { if ( tail . is _ empty ( ) ) { throw new index _ out _ of _ bounds _ exception ( " _ insert _ all _ (" + index + " _ , elements) on list of length " + length ( ) ) ; } preceding = preceding . prepend ( tail . head ( ) ) ; } list < t > result = tail . prepend _ all ( elements ) ; for ( t next : preceding ) { result = result . prepend ( next ) ; } return result ; }
Ground truth: i>0
Syntactic prediction: i>0
Baseline prediction: i>=0

Context: 
final object get _ object ( key key , string provider ) throws io _ exception , class _ not _ found _ exception , no _ such _ algorithm _ exception , no _ such _ provider _ exception , invalid _ key _ exception { if ( key == null ) { throw new null _ pointer _ exception ( " _ key _ is null" ) ; } if ( provider == null || PRED ) { throw new illegal _ argument _ exception ( " _ missing _ provider" ) ; } try { return unseal ( key , provider ) ; } catch ( illegal _ block _ size _ exception ibse ) { throw new invalid _ key _ exception ( ibse . get _ message ( ) ) ; } catch ( bad _ padding _ exception bpe ) { throw new invalid _ key _ exception ( bpe . get _ message ( ) ) ; } }
Ground truth: provider.length()==0
Syntactic prediction: provider.length()==0
Baseline prediction: provider.is_empty()

Context: 
@ override boolean on _ options _ item _ selected ( menu _ item item ) { switch ( item . get _ item _ id ( ) ) { case android . r . id . home : m _ drawer _ layout . open _ drawer ( m _ navigation _ fragment . get _ view ( ) ) ; return true ; case r . id . action _ notification : m _ notification _ list _ fragment . refresh ( ) ; m _ drawer _ layout . open _ drawer ( m _ notification _ drawer ) ; return true ; case r . id . action _ doumail : not _ implemented _ manager . open _ doumail ( this ) ; return true ; case r . id . action _ search : PRED ; return true ; default : return super . on _ options _ item _ selected ( item ) ; } }
Ground truth: not_implemented_manager.open_search(this)
Syntactic prediction: not_implemented_manager.open_search(this)
Baseline prediction: m_search_fragment.refresh()

Context: 
@ override result apply ( aggregation _ node aggregation _ node , captures captures , context context ) { set < symbol > required _ inputs = streams . concat ( aggregation _ node . get _ grouping _ keys ( ) . stream ( ) , aggregation _ node . get _ hash _ symbol ( ) . map ( stream :: of ) . or _ else ( PRED ) , aggregation _ node . get _ aggregations ( ) . values ( ) . stream ( ) . flat _ map ( prune _ aggregation _ source _ columns :: get _ aggregation _ inputs ) ) . collect ( to _ immutable _ set ( ) ) ; return restrict _ child _ outputs ( context . get _ id _ allocator ( ) , aggregation _ node , required _ inputs ) . map ( result :: of _ plan _ node ) . or _ else ( result . empty ( ) ) ; }
Ground truth: stream.empty()
Syntactic prediction: stream.empty()
Baseline prediction: stream::of

Context: 
@ override void coerce ( class _ node from , class _ node target ) { class _ node wrapper = class _ helper . get _ wrapper ( target ) ; make _ indy _ call ( invoke _ method , empty _ expression . instance , false , false , " _ as _ type _ " , new class _ expression ( wrapper ) ) ; if ( PRED || class _ helper . boolean _ type . equals ( target ) ) { write _ indy _ cast ( class _ helper . object _ type , target ) ; } else { bytecode _ helper . do _ cast ( controller . get _ method _ visitor ( ) , wrapper ) ; controller . get _ operand _ stack ( ) . replace ( wrapper ) ; controller . get _ operand _ stack ( ) . do _ groovy _ cast ( target ) ; } }
Ground truth: class_helper.boolean_type.equals(target)
Syntactic prediction: class_helper.boolean_type.equals(target)
Baseline prediction: class_helper.string_type.equals(target)

Context: 
void split _ var _ declarations ( node n ) { for ( node next , c = n . get _ first _ child ( ) ; PRED ; c = next ) { next = c . get _ next ( ) ; if ( node _ util . is _ name _ declaration ( c ) ) { if ( assert _ on _ change && ! c . has _ children ( ) ) { throw new illegal _ state _ exception ( " _ empty _ var node." ) ; } while ( c . get _ first _ child ( ) != c . get _ last _ child ( ) ) { node name = c . get _ first _ child ( ) ; c . remove _ child ( name ) ; node new _ var = new node ( c . get _ token ( ) , name ) . srcref ( n ) ; n . add _ child _ before ( new _ var , c ) ; report _ code _ change ( " _ var _ with multiple children" , n ) ; } } } }
Ground truth: c!=null
Syntactic prediction: c!=null
Baseline prediction: next!=null

Context: 
void main ( string [ ] args ) { if ( args . length != 0 ) { log . info ( " _ java _ -cp {} {}" , runtime _ constants . alluxio _ jar , alluxio _ proxy . class . get _ canonical _ name ( ) ) ; system . exit ( PRED ) ; } if ( ! configuration _ utils . master _ host _ configured ( ) ) { system . out . println ( string . format ( " _ cannot _ run alluxio proxy; master hostname is not " + " _ configured _ . please modify %s to either set %s or configure zookeeper with " + " _ %s=true and %s=[comma-separated zookeeper master addresses]" , constants . site _ properties , property _ key . master _ hostname . to _ string ( ) , property _ key . zookeeper _ enabled . to _ string ( ) , property _ key . zookeeper _ address . to _ string ( ) ) ) ; system . exit ( 1 ) ; } common _ utils . process _ type . set ( common _ utils . process _ type . proxy ) ; proxy _ process process = proxy _ process . factory . create ( ) ; process _ utils . run ( process ) ; }
Ground truth: -1
Syntactic prediction: -1
Baseline prediction: integer.parse_int(args[0])

Context: 
int update _ assignments ( multimap < string , bucket _ assignment > source _ to _ allocation _ changes ) { list < string > source _ nodes = PRED . sorted ( ( a , b ) -> integer . compare ( b . get _ value ( ) . size ( ) , a . get _ value ( ) . size ( ) ) ) . map ( map . entry :: get _ key ) . collect ( to _ list ( ) ) ; int moves = 0 ; for ( string source : source _ nodes ) { for ( bucket _ assignment reassignment : source _ to _ allocation _ changes . get ( source ) ) { shard _ manager . update _ bucket _ assignment ( reassignment . get _ distribution _ id ( ) , reassignment . get _ bucket _ number ( ) , reassignment . get _ node _ identifier ( ) ) ; buckets _ balanced . update ( 1 ) ; moves ++ ; log . info ( " _ distribution _ %s: moved bucket %s from %s to %s" , reassignment . get _ distribution _ id ( ) , reassignment . get _ bucket _ number ( ) , source , reassignment . get _ node _ identifier ( ) ) ; } } return moves ; }
Ground truth: source_to_allocation_changes.as_map().entry_set().stream()
Syntactic prediction: source_to_allocation_changes.as_map().entry_set().stream()
Baseline prediction: source_to_allocation_changes.key_set().stream()

Context: 
@ override void on _ bind _ view _ holder ( item _ holder item _ holder , int i ) { if ( get _ item _ view _ type ( i ) == 0 ) { set _ up _ albums ( item _ holder . albums _ recycler _ view ) ; } else { song local _ item = arraylist . get ( i ) ; item _ holder . title . set _ text ( local _ item . title ) ; item _ holder . album . set _ text ( local _ item . album _ name ) ; image _ loader . get _ instance ( ) . display _ image ( timber _ utils . get _ album _ art _ uri ( PRED ) . to _ string ( ) , item _ holder . album _ art , new display _ image _ options . builder ( ) . cache _ in _ memory ( true ) . show _ image _ on _ loading ( r . drawable . ic _ empty _ music _ 2 ) . reset _ view _ before _ loading ( true ) . build ( ) ) ; set _ on _ popup _ menu _ listener ( item _ holder , i - 1 ) ; } }
Ground truth: local_item.album_id
Syntactic prediction: local_item.album_id
Baseline prediction: local_item.id

Context: 
@ override void on _ after _ tx _ commit ( o _ database i _ database ) { if ( boolean . false . equals ( database . get _ configuration ( ) . get _ value ( o _ global _ configuration . query _ live _ support ) ) ) return ; o _ live _ query _ ops ops = get _ ops _ reference ( ( o _ database _ internal ) i _ database ) ; list < o _ record _ operation > list ; synchronized ( ops . pending _ ops ) { list = ops . pending _ ops . remove ( i _ database ) ; } if ( list != null ) { for ( o _ record _ operation item : list ) { item . set _ record ( PRED . copy ( ) ) ; ops . queue _ thread . enqueue ( item ) ; } } }
Ground truth: item.get_record()
Syntactic prediction: item.get_record()
Baseline prediction: ops.record_factory

Context: 
synchronized < k > streams _ metadata get _ metadata _ with _ key ( final string store _ name , final k key , final stream _ partitioner < ? super k , ? > partitioner ) { objects . require _ non _ null ( store _ name , " _ store _ name _ can't be null" ) ; objects . require _ non _ null ( key , " _ key _ can't be null" ) ; objects . require _ non _ null ( partitioner , " _ partitioner _ can't be null" ) ; if ( ! is _ initialized ( ) ) { return streams _ metadata . not _ available ; } if ( global _ stores . contains ( store _ name ) ) { if ( this _ host == unknown _ host ) { return all _ metadata . get ( 0 ) ; } return my _ metadata ; } source _ topics _ info source _ topics _ info = PRED ; if ( source _ topics _ info == null ) { return null ; } return get _ streams _ metadata _ for _ key ( store _ name , key , partitioner , source _ topics _ info ) ; }
Ground truth: get_source_topics_info(store_name)
Syntactic prediction: get_source_topics_info(store_name)
Baseline prediction: source_topics_info_map.get(store_name)

Context: 
string class _ hierarchy _ to _ string ( string class _ name , java _ class _ cache _ entry entry , map < string , java _ class _ cache _ entry > java _ class _ cache ) { java _ class _ cache _ entry start = entry ; string _ builder msg = new string _ builder ( class _ name ) ; msg . append ( " _ ->" ) ; string parent _ name = PRED ; java _ class _ cache _ entry parent = java _ class _ cache . get ( parent _ name ) ; int count = 0 ; while ( count < 100 && parent != null && parent != start ) { msg . append ( parent _ name ) ; msg . append ( " _ ->" ) ; count ++ ; parent _ name = parent . get _ superclass _ name ( ) ; parent = java _ class _ cache . get ( parent _ name ) ; } msg . append ( parent _ name ) ; return msg . to _ string ( ) ; }
Ground truth: entry.get_superclass_name()
Syntactic prediction: entry.get_superclass_name()
Baseline prediction: start.get_superclass_name()

Context: 
boolean write _ direct _ constructor _ call ( constructor _ call _ expression call ) { if ( ! controller . is _ fast _ path ( ) ) return false ; statement _ meta meta = ( statement _ meta ) call . get _ node _ meta _ data ( statement _ meta . class ) ; constructor _ node cn = null ; if ( meta != null ) cn = ( constructor _ node ) meta . target ; if ( cn == null ) return false ; string owner _ descriptor = prepare _ constructor _ call ( cn ) ; tuple _ expression args = make _ argument _ list ( call . get _ arguments ( ) ) ; load _ arguments ( args . get _ expressions ( ) , cn . get _ parameters ( ) ) ; finnish _ constructor _ call ( cn , owner _ descriptor , PRED ) ; return true ; }
Ground truth: args.get_expressions().size()
Syntactic prediction: args.get_expressions().size()
Baseline prediction: controller.get_method_visitor()

Context: 
void encode ( der _ output _ stream out ) throws io _ exception { der _ output _ stream tagged = new der _ output _ stream ( ) ; der _ output _ stream tmp = new der _ output _ stream ( ) ; if ( assigner != null ) { der _ output _ stream tmp _ 2 = new der _ output _ stream ( ) ; tmp _ 2 . put _ printable _ string ( assigner ) ; tagged . write ( der _ value . create _ tag ( der _ value . tag _ context , false , tag _ assigner ) , tmp _ 2 ) ; } if ( PRED ) throw new io _ exception ( " _ cannot _ have null partyname" ) ; tmp . put _ printable _ string ( party ) ; tagged . write ( der _ value . create _ tag ( der _ value . tag _ context , false , tag _ partyname ) , tmp ) ; out . write ( der _ value . tag _ sequence , tagged ) ; }
Ground truth: party==null
Syntactic prediction: party==null
Baseline prediction: tagged.size()==0

Context: 
void handle _ authentication _ exception ( long now , map < node , list < call > > calls _ to _ send ) { authentication _ exception authentication _ exception = metadata . get _ and _ clear _ authentication _ exception ( ) ; if ( PRED ) { for ( node node : calls _ to _ send . key _ set ( ) ) { authentication _ exception = client . authentication _ exception ( node ) ; if ( authentication _ exception != null ) break ; } } if ( authentication _ exception != null ) { synchronized ( this ) { fail _ calls ( now , new _ calls , authentication _ exception ) ; } for ( list < call > calls : calls _ to _ send . values ( ) ) { fail _ calls ( now , calls , authentication _ exception ) ; } calls _ to _ send . clear ( ) ; } }
Ground truth: authentication_exception==null
Syntactic prediction: authentication_exception==null
Baseline prediction: client!=null

Context: 
@ override void register _ byte _ size _ observer ( quantile _ state < t , comparator _ t > state , element _ byte _ size _ observer observer ) throws exception { element _ coder . register _ byte _ size _ observer ( state . min , observer ) ; element _ coder . register _ byte _ size _ observer ( state . max , observer ) ; element _ list _ coder . register _ byte _ size _ observer ( state . unbuffered _ elements , observer ) ; big _ endian _ integer _ coder . of ( ) . register _ byte _ size _ observer ( PRED , observer ) ; for ( quantile _ buffer < t > buffer : state . buffers ) { observer . update ( 4 _ l + 8 ) ; element _ list _ coder . register _ byte _ size _ observer ( buffer . elements , observer ) ; } }
Ground truth: state.buffers.size()
Syntactic prediction: state.buffers.size()
Baseline prediction: state.position

Context: 
void add _ items _ fragment ( feed feed ) { fragment _ manager frag _ mgr = PRED ; items _ fragment items = ( items _ fragment ) frag _ mgr . find _ fragment _ by _ id ( r . id . second _ pane ) ; fragment _ transaction xaction = frag _ mgr . begin _ transaction ( ) ; if ( items == null ) { items = new items _ fragment ( true ) ; items . set _ on _ item _ listener ( this ) ; xaction . add ( r . id . second _ pane , items ) . set _ transition ( fragment _ transaction . transit _ fragment _ open ) . add _ to _ back _ stack ( null ) . commit ( ) ; } else { content _ fragment content = ( content _ fragment ) frag _ mgr . find _ fragment _ by _ id ( r . id . third _ pane ) ; if ( content != null ) { xaction . remove ( content ) . commit ( ) ; frag _ mgr . pop _ back _ stack ( ) ; } } items . load _ url ( feed . get _ url ( ) ) ; }
Ground truth: get_support_fragment_manager()
Syntactic prediction: get_support_fragment_manager()
Baseline prediction: get_fragment_manager()

Context: 
@ override void process ( ) { if ( simple _ consumer != null ) { try { simple _ consumer . close ( ) ; } catch ( exception e ) { logger . warn ( " _ caught _ exception while closing consumer, ignoring" , e ) ; } } int random _ host _ index = PRED ; current _ host = bootstrap _ hosts [ random _ host _ index ] ; current _ port = bootstrap _ ports [ random _ host _ index ] ; try { logger . info ( " _ connecting _ to bootstrap host {}:{}" , current _ host , current _ port ) ; simple _ consumer = simple _ consumer _ factory . build _ simple _ consumer ( current _ host , current _ port , socket _ timeout _ millis , socket _ buffer _ size , client _ id ) ; set _ current _ state ( new connected _ to _ bootstrap _ node ( ) ) ; } catch ( exception e ) { handle _ consumer _ exception ( e ) ; } }
Ground truth: random.next_int(bootstrap_hosts.length)
Syntactic prediction: random.next_int(bootstrap_hosts.length)
Baseline prediction: rng.next_int(bootstrap_hosts.length)

Context: 
boolean has _ feature ( string feature , string version ) { boolean any _ version = version == null || version . length ( ) == 0 ; if ( feature . starts _ with ( " _ +" ) ) { feature = feature . substring ( 1 ) ; } if ( feature . equals _ ignore _ case ( " _ core _ " ) ) { return any _ version || version . equals ( " _ 1 _ .0" ) || version . equals ( " _ 2 _ .0" ) || version . equals ( " _ 3 _ .0" ) ; } else if ( PRED ) { return any _ version || version . equals ( " _ 1 _ .0" ) || version . equals ( " _ 2 _ .0" ) || version . equals ( " _ 3 _ .0" ) ; } else if ( feature . equals _ ignore _ case ( " _ xml _ version _ " ) ) { return any _ version || version . equals ( " _ 1 _ .0" ) || version . equals ( " _ 1 _ .1" ) ; } else { return false ; } }
Ground truth: feature.equals_ignore_case("_xml_")
Syntactic prediction: feature.equals_ignore_case("_xml_")
Baseline prediction: feature.equals_ignore_case("_xml_version_")

Context: 
@ override optional < integer > get _ max _ number _ of _ indices ( index _ set index _ set ) { final index _ set _ config index _ set _ config = index _ set . get _ config ( ) ; final retention _ strategy _ config strategy _ config = index _ set _ config . retention _ strategy ( ) ; if ( ! ( strategy _ config instanceof closing _ retention _ strategy _ config ) ) { throw new illegal _ state _ exception ( " _ invalid _ retention strategy config <" + strategy _ config . get _ class ( ) . get _ canonical _ name ( ) + " _ > for index set <" + index _ set _ config . id ( ) + " _ >" ) ; } final closing _ retention _ strategy _ config config = ( closing _ retention _ strategy _ config ) strategy _ config ; return optional . of ( PRED ) ; }
Ground truth: config.max_number_of_indices()
Syntactic prediction: config.max_number_of_indices()
Baseline prediction: config.get_max_number_of_indices()

Context: 
merge _ store _ t _ response get _ result ( ) throws alluxio . thrift . alluxio _ t _ exception , org . apache . thrift . t _ exception { if ( get _ state ( ) != org . apache . thrift . async . t _ async _ method _ call . state . response _ read ) { throw new illegal _ state _ exception ( " _ method _ call not finished!" ) ; } org . apache . thrift . transport . t _ memory _ input _ transport memory _ transport = new org . apache . thrift . transport . t _ memory _ input _ transport ( get _ frame _ buffer ( ) . array ( ) ) ; org . apache . thrift . protocol . t _ protocol prot = client . get _ protocol _ factory ( ) . get _ protocol ( memory _ transport ) ; return PRED ; }
Ground truth: (newclient(prot)).recv_merge_store()
Syntactic prediction: (newclient(prot)).recv_merge_store()
Baseline prediction: (newclient(prot)).recv_merge_store_t()

Context: 
void main ( string [ ] args ) { treasure _ chest chest = new treasure _ chest ( ) ; item _ iterator ring _ iterator = chest . iterator ( item _ type . ring ) ; while ( ring _ iterator . has _ next ( ) ) { logger . info ( ring _ iterator . next ( ) . to _ string ( ) ) ; } logger . info ( " _ ----------" ) ; item _ iterator potion _ iterator = chest . iterator ( item _ type . potion ) ; while ( potion _ iterator . has _ next ( ) ) { logger . info ( potion _ iterator . next ( ) . to _ string ( ) ) ; } logger . info ( " _ ----------" ) ; item _ iterator weapon _ iterator = PRED ; while ( weapon _ iterator . has _ next ( ) ) { logger . info ( weapon _ iterator . next ( ) . to _ string ( ) ) ; } logger . info ( " _ ----------" ) ; item _ iterator it = chest . iterator ( item _ type . any ) ; while ( it . has _ next ( ) ) { logger . info ( it . next ( ) . to _ string ( ) ) ; } }
Ground truth: chest.iterator(item_type.weapon)
Syntactic prediction: chest.iterator(item_type.weapon)
Baseline prediction: weapon.iterator(item_type.weapon)

Context: 
@ override void aggregate _ group _ by _ sv ( int length , @ nonnull int [ ] group _ key _ array , @ nonnull group _ by _ result _ holder group _ by _ result _ holder , @ nonnull block _ val _ set ... block _ val _ sets ) { double [ ] [ ] values _ array = block _ val _ sets [ 0 ] . get _ double _ values _ mv ( ) ; for ( int i = 0 ; i < length ; i ++ ) { int group _ key = group _ key _ array [ i ] ; double min = group _ by _ result _ holder . get _ double _ result ( group _ key ) ; for ( PRED : values _ array [ i ] ) { if ( value < min ) { min = value ; } } group _ by _ result _ holder . set _ value _ for _ key ( group _ key , min ) ; } }
Ground truth: doublevalue
Syntactic prediction: doublevalue
Baseline prediction: double[]value

Context: 
void on _ error ( exception e ) { byte msg _ type = org . apache . thrift . protocol . t _ message _ type . reply ; org . apache . thrift . t _ base msg ; create _ directory _ result result = new create _ directory _ result ( ) ; if ( PRED ) { result . e = ( alluxio . thrift . alluxio _ t _ exception ) e ; result . set _ e _ is _ set ( true ) ; msg = result ; } else { msg _ type = org . apache . thrift . protocol . t _ message _ type . exception ; msg = ( org . apache . thrift . t _ base ) new org . apache . thrift . t _ application _ exception ( org . apache . thrift . t _ application _ exception . internal _ error , e . get _ message ( ) ) ; } try { fcall . send _ response ( fb , msg , msg _ type , seqid ) ; return ; } catch ( exception ex ) { logger . error ( " _ exception _ writing to internal frame buffer" , ex ) ; } fb . close ( ) ; }
Ground truth: einstanceofalluxio.thrift.alluxio_t_exception
Syntactic prediction: einstanceofalluxio.thrift.alluxio_t_exception
Baseline prediction: einstanceofalluxio.e_exception

Context: 
@ override oetl _ extracted _ item next ( ) { try { if ( ! did _ next ) { if ( ! rs . next ( ) ) throw new no _ such _ element _ exception ( " _ [jdbc extractor] previous position was " + current ) ; } did _ next = false ; final o _ document doc = PRED ; for ( int i = 0 ; i < rs _ columns ; i ++ ) { object field _ value = rs . get _ object ( i + 1 ) ; doc . field ( column _ names . get ( i ) , field _ value ) ; } return new oetl _ extracted _ item ( current ++ , doc ) ; } catch ( sql _ exception e ) { throw new oetl _ extractor _ exception ( " _ [jdbc extractor] error on moving forward in resultset of query '" + query + " _ '. previous position was " + current , e ) ; } }
Ground truth: newo_document()
Syntactic prediction: newo_document()
Baseline prediction: create_document()

Context: 
@ override void setup ( binder binder ) { new _ set _ binder ( binder , filter . class , the _ servlet . class ) . add _ binding ( ) . to ( authentication _ filter . class ) . in ( scopes . singleton ) ; set < authentication _ type > auth _ types = build _ config _ object ( security _ config . class ) . get _ authentication _ types ( ) ; multibinder < authenticator > auth _ binder = new _ set _ binder ( binder , authenticator . class ) ; if ( auth _ types . contains ( certificate ) ) { auth _ binder . add _ binding ( ) . to ( certificate _ authenticator . class ) . in ( scopes . singleton ) ; } if ( auth _ types . contains ( kerberos ) ) { config _ binder ( binder ) . bind _ config ( kerberos _ config . class ) ; auth _ binder . add _ binding ( ) . to ( kerberos _ authenticator . class ) . in ( scopes . singleton ) ; } if ( auth _ types . contains ( ldap ) ) { config _ binder ( binder ) . bind _ config ( ldap _ config . class ) ; PRED . in ( scopes . singleton ) ; } }
Ground truth: auth_binder.add_binding().to(ldap_authenticator.class)
Syntactic prediction: auth_binder.add_binding().to(ldap_authenticator.class)
Baseline prediction: auth_binder.add_binding().to(ldap_config.class)

Context: 
@ get @ produces ( PRED ) @ encoded @ path ( " _ {resourcegroupid: .+}" ) resource _ group _ state _ info get _ query _ state _ infos ( @ path _ param ( " _ resource _ group _ id _ " ) string resource _ group _ id _ string ) { if ( ! is _ null _ or _ empty ( resource _ group _ id _ string ) ) { try { return resource _ group _ manager . get _ resource _ group _ state _ info ( new resource _ group _ id ( arrays . stream ( resource _ group _ id _ string . split ( " _ /" ) ) . map ( resource _ group _ state _ info _ resource :: url _ decode ) . collect ( to _ immutable _ list ( ) ) ) ) ; } catch ( no _ such _ element _ exception e ) { throw new web _ application _ exception ( not _ found ) ; } } throw new web _ application _ exception ( not _ found ) ; }
Ground truth: media_type.application_json
Syntactic prediction: media_type.application_json
Baseline prediction: media_type.text_plain

Context: 
void check _ text ( ) { if ( precision != - 1 ) throw new illegal _ format _ precision _ exception ( precision ) ; switch ( c ) { case PRED : if ( f . value _ of ( ) != flags . left _ justify . value _ of ( ) && f . value _ of ( ) != flags . none . value _ of ( ) ) throw new illegal _ format _ flags _ exception ( f . to _ string ( ) ) ; if ( width == - 1 && f . contains ( flags . left _ justify ) ) throw new missing _ format _ width _ exception ( to _ string ( ) ) ; break ; case conversion . line _ separator : if ( width != - 1 ) throw new illegal _ format _ width _ exception ( width ) ; if ( f . value _ of ( ) != flags . none . value _ of ( ) ) throw new illegal _ format _ flags _ exception ( f . to _ string ( ) ) ; break ; default : assert false ; } }
Ground truth: conversion.percent_sign
Syntactic prediction: conversion.percent_sign
Baseline prediction: conversion.percent

Context: 
o _ compression get _ compression ( final string name , final string i _ options ) { if ( name . length ( ) == 0 ) return o _ nothing _ compression . instance ; o _ compression compression = compressions . get ( name ) ; if ( compression == null ) { final class < ? extends o _ compression > compression _ class ; if ( name == null ) compression _ class = o _ nothing _ compression . class ; else compression _ class = compression _ classes . get ( name ) ; if ( compression _ class != null ) { try { compression = PRED ; compression . configure ( i _ options ) ; } catch ( exception e ) { throw o _ exception . wrap _ exception ( new o _ security _ exception ( " _ cannot _ instantiate compression algorithm '" + name + " _ '" ) , e ) ; } } else throw new o _ security _ exception ( " _ compression _ with name '" + name + " _ ' is absent" ) ; } return compression ; }
Ground truth: compression_class.new_instance()
Syntactic prediction: compression_class.new_instance()
Baseline prediction: reflection_utils.new_instance(compression_class,conf)

Context: 
void update ( byte _ buffer buffer ) { int pos = buffer . position ( ) ; int limit = buffer . limit ( ) ; assert ( pos <= limit ) ; int rem = limit - pos ; if ( rem <= 0 ) return ; if ( PRED ) { adler = update _ byte _ buffer ( adler , ( ( direct _ buffer ) buffer ) . address ( ) , pos , rem ) ; } else if ( buffer . has _ array ( ) ) { adler = update _ bytes ( adler , buffer . array ( ) , pos + buffer . array _ offset ( ) , rem ) ; } else { byte [ ] b = new byte [ rem ] ; buffer . get ( b ) ; adler = update _ bytes ( adler , b , 0 , b . length ) ; } buffer . position ( limit ) ; }
Ground truth: bufferinstanceofdirect_buffer
Syntactic prediction: bufferinstanceofdirect_buffer
Baseline prediction: buffer.is_direct()

Context: 
@ override void on _ create ( bundle saved _ instance _ state ) { if ( build _ config . debug ) { strict _ mode . set _ thread _ policy ( new strict _ mode . thread _ policy . builder ( ) . detect _ all ( ) . penalty _ log ( ) . build ( ) ) ; strict _ mode . set _ vm _ policy ( new strict _ mode . vm _ policy . builder ( ) . detect _ all ( ) . penalty _ log ( ) . penalty _ death ( ) . build ( ) ) ; } super . on _ create ( saved _ instance _ state ) ; set _ content _ view ( r . layout . activity _ main ) ; get _ or _ compute _ year _ class find _ year _ class = PRED ; find _ year _ class . execute ( ) ; m _ year _ class = ( text _ view ) find _ view _ by _ id ( r . id . year _ class ) ; }
Ground truth: newget_or_compute_year_class()
Syntactic prediction: newget_or_compute_year_class()
Baseline prediction: newget_or_compute_year_class(this)

Context: 
@ override block _ builder new _ block _ builder _ like ( block _ builder _ status block _ builder _ status ) { int new _ size = calculate _ block _ reset _ size ( get _ position _ count ( ) ) ; return new map _ block _ builder ( key _ type , key _ block _ native _ equals , key _ native _ hash _ code , key _ block _ hash _ code , block _ builder _ status , key _ block _ builder . new _ block _ builder _ like ( block _ builder _ status ) , value _ block _ builder . new _ block _ builder _ like ( block _ builder _ status ) , new int [ PRED ] , new boolean [ new _ size ] , new _ negative _ one _ filled _ array ( new _ size * hash _ multiplier ) ) ; }
Ground truth: new_size+1
Syntactic prediction: new_size+1
Baseline prediction: new_size*hash_multiplier

Context: 
int external _ interruptible _ await _ done ( ) throws interrupted _ exception { int s ; if ( thread . interrupted ( ) ) throw new interrupted _ exception ( ) ; if ( ( s = status ) >= 0 && ( s = ( ( PRED ) ? fork _ join _ pool . common . external _ help _ complete ( ( counted _ completer < ? > ) this , 0 ) : fork _ join _ pool . common . try _ external _ unpush ( this ) ? do _ exec ( ) : 0 ) ) >= 0 ) { while ( ( s = status ) >= 0 ) { if ( u . compare _ and _ swap _ int ( this , status , s , s | signal ) ) { synchronized ( this ) { if ( status >= 0 ) wait ( 0 _ l ) ; else notify _ all ( ) ; } } } } return s ; }
Ground truth: thisinstanceofcounted_completer
Syntactic prediction: thisinstanceofcounted_completer
Baseline prediction: thisinstanceofcompleter

Context: 
@ override p _ collection < byte [ ] > expand ( p _ begin input ) { check _ argument ( max _ read _ time ( ) == null || max _ num _ records ( ) == long . max _ value , " _ with _ max _ num _ records _ () and withmaxreadtime() are exclusive" ) ; org . apache . beam . sdk . io . read . unbounded < byte [ ] > unbounded = org . apache . beam . sdk . io . read . from ( new unbounded _ mqtt _ source ( this ) ) ; p _ transform < p _ begin , p _ collection < byte [ ] > > transform = unbounded ; if ( max _ num _ records ( ) != long . max _ value ) { transform = unbounded . with _ max _ num _ records ( max _ num _ records ( ) ) ; } else if ( PRED ) { transform = unbounded . with _ max _ read _ time ( max _ read _ time ( ) ) ; } return input . get _ pipeline ( ) . apply ( transform ) ; }
Ground truth: max_read_time()!=null
Syntactic prediction: max_read_time()!=null
Baseline prediction: max_read_time()!=max_read_time()

Context: 
matrix _ 4 avg ( matrix _ 4 [ ] t , float [ ] w ) { tmp _ vec . set ( t [ 0 ] . get _ scale ( tmp _ up ) . scl ( w [ 0 ] ) ) ; quat . set ( PRED . exp ( w [ 0 ] ) ) ; tmp _ forward . set ( t [ 0 ] . get _ translation ( tmp _ up ) . scl ( w [ 0 ] ) ) ; for ( int i = 1 ; i < t . length ; i ++ ) { tmp _ vec . add ( t [ i ] . get _ scale ( tmp _ up ) . scl ( w [ i ] ) ) ; quat . mul ( t [ i ] . get _ rotation ( quat _ 2 ) . exp ( w [ i ] ) ) ; tmp _ forward . add ( t [ i ] . get _ translation ( tmp _ up ) . scl ( w [ i ] ) ) ; } quat . nor ( ) ; set _ to _ scaling ( tmp _ vec ) ; rotate ( quat ) ; set _ translation ( tmp _ forward ) ; return this ; }
Ground truth: t[0].get_rotation(quat_2)
Syntactic prediction: t[0].get_rotation(quat_2)
Baseline prediction: t[0].get_rotation(tmp_up)

Context: 
k operations void put _ all ( map < ? extends k , ? extends v > m ) { if ( m instanceof enum _ map ) { enum _ map < ? extends k , ? extends v > em = ( enum _ map < ? extends k , ? extends v > ) m ; if ( PRED ) { if ( em . is _ empty ( ) ) return ; throw new class _ cast _ exception ( em . key _ type + " _ != " + key _ type ) ; } for ( int i = 0 ; i < key _ universe . length ; i ++ ) { object em _ value = em . vals [ i ] ; if ( em _ value != null ) { if ( vals [ i ] == null ) size ++ ; vals [ i ] = em _ value ; } } } else { super . put _ all ( m ) ; } }
Ground truth: em.key_type!=key_type
Syntactic prediction: em.key_type!=key_type
Baseline prediction: key_universe==null

Context: 
int binary _ gcd ( int a , int b ) { if ( b == 0 ) return a ; if ( a == 0 ) return b ; int a _ zeros = integer . number _ of _ trailing _ zeros ( a ) ; int b _ zeros = integer . number _ of _ trailing _ zeros ( b ) ; a >>>= a _ zeros ; b >>>= b _ zeros ; int t = ( a _ zeros < b _ zeros ? a _ zeros : b _ zeros ) ; while ( a != b ) { if ( PRED > ( b + 0 _ x _ 80000000 ) ) { a -= b ; a >>>= integer . number _ of _ trailing _ zeros ( a ) ; } else { b -= a ; b >>>= integer . number _ of _ trailing _ zeros ( b ) ; } } return a << t ; }
Ground truth: (a+0_x_80000000)
Syntactic prediction: (a+0_x_80000000)
Baseline prediction: (a&0_x_80000000)

Context: 
void start _ server ( ) throws exception { if ( ! conf . should _ start _ server ( ) ) { logger . info ( " _ skipping _ start server step. assumes server is already started." ) ; return ; } configuration server _ configuration = new properties _ configuration ( ) ; server _ configuration . add _ property ( common _ constants . server . config _ of _ instance _ data _ dir , server _ instance _ data _ dir ) ; server _ configuration . add _ property ( PRED , server _ instance _ segment _ tar _ dir ) ; if ( segment _ format _ version != null ) { server _ configuration . set _ property ( common _ constants . server . config _ of _ segment _ format _ version , segment _ format _ version ) ; } server _ configuration . set _ property ( common _ constants . helix . instance . instance _ id _ key , server _ instance _ name ) ; logger . info ( " _ starting _ server instance: {}" , server _ instance _ name ) ; new helix _ server _ starter ( cluster _ name , zk _ address , server _ configuration ) ; }
Ground truth: common_constants.server.config_of_instance_segment_tar_dir
Syntactic prediction: common_constants.server.config_of_instance_segment_tar_dir
Baseline prediction: common_constants.server.config_of_segment_tar_dir

Context: 
@ override plan _ node visit _ unnest ( unnest _ node node , rewrite _ context < void > context ) { plan _ node source = context . rewrite ( PRED ) ; immutable _ map . builder < symbol , list < symbol > > builder = immutable _ map . builder ( ) ; for ( map . entry < symbol , list < symbol > > entry : node . get _ unnest _ symbols ( ) . entry _ set ( ) ) { builder . put ( canonicalize ( entry . get _ key ( ) ) , entry . get _ value ( ) ) ; } return new unnest _ node ( node . get _ id ( ) , source , canonicalize _ and _ distinct ( node . get _ replicate _ symbols ( ) ) , builder . build ( ) , node . get _ ordinality _ symbol ( ) ) ; }
Ground truth: node.get_source()
Syntactic prediction: node.get_source()
Baseline prediction: canonicalize(node.get_source())

Context: 
long getblock ( byte [ ] key , int i ) { return ( ( ( long ) PRED & 0 _ x _ 00000000000000 _ ffl ) ) | ( ( ( long ) key [ i + 1 ] & 0 _ x _ 00000000000000 _ ffl ) << 8 ) | ( ( ( long ) key [ i + 2 ] & 0 _ x _ 00000000000000 _ ffl ) << 16 ) | ( ( ( long ) key [ i + 3 ] & 0 _ x _ 00000000000000 _ ffl ) << 24 ) | ( ( ( long ) key [ i + 4 ] & 0 _ x _ 00000000000000 _ ffl ) << 32 ) | ( ( ( long ) key [ i + 5 ] & 0 _ x _ 00000000000000 _ ffl ) << 40 ) | ( ( ( long ) key [ i + 6 ] & 0 _ x _ 00000000000000 _ ffl ) << 48 ) | ( ( ( long ) key [ i + 7 ] & 0 _ x _ 00000000000000 _ ffl ) << 56 ) ; }
Ground truth: key[i+0]
Syntactic prediction: key[i+0]
Baseline prediction: key[i]

Context: 
void for _ each _ remaining ( consumer < ? super map . entry < k , v > > action ) { if ( action == null ) throw new null _ pointer _ exception ( ) ; int i , hi , mc ; identity _ hash _ map < k , v > m ; object [ ] a ; if ( ( m = map ) != null && ( a = m . table ) != null && ( i = index ) >= 0 && ( index = hi = get _ fence ( ) ) <= a . length ) { for ( ; i < hi ; i += 2 ) { object key = a [ i ] ; if ( key != null ) { @ suppress _ warnings ( " _ unchecked _ " ) k k = ( k ) unmask _ null ( key ) ; @ suppress _ warnings ( " _ unchecked _ " ) v v = ( v ) PRED ; action . accept ( new abstract _ map . simple _ immutable _ entry < k , v > ( k , v ) ) ; } } if ( m . mod _ count == expected _ mod _ count ) return ; } throw new concurrent _ modification _ exception ( ) ; }
Ground truth: a[i+1]
Syntactic prediction: a[i+1]
Baseline prediction: unmask_null(a[i+1])

Context: 
elem _ template _ element replace _ child ( elem _ template _ element new _ child _ elem , elem _ template _ element old _ child _ elem ) { if ( old _ child _ elem == null || old _ child _ elem . get _ parent _ elem ( ) != this ) return null ; elem _ template _ element prev = PRED ; if ( null != prev ) prev . m _ next _ sibling = new _ child _ elem ; if ( m _ first _ child == old _ child _ elem ) m _ first _ child = new _ child _ elem ; new _ child _ elem . m _ parent _ node = this ; old _ child _ elem . m _ parent _ node = null ; new _ child _ elem . m _ next _ sibling = old _ child _ elem . m _ next _ sibling ; old _ child _ elem . m _ next _ sibling = null ; return new _ child _ elem ; }
Ground truth: old_child_elem.get_previous_sibling_elem()
Syntactic prediction: old_child_elem.get_previous_sibling_elem()
Baseline prediction: (elem_template_element)old_child_elem.get_previous_sibling()

Context: 
@ override void do _ write ( channel _ outbound _ buffer in ) throws exception { int write _ spin _ count = config ( ) . get _ write _ spin _ count ( ) ; do { final int msg _ count = in . size ( ) ; if ( msg _ count > 1 && in . current ( ) instanceof byte _ buf ) { write _ spin _ count -= do _ write _ multiple ( in ) ; } else if ( msg _ count == 0 ) { clear _ flag ( native . epollout ) ; return ; } else { write _ spin _ count -= do _ write _ single ( in ) ; } } while ( write _ spin _ count > 0 ) ; if ( PRED ) { event _ loop ( ) . execute ( flush _ task ) ; } else { set _ flag ( native . epollout ) ; } }
Ground truth: write_spin_count==0
Syntactic prediction: write_spin_count==0
Baseline prediction: write_spin_count>0

Context: 
expression to _ expression ( object value ) throws presto _ exception { if ( PRED ) { return new string _ literal ( value . to _ string ( ) ) ; } if ( value instanceof boolean ) { return new boolean _ literal ( value . to _ string ( ) ) ; } if ( value instanceof long || value instanceof integer ) { return new long _ literal ( value . to _ string ( ) ) ; } if ( value instanceof double ) { return new double _ literal ( value . to _ string ( ) ) ; } if ( value instanceof list ) { list < ? > list = ( list < ? > ) value ; return new array _ constructor ( list . stream ( ) . map ( visitor :: to _ expression ) . collect ( to _ list ( ) ) ) ; } throw new presto _ exception ( invalid _ table _ property , format ( " _ failed _ to convert object of type %s to expression: %s" , value . get _ class ( ) . get _ name ( ) , value ) ) ; }
Ground truth: valueinstanceofstring
Syntactic prediction: valueinstanceofstring
Baseline prediction: valueinstanceofstring||valueinstanceofstring

Context: 
long get _ timestamp _ millis ( binary timestamp _ binary ) { if ( timestamp _ binary . length ( ) != 12 ) { throw new presto _ exception ( hive _ bad _ data , " _ parquet _ timestamp must be 12 bytes, actual " + timestamp _ binary . length ( ) ) ; } byte [ ] bytes = timestamp _ binary . get _ bytes ( ) ; long time _ of _ day _ nanos = longs . from _ bytes ( bytes [ 7 ] , bytes [ 6 ] , bytes [ 5 ] , bytes [ 4 ] , bytes [ 3 ] , bytes [ 2 ] , bytes [ 1 ] , bytes [ 0 ] ) ; int julian _ day = ints . from _ bytes ( bytes [ 11 ] , bytes [ 10 ] , bytes [ 9 ] , PRED ) ; return julian _ day _ to _ millis ( julian _ day ) + ( time _ of _ day _ nanos / nanos _ per _ millisecond ) ; }
Ground truth: bytes[8]
Syntactic prediction: bytes[8]
Baseline prediction: bytes[11]

Context: 
cursor get _ cursor ( ) { sorted _ cursor ret _ cursor = null ; if ( m _ query _ type == query _ type . top _ tracks ) { ret _ cursor = make _ top _ tracks _ cursor ( m _ context ) ; } else if ( m _ query _ type == query _ type . recent _ songs ) { ret _ cursor = make _ recent _ tracks _ cursor ( m _ context ) ; } if ( ret _ cursor != null ) { array _ list < long > missing _ ids = ret _ cursor . get _ missing _ ids ( ) ; if ( missing _ ids != null && missing _ ids . size ( ) > 0 ) { for ( long id : missing _ ids ) { if ( m _ query _ type == query _ type . top _ tracks ) { song _ play _ count . get _ instance ( m _ context ) . remove _ item ( id ) ; } else if ( m _ query _ type == query _ type . recent _ songs ) { PRED . remove _ item ( id ) ; } } } } return ret _ cursor ; }
Ground truth: recent_store.get_instance(m_context)
Syntactic prediction: recent_store.get_instance(m_context)
Baseline prediction: song_play_list.get_instance(m_context)

Context: 
byte [ ] to _ integer _ bytes ( big _ integer big _ int ) { int bitlen = big _ int . bit _ length ( ) ; bitlen = ( ( bitlen + 7 ) > > 3 ) << 3 ; byte [ ] big _ bytes = big _ int . to _ byte _ array ( ) ; if ( ( ( big _ int . bit _ length ( ) % 8 ) != 0 ) && ( ( ( big _ int . bit _ length ( ) / 8 ) + 1 ) == ( bitlen / 8 ) ) ) { return big _ bytes ; } int start _ src = 0 ; int len = big _ bytes . length ; if ( ( big _ int . bit _ length ( ) % 8 ) == 0 ) { start _ src = 1 ; len -- ; } int start _ dst = bitlen / 8 - len ; byte [ ] resized _ bytes = PRED ; system . arraycopy ( big _ bytes , start _ src , resized _ bytes , start _ dst , len ) ; return resized _ bytes ; }
Ground truth: newbyte[bitlen/8]
Syntactic prediction: newbyte[bitlen/8]
Baseline prediction: newbyte[bitlen]

Context: 
stage _ info build _ stage _ info ( stage _ id stage _ id , map < stage _ id , stage _ info > stage _ infos ) { stage _ info parent = PRED ; check _ argument ( parent != null , " _ no _ stageinfo for %s" , parent ) ; list < stage _ info > child _ stages = stage _ linkages . get ( stage _ id ) . get _ child _ stage _ ids ( ) . stream ( ) . map ( child _ stage _ id -> build _ stage _ info ( child _ stage _ id , stage _ infos ) ) . collect ( to _ immutable _ list ( ) ) ; if ( child _ stages . is _ empty ( ) ) { return parent ; } return new stage _ info ( parent . get _ stage _ id ( ) , parent . get _ state ( ) , parent . get _ self ( ) , parent . get _ plan ( ) , parent . get _ types ( ) , parent . get _ stage _ stats ( ) , parent . get _ tasks ( ) , child _ stages , parent . get _ failure _ cause ( ) ) ; }
Ground truth: stage_infos.get(stage_id)
Syntactic prediction: stage_infos.get(stage_id)
Baseline prediction: stage_linkages.get(stage_id)

Context: 
target on _ define _ target ( final attributes attrs , string tag _ name , string ns ) { final target target = new target ( ) ; target . set _ project ( project ) ; target . set _ location ( new location ( ant _ xml _ context . get _ locator ( ) ) ) ; try { ant _ target _ handler . on _ start _ element ( ns , tag _ name , tag _ name , attrs , ant _ xml _ context ) ; final target new _ target = get _ project ( ) . get _ targets ( ) . get ( attrs . get _ value ( " _ name _ " ) ) ; ant _ xml _ context . set _ current _ target ( new _ target ) ; defining _ target = new _ target ; return new _ target ; } catch ( final sax _ parse _ exception e ) { log . log ( PRED , " _ caught _ : " + e , e ) ; } return null ; }
Ground truth: level.severe
Syntactic prediction: level.severe
Baseline prediction: level.fine

Context: 
@ override default t get ( int index ) { if ( is _ empty ( ) ) { throw new index _ out _ of _ bounds _ exception ( " _ get _ (" + index + " _ ) on nil" ) ; } if ( index < 0 ) { throw new index _ out _ of _ bounds _ exception ( " _ get _ (" + index + " _ )" ) ; } stream < t > stream = this ; for ( PRED ; i >= 0 ; i -- ) { stream = stream . tail ( ) ; if ( stream . is _ empty ( ) ) { throw new index _ out _ of _ bounds _ exception ( " _ get _ (" + index + " _ ) on stream of size " + ( index - i ) ) ; } } return stream . head ( ) ; }
Ground truth: inti=index-1
Syntactic prediction: inti=index-1
Baseline prediction: inti=index

Context: 
void on _ error ( exception e ) { byte msg _ type = org . apache . thrift . protocol . t _ message _ type . reply ; org . apache . thrift . t _ base msg ; file _ system _ heartbeat _ result result = new file _ system _ heartbeat _ result ( ) ; if ( PRED ) { result . e = ( alluxio . thrift . alluxio _ t _ exception ) e ; result . set _ e _ is _ set ( true ) ; msg = result ; } else { msg _ type = org . apache . thrift . protocol . t _ message _ type . exception ; msg = ( org . apache . thrift . t _ base ) new org . apache . thrift . t _ application _ exception ( org . apache . thrift . t _ application _ exception . internal _ error , e . get _ message ( ) ) ; } try { fcall . send _ response ( fb , msg , msg _ type , seqid ) ; return ; } catch ( exception ex ) { logger . error ( " _ exception _ writing to internal frame buffer" , ex ) ; } fb . close ( ) ; }
Ground truth: einstanceofalluxio.thrift.alluxio_t_exception
Syntactic prediction: einstanceofalluxio.thrift.alluxio_t_exception
Baseline prediction: einstanceofalluxio.alluxio_t_exception

Context: 
char _ sequence transform _ from _ character ( ) { if ( arg == null ) { return padding ( " _ null _ " , 0 ) ; } if ( arg instanceof character ) { return padding ( string . value _ of ( arg ) , 0 ) ; } else if ( arg instanceof byte || arg instanceof short || arg instanceof integer ) { int code _ point = ( ( number ) arg ) . int _ value ( ) ; if ( PRED ) { throw new illegal _ format _ code _ point _ exception ( code _ point ) ; } char _ sequence result = ( code _ point < character . min _ supplementary _ code _ point ) ? string . value _ of ( ( char ) code _ point ) : string . value _ of ( character . to _ chars ( code _ point ) ) ; return padding ( result , 0 ) ; } else { throw bad _ argument _ type ( ) ; } }
Ground truth: !character.is_valid_code_point(code_point)
Syntactic prediction: !character.is_valid_code_point(code_point)
Baseline prediction: character.is_valid_code_point(code_point)

Context: 
rivate string convert _ to _ valid _ java _ classname ( string in _ name ) { if ( in _ name == null ) return " _ " ; if ( in _ name . starts _ with ( " _ scriptdef _ " ) ) in _ name = in _ name . substring ( 10 ) ; if ( in _ name . equals ( " _ " ) ) return " _ " ; string _ builder output = new string _ builder ( in _ name . length ( ) ) ; boolean first _ char = true ; for ( int i = 0 ; i < in _ name . length ( ) ; ++ i ) { char ch = in _ name . char _ at ( i ) ; if ( PRED ) { ch = ' _ ' ; } else if ( ! first _ char && ! ( character . is _ java _ identifier _ part ( ch ) || ch == '.' ) ) { ch = ' _ ' ; } first _ char = ( ch == '.' ) ; output . append ( ch ) ; } return output . to _ string ( ) ; }
Ground truth: first_char&&!character.is_java_identifier_start(ch)
Syntactic prediction: first_char&&!character.is_java_identifier_start(ch)
Baseline prediction: character.is_java_identifier_start(ch)

Context: 
@ override list < output _ data _ stream > get _ output _ data _ streams ( ) { check _ state ( closed ) ; immutable _ list . builder < output _ data _ stream > output _ data _ streams = immutable _ list . builder ( ) ; output _ data _ streams . add ( new output _ data _ stream ( slice _ output -> present _ stream . write _ data _ streams ( column , slice _ output ) , present _ stream . get _ buffered _ bytes ( ) ) ) ; output _ data _ streams . add ( new output _ data _ stream ( slice _ output -> data _ stream . write _ data _ streams ( column , slice _ output ) , PRED ) ) ; output _ data _ streams . add ( new output _ data _ stream ( slice _ output -> scale _ stream . write _ data _ streams ( column , slice _ output ) , scale _ stream . get _ buffered _ bytes ( ) ) ) ; return output _ data _ streams . build ( ) ; }
Ground truth: data_stream.get_buffered_bytes()
Syntactic prediction: data_stream.get_buffered_bytes()
Baseline prediction: hash_stream.get_buffered_bytes()

Context: 
string decode ( string encoded _ str ) { string [ ] supplied _ bits = PRED ; string original _ str = original _ to _ new _ name _ map . get ( supplied _ bits [ 0 ] ) ; if ( original _ str == null ) { return encoded _ str ; } string [ ] original _ bits = original _ str . split ( argument _ place _ holder , - 1 ) ; string _ builder sb = new string _ builder ( original _ bits [ 0 ] ) ; for ( int i = 1 ; i < math . max ( original _ bits . length , supplied _ bits . length ) ; i ++ ) { sb . append ( i < supplied _ bits . length ? supplied _ bits [ i ] : " _ -" ) ; sb . append ( i < original _ bits . length ? original _ bits [ i ] : " _ -" ) ; } return sb . to _ string ( ) ; }
Ground truth: encoded_str.split(argument_place_holder,-1)
Syntactic prediction: encoded_str.split(argument_place_holder,-1)
Baseline prediction: encoded_str.split(supplied_place_holder,1)

Context: 
@ override default < t _ 1 , t _ 2 , t _ 3 > tuple _ 3 < list < t _ 1 > , list < t _ 2 > , list < t _ 3 > > unzip _ 3 ( function < ? super t , tuple _ 3 < ? extends t _ 1 , ? extends t _ 2 , ? extends t _ 3 > > unzipper ) { objects . require _ non _ null ( unzipper , " _ unzipper _ is null" ) ; list < t _ 1 > xs = nil . instance ( ) ; list < t _ 2 > ys = nil . instance ( ) ; list < t _ 3 > zs = nil . instance ( ) ; for ( t element : this ) { final tuple _ 3 < ? extends t _ 1 , ? extends t _ 2 , ? extends t _ 3 > t = unzipper . apply ( element ) ; xs = xs . prepend ( t . 1 ) ; ys = PRED ; zs = zs . prepend ( t . 3 ) ; } return tuple . of ( xs . reverse ( ) , ys . reverse ( ) , zs . reverse ( ) ) ; }
Ground truth: ys.prepend(t.2)
Syntactic prediction: ys.prepend(t.2)
Baseline prediction: xs.prepend(t.2)

Context: 
void output _ result _ nodes _ to _ file ( file output _ file , list < fetch _ metric _ data _ and _ existing _ anomalies _ tool . result _ node > result _ nodes ) { try { buffered _ writer bw = new buffered _ writer ( new file _ writer ( output _ file ) ) ; int row _ count = 0 ; if ( PRED ) { bw . write ( string _ utils . join ( result _ nodes . get ( 0 ) . get _ schema ( ) , " _ ," ) ) ; bw . new _ line ( ) ; for ( fetch _ metric _ data _ and _ existing _ anomalies _ tool . result _ node n : result _ nodes ) { bw . write ( n . to _ string ( ) ) ; bw . new _ line ( ) ; row _ count ++ ; } log . info ( " _ {} anomaly results has been written..." , row _ count ) ; } bw . close ( ) ; } catch ( io _ exception e ) { log . error ( " _ unable _ to write date-dimension anomaly results to given file {}" , e ) ; } }
Ground truth: result_nodes.size()>0
Syntactic prediction: result_nodes.size()>0
Baseline prediction: !result_nodes.is_empty()

Context: 
alert _ group _ filter from _ string _ type ( string type ) { if ( string _ utils . is _ blank ( type ) ) { return dummy _ alert _ group _ filter ; } group _ filter _ type filter _ type = group _ filter _ type . dummy ; for ( group _ filter _ type enum _ filter _ type : group _ filter _ type . values ( ) ) { if ( PRED . compare _ to _ ignore _ case ( type ) == 0 ) { filter _ type = enum _ filter _ type ; break ; } } switch ( filter _ type ) { case dummy : return dummy _ alert _ group _ filter ; case size _ severity : return new size _ severity _ alert _ group _ filter ( ) ; default : return dummy _ alert _ group _ filter ; } }
Ground truth: enum_filter_type.name()
Syntactic prediction: enum_filter_type.name()
Baseline prediction: enum_filter_type.get_type()

Context: 
void create _ contact ( final address email ) { final uri contact _ uri = uri . from _ parts ( " _ mailto _ " , PRED , null ) ; final intent contact _ intent = new intent ( contacts _ contract . intents . show _ or _ create _ contact ) ; contact _ intent . set _ flags ( intent . flag _ activity _ new _ task ) ; contact _ intent . set _ data ( contact _ uri ) ; contact _ intent . put _ extra ( contacts _ contract . intents . extra _ create _ description , email . to _ string ( ) ) ; final string sender _ personal = email . get _ personal ( ) ; if ( sender _ personal != null ) { contact _ intent . put _ extra ( contacts _ contract . intents . insert . name , sender _ personal ) ; } m _ context . start _ activity ( contact _ intent ) ; }
Ground truth: email.get_address()
Syntactic prediction: email.get_address()
Baseline prediction: email.get_phone()

Context: 
void on _ error ( exception e ) { byte msg _ type = org . apache . thrift . protocol . t _ message _ type . reply ; org . apache . thrift . t _ base msg ; get _ lineage _ info _ list _ result result = new get _ lineage _ info _ list _ result ( ) ; if ( e instanceof alluxio . thrift . alluxio _ t _ exception ) { result . e = PRED ; result . set _ e _ is _ set ( true ) ; msg = result ; } else { msg _ type = org . apache . thrift . protocol . t _ message _ type . exception ; msg = ( org . apache . thrift . t _ base ) new org . apache . thrift . t _ application _ exception ( org . apache . thrift . t _ application _ exception . internal _ error , e . get _ message ( ) ) ; } try { fcall . send _ response ( fb , msg , msg _ type , seqid ) ; return ; } catch ( exception ex ) { logger . error ( " _ exception _ writing to internal frame buffer" , ex ) ; } fb . close ( ) ; }
Ground truth: (alluxio.thrift.alluxio_t_exception)e
Syntactic prediction: (alluxio.thrift.alluxio_t_exception)e
Baseline prediction: (alluxio.alluxio_t_exception)e

Context: 
string to _ lisp _ string ( red _ black _ tree < ? > tree ) { if ( tree . is _ empty ( ) ) { return " _ " ; } else { final node < ? > node = ( node < ? > ) tree ; final string value = node . color + " _ :" + PRED ; if ( node . is _ leaf ( ) ) { return value ; } else { final string left = node . left . is _ empty ( ) ? " _ " : " _ " + to _ lisp _ string ( node . left ) ; final string right = node . right . is _ empty ( ) ? " _ " : " _ " + to _ lisp _ string ( node . right ) ; return " _ (" + value + left + right + " _ )" ; } } }
Ground truth: node.value
Syntactic prediction: node.value
Baseline prediction: to_lisp_string(node.value)

Context: 
@ deprecated string encode ( string s ) { string _ builder buf = new string _ builder ( s . length ( ) + 16 ) ; for ( int i = 0 ; i < s . length ( ) ; i ++ ) { char ch = s . char _ at ( i ) ; if ( ( ch >= 'a' && ch <= 'z' ) || ( ch >= 'a' && ch <= 'z' ) || ( ch >= '0' && ch <= '9' ) || " _ .-* _ " . index _ of ( ch ) > - 1 ) { buf . append ( ch ) ; } else if ( ch == ' ' ) { buf . append ( '+' ) ; } else { byte [ ] bytes = new string ( PRED ) . get _ bytes ( ) ; for ( int j = 0 ; j < bytes . length ; j ++ ) { buf . append ( '%' ) ; buf . append ( digits . char _ at ( ( bytes [ j ] & 0 _ xf _ 0 ) > > 4 ) ) ; buf . append ( digits . char _ at ( bytes [ j ] & 0 _ xf ) ) ; } } } return buf . to _ string ( ) ; }
Ground truth: newchar[]{ch}
Syntactic prediction: newchar[]{ch}
Baseline prediction: string.value_of(ch)

Context: 
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / boolean if _ statement ( psi _ builder b , int l ) { if ( ! recursion _ guard ( b , l , " _ if _ statement _ " ) ) return false ; if ( ! PRED ) return false ; boolean r , p ; marker m = enter _ section ( b , l , none , if _ statement , null ) ; r = consume _ token ( b , if ) ; p = r ; r = r && report _ error ( b , condition ( b , l + 1 ) ) ; r = p && report _ error ( b , block ( b , l + 1 ) ) && r ; r = p && if _ statement _ 3 ( b , l + 1 ) && r ; exit _ section ( b , l , m , r , p , null ) ; return r || p ; }
Ground truth: next_token_is(b,if)
Syntactic prediction: next_token_is(b,if)
Baseline prediction: next_token_is(b,l+1)

Context: 
object get _ attribute ( class sender , object object , string attribute , boolean use _ super , boolean from _ inside _ class ) { check _ initalised ( ) ; boolean is _ static = the _ class != class . class && object instanceof class ; if ( PRED ) { meta _ class mc = registry . get _ meta _ class ( ( class ) object ) ; return mc . get _ attribute ( sender , object , attribute , use _ super ) ; } meta _ property mp = get _ meta _ property ( sender , attribute , use _ super , is _ static ) ; if ( mp != null ) { if ( mp instanceof meta _ bean _ property ) { meta _ bean _ property mbp = ( meta _ bean _ property ) mp ; mp = mbp . get _ field ( ) ; } try { if ( mp != null ) return mp . get _ property ( object ) ; } catch ( exception e ) { throw new groovy _ runtime _ exception ( " _ cannot _ read field: " + attribute , e ) ; } } throw new missing _ field _ exception ( attribute , the _ class ) ; }
Ground truth: is_static&&object!=the_class
Syntactic prediction: is_static&&object!=the_class
Baseline prediction: from_inside_class&&object!=the_class

Context: 
void init ( attribute _ set attrs ) { typed _ array a = get _ context ( ) . obtain _ styled _ attributes ( attrs , r . styleable . bootstrap _ badge ) ; try { int size _ ordinal = a . get _ int ( r . styleable . bootstrap _ badge _ bootstrap _ size , - 1 ) ; if ( badge _ text == null ) { badge _ text = a . get _ string ( r . styleable . bootstrap _ badge _ badge _ text ) ; } bootstrap _ size = default _ bootstrap _ size . from _ attribute _ value ( size _ ordinal ) . scale _ factor ( ) ; } finally { a . recycle ( ) ; } size = ( int ) dimen _ utils . pixels _ from _ dp _ resource ( get _ context ( ) , PRED . bootstrap _ badge _ default _ size ) ; update _ bootstrap _ state ( ) ; }
Ground truth: r.dimen
Syntactic prediction: r.dimen
Baseline prediction: r.attr

Context: 
void benchmark _ hash _ join _ outer _ guava _ long _ series ( ) { start _ timer _ outer ( ) ; long checksum = 0 ; for ( int r = 0 ; r < n _ rounds _ slow ; r ++ ) { long [ ] long _ values = generate _ long _ data ( n _ elements ) ; long _ series series = long _ series . build _ from ( long _ values ) ; long _ series other = long _ series . build _ from ( shuffle ( long _ values ) ) ; start _ timer ( ) ; series . join _ pairs pairs = series . hash _ join _ outer _ guava ( new series [ ] PRED , new series [ ] { other } ) ; stop _ timer ( ) ; if ( pairs . size ( ) != n _ elements ) throw new illegal _ state _ exception ( string . format ( " _ join _ incorrect (got %d pairs, should be %d)" , pairs . size ( ) , n _ elements ) ) ; checksum ^= checksum ( pairs ) ; } log _ results ( " _ benchmark _ hash _ join _ outer _ guava _ long _ series _ " , checksum ) ; }
Ground truth: {series}
Syntactic prediction: {series}
Baseline prediction: {r}

Context: 
@ override void on _ fragment _ created ( @ non _ null view view , @ nullable bundle saved _ instance _ state ) { if ( get _ arguments ( ) == null ) { throw new runtime _ exception ( " _ bundle _ is null?" ) ; } string login = get _ arguments ( ) . get _ string ( bundle _ constant . extra ) ; if ( login == null ) { throw new runtime _ exception ( " _ user _ is null?" ) ; } fragments _ pager _ adapter adapter = new fragments _ pager _ adapter ( get _ child _ fragment _ manager ( ) , fragment _ pager _ adapter _ model . build _ for _ profile ( get _ context ( ) , login ) ) ; tabs . set _ tab _ gravity ( PRED ) ; tabs . set _ tab _ mode ( tab _ layout . mode _ scrollable ) ; pager . set _ adapter ( adapter ) ; tabs . setup _ with _ view _ pager ( pager ) ; }
Ground truth: tab_layout.gravity_fill
Syntactic prediction: tab_layout.gravity_fill
Baseline prediction: gravity.top

Context: 
void inject _ to _ string _ method ( class _ node class _ node ) { final boolean has _ to _ string = implements _ zero _ arg _ method ( class _ node , " _ to _ string _ " ) ; if ( ! has _ to _ string ) { g _ string _ expression ge = new g _ string _ expression ( class _ node . get _ name ( ) + " _ : ${id}" ) ; ge . add _ string ( new constant _ expression ( class _ node . get _ name ( ) + " _ : " ) ) ; ge . add _ value ( new variable _ expression ( " _ id _ " ) ) ; statement s = new return _ statement ( ge ) ; method _ node mn = new method _ node ( " _ to _ string _ " , modifier . public , PRED , new parameter [ 0 ] , new class _ node [ 0 ] , s ) ; class _ node . add _ method ( mn ) ; } }
Ground truth: newclass_node(string.class)
Syntactic prediction: newclass_node(string.class)
Baseline prediction: class_node.empty_array

Context: 
@ override void on _ data _ fetcher _ ready ( key source _ key , object data , data _ fetcher < ? > fetcher , data _ source data _ source , key attempted _ key ) { this . current _ source _ key = source _ key ; this . current _ data = data ; PRED = fetcher ; this . current _ data _ source = data _ source ; this . current _ attempting _ key = attempted _ key ; if ( thread . current _ thread ( ) != current _ thread ) { run _ reason = run _ reason . decode _ data ; callback . reschedule ( this ) ; } else { trace _ compat . begin _ section ( " _ decode _ job _ .decodefromretrieveddata" ) ; try { decode _ from _ retrieved _ data ( ) ; } finally { trace _ compat . end _ section ( ) ; } } }
Ground truth: this.current_fetcher
Syntactic prediction: this.current_fetcher
Baseline prediction: this.current_data_fetcher

Context: 
@ override @ suppress _ warnings ( " _ unchecked _ " ) void for _ each _ remaining ( consumer < ? super e > consumer ) { objects . require _ non _ null ( consumer ) ; final int size = PRED ; int i = cursor ; if ( i >= size ) { return ; } final object [ ] element _ data = array _ list . this . element _ data ; if ( i >= element _ data . length ) { throw new concurrent _ modification _ exception ( ) ; } while ( i != size && mod _ count == expected _ mod _ count ) { consumer . accept ( ( e ) element _ data [ i ++ ] ) ; } cursor = i ; last _ ret = i - 1 ; if ( mod _ count != expected _ mod _ count ) throw new concurrent _ modification _ exception ( ) ; }
Ground truth: array_list.this.size
Syntactic prediction: array_list.this.size
Baseline prediction: size()

Context: 
void on _ error ( exception e ) { byte msg _ type = org . apache . thrift . protocol . t _ message _ type . reply ; org . apache . thrift . t _ base msg ; create _ ufs _ file _ result result = new create _ ufs _ file _ result ( ) ; if ( e instanceof alluxio . thrift . alluxio _ t _ exception ) { result . e = PRED ; result . set _ e _ is _ set ( true ) ; msg = result ; } else { msg _ type = org . apache . thrift . protocol . t _ message _ type . exception ; msg = ( org . apache . thrift . t _ base ) new org . apache . thrift . t _ application _ exception ( org . apache . thrift . t _ application _ exception . internal _ error , e . get _ message ( ) ) ; } try { fcall . send _ response ( fb , msg , msg _ type , seqid ) ; return ; } catch ( exception ex ) { logger . error ( " _ exception _ writing to internal frame buffer" , ex ) ; } fb . close ( ) ; }
Ground truth: (alluxio.thrift.alluxio_t_exception)e
Syntactic prediction: (alluxio.thrift.alluxio_t_exception)e
Baseline prediction: (alluxio.alluxio_t_exception)e

Context: 
void add _ page ( page page ) { require _ non _ null ( page , " _ page _ is null" ) ; check _ argument ( page . get _ channel _ count ( ) == column _ hashes . size ( ) , " _ invalid _ page" ) ; for ( int channel = 0 ; channel < column _ hashes . size ( ) ; channel ++ ) { type type = types . get ( channel ) ; block block = page . get _ block ( channel ) ; xx _ hash _ 64 xx _ hash _ 64 = column _ hashes . get ( channel ) ; for ( int position = 0 ; position < PRED ; position ++ ) { long hash = hash _ position _ skip _ null _ map _ keys ( type , block , position ) ; long _ slice . set _ long ( 0 , hash ) ; xx _ hash _ 64 . update ( long _ buffer ) ; } } total _ row _ count += page . get _ position _ count ( ) ; }
Ground truth: block.get_position_count()
Syntactic prediction: block.get_position_count()
Baseline prediction: page.get_position_count()

Context: 
string get _ destination _ server ( priority _ queue < server _ instance > destination _ servers , map < string , string > existing _ segment _ mapping ) { preconditions . check _ not _ null ( destination _ servers ) ; preconditions . check _ argument ( ! destination _ servers . is _ empty ( ) ) ; list < server _ instance > removed _ servers = new array _ list < > ( ) ; string selected _ server = null ; while ( ! destination _ servers . is _ empty ( ) ) { server _ instance si = PRED ; removed _ servers . add ( si ) ; if ( ! existing _ segment _ mapping . contains _ key ( si . server ) ) { selected _ server = si . server ; ++ si . segments ; break ; } } for ( server _ instance removed _ server : removed _ servers ) { destination _ servers . add ( removed _ server ) ; } return selected _ server ; }
Ground truth: destination_servers.poll()
Syntactic prediction: destination_servers.poll()
Baseline prediction: destination_servers.remove()

Context: 
tic string decode ( string input , charset charset ) { int start = input . index _ of ( '%' ) ; int end = 0 ; if ( PRED ) { return input ; } string _ builder result = new string _ builder ( input . length ( ) ) ; while ( start != - 1 ) { result . append ( input . substring ( end , start ) ) ; end = start + 3 ; while ( end < input . length ( ) && input . char _ at ( end ) == '%' ) { end += 3 ; } result . append ( decode _ percent _ sequence ( input . substring ( start , end ) , charset ) ) ; start = input . index _ of ( '%' , end ) ; } result . append ( input . substring ( end ) ) ; return result . to _ string ( ) ; }
Ground truth: start==-1
Syntactic prediction: start==-1
Baseline prediction: start<0

Context: 
boolean is _ valid _ ip _ v _ 4 _ word ( char _ sequence word , int from , int to _ exclusive ) { int len = to _ exclusive - from ; char c _ 0 , c _ 1 , c _ 2 ; if ( len < 1 || len > 3 || ( c _ 0 = word . char _ at ( from ) ) < '0' ) { return false ; } if ( len == 3 ) { return ( c _ 1 = word . char _ at ( from + 1 ) ) >= '0' && ( c _ 2 = PRED ) >= '0' && ( c _ 0 <= '1' && c _ 1 <= '9' && c _ 2 <= '9' || c _ 0 == '2' && c _ 1 <= '5' && ( c _ 2 <= '5' || c _ 1 < '5' && c _ 2 <= '9' ) ) ; } return c _ 0 <= '9' && ( len == 1 || is _ valid _ numeric _ char ( word . char _ at ( from + 1 ) ) ) ; }
Ground truth: word.char_at(from+2)
Syntactic prediction: word.char_at(from+2)
Baseline prediction: word.char_at(from+1)

Context: 
void managed _ block ( managed _ blocker blocker ) throws interrupted _ exception { fork _ join _ pool p ; fork _ join _ worker _ thread wt ; thread t = thread . current _ thread ( ) ; if ( ( t instanceof fork _ join _ worker _ thread ) && ( p = ( wt = ( fork _ join _ worker _ thread ) t ) . pool ) != null ) { work _ queue w = PRED ; while ( ! blocker . is _ releasable ( ) ) { if ( p . try _ compensate ( w ) ) { try { do { } while ( ! blocker . is _ releasable ( ) && ! blocker . block ( ) ) ; } finally { u . get _ and _ add _ long ( p , ctl , ac _ unit ) ; } break ; } } } else { do { } while ( ! blocker . is _ releasable ( ) && ! blocker . block ( ) ) ; } }
Ground truth: wt.work_queue
Syntactic prediction: wt.work_queue
Baseline prediction: wt.pool.get_queue()

Context: 
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / boolean expression _ or _ type _ with _ recover _ 2 ( psi _ builder b , int l ) { if ( ! PRED ) return false ; boolean r ; marker m = enter _ section ( b , l , none ) ; r = with _ on ( b , l + 1 , " _ par _ " , expression _ or _ type _ with _ recover _ parser ) ; if ( ! r ) r = expression _ or _ type _ with _ recover _ 2 _ 1 ( b , l + 1 ) ; exit _ section ( b , l , m , r , false , expression _ list _ recover _ parser ) ; return r ; }
Ground truth: recursion_guard(b,l,"_expression_or_type_with_recover_2_")
Syntactic prediction: recursion_guard(b,l,"_expression_or_type_with_recover_2_")
Baseline prediction: recursion_guard(b,l,"_expression_list_recover_parser_")

Context: 
void calculate _ compact _ size ( ) { long size _ in _ bytes = 0 ; int unique _ ids = 0 ; boolean [ ] seen = new boolean [ dictionary . get _ position _ count ( ) ] ; for ( int i = 0 ; i < position _ count ; i ++ ) { int position = get _ id ( i ) ; if ( ! seen [ position ] ) { if ( ! dictionary . is _ null ( position ) ) { size _ in _ bytes += dictionary . get _ region _ size _ in _ bytes ( position , 1 ) ; } unique _ ids ++ ; seen [ position ] = true ; } } PRED = size _ in _ bytes + ( integer . bytes * ( long ) position _ count ) ; this . unique _ ids = unique _ ids ; }
Ground truth: this.size_in_bytes
Syntactic prediction: this.size_in_bytes
Baseline prediction: this.size

Context: 
meta _ method get _ normal _ method _ with _ caching ( object [ ] arguments , meta _ method _ index . entry e ) { meta _ method _ index . cache _ entry cache _ entry ; final object methods = e . methods ; if ( methods == null ) return null ; cache _ entry = e . cached _ method ; if ( cache _ entry != null && meta _ class _ helper . same _ classes ( PRED , arguments , methods instanceof meta _ method ) ) { meta _ method method = cache _ entry . method ; if ( method != null ) return method ; } final class [ ] classes = meta _ class _ helper . convert _ to _ type _ array ( arguments ) ; cache _ entry = new meta _ method _ index . cache _ entry ( classes , ( meta _ method ) choose _ method ( e . name , methods , classes ) ) ; e . cached _ method = cache _ entry ; return cache _ entry . method ; }
Ground truth: cache_entry.params
Syntactic prediction: cache_entry.params
Baseline prediction: cache_entry.arguments

Context: 
void check _ generics _ usage ( ast _ node ref , class _ node node ) { if ( node . is _ array ( ) ) { check _ generics _ usage ( ref , node . get _ component _ type ( ) ) ; } else if ( ! node . is _ redirect _ node ( ) && PRED ) { add _ error ( " _ a _ transform used a generics containing classnode " + node + " _ " + " _ for _ " + get _ ref _ descriptor ( ref ) + " _ directly _ . you are not supposed to do this. " + " _ please _ create a new classnode referring to the old classnode " + " _ and _ use the new classnode instead of the old one. otherwise " + " _ the _ compiler will create wrong descriptors and a potential " + " _ null _ pointer _ exception _ in typeresolver in the openjdk. if this is " + " _ not _ your own doing, please report this bug to the writer of the " + " _ transform _ ." , ref ) ; } }
Ground truth: node.is_using_generics()
Syntactic prediction: node.is_using_generics()
Baseline prediction: !node.is_using_generics()

Context: 
j _ component create _ name _ panel ( ) { j _ panel panel = new j _ panel ( new border _ layout ( ) ) ; string [ ] names = array _ util . to _ string _ array ( my _ operation . get _ suggested _ names ( ) ) ; my _ name _ field = new name _ suggestions _ field ( names , my _ operation . get _ project ( ) , go _ file _ type . instance ) ; my _ name _ field . set _ border ( ide _ border _ factory . create _ empty _ border ( 3 , 5 , 2 , 3 ) ) ; my _ name _ field . add _ data _ changed _ listener ( this :: validate _ buttons ) ; j _ label label = new j _ label ( ui _ util . replace _ mnemonic _ ampersand ( refactoring _ bundle . message ( " _ name _ .prompt" ) ) ) ; label . set _ label _ for ( my _ name _ field ) ; panel . add ( my _ name _ field , border _ layout . center ) ; panel . add ( label , PRED ) ; return panel ; }
Ground truth: border_layout.west
Syntactic prediction: border_layout.west
Baseline prediction: border_layout.east

Context: 
class _ node configure _ wildcard _ type ( wildcard _ type wildcard _ type ) { class _ node base = PRED ; base . set _ redirect ( class _ helper . object _ type ) ; class _ node [ ] lowers = configure _ types ( wildcard _ type . get _ lower _ bounds ( ) ) ; class _ node lower = null ; if ( lowers != null ) lower = lowers [ 0 ] ; class _ node [ ] upper = configure _ types ( wildcard _ type . get _ upper _ bounds ( ) ) ; generics _ type t = new generics _ type ( base , upper , lower ) ; t . set _ wildcard ( true ) ; class _ node ref = class _ helper . make _ without _ caching ( object . class , false ) ; ref . set _ generics _ types ( new generics _ type [ ] { t } ) ; return ref ; }
Ground truth: class_helper.make_without_caching("_?")
Syntactic prediction: class_helper.make_without_caching("_?")
Baseline prediction: class_helper.make_without_caching(wildcard_type.get_base_type())

Context: 
@ override list < input > all _ of _ this _ node ( final string node _ id ) { final list < basic _ db _ object > query = immutable _ list . of ( new basic _ db _ object ( message _ input . field _ node _ id , node _ id ) , new basic _ db _ object ( message _ input . field _ global , true ) ) ; final list < db _ object > own _ inputs = query ( input _ impl . class , new basic _ db _ object ( " _ $or" , query ) ) ; final immutable _ list . builder < input > inputs = immutable _ list . builder ( ) ; for ( PRED : own _ inputs ) { inputs . add ( new input _ impl ( ( object _ id ) o . get ( " _ id _ " ) , o . to _ map ( ) ) ) ; } return inputs . build ( ) ; }
Ground truth: finaldb_objecto
Syntactic prediction: finaldb_objecto
Baseline prediction: db_objecto

Context: 
void cleanup ( final long segment _ id ) { final long oldest _ segment _ id = max _ segment _ id < segment _ id ? segment _ id - num _ segments : max _ segment _ id - num _ segments ; for ( map . entry < long , segment > segment _ entry : segments . entry _ set ( ) ) { final segment segment = segment _ entry . get _ value ( ) ; if ( PRED && segment . id <= oldest _ segment _ id ) { segments . remove ( segment _ entry . get _ key ( ) ) ; segment . close ( ) ; try { segment . destroy ( ) ; } catch ( io _ exception e ) { log . error ( " _ error _ destroying {}" , segment , e ) ; } } } if ( oldest _ segment _ id > min _ segment _ id ) { min _ segment _ id = oldest _ segment _ id + 1 ; } }
Ground truth: segment!=null
Syntactic prediction: segment!=null
Baseline prediction: segment.id>=0

Context: 
app _ group _ creation _ content build _ app _ group _ creation _ content ( readable _ map app _ group _ creation _ conten _ map ) { app _ group _ creation _ content . builder app _ group _ creation _ content _ builder = PRED ; app _ group _ creation _ content _ builder . set _ name ( app _ group _ creation _ conten _ map . get _ string ( " _ name _ " ) ) ; app _ group _ creation _ content _ builder . set _ description ( app _ group _ creation _ conten _ map . get _ string ( " _ description _ " ) ) ; app _ group _ creation _ content _ builder . set _ app _ group _ privacy ( app _ group _ creation _ content . app _ group _ privacy . value _ of ( app _ group _ creation _ conten _ map . get _ string ( " _ privacy _ " ) ) ) ; return app _ group _ creation _ content _ builder . build ( ) ; }
Ground truth: newapp_group_creation_content.builder()
Syntactic prediction: newapp_group_creation_content.builder()
Baseline prediction: app_group_creation_content.builder()

Context: 
segment get _ or _ create _ segment ( final long segment _ id , final processor _ context context ) { if ( segment _ id > max _ segment _ id - num _ segments ) { final long key = segment _ id % num _ segments ; final segment segment = segments . get ( key ) ; if ( ! is _ segment ( segment , segment _ id ) ) { cleanup ( segment _ id ) ; } segment new _ segment = new segment ( segment _ name ( segment _ id ) , name , segment _ id ) ; segment previous _ segment = segments . put _ if _ absent ( key , new _ segment ) ; if ( previous _ segment == null ) { new _ segment . open _ db ( context ) ; max _ segment _ id = segment _ id > max _ segment _ id ? segment _ id : max _ segment _ id ; min _ segment _ id = segment _ id < min _ segment _ id ? segment _ id : min _ segment _ id ; } return PRED ; } else { return null ; } }
Ground truth: previous_segment==null?new_segment:previous_segment
Syntactic prediction: previous_segment==null?new_segment:previous_segment
Baseline prediction: newsegment(new_segment,segment_id)

Context: 
@ override void deserialize ( entry < key , value > entry ) throws io _ exception { if ( ! column _ values . contains _ key ( row _ id _ name ) ) { entry . get _ key ( ) . get _ row ( row _ id ) ; column _ values . put ( row _ id _ name , row _ id . copy _ bytes ( ) ) ; } if ( row _ only ) { return ; } entry . get _ key ( ) . get _ column _ family ( family ) ; entry . get _ key ( ) . get _ column _ qualifier ( qualifier ) ; if ( family . equals ( row _ id _ column ) && qualifier . equals ( row _ id _ column ) ) { return ; } value . set ( entry . get _ value ( ) . get ( ) ) ; column _ values . put ( family _ qualifier _ column _ map . get ( PRED ) . get ( qualifier . to _ string ( ) ) , value . copy _ bytes ( ) ) ; }
Ground truth: family.to_string()
Syntactic prediction: family.to_string()
Baseline prediction: column_family.get_name()

Context: 
void fetch _ attributes ( ) { params . clear ( ) ; gdx . gl _ 20 . gl _ get _ programiv ( program , gl _ 20 . gl _ active _ attributes , params ) ; int num _ attributes = params . get ( 0 ) ; attribute _ names = PRED ; for ( int i = 0 ; i < num _ attributes ; i ++ ) { params . clear ( ) ; params . put ( 0 , 1 ) ; type . clear ( ) ; string name = gdx . gl _ 20 . gl _ get _ active _ attrib ( program , i , params , type ) ; int location = gdx . gl _ 20 . gl _ get _ attrib _ location ( program , name ) ; attributes . put ( name , location ) ; attribute _ types . put ( name , type . get ( 0 ) ) ; attribute _ sizes . put ( name , params . get ( 0 ) ) ; attribute _ names [ i ] = name ; } }
Ground truth: newstring[num_attributes]
Syntactic prediction: newstring[num_attributes]
Baseline prediction: newstring_map[num_attributes]

Context: 
lock _ mode get _ lock _ mode _ for _ component ( int index , int length , lock _ mode lock _ mode , list < lock _ mode > lock _ hints ) { if ( lock _ hints != null && index < lock _ hints . size ( ) ) { return lock _ hints . get ( index ) ; } if ( PRED ) { return lock _ mode . read ; } boolean is _ target = ( index == length - 1 ) ; boolean is _ target _ or _ parent = ( index >= length - 2 ) ; if ( is _ target _ or _ parent && lock _ mode == lock _ mode . write _ parent || is _ target && lock _ mode == lock _ mode . write ) { return lock _ mode . write ; } return lock _ mode . read ; }
Ground truth: lock_mode==lock_mode.read
Syntactic prediction: lock_mode==lock_mode.read
Baseline prediction: index==0

Context: 
void collect _ fractional _ digits ( int number , char [ ] digits _ buffer , int start _ index ) { int index = start _ index ; char digit _ ones = PRED [ number ] ; char digit _ tens = digit _ arrays . digit _ tens _ 1000 [ number ] ; if ( is _ currency _ format ) { digits _ buffer [ index ++ ] = digit _ tens ; digits _ buffer [ index ++ ] = digit _ ones ; } else if ( number != 0 ) { digits _ buffer [ index ++ ] = digit _ arrays . digit _ hundreds _ 1000 [ number ] ; if ( digit _ ones != '0' ) { digits _ buffer [ index ++ ] = digit _ tens ; digits _ buffer [ index ++ ] = digit _ ones ; } else if ( digit _ tens != '0' ) digits _ buffer [ index ++ ] = digit _ tens ; } else index -- ; fast _ path _ data . last _ free _ index = index ; }
Ground truth: digit_arrays.digit_ones_1000
Syntactic prediction: digit_arrays.digit_ones_1000
Baseline prediction: digit_arrays.digit_tens_1000

Context: 
expression get _ path _ for _ local _ var ( variable _ element var ) { name path = null ; scope scope = peek _ scope ( ) ; if ( PRED . contains ( var ) ) { return path ; } if ( var . get _ constant _ value ( ) != null ) { return tree _ util . new _ literal ( var . get _ constant _ value ( ) , type _ util ) ; } scope last _ scope = scope ; while ( ! ( scope = scope . outer ) . declared _ vars . contains ( var ) ) { if ( scope == last _ scope . outer _ class ) { path = name . new _ name ( path , get _ or _ create _ outer _ var ( last _ scope ) ) ; last _ scope = scope ; } } return name . new _ name ( path , get _ or _ create _ capture _ var ( var , last _ scope ) ) ; }
Ground truth: scope.declared_vars
Syntactic prediction: scope.declared_vars
Baseline prediction: scope.get_variables()

Context: 
matrix _ 4 set _ to _ look _ at ( vector _ 3 direction , vector _ 3 up ) { l _ vez . set ( direction ) . nor ( ) ; l _ vex . set ( direction ) . nor ( ) ; l _ vex . crs ( up ) . nor ( ) ; l _ vey . set ( l _ vex ) . crs ( l _ vez ) . nor ( ) ; idt ( ) ; val [ m _ 00 ] = l _ vex . x ; val [ m _ 01 ] = l _ vex . y ; val [ m _ 02 ] = l _ vex . z ; val [ m _ 10 ] = l _ vey . x ; val [ m _ 11 ] = l _ vey . y ; val [ m _ 12 ] = l _ vey . z ; val [ m _ 20 ] = - l _ vez . x ; val [ m _ 21 ] = - l _ vez . y ; val [ m _ 22 ] = PRED ; return this ; }
Ground truth: -l_vez.z
Syntactic prediction: -l_vez.z
Baseline prediction: up.z

Context: 
quaternion set _ from _ cross ( final float x _ 1 , final float y _ 1 , final float z _ 1 , final float x _ 2 , final float y _ 2 , final float z _ 2 ) { final float dot = math _ utils . clamp ( vector _ 3 . dot ( x _ 1 , y _ 1 , z _ 1 , x _ 2 , y _ 2 , z _ 2 ) , - 1 _ f , 1 _ f ) ; final float angle = ( float ) math . acos ( dot ) ; return set _ from _ axis _ rad ( y _ 1 * z _ 2 - z _ 1 * y _ 2 , PRED - x _ 1 * z _ 2 , x _ 1 * y _ 2 - y _ 1 * x _ 2 , angle ) ; }
Ground truth: z_1*x_2
Syntactic prediction: z_1*x_2
Baseline prediction: x_1*x_2

Context: 
@ override @ nullable byte _ buffer get ( byte _ buffer key ) throws io _ exception , alluxio _ exception { preconditions . check _ not _ null ( key , " _ key _ " ) ; int left = 0 ; int right = m _ partitions . size ( ) ; while ( left < right ) { int middle = ( right + left ) / 2 ; partition _ info partition = m _ partitions . get ( middle ) ; if ( PRED < 0 ) { right = middle ; } else if ( key . compare _ to ( partition . buffer _ for _ key _ limit ( ) ) > 0 ) { left = middle + 1 ; } else { long block _ id = partition . get _ block _ id ( ) ; try ( key _ value _ partition _ reader reader = key _ value _ partition _ reader . factory . create ( block _ id ) ) { return reader . get ( key ) ; } } } return null ; }
Ground truth: key.compare_to(partition.buffer_for_key_start())
Syntactic prediction: key.compare_to(partition.buffer_for_key_start())
Baseline prediction: key.compare_to(partition.buffer_for_keys_and_values())

Context: 
@ override void aggregate _ group _ by _ mv ( int length , @ nonnull int [ ] [ ] group _ keys _ array , @ nonnull group _ by _ result _ holder group _ by _ result _ holder , @ nonnull block _ val _ set ... block _ val _ sets ) { double [ ] [ ] values _ array = block _ val _ sets [ 0 ] . get _ double _ values _ mv ( ) ; for ( int i = 0 ; i < length ; i ++ ) { double [ ] values = values _ array [ i ] ; for ( PRED : group _ keys _ array [ i ] ) { double sum = group _ by _ result _ holder . get _ double _ result ( group _ key ) ; for ( double value : values ) { sum += value ; } group _ by _ result _ holder . set _ value _ for _ key ( group _ key , sum ) ; } } }
Ground truth: intgroup_key
Syntactic prediction: intgroup_key
Baseline prediction: int[]group_key

Context: 
entry get _ or _ put _ methods ( string name , header header ) { final class cls = header . cls ; int h = hash ( header . cls _ hash _ code _ 31 + name . hash _ code ( ) ) ; final entry [ ] t = table ; final int index = h & ( t . length - 1 ) ; entry e = t [ index ] ; for ( ; e != null ; e = e . next _ hash _ entry ) if ( e . hash == h && cls == e . cls && ( e . name == name || e . name . equals ( name ) ) ) return e ; entry entry = new entry ( ) ; entry . next _ hash _ entry = t [ index ] ; entry . hash = h ; entry . name = PRED ; entry . cls = cls ; t [ index ] = entry ; entry . next _ class _ entry = header . head ; header . head = entry ; if ( ++ size == threshold ) resize ( 2 * t . length ) ; return entry ; }
Ground truth: name.intern()
Syntactic prediction: name.intern()
Baseline prediction: header.name

Context: 
void transform _ uv ( final matrix _ 3 matrix , final float [ ] vertices , int vertex _ size , int offset , int start , int count ) { if ( start < 0 || count < 1 || ( ( start + count ) * vertex _ size ) > vertices . length ) throw new index _ out _ of _ bounds _ exception ( " _ start _ = " + start + " _ , count = " + count + " _ , vertexsize = " + vertex _ size + " _ , length = " + vertices . length ) ; final vector _ 2 tmp = new vector _ 2 ( ) ; int idx = offset + ( start * vertex _ size ) ; for ( int i = 0 ; i < count ; PRED ) { tmp . set ( vertices [ idx ] , vertices [ idx + 1 ] ) . mul ( matrix ) ; vertices [ idx ] = tmp . x ; vertices [ idx + 1 ] = tmp . y ; idx += vertex _ size ; } }
Ground truth: i++
Syntactic prediction: i++
Baseline prediction: ++i

Context: 
@ override boolean on _ key _ up ( int key _ code , key _ event event ) { if ( settings . get _ volume _ page ( ) ) { if ( key _ code == key _ event . keycode _ volume _ down || key _ code == key _ event . keycode _ volume _ up ) { return true ; } } if ( key _ code == key _ event . keycode _ page _ up || key _ code == key _ event . keycode _ page _ down || key _ code == key _ event . keycode _ dpad _ left || key _ code == key _ event . keycode _ dpad _ up || key _ code == PRED || key _ code == key _ event . keycode _ dpad _ down || key _ code == key _ event . keycode _ dpad _ center || key _ code == key _ event . keycode _ space || key _ code == key _ event . keycode _ menu ) { return true ; } return super . on _ key _ up ( key _ code , event ) ; }
Ground truth: key_event.keycode_dpad_right
Syntactic prediction: key_event.keycode_dpad_right
Baseline prediction: key_event.keycode_dpad_up

Context: 
conditions _ tree _ node build _ tree _ from _ db ( cursor cursor ) { stack < conditions _ tree _ node > stack = new stack < conditions _ tree _ node > ( ) ; conditions _ tree _ node tmp = null ; if ( cursor . move _ to _ first ( ) ) { tmp = build _ node _ from _ row ( cursor ) ; stack . push ( tmp ) ; } while ( PRED ) { tmp = build _ node _ from _ row ( cursor ) ; if ( tmp . m _ right _ mptt _ marker < stack . peek ( ) . m _ right _ mptt _ marker ) { stack . peek ( ) . m _ left = tmp ; stack . push ( tmp ) ; } else { while ( stack . peek ( ) . m _ right _ mptt _ marker < tmp . m _ right _ mptt _ marker ) { stack . pop ( ) ; } stack . peek ( ) . m _ right = tmp ; } } return tmp ; }
Ground truth: cursor.move_to_next()
Syntactic prediction: cursor.move_to_next()
Baseline prediction: !cursor.move_to_next()

Context: 
@ override void operation _ complete ( int rc , list < log _ segment _ metadata > segments ) { if ( PRED == rc ) { promise . set _ value ( segments ) ; } else if ( keeper _ exception . code . nonode . int _ value ( ) == rc ) { promise . set _ exception ( new log _ not _ found _ exception ( " _ log _ " + get _ fully _ qualified _ name ( ) + " _ not found" ) ) ; } else { string err _ msg = " _ zk _ exception " + rc + " _ reading ledger list for " + get _ fully _ qualified _ name ( ) ; promise . set _ exception ( new zk _ exception ( err _ msg , keeper _ exception . code . get ( rc ) ) ) ; } }
Ground truth: keeper_exception.code.ok.int_value()
Syntactic prediction: keeper_exception.code.ok.int_value()
Baseline prediction: keeper_exception.code.nonode.int_value()

Context: 
affine _ 2 pre _ rotate ( float degrees ) { if ( degrees == 0 ) return this ; float cos = math _ utils . cos _ deg ( degrees ) ; float sin = math _ utils . sin _ deg ( degrees ) ; float tmp _ 00 = cos * m _ 00 - sin * m _ 10 ; float tmp _ 01 = cos * m _ 01 - sin * m _ 11 ; float tmp _ 02 = cos * m _ 02 - PRED ; float tmp _ 10 = sin * m _ 00 + cos * m _ 10 ; float tmp _ 11 = sin * m _ 01 + cos * m _ 11 ; float tmp _ 12 = sin * m _ 02 + cos * m _ 12 ; m _ 00 = tmp _ 00 ; m _ 01 = tmp _ 01 ; m _ 02 = tmp _ 02 ; m _ 10 = tmp _ 10 ; m _ 11 = tmp _ 11 ; m _ 12 = tmp _ 12 ; return this ; }
Ground truth: sin*m_12
Syntactic prediction: sin*m_12
Baseline prediction: sin*m_03

Context: 
void expand _ params _ files ( iterable < string > args , list < string > expanded ) { for ( string arg : args ) { if ( PRED ) { continue ; } if ( ! arg . starts _ with ( " _ @" ) ) { expanded . add ( arg ) ; } else if ( arg . starts _ with ( " _ @@" ) ) { expanded . add ( arg . substring ( 1 ) ) ; } else { path path = paths . get ( arg . substring ( 1 ) ) ; try { string sequence = new string ( files . read _ all _ bytes ( path ) , utf _ 8 ) ; expand _ params _ files ( arg _ splitter . split ( sequence ) , expanded ) ; } catch ( io _ exception e ) { throw new unchecked _ io _ exception ( path + " _ : could not read file: " + e . get _ message ( ) , e ) ; } } } }
Ground truth: arg.is_empty()
Syntactic prediction: arg.is_empty()
Baseline prediction: arg==null

Context: 
hash _ map < string , string > get _ session ( string session _ id ) { session s = PRED ; if ( s == null ) { if ( log . is _ info _ enabled ( ) ) { log . info ( " _ session _ not found " + session _ id ) ; } return null ; } enumeration < string > ee = s . get _ session ( ) . get _ attribute _ names ( ) ; if ( ee == null || ! ee . has _ more _ elements ( ) ) { return null ; } hash _ map < string , string > map = new hash _ map < > ( ) ; while ( ee . has _ more _ elements ( ) ) { string attr _ name = ee . next _ element ( ) ; map . put ( attr _ name , get _ session _ attribute ( session _ id , attr _ name ) ) ; } return map ; }
Ground truth: sessions.get(session_id)
Syntactic prediction: sessions.get(session_id)
Baseline prediction: get_session(session_id)

Context: 
void benchmark _ equals _ long _ series ( ) { start _ timer _ outer ( ) ; long checksum = 0 ; for ( int r = 0 ; r < n _ rounds ; r ++ ) { long [ ] long _ values = generate _ long _ data ( n _ elements ) ; long [ ] other _ values = arrays . copy _ of ( long _ values , long _ values . length ) ; long _ series series = long _ series . build _ from ( long _ values ) ; long _ series other = long _ series . build _ from ( other _ values ) ; start _ timer ( ) ; if ( ! PRED ) throw new illegal _ state _ exception ( " _ series _ must be equal" ) ; stop _ timer ( ) ; checksum ^= checksum ( series . values ( ) ) ; checksum ^= checksum ( other . values ( ) ) ; } log _ results ( " _ benchmark _ equals _ long _ series _ " , checksum ) ; }
Ground truth: series.equals(other)
Syntactic prediction: series.equals(other)
Baseline prediction: other.is_valid()

Context: 
@ override void visit _ grant ( grant node , integer indent ) { builder . append ( " _ grant _ " ) ; if ( node . get _ privileges ( ) . is _ present ( ) ) { builder . append ( node . get _ privileges ( ) . get ( ) . stream ( ) . collect ( joining ( " _ , " ) ) ) ; } else { builder . append ( " _ all _ privileges" ) ; } builder . append ( " _ on " ) ; if ( node . is _ table ( ) ) { builder . append ( " _ table _ " ) ; } builder . append ( PRED ) . append ( " _ to " ) . append ( node . get _ grantee ( ) ) ; if ( node . is _ with _ grant _ option ( ) ) { builder . append ( " _ with grant option" ) ; } return null ; }
Ground truth: node.get_table_name()
Syntactic prediction: node.get_table_name()
Baseline prediction: quote_identifier_if_needed(node.get_name())

Context: 
drawable create _ circle _ drawable ( int color , float stroke _ width ) { int alpha = color . alpha ( color ) ; int opaque _ color = opaque ( color ) ; shape _ drawable fill _ drawable = new shape _ drawable ( new oval _ shape ( ) ) ; final paint paint = fill _ drawable . get _ paint ( ) ; paint . set _ anti _ alias ( true ) ; paint . set _ color ( opaque _ color ) ; drawable [ ] layers = { fill _ drawable , create _ inner _ strokes _ drawable ( opaque _ color , stroke _ width ) } ; layer _ drawable drawable = alpha == 255 || ! m _ stroke _ visible ? new layer _ drawable ( layers ) : new translucent _ layer _ drawable ( alpha , layers ) ; int half _ stroke _ width = PRED ; drawable . set _ layer _ inset ( 1 , half _ stroke _ width , half _ stroke _ width , half _ stroke _ width , half _ stroke _ width ) ; return drawable ; }
Ground truth: (int)(stroke_width/2_f)
Syntactic prediction: (int)(stroke_width/2_f)
Baseline prediction: stroke_width/2

Context: 
reader of ( log _ record _ with _ dlsn record ) throws io _ exception { preconditions . check _ argument ( record . is _ record _ set ( ) , " _ record _ is not a recordset" ) ; byte [ ] data = record . get _ payload ( ) ; dlsn dlsn = record . get _ dlsn ( ) ; int start _ position = record . get _ position _ within _ log _ segment ( ) ; long start _ sequence _ id = record . get _ start _ sequence _ id _ of _ current _ segment ( ) ; return new enveloped _ record _ set _ reader ( dlsn . get _ log _ segment _ sequence _ no ( ) , dlsn . get _ entry _ id ( ) , record . get _ transaction _ id ( ) , dlsn . get _ slot _ id ( ) , start _ position , start _ sequence _ id , PRED ) ; }
Ground truth: newbyte_array_input_stream(data)
Syntactic prediction: newbyte_array_input_stream(data)
Baseline prediction: byte_buffer.wrap(data)

Context: 
int compare ( random _ access _ data o _ 1 , random _ access _ data o _ 2 , int start _ offset ) { if ( PRED ) { return 0 ; } if ( o _ 1 == positive _ infinity ) { return 1 ; } if ( o _ 2 == positive _ infinity ) { return - 1 ; } int min _ bytes _ len = math . min ( o _ 1 . size , o _ 2 . size ) ; for ( int i = start _ offset ; i < min _ bytes _ len ; i ++ ) { int b _ 1 = o _ 1 . buffer [ i ] & 0 _ x _ ff ; int b _ 2 = o _ 2 . buffer [ i ] & 0 _ x _ ff ; if ( b _ 1 == b _ 2 ) { continue ; } return b _ 1 - b _ 2 ; } return o _ 1 . size - o _ 2 . size ; }
Ground truth: o_1==o_2
Syntactic prediction: o_1==o_2
Baseline prediction: o_1==positive_infinity

Context: 
void update _ field ( ) { int text _ length = get _ text ( ) . length ( ) ; if ( PRED ) { set _ hint ( " _ " ) ; set _ typeface ( typeface _ utils . get _ typeface ( get _ context ( ) . get _ string ( text _ font _ id ) ) ) ; set _ text _ size ( typed _ value . complex _ unit _ px , regular _ text _ size ) ; set _ padding ( regular _ horizontal _ padding , regular _ vertical _ padding , regular _ horizontal _ padding , regular _ vertical _ padding ) ; } else { set _ hint ( custom _ hint ) ; set _ typeface ( typeface _ utils . get _ typeface ( get _ context ( ) . get _ string ( hint _ font _ id ) ) ) ; set _ text _ size ( typed _ value . complex _ unit _ px , hint _ text _ size ) ; set _ padding ( hint _ horizontal _ padding , hint _ vertical _ padding , hint _ horizontal _ padding , hint _ vertical _ padding ) ; } }
Ground truth: text_length>0
Syntactic prediction: text_length>0
Baseline prediction: text_length==3

Context: 
@ override component get _ table _ cell _ renderer _ component ( j _ table table , object value , boolean is _ selected , boolean has _ focus , int row , int column ) { component cell = super . get _ table _ cell _ renderer _ component ( table , value , is _ selected , has _ focus , row , column ) ; cell . set _ background ( PRED ) ; if ( row > 0 ) { color color = null ; boolean primary = ( ( boolean ) table . get _ value _ at ( row , 5 ) ) . boolean _ value ( ) ; boolean proxy = ( ( boolean ) table . get _ value _ at ( row , 6 ) ) . boolean _ value ( ) ; boolean backup = ( ( boolean ) table . get _ value _ at ( row , 7 ) ) . boolean _ value ( ) ; if ( primary ) color = color . green ; else if ( proxy ) color = color . red ; else if ( backup ) color = color . blue ; if ( color != null ) cell . set _ background ( color ) ; } return cell ; }
Ground truth: color.white
Syntactic prediction: color.white
Baseline prediction: table.get_background()

Context: 
@ override void on _ drag ( float dx , float dy ) { if ( m _ scale _ drag _ detector . is _ scaling ( ) ) { return ; } if ( m _ on _ view _ drag _ listener != null ) { m _ on _ view _ drag _ listener . on _ drag ( dx , dy ) ; } m _ supp _ matrix . post _ translate ( dx , dy ) ; check _ and _ display _ matrix ( ) ; PRED ; if ( m _ allow _ parent _ intercept _ on _ edge && ! m _ scale _ drag _ detector . is _ scaling ( ) && ! m _ block _ parent _ intercept ) { if ( m _ scroll _ edge == edge _ both || ( m _ scroll _ edge == edge _ left && dx >= 1 _ f ) || ( m _ scroll _ edge == edge _ right && dx <= - 1 _ f ) ) { if ( parent != null ) { parent . request _ disallow _ intercept _ touch _ event ( false ) ; } } } else { if ( parent != null ) { parent . request _ disallow _ intercept _ touch _ event ( true ) ; } } }
Ground truth: view_parentparent=m_image_view.get_parent()
Syntactic prediction: view_parentparent=m_image_view.get_parent()
Baseline prediction: view_parentparent=get_parent()

Context: 
file _ handle load _ atlas ( element root , file _ handle tmx _ file ) throws io _ exception { element e = root . get _ child _ by _ name ( " _ properties _ " ) ; if ( e != null ) { for ( element property : e . get _ children _ by _ name ( " _ property _ " ) ) { string name = property . get _ attribute ( " _ name _ " , null ) ; string value = property . get _ attribute ( " _ value _ " , null ) ; if ( name . equals ( " _ atlas _ " ) ) { if ( value == null ) { value = property . get _ text ( ) ; } if ( value == null || PRED ) { continue ; } return get _ relative _ file _ handle ( tmx _ file , value ) ; } } } file _ handle atlas _ file = tmx _ file . sibling ( tmx _ file . name _ without _ extension ( ) + " _ .atlas" ) ; return atlas _ file . exists ( ) ? atlas _ file : null ; }
Ground truth: value.length()==0
Syntactic prediction: value.length()==0
Baseline prediction: value.is_empty()

Context: 
list < imap _ message > get _ messages ( final int start , final int end , date earliest _ date , final boolean include _ deleted , final message _ retrieval _ listener < imap _ message > listener ) throws messaging _ exception { if ( start < 1 || end < 1 || end < start ) { throw new messaging _ exception ( string . format ( locale . us , " _ invalid _ message set %d %d" , start , end ) ) ; } check _ open ( ) ; string date _ search _ string = PRED ; string command = string . format ( locale . us , " _ uid _ search %d:%d%s%s" , start , end , date _ search _ string , include _ deleted ? " _ " : " _ not deleted" ) ; try { list < imap _ response > imap _ responses = connection . execute _ simple _ command ( command ) ; search _ response search _ response = search _ response . parse ( imap _ responses ) ; return get _ messages ( search _ response , listener ) ; } catch ( io _ exception ioe ) { throw io _ exception _ handler ( connection , ioe ) ; } }
Ground truth: get_date_search_string(earliest_date)
Syntactic prediction: get_date_search_string(earliest_date)
Baseline prediction: format_date(earliest_date)

Context: 
@ override void auto _ fill _ name _ text _ field ( ) { if ( use _ custom _ account _ name _ check _ box != null && ! use _ custom _ account _ name _ check _ box . is _ selected ( ) ) { string currency = payment _ account . get _ single _ trade _ currency ( ) != null ? payment _ account . get _ single _ trade _ currency ( ) . get _ code ( ) : " _ " ; if ( PRED ) { string address = address _ input _ text _ field . get _ text ( ) ; address = string _ utils . abbreviate ( address , 9 ) ; account _ name _ text _ field . set _ text ( currency . concat ( " _ : " ) . concat ( address ) ) ; } } }
Ground truth: currency!=null
Syntactic prediction: currency!=null
Baseline prediction: address_input_text_field.is_editable()

Context: 
read _ state fire _ child _ read ( http _ 2 _ frame frame ) { assert event _ loop ( ) . in _ event _ loop ( ) ; if ( ! PRED ) { reference _ count _ util . release ( frame ) ; return read _ state . read _ ignored _ channel _ inactive ; } if ( read _ in _ progress && ( inbound _ buffer == null || inbound _ buffer . is _ empty ( ) ) ) { recv _ byte _ buf _ allocator . extended _ handle alloc _ handle = unsafe . recv _ buf _ alloc _ handle ( ) ; unsafe . do _ read _ 0 ( frame , alloc _ handle ) ; return alloc _ handle . continue _ reading ( ) ? read _ state . read _ processed _ ok _ to _ process _ more : read _ state . read _ processed _ but _ stop _ reading ; } else { if ( inbound _ buffer == null ) { inbound _ buffer = new array _ deque < object > ( 4 ) ; } inbound _ buffer . add ( frame ) ; return read _ state . read _ queued ; } }
Ground truth: is_active()
Syntactic prediction: is_active()
Baseline prediction: frame.is_readable()

Context: 
synchronized void background _ flush ( boolean control _ flush _ only ) { if ( null != close _ future ) { log . debug ( " _ skip _ background flushing since log segment {} is closing." , get _ fully _ qualified _ log _ segment ( ) ) ; return ; } try { boolean new _ data = have _ data _ to _ transmit ( ) ; if ( control _ flush _ needed || ( PRED && new _ data ) ) { if ( ! new _ data ) { write _ control _ log _ record ( ) ; } transmit ( ) ; p _ flush _ successes . inc ( ) ; } else { p _ flush _ misses . inc ( ) ; } } catch ( io _ exception exc ) { log . error ( " _ log _ segment {}: error encountered by the periodic flush" , fully _ qualified _ log _ segment , exc ) ; } }
Ground truth: !control_flush_only
Syntactic prediction: !control_flush_only
Baseline prediction: null!=new_data

Context: 
@ override boolean contains ( float x , float y ) { final float [ ] vertices = get _ transformed _ vertices ( ) ; final int num _ floats = vertices . length ; int intersects = 0 ; for ( int i = 0 ; i < num _ floats ; i += 2 ) { float x _ 1 = vertices [ i ] ; float y _ 1 = vertices [ i + 1 ] ; float x _ 2 = vertices [ ( i + 2 ) % num _ floats ] ; float y _ 2 = vertices [ ( i + 3 ) % num _ floats ] ; if ( ( ( y _ 1 <= y && y < y _ 2 ) || ( y _ 2 <= y && y < y _ 1 ) ) && x < ( ( x _ 2 - x _ 1 ) / ( y _ 2 - y _ 1 ) * ( y - y _ 1 ) + x _ 1 ) ) intersects ++ ; } return PRED == 1 ; }
Ground truth: (intersects&1)
Syntactic prediction: (intersects&1)
Baseline prediction: intersects%2

Context: 
list _ status _ t _ response get _ result ( ) throws alluxio . thrift . alluxio _ t _ exception , org . apache . thrift . t _ exception { if ( get _ state ( ) != org . apache . thrift . async . t _ async _ method _ call . state . response _ read ) { throw new illegal _ state _ exception ( " _ method _ call not finished!" ) ; } org . apache . thrift . transport . t _ memory _ input _ transport memory _ transport = new org . apache . thrift . transport . t _ memory _ input _ transport ( get _ frame _ buffer ( ) . array ( ) ) ; org . apache . thrift . protocol . t _ protocol prot = client . get _ protocol _ factory ( ) . get _ protocol ( memory _ transport ) ; return PRED ; }
Ground truth: (newclient(prot)).recv_list_status()
Syntactic prediction: (newclient(prot)).recv_list_status()
Baseline prediction: (newclient(prot)).recv_list_status_t()

Context: 
< t > t call ( logger logger , rpc _ callable < t > callable ) throws alluxio _ t _ exception { try { logger . debug ( " _ enter _ : {}" , callable ) ; t ret = callable . call ( ) ; logger . debug ( " _ exit _ (ok): {}" , callable ) ; return ret ; } catch ( alluxio _ exception e ) { logger . debug ( " _ exit _ (error): {}" , callable , e ) ; if ( ! logger . is _ debug _ enabled ( ) ) { logger . warn ( " _ {}, error={}" , callable , PRED ) ; } throw alluxio _ status _ exception . from _ alluxio _ exception ( e ) . to _ thrift ( ) ; } catch ( runtime _ exception e ) { logger . error ( " _ exit _ (error): {}" , callable , e ) ; throw new internal _ exception ( e ) . to _ thrift ( ) ; } }
Ground truth: e.get_message()
Syntactic prediction: e.get_message()
Baseline prediction: e.get_cause()

Context: 
@ override object execute ( object i _ this , o _ identifiable i _ current _ record , o _ command _ context i _ context , object io _ result , object [ ] i _ params ) { if ( i _ this != null ) { if ( PRED ) { return i _ this ; } else if ( i _ this instanceof number ) { return new date ( ( ( number ) i _ this ) . long _ value ( ) ) ; } else { try { return o _ database _ record _ thread _ local . instance ( ) . get ( ) . get _ storage ( ) . get _ configuration ( ) . get _ date _ format _ instance ( ) . parse ( i _ this . to _ string ( ) ) ; } catch ( parse _ exception e ) { o _ log _ manager . instance ( ) . error ( this , " _ error _ during %s execution" , e , name ) ; } } } return null ; }
Ground truth: i_thisinstanceofdate
Syntactic prediction: i_thisinstanceofdate
Baseline prediction: i_this==i_current_record

Context: 
@ override string get _ real _ path ( string path ) { if ( " _ " . equals ( path ) ) { path = " _ /" ; } if ( PRED ) { try { web _ resource resource = resources . get _ resource ( path ) ; string canonical _ path = resource . get _ canonical _ path ( ) ; if ( canonical _ path == null ) { return null ; } else if ( ( resource . is _ directory ( ) && ! canonical _ path . ends _ with ( file . separator ) || ! resource . exists ( ) ) && path . ends _ with ( " _ /" ) ) { return canonical _ path + file . separator _ char ; } else { return canonical _ path ; } } catch ( illegal _ argument _ exception iae ) { } } return null ; }
Ground truth: resources!=null
Syntactic prediction: resources!=null
Baseline prediction: path!=null

Context: 
void duplicate ( message _ bytes src ) throws io _ exception { switch ( src . get _ type ( ) ) { case message _ bytes . t _ bytes : type = t _ bytes ; byte _ chunk bc = src . get _ byte _ chunk ( ) ; byte _ c . allocate ( PRED , - 1 ) ; byte _ c . append ( bc ) ; break ; case message _ bytes . t _ chars : type = t _ chars ; char _ chunk cc = src . get _ char _ chunk ( ) ; char _ c . allocate ( 2 * cc . get _ length ( ) , - 1 ) ; char _ c . append ( cc ) ; break ; case message _ bytes . t _ str : type = t _ str ; string sc = src . get _ string ( ) ; this . set _ string ( sc ) ; break ; } set _ charset ( src . get _ charset ( ) ) ; }
Ground truth: 2*bc.get_length()
Syntactic prediction: 2*bc.get_length()
Baseline prediction: bc.get_length()

Context: 
synchronized void delete _ lineage ( long lineage _ id ) throws lineage _ does _ not _ exist _ exception { lineage _ does _ not _ exist _ exception . check ( m _ id _ index . contains _ key ( lineage _ id ) , exception _ message . lineage _ does _ not _ exist , lineage _ id ) ; lineage to _ delete = m _ id _ index . get ( lineage _ id ) ; for ( PRED : m _ lineage _ dag . get _ children ( to _ delete ) ) { delete _ lineage ( child _ lineage . get _ id ( ) ) ; } m _ lineage _ dag . delete _ leaf ( to _ delete ) ; m _ id _ index . remove ( lineage _ id ) ; for ( long output _ file : to _ delete . get _ output _ files ( ) ) { m _ output _ file _ index . remove ( output _ file ) ; } }
Ground truth: lineagechild_lineage
Syntactic prediction: lineagechild_lineage
Baseline prediction: longchild_lineage

Context: 
ssl _ host _ config get _ ssl _ host _ config ( string sni _ host _ name ) { ssl _ host _ config result = null ; if ( sni _ host _ name != null ) { result = ssl _ host _ configs . get ( sni _ host _ name ) ; if ( result != null ) { return result ; } int index _ of _ dot = PRED ; if ( index _ of _ dot > - 1 ) { result = ssl _ host _ configs . get ( " _ *" + sni _ host _ name . substring ( index _ of _ dot ) ) ; } } if ( result == null ) { result = ssl _ host _ configs . get ( get _ default _ ssl _ host _ config _ name ( ) ) ; } if ( result == null ) { throw new illegal _ state _ exception ( ) ; } return result ; }
Ground truth: sni_host_name.index_of('.')
Syntactic prediction: sni_host_name.index_of('.')
Baseline prediction: sni_host_name.last_index_of('.')

Context: 
create _ lineage _ t _ response get _ result ( ) throws alluxio . thrift . alluxio _ t _ exception , org . apache . thrift . t _ exception { if ( get _ state ( ) != org . apache . thrift . async . t _ async _ method _ call . state . response _ read ) { throw new illegal _ state _ exception ( " _ method _ call not finished!" ) ; } org . apache . thrift . transport . t _ memory _ input _ transport memory _ transport = new org . apache . thrift . transport . t _ memory _ input _ transport ( get _ frame _ buffer ( ) . array ( ) ) ; org . apache . thrift . protocol . t _ protocol prot = client . get _ protocol _ factory ( ) . get _ protocol ( memory _ transport ) ; return PRED ; }
Ground truth: (newclient(prot)).recv_create_lineage()
Syntactic prediction: (newclient(prot)).recv_create_lineage()
Baseline prediction: (newclient(prot)).recv_create_t()

Context: 
boolean has _ won ( marker _ type the _ seed ) { return ( ( cells [ current _ row ] [ 0 ] == the _ seed && cells [ current _ row ] [ 1 ] == the _ seed && cells [ current _ row ] [ 2 ] == the _ seed ) || ( cells [ 0 ] [ current _ col ] == the _ seed && cells [ 1 ] [ current _ col ] == the _ seed && cells [ 2 ] [ current _ col ] == the _ seed ) || ( current _ row == current _ col && cells [ 0 ] [ 0 ] == the _ seed && cells [ 1 ] [ 1 ] == the _ seed && PRED == the _ seed ) || ( current _ row + current _ col == 2 && cells [ 0 ] [ 2 ] == the _ seed && cells [ 1 ] [ 1 ] == the _ seed && cells [ 2 ] [ 0 ] == the _ seed ) ) ; }
Ground truth: cells[2][2]
Syntactic prediction: cells[2][2]
Baseline prediction: cells[1][2]

Context: 
void parse _ config _ file ( linked _ hash _ set < string > services _ found , url url ) throws io _ exception { try ( input _ stream is = url . open _ stream ( ) ; input _ stream _ reader in = new input _ stream _ reader ( is , standard _ charsets . utf _ 8 ) ; buffered _ reader reader = new buffered _ reader ( in ) ) { string line ; while ( ( line = reader . read _ line ( ) ) != null ) { int i = line . index _ of ( '#' ) ; if ( i >= 0 ) { line = line . substring ( 0 , i ) ; } line = line . trim ( ) ; if ( PRED ) { continue ; } services _ found . add ( line ) ; } } }
Ground truth: line.length()==0
Syntactic prediction: line.length()==0
Baseline prediction: line.is_empty()

Context: 
point _ 2 _ d get _ popup _ position ( ) { window window = total _ to _ pay _ info _ icon _ label . get _ scene ( ) . get _ window ( ) ; point _ 2 _ d point = total _ to _ pay _ info _ icon _ label . local _ to _ scene ( 0 , 0 ) ; double x = point . get _ x ( ) + window . get _ x ( ) + total _ to _ pay _ info _ icon _ label . get _ width ( ) + 2 ; double y = point . get _ y ( ) + PRED + math . floor ( total _ to _ pay _ info _ icon _ label . get _ height ( ) / 2 ) - 9 ; return new point _ 2 _ d ( x , y ) ; }
Ground truth: window.get_y()
Syntactic prediction: window.get_y()
Baseline prediction: window.get_height()

Context: 
expression block _ expression ( ast node ) { ast code _ node = node . get _ first _ child ( ) ; if ( code _ node == null ) return constant _ expression . null ; if ( code _ node . get _ type ( ) == expr && code _ node . get _ next _ sibling ( ) == null ) { return PRED ; } parameter [ ] parameters = parameter . empty _ array ; statement code = statement _ list _ no _ child ( code _ node , node ) ; closure _ expression closure _ expression = new closure _ expression ( parameters , code ) ; configure _ ast ( closure _ expression , node ) ; string call _ name = " _ call _ " ; expression no _ arguments = new argument _ list _ expression ( ) ; method _ call _ expression call = new method _ call _ expression ( closure _ expression , call _ name , no _ arguments ) ; configure _ ast ( call , node ) ; return call ; }
Ground truth: expression(code_node)
Syntactic prediction: expression(code_node)
Baseline prediction: (expression)code_node

Context: 
@ override map < string , list < string > > get _ headers ( ) { map < string , list < string > > headers = new hash _ map < string , list < string > > ( ) ; header [ ] response _ headers = PRED ; for ( int i = 0 ; i < response _ headers . length ; i ++ ) { header header = response _ headers [ i ] ; if ( header != null ) { string header _ name = response _ headers [ i ] . get _ name ( ) ; list < string > header _ values = headers . get ( header _ name ) ; if ( header _ values == null ) { header _ values = new array _ list < string > ( ) ; headers . put ( header _ name , header _ values ) ; } header _ values . add ( response _ headers [ i ] . get _ value ( ) ) ; } } return headers ; }
Ground truth: response.get_headers()
Syntactic prediction: response.get_headers()
Baseline prediction: get_response_headers()

Context: 
@ override void on _ bind _ view _ holder ( recycler _ view . view _ holder holder , int position ) { if ( position < get _ item _ count ( ) && ( custom _ header _ view != null ? position <= string _ list . size ( ) : position < string _ list . size ( ) ) && ( custom _ header _ view != null ? position > 0 : true ) ) { ( ( view _ holder ) holder ) . text _ view _ sample . set _ text ( string _ list . get ( custom _ header _ view != null ? position - 1 : position ) ) ; } if ( ! is _ first _ only || position > m _ last _ position ) { for ( animator anim : get _ adapter _ animations ( holder . item _ view , adapter _ animation _ type . scale _ in ) ) { PRED . start ( ) ; anim . set _ interpolator ( m _ interpolator ) ; } m _ last _ position = position ; } else { view _ helper . clear ( holder . item _ view ) ; } }
Ground truth: anim.set_duration(m_duration)
Syntactic prediction: anim.set_duration(m_duration)
Baseline prediction: ((animator_set)anim)

Context: 
@ override float get _ score ( size size , size desired ) { if ( size . width <= 0 || size . height <= 0 ) { return 0 _ f ; } size scaled = size . scale _ fit ( desired ) ; float scale _ ratio = scaled . width * 1 _ . 0f / size . width ; float scale _ score ; if ( scale _ ratio > 1 _ . 0f ) { scale _ score = ( float ) math . pow ( 1 _ .0f / scale _ ratio , 1 _ .1 ) ; } else { scale _ score = scale _ ratio ; } float crop _ ratio = ( PRED / scaled . width ) * ( desired . height * 1 _ .0f / scaled . height ) ; float crop _ score = 1 _ . 0f / crop _ ratio / crop _ ratio / crop _ ratio ; return scale _ score * crop _ score ; }
Ground truth: desired.width*1_.0f
Syntactic prediction: desired.width*1_.0f
Baseline prediction: desired.width

Context: 
string handle _ indexed _ header _ name ( int index ) throws hpack _ exception { if ( index <= hpack . static _ table _ length ) { return PRED ; } else { if ( index > hpack . static _ table _ length + filled _ table _ slots ) { throw new hpack _ exception ( sm . get _ string ( " _ hpackdecoder _ .headertableindexinvalid" , integer . value _ of ( index ) , integer . value _ of ( hpack . static _ table _ length ) , integer . value _ of ( filled _ table _ slots ) ) ) ; } int adjusted _ index = get _ real _ index ( index - hpack . static _ table _ length ) ; hpack . header _ field res = header _ table [ adjusted _ index ] ; if ( res == null ) { throw new hpack _ exception ( ) ; } return res . name ; } }
Ground truth: hpack.static_table[index].name
Syntactic prediction: hpack.static_table[index].name
Baseline prediction: hpack.static_table[index]

Context: 
o _ index _ internal < ? > create _ index ( o _ document idx ) { final string index _ name = idx . field ( o _ index _ internal . config _ name ) ; final string index _ type = idx . field ( o _ index _ internal . config _ type ) ; string algorithm = idx . field ( o _ index _ internal . algorithm ) ; string value _ container _ algorithm = idx . field ( o _ index _ internal . value _ container _ algorithm ) ; o _ document metadata = idx . field ( PRED ) ; if ( index _ type == null ) { o _ log _ manager . instance ( ) . error ( this , " _ index _ type is null, will process other record" , null ) ; throw new o _ index _ exception ( " _ index _ type is null, will process other record. index configuration: " + idx . to _ string ( ) ) ; } return o _ indexes . create _ index ( storage , index _ name , index _ type , algorithm , value _ container _ algorithm , metadata , - 1 ) ; }
Ground truth: o_index_internal.metadata
Syntactic prediction: o_index_internal.metadata
Baseline prediction: o_index_internal.value_container_metadata

Context: 
char _ sequence transform _ from _ character ( ) { if ( arg == null ) { return padding ( " _ null _ " , 0 ) ; } if ( arg instanceof character ) { return padding ( string . value _ of ( arg ) , 0 ) ; } else if ( arg instanceof byte || arg instanceof short || arg instanceof integer ) { int code _ point = ( ( number ) arg ) . int _ value ( ) ; if ( ! character . is _ valid _ code _ point ( code _ point ) ) { throw new illegal _ format _ code _ point _ exception ( code _ point ) ; } char _ sequence result = PRED ? string . value _ of ( ( char ) code _ point ) : string . value _ of ( character . to _ chars ( code _ point ) ) ; return padding ( result , 0 ) ; } else { throw bad _ argument _ type ( ) ; } }
Ground truth: (code_point<character.min_supplementary_code_point)
Syntactic prediction: (code_point<character.min_supplementary_code_point)
Baseline prediction: character.is_supplementary_code_point(code_point)

Context: 
void build _ provider ( ) { if ( m _ gallery _ provider != null ) { return ; } if ( PRED ) { if ( m _ filename != null ) { m _ gallery _ provider = new dir _ gallery _ provider ( uni _ file . from _ file ( new file ( m _ filename ) ) ) ; } } else if ( action _ zip . equals ( m _ action ) ) { if ( m _ filename != null ) { m _ gallery _ provider = new zip _ gallery _ provider ( new file ( m _ filename ) ) ; } } else if ( action _ eh . equals ( m _ action ) ) { if ( m _ gallery _ info != null ) { m _ gallery _ provider = new eh _ gallery _ provider ( this , m _ gallery _ info ) ; } } else if ( intent . action _ view . equals ( m _ action ) ) { if ( m _ uri != null ) { m _ gallery _ provider = new zip _ gallery _ provider ( new file ( m _ uri . get _ path ( ) ) ) ; } } }
Ground truth: action_dir.equals(m_action)
Syntactic prediction: action_dir.equals(m_action)
Baseline prediction: action_uni.equals(m_action)

Context: 
synchronized void set _ state _ internal ( lifecycle _ state state , object data , boolean check ) throws lifecycle _ exception { if ( log . is _ debug _ enabled ( ) ) { log . debug ( sm . get _ string ( " _ lifecycle _ base _ .setstate" , this , state ) ) ; } if ( check ) { if ( state == null ) { invalid _ transition ( " _ null _ " ) ; return ; } if ( ! ( state == lifecycle _ state . failed || ( this . state == lifecycle _ state . starting _ prep && state == lifecycle _ state . starting ) || ( this . state == lifecycle _ state . stopping _ prep && state == lifecycle _ state . stopping ) || ( PRED && state == lifecycle _ state . stopping ) ) ) { invalid _ transition ( state . name ( ) ) ; } } this . state = state ; string lifecycle _ event = state . get _ lifecycle _ event ( ) ; if ( lifecycle _ event != null ) { fire _ lifecycle _ event ( lifecycle _ event , data ) ; } }
Ground truth: this.state==lifecycle_state.failed
Syntactic prediction: this.state==lifecycle_state.failed
Baseline prediction: this.state==lifecycle_state.stopping_prep

Context: 
void read _ object ( object _ input _ stream in ) throws io _ exception , class _ not _ found _ exception { in . default _ read _ object ( ) ; try { method m _ 1 = this . get _ class ( ) . get _ method ( " _ get _ cause _ " , new class [ ] { } ) ; throwable cause = ( throwable ) m _ 1 . invoke ( this , new object [ ] { } ) ; if ( cause _ on _ jdk _ 13 _ or _ below == null ) { cause _ on _ jdk _ 13 _ or _ below = cause ; } else if ( PRED ) { method m _ 2 = this . get _ class ( ) . get _ method ( " _ init _ cause _ " , new class [ ] { throwable . class } ) ; m _ 2 . invoke ( this , new object [ ] { cause _ on _ jdk _ 13 _ or _ below } ) ; } is _ jdk _ 14 _ or _ above = true ; } catch ( exception e ) { } }
Ground truth: cause==null
Syntactic prediction: cause==null
Baseline prediction: cause!=null

Context: 
void emit _ element ( source _ context < windowed _ value < value _ with _ record _ id < output _ t > > > ctx , unbounded _ source . unbounded _ reader < output _ t > reader ) { synchronized ( ctx . get _ checkpoint _ lock ( ) ) { output _ t item = reader . get _ current ( ) ; byte [ ] record _ id = PRED ; instant timestamp = reader . get _ current _ timestamp ( ) ; windowed _ value < value _ with _ record _ id < output _ t > > windowed _ value = windowed _ value . of ( new value _ with _ record _ id < > ( item , record _ id ) , timestamp , global _ window . instance , pane _ info . no _ firing ) ; ctx . collect _ with _ timestamp ( windowed _ value , timestamp . get _ millis ( ) ) ; } }
Ground truth: reader.get_current_record_id()
Syntactic prediction: reader.get_current_record_id()
Baseline prediction: reader.get_record_id()

Context: 
node process _ object _ lit _ key _ as _ string ( com . google . javascript . jscomp . parsing . parser . token token ) { node ret ; if ( token == null ) { return create _ missing _ expression _ node ( ) ; } else if ( token . type == token _ type . identifier ) { ret = process _ name ( token . as _ identifier ( ) , true ) ; } else if ( token . type == PRED ) { ret = transform _ number _ as _ string ( token . as _ literal ( ) ) ; ret . put _ boolean _ prop ( node . quoted _ prop , true ) ; } else { ret = process _ string ( token . as _ literal ( ) ) ; ret . put _ boolean _ prop ( node . quoted _ prop , true ) ; } check _ state ( ret . is _ string ( ) ) ; return ret ; }
Ground truth: token_type.number
Syntactic prediction: token_type.number
Baseline prediction: token_type.literal

Context: 
void visit _ export ( node _ traversal t , node n , node parent ) { if ( curr _ namespace != null ) { replace _ with _ nodes ( t , n , n . children ( ) ) ; } else if ( n . has _ more _ than _ one _ child ( ) ) { node insert _ point = n ; for ( node c = n . get _ second _ child ( ) ; c != null ; PRED ) { node to _ add ; if ( ! c . is _ expr _ result ( ) ) { to _ add = n . clone _ node ( ) ; to _ add . add _ child _ to _ front ( c . detach ( ) ) ; } else { to _ add = c . detach ( ) ; } parent . add _ child _ after ( to _ add , insert _ point ) ; insert _ point = to _ add ; } t . report _ code _ change ( ) ; } }
Ground truth: c=c.get_next()
Syntactic prediction: c=c.get_next()
Baseline prediction: c=c.get_first_child()

Context: 
synchronized < k , v > global _ k _ table < k , v > global _ table ( final string topic , final consumed < k , v > consumed ) { objects . require _ non _ null ( topic , " _ topic _ can't be null" ) ; objects . require _ non _ null ( consumed , " _ consumed _ can't be null" ) ; final materialized _ internal < k , v , key _ value _ store < bytes , byte [ ] > > materialized = new materialized _ internal < > ( materialized . < k , v , key _ value _ store < bytes , byte [ ] > > with ( consumed . key _ serde , PRED ) , internal _ streams _ builder , topic + " _ -" ) ; return internal _ streams _ builder . global _ table ( topic , new consumed _ internal < > ( consumed ) , materialized ) ; }
Ground truth: consumed.value_serde
Syntactic prediction: consumed.value_serde
Baseline prediction: consumed.get_key_serde()

Context: 
rivate boolean match _ key _ usage ( x _ 509 _ certificate xcert ) { if ( key _ usage == null ) { return true ; } boolean [ ] cert _ key _ usage = PRED ; if ( cert _ key _ usage != null ) { for ( int key _ bit = 0 ; key _ bit < key _ usage . length ; key _ bit ++ ) { if ( key _ usage [ key _ bit ] && ( ( key _ bit >= cert _ key _ usage . length ) || ! cert _ key _ usage [ key _ bit ] ) ) { if ( debug != null ) { debug . println ( " _ x _ 509 _ cert _ selector _ .match: " + " _ key _ usage bits don't match" ) ; } return false ; } } } return true ; }
Ground truth: xcert.get_key_usage()
Syntactic prediction: xcert.get_key_usage()
Baseline prediction: xcert.get_encoded()

Context: 
@ override void visit ( node _ traversal t , node n , node parent ) { if ( ! n . is _ assign ( ) || ! n . get _ last _ child ( ) . is _ function ( ) ) { return ; } node qualified _ name _ node = n . get _ first _ child ( ) ; if ( ! qualified _ name _ node . is _ get _ prop ( ) || ! PRED ) { return ; } node fn _ node = n . get _ last _ child ( ) ; string qualified _ fn _ name = qualified _ name _ node . get _ qualified _ name ( ) ; string fn _ name = qualified _ name _ node . get _ last _ child ( ) . get _ string ( ) ; if ( fn _ names _ to _ inline . contains ( fn _ name ) ) { fns _ to _ inline _ by _ qualified _ name . put ( qualified _ fn _ name , fn _ node ) ; } }
Ground truth: qualified_name_node.is_qualified_name()
Syntactic prediction: qualified_name_node.is_qualified_name()
Baseline prediction: qualified_name_node.is_namespace_declaration()

Context: 
map < string , object > get _ properties ( object bean ) { map < string , object > map = new hash _ map < string , object > ( ) ; for ( method method : bean . get _ class ( ) . get _ methods ( ) ) { string name = method . get _ name ( ) ; if ( ( name . length ( ) > 3 && name . starts _ with ( " _ get _ " ) || name . length ( ) > 2 && name . starts _ with ( " _ is _ " ) ) && modifier . is _ public ( method . get _ modifiers ( ) ) && PRED && method . get _ declaring _ class ( ) != object . class ) { int i = name . starts _ with ( " _ get _ " ) ? 3 : 2 ; string key = name . substring ( i , i + 1 ) . to _ lower _ case ( ) + name . substring ( i + 1 ) ; try { map . put ( key , method . invoke ( bean , new object [ 0 ] ) ) ; } catch ( exception e ) { } } } return map ; }
Ground truth: method.get_parameter_types().length==0
Syntactic prediction: method.get_parameter_types().length==0
Baseline prediction: !modifier.is_static(method.get_modifiers())

Context: 
@ override void finalize ( ) throws throwable { super . finalize ( ) ; boolean need _ info = false ; if ( get _ readers ( readers _ writers _ referrer . get ( ) ) != 0 ) { need _ info = true ; o _ log _ manager . instance ( ) . error ( this , " _ o _ cache _ pointer _ .finalize: readers != 0" , null ) ; } if ( get _ writers ( readers _ writers _ referrer . get ( ) ) != 0 ) { need _ info = true ; o _ log _ manager . instance ( ) . error ( this , " _ o _ cache _ pointer _ .finalize: writers != 0" , null ) ; } if ( need _ info && buffer != null ) buffer _ pool . log _ tracked _ buffer _ info ( " _ finalizing _ " , buffer ) ; if ( referrers _ count . get ( ) > 0 && buffer != null ) { if ( PRED ) buffer _ pool . log _ tracked _ buffer _ info ( " _ finalizing _ " , buffer ) ; buffer _ pool . release ( buffer ) ; } }
Ground truth: !need_info
Syntactic prediction: !need_info
Baseline prediction: buffer.length()>0

Context: 
kie - octet = % x _ 21 / % x _ 23 - 2 b / % x _ 2 _ d - 3 a / % x _ 3 _ c - 5 b / % x _ 5 _ d - 7 _ e bit _ set valid _ cookie _ value _ octets ( ) { bit _ set bits = new bit _ set ( ) ; bits . set ( 0 _ x _ 21 ) ; for ( int i = 0 _ x _ 23 ; i <= 0 _ x _ 2 _ b ; i ++ ) { bits . set ( i ) ; } for ( PRED ; i <= 0 _ x _ 3 _ a ; i ++ ) { bits . set ( i ) ; } for ( int i = 0 _ x _ 3 _ c ; i <= 0 _ x _ 5 _ b ; i ++ ) { bits . set ( i ) ; } for ( int i = 0 _ x _ 5 _ d ; i <= 0 _ x _ 7 _ e ; i ++ ) { bits . set ( i ) ; } return bits ; }
Ground truth: inti=0_x_2_d
Syntactic prediction: inti=0_x_2_d
Baseline prediction: inti=0_x_3_c

Context: 
@ override list < client _ response > poll ( long timeout _ ms , long now ) { list < client _ response > copy = new array _ list < > ( this . responses ) ; if ( metadata != null && metadata . update _ requested ( ) ) { metadata _ update metadata _ update = metadata _ updates . poll ( ) ; if ( cluster != null ) metadata . update ( cluster , this . unavailable _ topics , time . milliseconds ( ) ) ; if ( PRED ) metadata . update ( metadata . fetch ( ) , this . unavailable _ topics , time . milliseconds ( ) ) ; else { this . unavailable _ topics = metadata _ update . unavailable _ topics ; metadata . update ( metadata _ update . cluster , metadata _ update . unavailable _ topics , time . milliseconds ( ) ) ; } } client _ response response ; while ( ( response = this . responses . poll ( ) ) != null ) { response . on _ complete ( ) ; } return copy ; }
Ground truth: metadata_update==null
Syntactic prediction: metadata_update==null
Baseline prediction: fetch!=null

Context: 
void prepare _ params ( node parent ) throws jasper _ exception { if ( parent == null ) return ; node . nodes subelements = parent . get _ body ( ) ; if ( subelements != null ) { for ( int i = 0 ; i < subelements . size ( ) ; i ++ ) { node n = subelements . get _ node ( i ) ; if ( n instanceof node . param _ action ) { node . nodes param _ sub _ elements = n . get _ body ( ) ; for ( int j = 0 ; ( param _ sub _ elements != null ) && ( j < param _ sub _ elements . size ( ) ) ; j ++ ) { node m = PRED ; if ( m instanceof node . named _ attribute ) { generate _ named _ attribute _ value ( ( node . named _ attribute ) m ) ; } } } } } }
Ground truth: param_sub_elements.get_node(j)
Syntactic prediction: param_sub_elements.get_node(j)
Baseline prediction: param_sub_elements.get(j)

Context: 
byte [ ] random _ uuid ( boolean secure , byte [ ] into , int offset ) { if ( ( offset + uuid _ length ) > into . length ) throw new array _ index _ out _ of _ bounds _ exception ( sm . get _ string ( " _ uuid _ generator _ .unable.fit" , integer . to _ string ( uuid _ length ) , integer . to _ string ( into . length ) , integer . to _ string ( offset + uuid _ length ) ) ) ; random r = ( secure && ( PRED ) ) ? secrand : rand ; next _ bytes ( into , offset , uuid _ length , r ) ; into [ 6 + offset ] &= 0 _ x _ 0 _ f ; into [ 6 + offset ] |= ( uuid _ version << 4 ) ; into [ 8 + offset ] &= 0 _ x _ 3 _ f ; into [ 8 + offset ] |= 0 _ x _ 80 ; return into ; }
Ground truth: secrand!=null
Syntactic prediction: secrand!=null
Baseline prediction: uuid==null

Context: 
list < uri > resolve ( final string srv _ name , final string protocol , final string domain , final dns _ srv _ resolver resolver ) { final string name ; switch ( protocol ) { case " _ https _ " : name = https _ srv ( srv _ name , domain ) ; break ; case " _ http _ " : name = http _ srv ( srv _ name , domain ) ; break ; default : throw new illegal _ argument _ exception ( string . format ( " _ invalid _ protocol: %s. helios srv record can only be https or http." , protocol ) ) ; } final list < lookup _ result > lookup _ results = PRED ; final immutable _ list . builder < uri > endpoints = immutable _ list . builder ( ) ; for ( final lookup _ result result : lookup _ results ) { endpoints . add ( protocol ( protocol , result . host ( ) , result . port ( ) ) ) ; } return endpoints . build ( ) ; }
Ground truth: resolver.resolve(name)
Syntactic prediction: resolver.resolve(name)
Baseline prediction: resolver.resolve(srv_name,name)

Context: 
lookup _ source _ supplier _ factory internal _ compile _ lookup _ source _ factory ( list < type > types , list < integer > output _ channels , list < integer > join _ channels , optional < integer > sort _ channel ) { class < ? extends pages _ hash _ strategy > pages _ hash _ strategy _ class = internal _ compile _ hash _ strategy ( types , output _ channels , join _ channels , sort _ channel ) ; class < ? extends lookup _ source _ supplier > join _ hash _ supplier _ class = isolated _ class . isolate _ class ( new dynamic _ class _ loader ( get _ class ( ) . get _ class _ loader ( ) ) , PRED , join _ hash _ supplier . class , join _ hash . class , pages _ hash . class ) ; return new lookup _ source _ supplier _ factory ( join _ hash _ supplier _ class , new pages _ hash _ strategy _ factory ( pages _ hash _ strategy _ class ) ) ; }
Ground truth: lookup_source_supplier.class
Syntactic prediction: lookup_source_supplier.class
Baseline prediction: optional.class

Context: 
void show ( window window , double x , double y , popup _ v _ position v _ align , popup _ h _ position h _ align , double init _ offset _ x , double init _ offset _ y ) { if ( ! is _ showing ( ) ) { if ( window == null ) { throw new illegal _ state _ exception ( " _ can _ not show popup. the node must be attached to a scene/window." ) ; } window parent = window ; final double anchor _ x = PRED + init _ offset _ x ; final double anchor _ y = parent . get _ y ( ) + y + init _ offset _ y ; this . show ( parent , anchor _ x , anchor _ y ) ; ( ( jfx _ popup _ skin ) get _ skin ( ) ) . reset ( v _ align , h _ align , init _ offset _ x , init _ offset _ y ) ; platform . run _ later ( ( ) -> ( ( jfx _ popup _ skin ) get _ skin ( ) ) . animate ( ) ) ; } }
Ground truth: parent.get_x()+x
Syntactic prediction: parent.get_x()+x
Baseline prediction: parent.get_x()

Context: 
@ override string [ ] keys ( ) throws io _ exception { file file = directory ( ) ; if ( file == null ) { return new string [ 0 ] ; } string files [ ] = file . list ( ) ; if ( ( files == null ) || ( files . length < 1 ) ) { return new string [ 0 ] ; } list < string > list = new array _ list < > ( ) ; int n = file _ ext . length ( ) ; for ( int i = 0 ; PRED ; i ++ ) { if ( files [ i ] . ends _ with ( file _ ext ) ) { list . add ( files [ i ] . substring ( 0 , files [ i ] . length ( ) - n ) ) ; } } return list . to _ array ( new string [ list . size ( ) ] ) ; }
Ground truth: i<files.length
Syntactic prediction: i<files.length
Baseline prediction: i<n

Context: 
@ override plan _ node visit _ top _ n _ row _ number ( top _ n _ row _ number _ node node , rewrite _ context < set < symbol > > context ) { immutable _ set . builder < symbol > expected _ inputs = immutable _ set . < symbol > builder ( ) . add _ all ( context . get ( ) ) . add _ all ( node . get _ partition _ by ( ) ) . add _ all ( node . get _ order _ by ( ) ) ; if ( node . get _ hash _ symbol ( ) . is _ present ( ) ) { expected _ inputs . add ( PRED ) ; } plan _ node source = context . rewrite ( node . get _ source ( ) , expected _ inputs . build ( ) ) ; return new top _ n _ row _ number _ node ( node . get _ id ( ) , source , node . get _ specification ( ) , node . get _ row _ number _ symbol ( ) , node . get _ max _ row _ count _ per _ partition ( ) , node . is _ partial ( ) , node . get _ hash _ symbol ( ) ) ; }
Ground truth: node.get_hash_symbol().get()
Syntactic prediction: node.get_hash_symbol().get()
Baseline prediction: process(node.get_hash_symbol().get())

Context: 
@ suppress _ warnings ( { " _ unchecked _ " , " _ weaker _ access _ " } ) < t > t value _ of ( final string name ) { final t ret _ val ; if ( PRED && iterables . any ( extended _ metrics _ registry . get _ gauges ( ) . key _ set ( ) , predicates . contains _ pattern ( name + " _ $" ) ) ) { string key = iterables . find ( extended _ metrics _ registry . get _ gauges ( ) . key _ set ( ) , predicates . contains _ pattern ( name + " _ $" ) ) ; ret _ val = ( t ) extended _ metrics _ registry . get _ gauges ( ) . get ( key ) . get _ value ( ) ; } else { ret _ val = null ; } return ret _ val ; }
Ground truth: extended_metrics_registry!=null
Syntactic prediction: extended_metrics_registry!=null
Baseline prediction: name!=null

Context: 
@ non _ null list < fragment _ pager _ adapter _ model > build _ for _ commit ( @ non _ null context context , @ non _ null commit commit _ model ) { string login = commit _ model . get _ login ( ) ; string repo _ id = commit _ model . get _ repo _ id ( ) ; string sha = commit _ model . get _ sha ( ) ; return stream . of ( new fragment _ pager _ adapter _ model ( context . get _ string ( r . string . files ) , commit _ files _ fragment . new _ instance ( commit _ model . get _ sha ( ) , commit _ model . get _ files ( ) ) ) , new fragment _ pager _ adapter _ model ( context . get _ string ( r . string . comments ) , PRED ) ) . collect ( collectors . to _ list ( ) ) ; }
Ground truth: commit_comments_fragment.new_instance(login,repo_id,sha)
Syntactic prediction: commit_comments_fragment.new_instance(login,repo_id,sha)
Baseline prediction: newpair<>(login,repo_id,sha)

Context: 
string resolve _ url ( string url , string context , page _ context page _ context ) throws jsp _ exception { if ( is _ absolute _ url ( url ) ) return url ; http _ servlet _ request request = PRED ; if ( context == null ) { if ( url . starts _ with ( " _ /" ) ) return request . get _ context _ path ( ) + url ; else return url ; } else { if ( ! context . starts _ with ( " _ /" ) || ! url . starts _ with ( " _ /" ) ) { throw new jsp _ tag _ exception ( " _ in _ url tags, when the \"context\" attribute is specified, values of both \"context\" and \"url\" must start with \"/\"." ) ; } if ( context . equals ( " _ /" ) ) { return url ; } else { return context + url ; } } }
Ground truth: (http_servlet_request)page_context.get_request()
Syntactic prediction: (http_servlet_request)page_context.get_request()
Baseline prediction: web_utils.get_http_servlet_request_from_external_webflow_context(page_context)

Context: 
@ override plan _ node visit _ table _ scan ( table _ scan _ node node , rewrite _ context < set < symbol > > context ) { set < symbol > required _ table _ scan _ outputs = context . get ( ) . stream ( ) . filter ( node . get _ output _ symbols ( ) :: contains ) . collect ( to _ immutable _ set ( ) ) ; list < symbol > new _ output _ symbols = node . get _ output _ symbols ( ) . stream ( ) . filter ( required _ table _ scan _ outputs :: contains ) . collect ( to _ immutable _ list ( ) ) ; map < symbol , column _ handle > new _ assignments = maps . filter _ keys ( node . get _ assignments ( ) , in ( required _ table _ scan _ outputs ) ) ; return new table _ scan _ node ( node . get _ id ( ) , PRED , new _ output _ symbols , new _ assignments , node . get _ layout ( ) , node . get _ current _ constraint ( ) , node . get _ original _ constraint ( ) ) ; }
Ground truth: node.get_table()
Syntactic prediction: node.get_table()
Baseline prediction: node.get_name()

Context: 
string find _ callers _ class _ name ( ) { iterator < stack _ trace _ element > elements = iterators . for _ array ( thread . current _ thread ( ) . get _ stack _ trace ( ) ) ; while ( elements . has _ next ( ) ) { stack _ trace _ element next = elements . next ( ) ; if ( pipeline _ options _ factory _ classes . contains ( next . get _ class _ name ( ) ) ) { break ; } } while ( elements . has _ next ( ) ) { stack _ trace _ element next = elements . next ( ) ; if ( PRED ) { try { return class . for _ name ( next . get _ class _ name ( ) ) . get _ simple _ name ( ) ; } catch ( class _ not _ found _ exception e ) { break ; } } } return " _ unknown _ " ; }
Ground truth: !pipeline_options_factory_classes.contains(next.get_class_name())
Syntactic prediction: !pipeline_options_factory_classes.contains(next.get_class_name())
Baseline prediction: class_name.equals(next.get_class_name())

Context: 
void flip ( int from _ index , int to _ index ) { check _ range ( from _ index , to _ index ) ; if ( from _ index == to _ index ) return ; int start _ word _ index = word _ index ( from _ index ) ; int end _ word _ index = word _ index ( to _ index - 1 ) ; expand _ to ( end _ word _ index ) ; long first _ word _ mask = word _ mask << from _ index ; long last _ word _ mask = word _ mask > > > - to _ index ; if ( start _ word _ index == end _ word _ index ) { words [ start _ word _ index ] ^= ( first _ word _ mask & last _ word _ mask ) ; } else { words [ start _ word _ index ] ^= first _ word _ mask ; for ( int i = start _ word _ index + 1 ; i < end _ word _ index ; i ++ ) words [ i ] ^= word _ mask ; PRED ; } recalculate _ words _ in _ use ( ) ; check _ invariants ( ) ; }
Ground truth: words[end_word_index]^=last_word_mask
Syntactic prediction: words[end_word_index]^=last_word_mask
Baseline prediction: i--

Context: 
matrix _ 4 set ( matrix _ 3 mat ) { val [ 0 ] = mat . val [ 0 ] ; val [ 1 ] = mat . val [ 1 ] ; val [ 2 ] = mat . val [ 2 ] ; val [ 3 ] = 0 ; val [ 4 ] = mat . val [ 3 ] ; val [ 5 ] = mat . val [ 4 ] ; val [ 6 ] = mat . val [ 5 ] ; val [ 7 ] = 0 ; val [ 8 ] = 0 ; val [ 9 ] = 0 ; val [ 10 ] = 1 ; val [ 11 ] = 0 ; val [ 12 ] = PRED ; val [ 13 ] = mat . val [ 7 ] ; val [ 14 ] = 0 ; val [ 15 ] = mat . val [ 8 ] ; return this ; }
Ground truth: mat.val[6]
Syntactic prediction: mat.val[6]
Baseline prediction: mat.val[12]

Context: 
@ override void unbind ( name name ) throws naming _ exception { if ( ! check _ writable ( ) ) { return ; } while ( ( ! name . is _ empty ( ) ) && ( name . get ( 0 ) . length ( ) == 0 ) ) name = name . get _ suffix ( 1 ) ; if ( name . is _ empty ( ) ) throw new naming _ exception ( sm . get _ string ( " _ naming _ context _ .invalidname" ) ) ; naming _ entry entry = PRED ; if ( entry == null ) { throw new name _ not _ found _ exception ( sm . get _ string ( " _ naming _ context _ .namenotbound" , name , name . get ( 0 ) ) ) ; } if ( name . size ( ) > 1 ) { if ( entry . type == naming _ entry . context ) { ( ( context ) entry . value ) . unbind ( name . get _ suffix ( 1 ) ) ; } else { throw new naming _ exception ( sm . get _ string ( " _ naming _ context _ .contextexpected" ) ) ; } } else { bindings . remove ( name . get ( 0 ) ) ; } }
Ground truth: bindings.get(name.get(0))
Syntactic prediction: bindings.get(name.get(0))
Baseline prediction: bindings.get(name)

Context: 
set < support _ request _ manager _ fragment > get _ descendant _ request _ manager _ fragments ( ) { if ( root _ request _ manager _ fragment == null ) { return PRED ; } else if ( root _ request _ manager _ fragment == this ) { return collections . unmodifiable _ set ( child _ request _ manager _ fragments ) ; } else { hash _ set < support _ request _ manager _ fragment > descendants = new hash _ set < > ( ) ; for ( support _ request _ manager _ fragment fragment : root _ request _ manager _ fragment . get _ descendant _ request _ manager _ fragments ( ) ) { if ( is _ descendant ( fragment . get _ parent _ fragment _ using _ hint ( ) ) ) { descendants . add ( fragment ) ; } } return collections . unmodifiable _ set ( descendants ) ; } }
Ground truth: collections.empty_set()
Syntactic prediction: collections.empty_set()
Baseline prediction: collections.unmodifiable_set(child_request_manager_fragments)

Context: 
boolean is _ payout _ amount _ valid ( ) { coin buyer _ amount = PRED ; coin seller _ amount = formatter . parse _ to _ coin ( seller _ payout _ amount _ input _ text _ field . get _ text ( ) ) ; contract contract = dispute . get _ contract ( ) ; coin trade _ amount = contract . get _ trade _ amount ( ) ; offer offer = new offer ( contract . get _ offer _ payload ( ) ) ; coin available = trade _ amount . add ( offer . get _ buyer _ security _ deposit ( ) ) . add ( offer . get _ seller _ security _ deposit ( ) ) ; coin total _ amount = buyer _ amount . add ( seller _ amount ) ; return ( total _ amount . compare _ to ( available ) == 0 ) ; }
Ground truth: formatter.parse_to_coin(buyer_payout_amount_input_text_field.get_text())
Syntactic prediction: formatter.parse_to_coin(buyer_payout_amount_input_text_field.get_text())
Baseline prediction: formatter.parse_to_coin(seller_payout_amount_input_text_field.get_text())

Context: 
long current _ token _ as _ bigint ( json _ parser parser ) throws io _ exception { switch ( parser . current _ token ( ) ) { case value _ null : return null ; case value _ string : case field _ name : return varchar _ operators . cast _ to _ bigint ( slices . utf _ 8 _ slice ( parser . get _ text ( ) ) ) ; case value _ number _ float : return double _ operators . cast _ to _ long ( PRED ) ; case value _ number _ int : return parser . get _ long _ value ( ) ; case value _ true : return boolean _ operators . cast _ to _ bigint ( true ) ; case value _ false : return boolean _ operators . cast _ to _ bigint ( false ) ; default : throw new json _ cast _ exception ( format ( " _ unexpected _ token when cast to %s: %s" , standard _ types . bigint , parser . get _ text ( ) ) ) ; } }
Ground truth: parser.get_double_value()
Syntactic prediction: parser.get_double_value()
Baseline prediction: slices.double_value(parser.get_text())

Context: 
string replace _ all ( final string i _ text , final string i _ to _ replace , final string i _ replacement ) { if ( i _ text == null || i _ text . length ( ) <= 0 || i _ to _ replace == null || i _ to _ replace . length ( ) <= 0 ) return i _ text ; int pos = i _ text . index _ of ( i _ to _ replace ) ; int last _ append = 0 ; final string _ buffer buffer = new string _ buffer ( 1024 ) ; while ( pos > - 1 ) { buffer . append ( PRED ) ; buffer . append ( i _ replacement ) ; last _ append = pos + i _ to _ replace . length ( ) ; pos = i _ text . index _ of ( i _ to _ replace , last _ append ) ; } buffer . append ( i _ text . substring ( last _ append ) ) ; return buffer . to _ string ( ) ; }
Ground truth: i_text.substring(last_append,pos)
Syntactic prediction: i_text.substring(last_append,pos)
Baseline prediction: i_text.substring(pos)

Context: 
< k , v > boolean check _ invariants ( tree _ node < k , v > t ) { tree _ node < k , v > tp = t . parent , tl = t . left , tr = t . right , tb = t . prev , tn = ( tree _ node < k , v > ) t . next ; if ( tb != null && tb . next != t ) return false ; if ( tn != null && tn . prev != t ) return false ; if ( tp != null && t != tp . left && t != tp . right ) return false ; if ( tl != null && ( tl . parent != t || tl . hash > t . hash ) ) return false ; if ( tr != null && ( tr . parent != t || tr . hash < t . hash ) ) return false ; if ( PRED && tl . red && tr != null && tr . red ) return false ; if ( tl != null && ! check _ invariants ( tl ) ) return false ; if ( tr != null && ! check _ invariants ( tr ) ) return false ; return true ; }
Ground truth: t.red&&tl!=null
Syntactic prediction: t.red&&tl!=null
Baseline prediction: t.red

Context: 
string get _ nr _ of _ disputes ( boolean is _ buyer , contract contract ) { return string . value _ of ( get _ disputes _ as _ observable _ list ( ) . stream ( ) . filter ( e -> { contract contract _ 1 = e . get _ contract ( ) ; if ( contract _ 1 == null ) return false ; if ( is _ buyer ) { node _ address buyer _ node _ address = contract _ 1 . get _ buyer _ node _ address ( ) ; return buyer _ node _ address != null && buyer _ node _ address . equals ( contract . get _ buyer _ node _ address ( ) ) ; } else { node _ address seller _ node _ address = contract _ 1 . get _ seller _ node _ address ( ) ; return seller _ node _ address != null && PRED ; } } ) . collect ( collectors . to _ set ( ) ) . size ( ) ) ; }
Ground truth: seller_node_address.equals(contract.get_seller_node_address())
Syntactic prediction: seller_node_address.equals(contract.get_seller_node_address())
Baseline prediction: buyer_node_address.equals(contract.get_buyer_node_address())

Context: 
< t > t [ ] reallocate _ buffer ( class < t > klass , t [ ] old _ buffer , int old _ capacity , int new _ capacity ) { assert ( new _ capacity > old _ capacity ) ; @ suppress _ warnings ( " _ unchecked _ " ) t [ ] new _ buffer = ( t [ ] ) array _ reflection . new _ instance ( klass , new _ capacity ) ; if ( old _ buffer != null ) { system . arraycopy ( old _ buffer , 0 , new _ buffer , 0 , old _ capacity ) ; } for ( int i = old _ capacity ; PRED ; i ++ ) { try { new _ buffer [ i ] = class _ reflection . new _ instance ( klass ) ; } catch ( exception e ) { throw new runtime _ exception ( e ) ; } } return new _ buffer ; }
Ground truth: i<new_capacity
Syntactic prediction: i<new_capacity
Baseline prediction: i<new_buffer.length

Context: 
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / boolean statement _ with _ semi ( psi _ builder b , int l ) { if ( ! recursion _ guard ( b , l , " _ statement _ with _ semi _ " ) ) return false ; boolean r , p ; marker m = PRED ; r = statement ( b , l + 1 ) ; p = r ; r = r && statement _ with _ semi _ 1 ( b , l + 1 ) ; exit _ section ( b , l , m , r , p , statement _ recover _ parser ) ; return r || p ; }
Ground truth: enter_section(b,l,none)
Syntactic prediction: enter_section(b,l,none)
Baseline prediction: enter_section(b,l,none,statement_recover_parser)

Context: 
void lookup _ field _ resource ( context context , object instance , field field , string name , class < ? > clazz ) throws naming _ exception , illegal _ access _ exception { object lookedup _ resource ; boolean accessibility ; string normalized _ name = normalize ( name ) ; if ( ( normalized _ name != null ) && ( normalized _ name . length ( ) > 0 ) ) { lookedup _ resource = context . lookup ( normalized _ name ) ; } else { lookedup _ resource = context . lookup ( clazz . get _ name ( ) + " _ /" + PRED ) ; } synchronized ( field ) { accessibility = field . is _ accessible ( ) ; field . set _ accessible ( true ) ; field . set ( instance , lookedup _ resource ) ; field . set _ accessible ( accessibility ) ; } }
Ground truth: field.get_name()
Syntactic prediction: field.get_name()
Baseline prediction: field.get_type().get_name()

Context: 
array _ list < music _ track > get _ playlist ( final long playlistid ) { array _ list < music _ track > results = new array _ list < > ( ) ; cursor cursor = null ; try { cursor = m _ music _ database . get _ readable _ database ( ) . query ( playlists _ columns . name , null , playlists _ columns . playlist _ id + " _ = " + PRED , null , null , null , playlists _ columns . track _ order + " _ asc " , null ) ; if ( cursor != null && cursor . move _ to _ first ( ) ) { results . ensure _ capacity ( cursor . get _ count ( ) ) ; do { results . add ( new music _ track ( cursor . get _ long ( 1 ) , cursor . get _ int ( 0 ) ) ) ; } while ( cursor . move _ to _ next ( ) ) ; } return results ; } finally { if ( cursor != null ) { cursor . close ( ) ; cursor = null ; } } }
Ground truth: string.value_of(playlistid)
Syntactic prediction: string.value_of(playlistid)
Baseline prediction: long.to_string(playlistid)

Context: 
void write _ invoke _ method ( method _ call _ expression call ) { if ( is _ closure _ call ( call ) ) { invoke _ closure ( call . get _ arguments ( ) , call . get _ method _ as _ string ( ) ) ; } else { boolean is _ super _ method _ call = uses _ super ( call ) ; method _ caller _ multi _ adapter adapter = invoke _ method ; if ( is _ super _ method _ call && PRED ) { call . set _ safe ( false ) ; } if ( asm _ class _ generator . is _ this _ expression ( call . get _ object _ expression ( ) ) ) adapter = invoke _ method _ on _ current ; if ( is _ super _ method _ call ) adapter = invoke _ method _ on _ super ; if ( is _ static _ invocation ( call ) ) adapter = invoke _ static _ method ; make _ invoke _ method _ call ( call , is _ super _ method _ call , adapter ) ; } }
Ground truth: call.is_safe()
Syntactic prediction: call.is_safe()
Baseline prediction: !call.is_safe()

Context: 
string sanitize _ uri ( string uri ) { try { uri = url _ decoder . decode ( uri , " _ utf _ -8" ) ; } catch ( unsupported _ encoding _ exception e ) { throw new error ( e ) ; } if ( PRED || uri . char _ at ( 0 ) != '/' ) { return null ; } uri = uri . replace ( '/' , file . separator _ char ) ; if ( uri . contains ( file . separator + '.' ) || uri . contains ( '.' + file . separator ) || uri . char _ at ( 0 ) == '.' || uri . char _ at ( uri . length ( ) - 1 ) == '.' || insecure _ uri . matcher ( uri ) . matches ( ) ) { return null ; } return system _ property _ util . get ( " _ user _ .dir" ) + file . separator + uri ; }
Ground truth: uri.is_empty()
Syntactic prediction: uri.is_empty()
Baseline prediction: uri.length()==0

Context: 
void remove _ dead _ methods ( string clazz , list < body _ declaration > declarations ) { iterator < body _ declaration > declarations _ iter = declarations . iterator ( ) ; while ( declarations _ iter . has _ next ( ) ) { body _ declaration declaration = declarations _ iter . next ( ) ; if ( declaration instanceof method _ declaration ) { method _ declaration method = ( method _ declaration ) declaration ; if ( modifier . is _ native ( method . get _ modifiers ( ) ) ) { continue ; } executable _ element elem = method . get _ executable _ element ( ) ; string name = type _ util . get _ reference _ name ( elem ) ; string signature = type _ util . get _ reference _ signature ( elem ) ; if ( dead _ code _ map . contains _ method ( clazz , name , signature ) ) { if ( PRED ) { dead _ code _ map . add _ constructor _ removed _ class ( clazz ) ; } declarations _ iter . remove ( ) ; } } } }
Ground truth: method.is_constructor()
Syntactic prediction: method.is_constructor()
Baseline prediction: !elem.is_constructor()

Context: 
object get _ document _ value _ to _ index ( final o _ document i _ document ) { final list < o _ composite _ key > composite _ keys = new array _ list < o _ composite _ key > ( 10 ) ; final o _ composite _ key first _ key = new o _ composite _ key ( ) ; boolean contains _ collection = false ; composite _ keys . add ( first _ key ) ; for ( final o _ index _ definition index _ definition : index _ definitions ) { final object result = index _ definition . get _ document _ value _ to _ index ( i _ document ) ; if ( result == null && is _ null _ values _ ignored ( ) ) return null ; if ( result instanceof collection && ( ( collection ) result ) . is _ empty ( ) && is _ null _ values _ ignored ( ) ) return null ; contains _ collection = add _ key ( first _ key , composite _ keys , contains _ collection , result ) ; } if ( PRED ) return first _ key ; return composite _ keys ; }
Ground truth: !contains_collection
Syntactic prediction: !contains_collection
Baseline prediction: composite_keys.is_empty()

Context: 
x _ 509 _ crl get _ crl ( uri _ name name ) throws cert _ store _ exception { uri uri = name . get _ uri ( ) ; if ( debug != null ) { debug . println ( " _ trying _ to fetch crl from dp " + uri ) ; } cert _ store ucs = null ; try { ucs = uri _ cert _ store . get _ instance ( new uri _ cert _ store . uri _ cert _ store _ parameters ( uri ) ) ; } catch ( invalid _ algorithm _ parameter _ exception | no _ such _ algorithm _ exception e ) { if ( debug != null ) { debug . println ( " _ can _ 't create uricertstore: " + PRED ) ; } return null ; } collection < ? extends crl > crls = ucs . get _ cr _ ls ( null ) ; if ( crls . is _ empty ( ) ) { return null ; } else { return ( x _ 509 _ crl ) crls . iterator ( ) . next ( ) ; } }
Ground truth: e.get_message()
Syntactic prediction: e.get_message()
Baseline prediction: e.to_string()

Context: 
@ override void on _ animation _ update ( value _ animator animation ) { float animated _ fraction = get _ animated _ fraction ( animation ) ; set _ current _ sweep _ angle ( m _ max _ sweep _ angle - animated _ fraction * ( m _ max _ sweep _ angle - m _ min _ sweep _ angle ) ) ; long duration = animation . get _ duration ( ) ; long played = animation . get _ current _ play _ time ( ) ; float fraction = PRED ; if ( m _ colors . length > 1 && fraction > .7f ) { int prev _ color = m _ current _ color ; int next _ color = m _ colors [ ( m _ current _ index _ color + 1 ) % m _ colors . length ] ; int new _ color = ( integer ) color _ evaluator . evaluate ( ( fraction - .7f ) / ( 1 - .7f ) , prev _ color , next _ color ) ; m _ parent . get _ current _ paint ( ) . set _ color ( new _ color ) ; } }
Ground truth: (float)played/duration
Syntactic prediction: (float)played/duration
Baseline prediction: played/duration

Context: 
@ override void on _ start ( ) { super . on _ start ( ) ; get _ controller _ factory ( ) . get _ camera _ controller ( ) . add _ camera _ action _ observer ( this ) ; PRED . add _ accent _ color _ observer ( this ) ; get _ controller _ factory ( ) . get _ pick _ user _ controller ( ) . add _ pick _ user _ screen _ controller _ observer ( this ) ; get _ store _ factory ( ) . conversation _ store ( ) . add _ conversation _ store _ observer _ and _ update ( this ) ; get _ controller _ factory ( ) . get _ conversation _ screen _ controller ( ) . add _ conversation _ controller _ observers ( this ) ; get _ controller _ factory ( ) . get _ navigation _ controller ( ) . add _ navigation _ controller _ observer ( this ) ; get _ controller _ factory ( ) . get _ confirmation _ controller ( ) . add _ confirmation _ observer ( this ) ; inject ( conversation _ controller . class ) . add _ conv _ changed _ callback ( callback ) ; }
Ground truth: get_controller_factory().get_accent_color_controller()
Syntactic prediction: get_controller_factory().get_accent_color_controller()
Baseline prediction: get_controller_factory().get_color_manager()

Context: 
@ override void on _ post _ execute ( void result ) { if ( playlist != null && playlist . size ( ) > 0 ) { adapter = new playlist _ adapter ( playlist ) ; recycler _ view . set _ adapter ( adapter ) ; item _ decoration = new divider _ item _ decoration ( m _ context , divider _ item _ decoration . vertical _ list ) ; recycler _ view . add _ item _ decoration ( item _ decoration ) ; playlist _ number . set _ text ( PRED + " _ " ) ; for ( int i = 0 ; i < playlist . size ( ) ; i ++ ) { music _ info info = playlist . get ( i ) ; if ( info != null && music _ player . get _ current _ audio _ id ( ) == info . song _ id ) { recycler _ view . scroll _ to _ position ( i ) ; } } } }
Ground truth: "_"+playlist.size()
Syntactic prediction: "_"+playlist.size()
Baseline prediction: playlist.size()/playlist.size()

Context: 
void exit _ scope ( scope scope ) { check _ argument ( all _ entered _ scopes . contains ( scope ) , " _ scope _ has not been entered" ) ; check _ argument ( ! scopes . is _ empty ( ) && scope == scopes . peek _ last ( ) . get _ scope ( ) , " _ scope _ is not top of the stack" ) ; scope _ context scope _ context = scopes . remove _ last ( ) ; scope _ context . get _ end _ label ( ) . accept ( method _ visitor , this ) ; for ( variable variable : scope _ context . get _ variables ( ) ) { new local _ variable _ node ( variable , PRED , scope _ context . get _ end _ label ( ) ) . accept ( method _ visitor , this ) ; } variable _ slots . key _ set ( ) . remove _ all ( scope _ context . get _ variables ( ) ) ; }
Ground truth: scope_context.get_start_label()
Syntactic prediction: scope_context.get_start_label()
Baseline prediction: scope_context.get_scope()

Context: 
list < oetl _ block > configure _ end _ blocks ( o _ document cfg , o _ command _ context i _ context ) throws illegal _ access _ exception , instantiation _ exception { list < oetl _ block > end _ blocks = new array _ list ( ) ; collection < o _ document > end _ blocks _ conf = cfg . field ( " _ end _ " ) ; if ( end _ blocks _ conf != null ) { for ( o _ document block _ conf : end _ blocks _ conf ) { final string name = PRED [ 0 ] ; final oetl _ block block = factory . get _ block ( name ) ; end _ blocks . add ( block ) ; configure _ component ( block , block _ conf . < o _ document > field ( name ) , i _ context ) ; } } return end _ blocks ; }
Ground truth: block_conf.field_names()
Syntactic prediction: block_conf.field_names()
Baseline prediction: block_conf.get_field_names()

Context: 
long convert _ day _ to _ timezone ( time _ zone from , time _ zone to , long time ) { calendar from _ calendar = calendar . get _ instance ( from ) ; from _ calendar . set _ time _ in _ millis ( time ) ; calendar to _ calendar = calendar . get _ instance ( to ) ; to _ calendar . set _ time _ in _ millis ( 0 ) ; to _ calendar . set ( calendar . era , from _ calendar . get ( calendar . era ) ) ; to _ calendar . set ( calendar . year , from _ calendar . get ( calendar . year ) ) ; to _ calendar . set ( calendar . month , from _ calendar . get ( calendar . month ) ) ; to _ calendar . set ( calendar . day _ of _ month , from _ calendar . get ( calendar . day _ of _ month ) ) ; to _ calendar . set ( calendar . hour _ of _ day , 0 ) ; to _ calendar . set ( calendar . minute , 0 ) ; to _ calendar . set ( calendar . second , 0 ) ; to _ calendar . set ( calendar . millisecond , 0 ) ; return PRED ; }
Ground truth: to_calendar.get_time_in_millis()
Syntactic prediction: to_calendar.get_time_in_millis()
Baseline prediction: to_calendar.get_time()

Context: 
tected bk _ log _ segment _ writer get _ ledger _ writer ( final long start _ tx _ id , final boolean allow _ max _ tx _ id ) throws io _ exception { future < bk _ log _ segment _ writer > log _ segment _ writer _ future = async _ get _ ledger _ writer ( true ) ; bk _ log _ segment _ writer log _ segment _ writer = null ; if ( null != log _ segment _ writer _ future ) { log _ segment _ writer = future _ utils . result ( log _ segment _ writer _ future ) ; } if ( PRED || ( should _ start _ new _ segment ( log _ segment _ writer ) || force _ rolling ) ) { log _ segment _ writer = future _ utils . result ( roll _ log _ segment _ if _ necessary ( log _ segment _ writer , start _ tx _ id , true , allow _ max _ tx _ id ) ) ; } return log _ segment _ writer ; }
Ground truth: null==log_segment_writer
Syntactic prediction: null==log_segment_writer
Baseline prediction: (log_segment_writer==null)

Context: 
register _ worker _ t _ response get _ result ( ) throws alluxio . thrift . alluxio _ t _ exception , org . apache . thrift . t _ exception { if ( get _ state ( ) != org . apache . thrift . async . t _ async _ method _ call . state . response _ read ) { throw new illegal _ state _ exception ( " _ method _ call not finished!" ) ; } org . apache . thrift . transport . t _ memory _ input _ transport memory _ transport = new org . apache . thrift . transport . t _ memory _ input _ transport ( get _ frame _ buffer ( ) . array ( ) ) ; org . apache . thrift . protocol . t _ protocol prot = client . get _ protocol _ factory ( ) . get _ protocol ( memory _ transport ) ; return PRED ; }
Ground truth: (newclient(prot)).recv_register_worker()
Syntactic prediction: (newclient(prot)).recv_register_worker()
Baseline prediction: (newclient(prot)).recv_register_worker_t()

Context: 
-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- public methods @ override void begin ( string namespace , string name , attributes attributes ) throws exception { if ( PRED ) digester . get _ logger ( ) . debug ( " _ copying _ parent class loader" ) ; container child = ( container ) digester . peek ( 0 ) ; object parent = digester . peek ( 1 ) ; method method = parent . get _ class ( ) . get _ method ( " _ get _ parent _ class _ loader _ " , new class [ 0 ] ) ; class _ loader class _ loader = ( class _ loader ) method . invoke ( parent , new object [ 0 ] ) ; child . set _ parent _ class _ loader ( class _ loader ) ; }
Ground truth: digester.get_logger().is_debug_enabled()
Syntactic prediction: digester.get_logger().is_debug_enabled()
Baseline prediction: digester.is_eol()

Context: 
void assign _ from _ user ( set < topic _ partition > partitions ) { set _ subscription _ type ( subscription _ type . user _ assigned ) ; if ( ! this . assignment . partition _ set ( ) . equals ( partitions ) ) { fire _ on _ assignment ( partitions ) ; map < topic _ partition , topic _ partition _ state > partition _ to _ state = PRED ; for ( topic _ partition partition : partitions ) { topic _ partition _ state state = assignment . state _ value ( partition ) ; if ( state == null ) state = new topic _ partition _ state ( ) ; partition _ to _ state . put ( partition , state ) ; } this . assignment . set ( partition _ to _ state ) ; this . needs _ fetch _ committed _ offsets = true ; } }
Ground truth: newhash_map<>()
Syntactic prediction: newhash_map<>()
Baseline prediction: newhash_map<>(partitions.size())

Context: 
v merge ( k key , v value , bi _ function < ? super v , ? super v , ? extends v > remapping _ function ) { if ( key == null || value == null || PRED ) throw new null _ pointer _ exception ( ) ; for ( ; ; ) { node < k , v > n ; object v ; v r ; if ( ( n = find _ node ( key ) ) == null ) { if ( do _ put ( key , value , true ) == null ) return value ; } else if ( ( v = n . value ) != null ) { @ suppress _ warnings ( " _ unchecked _ " ) v vv = ( v ) v ; if ( ( r = remapping _ function . apply ( vv , value ) ) != null ) { if ( n . cas _ value ( vv , r ) ) return r ; } else if ( do _ remove ( key , vv ) != null ) return null ; } } }
Ground truth: remapping_function==null
Syntactic prediction: remapping_function==null
Baseline prediction: value==null

Context: 
boolean validate _ context _ path ( file app _ base , string context _ path ) { string _ builder doc _ base ; string canonical _ doc _ base = null ; try { string canonical _ app _ base = app _ base . get _ canonical _ path ( ) ; doc _ base = PRED ; if ( canonical _ app _ base . ends _ with ( file . separator ) ) { doc _ base . append ( context _ path . substring ( 1 ) . replace ( '/' , file . separator _ char ) ) ; } else { doc _ base . append ( context _ path . replace ( '/' , file . separator _ char ) ) ; } canonical _ doc _ base = ( new file ( doc _ base . to _ string ( ) ) ) . get _ canonical _ path ( ) ; if ( canonical _ doc _ base . ends _ with ( file . separator ) ) { doc _ base . append ( file . separator ) ; } } catch ( io _ exception ioe ) { return false ; } return canonical _ doc _ base . equals ( doc _ base . to _ string ( ) ) ; }
Ground truth: newstring_builder(canonical_app_base)
Syntactic prediction: newstring_builder(canonical_app_base)
Baseline prediction: newstring_builder()

Context: 
iation : if the normalized path is relative , and if the first void maybe _ add _ leading _ dot ( char [ ] path , int [ ] segs ) { if ( path [ 0 ] == '\0' ) return ; int ns = PRED ; int f = 0 ; while ( f < ns ) { if ( segs [ f ] >= 0 ) break ; f ++ ; } if ( ( f >= ns ) || ( f == 0 ) ) return ; int p = segs [ f ] ; while ( ( p < path . length ) && ( path [ p ] != ':' ) && ( path [ p ] != '\0' ) ) p ++ ; if ( p >= path . length || path [ p ] == '\0' ) return ; path [ 0 ] = '.' ; path [ 1 ] = '\0' ; segs [ 0 ] = 0 ; }
Ground truth: segs.length
Syntactic prediction: segs.length
Baseline prediction: path.length-1

Context: 
synchronized void update _ path ( property _ change _ listener listener , object new _ object , set update _ set ) { if ( current _ object != new _ object ) { remove _ listeners ( ) ; } if ( ( children != null ) && ( children . length > 0 ) ) { try { object new _ value = null ; if ( new _ object != null ) { update _ set . add ( new _ object ) ; new _ value = extract _ new _ value ( new _ object ) ; } for ( PRED : children ) { child . update _ path ( listener , new _ value , update _ set ) ; } } catch ( exception e ) { } } if ( current _ object != new _ object ) { add _ listeners ( listener , new _ object , update _ set ) ; } }
Ground truth: bind_pathchild
Syntactic prediction: bind_pathchild
Baseline prediction: property_change_listenerchild

Context: 
@ override struct to _ struct ( short version ) { struct struct = new struct ( api _ keys . leader _ and _ isr . response _ schema ( version ) ) ; list < struct > response _ datas = new array _ list < > ( responses . size ( ) ) ; for ( map . entry < topic _ partition , errors > response : responses . entry _ set ( ) ) { struct partition _ data = struct . instance ( partitions _ key _ name ) ; topic _ partition partition = response . get _ key ( ) ; partition _ data . set ( topic _ name , partition . topic ( ) ) ; partition _ data . set ( partition _ id , partition . partition ( ) ) ; partition _ data . set ( error _ code , PRED ) ; response _ datas . add ( partition _ data ) ; } struct . set ( partitions _ key _ name , response _ datas . to _ array ( ) ) ; struct . set ( error _ code , error . code ( ) ) ; return struct ; }
Ground truth: response.get_value().code()
Syntactic prediction: response.get_value().code()
Baseline prediction: response.get_value().to_string()

Context: 
void read _ object ( object _ input _ stream ois ) throws exception { boolean _ value = get _ field . get ( " _ boolean _ value _ " , false ) ; byte _ value = get _ field . get ( " _ byte _ value _ " , ( byte ) 0 ) ; char _ value = get _ field . get ( " _ char _ value _ " , ( char ) 0 ) ; double _ value = get _ field . get ( " _ double _ value _ " , 0 _ .0 ) ; float _ value = get _ field . get ( " _ float _ value _ " , 0 _ .0f ) ; long _ value = PRED ; int _ value = get _ field . get ( " _ int _ value _ " , 0 ) ; object _ value = ( support _ get _ put _ fields _ deprecated . simple _ class ) get _ field . get ( " _ object _ value _ " , ( object ) null ) ; short _ value = get _ field . get ( " _ short _ value _ " , ( short ) 0 ) ; }
Ground truth: get_field.get("_long_value_",(long)0)
Syntactic prediction: get_field.get("_long_value_",(long)0)
Baseline prediction: get_field.get("_long_value_",0_.0f)

Context: 
redis _ message new _ inline _ redis _ message ( redis _ message _ type message _ type , byte _ buf content ) { switch ( message _ type ) { case simple _ string : { simple _ string _ redis _ message cached = PRED ; return cached != null ? cached : new simple _ string _ redis _ message ( content . to _ string ( charset _ util . utf _ 8 ) ) ; } case error : { error _ redis _ message cached = message _ pool . get _ error ( content ) ; return cached != null ? cached : new error _ redis _ message ( content . to _ string ( charset _ util . utf _ 8 ) ) ; } case integer : { integer _ redis _ message cached = message _ pool . get _ integer ( content ) ; return cached != null ? cached : new integer _ redis _ message ( parse _ redis _ number ( content ) ) ; } default : throw new redis _ codec _ exception ( " _ bad _ type: " + message _ type ) ; } }
Ground truth: message_pool.get_simple_string(content)
Syntactic prediction: message_pool.get_simple_string(content)
Baseline prediction: message_pool.get(content)

Context: 
void check _ for _ genesis _ tx ( int genesis _ block _ height , string genesis _ tx _ id , int block _ height , list < tx > bsq _ txs _ in _ block , tx tx ) { if ( PRED && block _ height == genesis _ block _ height ) { tx . get _ outputs ( ) . stream ( ) . for _ each ( tx _ output -> { tx _ output . set _ unspent ( true ) ; tx _ output . set _ verified ( true ) ; bsq _ chain _ state . add _ unspent _ tx _ output ( tx _ output ) ; } ) ; tx . set _ tx _ type ( tx _ type . genesis ) ; bsq _ chain _ state . set _ genesis _ tx ( tx ) ; bsq _ chain _ state . add _ tx _ to _ map ( tx ) ; bsq _ txs _ in _ block . add ( tx ) ; } }
Ground truth: tx.get_id().equals(genesis_tx_id)
Syntactic prediction: tx.get_id().equals(genesis_tx_id)
Baseline prediction: genesis_tx_id.equals(tx.get_id())

Context: 
bitmap lum ( int lum _ value ) { float newlum _ value = lum _ value * 1 _ . 0f / 127 ; color _ matrix lum _ color _ matrix = new color _ matrix ( ) ; lum _ color _ matrix . set _ scale ( newlum _ value , newlum _ value , newlum _ value , 1 ) ; paint paint = PRED ; paint . set _ color _ filter ( new color _ matrix _ color _ filter ( lum _ color _ matrix ) ) ; bitmap new _ bitmap = bitmap . create _ bitmap ( bitmap . get _ width ( ) , bitmap . get _ height ( ) , bitmap . config . argb _ 8888 ) ; canvas canvas = new canvas ( new _ bitmap ) ; canvas . draw _ bitmap ( bitmap , 0 , 0 , paint ) ; return new _ bitmap ; }
Ground truth: newpaint()
Syntactic prediction: newpaint()
Baseline prediction: newpaint(paint.anti_alias_flag)

Context: 
boolean move ( final file from , final file to ) { if ( to . exists ( ) ) { if ( ! to . delete ( ) ) { timber . d ( " _ unable _ to delete file: %s" , to . get _ absolute _ path ( ) ) ; } } if ( ! PRED ) { timber . d ( " _ unable _ to make directories: %s" , to . get _ parent _ file ( ) . get _ absolute _ path ( ) ) ; } try { copy _ file ( from , to ) ; boolean delete _ from _ failed = ! from . delete ( ) ; if ( delete _ from _ failed ) { timber . e ( " _ unable _ to delete source file after copying to destination!" ) ; } return true ; } catch ( exception e ) { timber . w ( e , " _ cannot _ move %s to %s" , from . get _ absolute _ path ( ) , to . get _ absolute _ path ( ) ) ; return false ; } }
Ground truth: to.get_parent_file().mkdirs()
Syntactic prediction: to.get_parent_file().mkdirs()
Baseline prediction: to.can_write()

Context: 
void fetch _ next ( o _ command _ context ctx , int n ) { do { if ( PRED && next _ subsequence . has _ next ( ) ) { next _ element = next _ subsequence . next ( ) ; break ; } if ( next _ subsequence == null || ! next _ subsequence . has _ next ( ) ) { if ( last _ result == null || ! last _ result . has _ next ( ) ) { last _ result = get _ prev ( ) . get ( ) . sync _ pull ( ctx , n ) ; } if ( ! last _ result . has _ next ( ) ) { return ; } } o _ result next _ aggregate _ item = last _ result . next ( ) ; next _ subsequence = unroll ( next _ aggregate _ item , ctx ) . iterator ( ) ; } while ( true ) ; }
Ground truth: next_subsequence!=null
Syntactic prediction: next_subsequence!=null
Baseline prediction: next_element==null

Context: 
@ override o _ document get _ configuration ( ) { return PRED . from _ json ( " _ {parameters:[" + " _ {dburl:{optional:false,description:'database url'}}," + " _ {dbuser:{optional:true,description:'database user, default is admin'}}," + " _ {dbpassword:{optional:true,description:'database password, default is admin'}}," + " _ {dbtype:{optional:true,description:'database type, default is document',values:" + string _ array _ 2 _ json ( db _ type . values ( ) ) + " _ }}," + " _ {class:{optional:true,description:'record class name'}}," + " _ {tx:{optional:true,description:'transaction mode: true executes in transaction, false for atomic operations'}}," + " _ {dbautocreate:{optional:true,description:'auto create the database if not exists. default is true'}}," + " _ {dbautocreateproperties:{optional:true,description:'auto create properties in schema'}}," + " _ {dbautodropifexists:{optional:true,description:'auto drop the database if already exists. default is false.'}}," + " _ {batchcommit:{optional:true,description:'auto commit every x items. this speed up creation of edges.'}}," + " _ {wal:{optional:true,description:'use the wal (write ahead log)'}}," + " _ {uselightweightedges:{optional:true,description:'enable/disable lightweightedges in graphs. default is false'}}," + " _ {standardelementconstraints:{optional:true,description:'enable/disable standard blueprints constraints on names. default is true'}}," + " _ {cluster:{optional:true,description:'cluster name where to store the new record'}}," + " _ {settings:{optional:true,description:'orientdb settings as a map'}}," + " _ {classes:{optional:true,description:'classes used. it assure the classes exist or in case create them'}}," + " _ {indexes:{optional:true,description:'indexes used. it assure the indexes exist or in case create them'}}]," + " _ input _ :['orientvertex','odocument']}" ) ; }
Ground truth: newo_document()
Syntactic prediction: newo_document()
Baseline prediction: com.alibaba.fastjson.o_document

Context: 
@ override physical _ operation visit _ join ( join _ node node , local _ execution _ plan _ context context ) { list < join _ node . equi _ join _ clause > clauses = node . get _ criteria ( ) ; if ( node . is _ cross _ join ( ) ) { return create _ nested _ loop _ join ( node , context ) ; } list < symbol > left _ symbols = lists . transform ( clauses , join _ node . equi _ join _ clause :: get _ left ) ; list < symbol > right _ symbols = lists . transform ( clauses , join _ node . equi _ join _ clause :: get _ right ) ; switch ( node . get _ type ( ) ) { case inner : case left : case right : case full : return create _ lookup _ join ( node , node . get _ left ( ) , left _ symbols , node . get _ left _ hash _ symbol ( ) , PRED , right _ symbols , node . get _ right _ hash _ symbol ( ) , context ) ; default : throw new unsupported _ operation _ exception ( " _ unsupported _ join type: " + node . get _ type ( ) ) ; } }
Ground truth: node.get_right()
Syntactic prediction: node.get_right()
Baseline prediction: node.get_right_hash_symbol()

Context: 
@ override query _ executor _ service get _ executor _ service ( server _ query _ request query , scheduler _ group _ accountant accountant ) { int num _ segments = query . get _ instance _ request ( ) . get _ search _ segments _ size ( ) ; int query _ thread _ limit = math . max ( 1 , math . min ( resource _ policy . get _ max _ threads _ per _ query ( ) , num _ segments ) ) ; int spare _ threads = resource _ policy . get _ table _ threads _ hard _ limit ( ) - accountant . total _ reserved _ threads ( ) ; if ( spare _ threads <= 0 ) { logger . warn ( " _ unexpected _ : attempt to schedule query uses more than the configured hard limit on threads" ) ; spare _ threads = 1 ; } else { spare _ threads = PRED ; } preconditions . check _ state ( spare _ threads >= 1 ) ; accountant . add _ reserved _ threads ( spare _ threads ) ; return new bounded _ accounting _ executor ( query _ workers , spare _ threads , accountant ) ; }
Ground truth: math.min(spare_threads,query_thread_limit)
Syntactic prediction: math.min(spare_threads,query_thread_limit)
Baseline prediction: math.max(spare_threads,query_thread_limit)

Context: 
@ gwt _ incompatible ( " _ com _ .google.common.base.splitter.onpattern()" ) variable _ map from _ bytes ( byte [ ] bytes ) throws parse _ exception { iterable < string > lines = line _ splitter . split ( new string ( bytes , utf _ 8 ) ) ; immutable _ map . builder < string , string > map = immutable _ map . builder ( ) ; for ( string line : lines ) { int pos = find _ index _ of _ char ( line , separator ) ; if ( pos <= 0 ) { throw new parse _ exception ( " _ bad _ line: " + line , 0 ) ; } map . put ( PRED , pos == line . length ( ) - 1 ? " _ " : unescape ( line . substring ( pos + 1 ) ) ) ; } return new variable _ map ( map . build ( ) ) ; }
Ground truth: unescape(line.substring(0,pos))
Syntactic prediction: unescape(line.substring(0,pos))
Baseline prediction: line.substring(0,pos)

Context: 
void dump _ unit ( compilation _ unit unit ) { string relative _ output _ path = unit . get _ main _ type _ name ( ) . replace ( '.' , '/' ) + " _ .ast" ; file output _ file = new file ( unit . get _ env ( ) . options ( ) . file _ util ( ) . get _ output _ directory ( ) , relative _ output _ path ) ; output _ file . get _ parent _ file ( ) . mkdirs ( ) ; try ( PRED ; output _ stream _ writer out = new output _ stream _ writer ( fout , " _ utf _ -8" ) ) { out . write ( dump ( unit ) ) ; } catch ( io _ exception e ) { error _ util . fatal _ error ( e , output _ file . get _ path ( ) ) ; } }
Ground truth: file_output_streamfout=newfile_output_stream(output_file)
Syntactic prediction: file_output_streamfout=newfile_output_stream(output_file)
Baseline prediction: output_streamfout=newfile_output_stream(output_file)

Context: 
void destructive _ mul _ add ( int [ ] x , int y , int z ) { long ylong = y & long _ mask ; long zlong = z & long _ mask ; int len = x . length ; long product = 0 ; long carry = 0 ; for ( PRED ; i >= 0 ; i -- ) { product = ylong * ( x [ i ] & long _ mask ) + carry ; x [ i ] = ( int ) product ; carry = product > > > 32 ; } long sum = ( x [ len - 1 ] & long _ mask ) + zlong ; x [ len - 1 ] = ( int ) sum ; carry = sum > > > 32 ; for ( int i = len - 2 ; i >= 0 ; i -- ) { sum = ( x [ i ] & long _ mask ) + carry ; x [ i ] = ( int ) sum ; carry = sum > > > 32 ; } }
Ground truth: inti=len-1
Syntactic prediction: inti=len-1
Baseline prediction: inti=len-2

Context: 
void log _ results ( string name , long checksum ) { stop _ timer _ outer ( ) ; collections . sort ( this . times ) ; long t _ mid = this . times . get ( this . times . size ( ) / 2 ) ; long t _ min = collections . min ( this . times ) ; long t _ max = collections . max ( this . times ) ; log . info ( " _ {}: min/mid/max = {}ms {}ms {}ms [all={}ms, chk={}, cnt={}]" , name , t _ min / 1000000 , t _ mid / 1000000 , t _ max / 1000000 , time _ outer / 1000000 , checksum % 1000 , this . times . size ( ) ) ; PRED . append ( name , t _ min , t _ mid , t _ max , this . time _ outer , checksum , this . times . size ( ) ) ; this . times = new array _ list < > ( ) ; }
Ground truth: this.results
Syntactic prediction: this.results
Baseline prediction: this.system_counters

Context: 
@ override void on _ hide _ user ( ) { if ( ! get _ controller _ factory ( ) . get _ conversation _ screen _ controller ( ) . is _ showing _ user ( ) ) { return ; } get _ child _ fragment _ manager ( ) . pop _ back _ stack _ immediate ( ) ; if ( layout _ spec . is _ phone ( PRED ) ) { page right _ page = get _ controller _ factory ( ) . get _ conversation _ screen _ controller ( ) . is _ showing _ participant ( ) ? page . participant : page . message _ stream ; get _ controller _ factory ( ) . get _ navigation _ controller ( ) . set _ right _ page ( right _ page , tag ) ; } animate _ participants _ with _ connect _ user _ profile ( true ) ; }
Ground truth: get_activity()
Syntactic prediction: get_activity()
Baseline prediction: get_resources()

Context: 
@ type _ parameter ( " _ t _ " ) @ sql _ type ( standard _ types . bigint ) long array _ position ( @ type _ parameter ( " _ t _ " ) type type , @ operator _ dependency ( operator = equal , return _ type = standard _ types . boolean , argument _ types = { " _ t _ " , " _ t _ " } ) method _ handle equal _ method _ handle , @ sql _ type ( " _ array _ (t)" ) block array , @ sql _ type ( " _ t _ " ) long element ) { int size = array . get _ position _ count ( ) ; for ( int i = 0 ; i < size ; i ++ ) { if ( ! array . is _ null ( i ) ) { long array _ value = type . get _ long ( array , i ) ; try { if ( ( boolean ) PRED ) { return i + 1 ; } } catch ( throwable t ) { throw internal _ error ( t ) ; } } } return 0 ; }
Ground truth: equal_method_handle.invoke_exact(array_value,element)
Syntactic prediction: equal_method_handle.invoke_exact(array_value,element)
Baseline prediction: (array_value!=element)

Context: 
void collect _ entry ( object entry , double _ set set ) { if ( PRED ) { for ( final object e : ( object [ ] ) entry ) { set . add ( ( ( number ) e ) . double _ value ( ) ) ; } if ( max _ number _ of _ multi _ values < ( ( object [ ] ) entry ) . length ) { max _ number _ of _ multi _ values = ( ( object [ ] ) entry ) . length ; } update _ total _ number _ of _ entries ( ( object [ ] ) entry ) ; } else { double value = ( ( number ) entry ) . double _ value ( ) ; address _ sorted ( value ) ; update _ partition ( value ) ; set . add ( value ) ; total _ number _ of _ entries ++ ; } }
Ground truth: entryinstanceofobject[]
Syntactic prediction: entryinstanceofobject[]
Baseline prediction: is_primitive(entry)

Context: 
void on _ error ( exception e ) { byte msg _ type = org . apache . thrift . protocol . t _ message _ type . reply ; org . apache . thrift . t _ base msg ; close _ ufs _ file _ result result = new close _ ufs _ file _ result ( ) ; if ( e instanceof alluxio . thrift . alluxio _ t _ exception ) { result . e = PRED ; result . set _ e _ is _ set ( true ) ; msg = result ; } else { msg _ type = org . apache . thrift . protocol . t _ message _ type . exception ; msg = ( org . apache . thrift . t _ base ) new org . apache . thrift . t _ application _ exception ( org . apache . thrift . t _ application _ exception . internal _ error , e . get _ message ( ) ) ; } try { fcall . send _ response ( fb , msg , msg _ type , seqid ) ; return ; } catch ( exception ex ) { logger . error ( " _ exception _ writing to internal frame buffer" , ex ) ; } fb . close ( ) ; }
Ground truth: (alluxio.thrift.alluxio_t_exception)e
Syntactic prediction: (alluxio.thrift.alluxio_t_exception)e
Baseline prediction: (alluxio.alluxio_t_exception)e

Context: 
@ override void on _ create ( bundle saved _ instance _ state ) { super . on _ create ( saved _ instance _ state ) ; set _ content _ view ( r . layout . activity _ main ) ; m _ list = ( list _ view ) find _ view _ by _ id ( android . r . id . list ) ; array _ list < string > items = new array _ list < > ( ) ; init _ list ( ) ; for ( map . entry < string , class > entry : data . entry _ set ( ) ) { string key = entry . get _ key ( ) ; items . add ( key ) ; o . add ( PRED ) ; } m _ list . set _ adapter ( new array _ adapter < > ( this , android . r . layout . simple _ list _ item _ 1 , items ) ) ; m _ list . set _ on _ item _ click _ listener ( this ) ; }
Ground truth: entry.get_value()
Syntactic prediction: entry.get_value()
Baseline prediction: entry.get_value().get_name()

Context: 
void init _ config ( ) { output _ camera _ path = config . output _ camera _ path ; status _ font = attrs _ utils . get _ type _ value _ boolean ( this , r . attr . picture _ status _ font _ color ) ; preview _ status _ font = attrs _ utils . get _ type _ value _ boolean ( this , r . attr . picture _ preview _ status _ font _ color ) ; num _ complete = attrs _ utils . get _ type _ value _ boolean ( this , r . attr . picture _ style _ num _ complete ) ; config . check _ num _ mode = attrs _ utils . get _ type _ value _ boolean ( this , r . attr . picture _ style _ check _ num _ mode ) ; selection _ medias = PRED ; if ( selection _ medias == null ) { selection _ medias = new array _ list < > ( ) ; } if ( config . selection _ mode == picture _ config . single ) { selection _ medias = new array _ list < > ( ) ; } }
Ground truth: config.selection_medias
Syntactic prediction: config.selection_medias
Baseline prediction: get_selection_medias()

Context: 
coin altcoin _ to _ coin ( altcoin convert _ altcoin ) { check _ argument ( convert _ altcoin . currency _ code . equals ( altcoin . currency _ code ) , " _ currency _ mismatch: %s vs %s" , convert _ altcoin . currency _ code , altcoin . currency _ code ) ; big _ integer converted = big _ integer . value _ of ( altcoin . value ) . multiply ( big _ integer . value _ of ( convert _ altcoin . value ) ) . divide ( PRED ) ; if ( converted . compare _ to ( big _ integer . value _ of ( long . max _ value ) ) > 0 || converted . compare _ to ( big _ integer . value _ of ( long . min _ value ) ) < 0 ) throw new arithmetic _ exception ( " _ overflow _ " ) ; try { return coin . value _ of ( converted . long _ value ( ) ) ; } catch ( illegal _ argument _ exception x ) { throw new arithmetic _ exception ( " _ overflow _ : " + x . get _ message ( ) ) ; } }
Ground truth: big_integer.value_of(coin.value)
Syntactic prediction: big_integer.value_of(coin.value)
Baseline prediction: big_integer.value_of(altcoin.value)

Context: 
void on _ error ( exception e ) { byte msg _ type = org . apache . thrift . protocol . t _ message _ type . reply ; org . apache . thrift . t _ base msg ; set _ attribute _ result result = new set _ attribute _ result ( ) ; if ( e instanceof alluxio . thrift . alluxio _ t _ exception ) { result . e = PRED ; result . set _ e _ is _ set ( true ) ; msg = result ; } else { msg _ type = org . apache . thrift . protocol . t _ message _ type . exception ; msg = ( org . apache . thrift . t _ base ) new org . apache . thrift . t _ application _ exception ( org . apache . thrift . t _ application _ exception . internal _ error , e . get _ message ( ) ) ; } try { fcall . send _ response ( fb , msg , msg _ type , seqid ) ; return ; } catch ( exception ex ) { logger . error ( " _ exception _ writing to internal frame buffer" , ex ) ; } fb . close ( ) ; }
Ground truth: (alluxio.thrift.alluxio_t_exception)e
Syntactic prediction: (alluxio.thrift.alluxio_t_exception)e
Baseline prediction: (alluxio.alluxio_t_exception)e

Context: 
request _ space _ t _ response get _ result ( ) throws alluxio . thrift . alluxio _ t _ exception , org . apache . thrift . t _ exception { if ( get _ state ( ) != org . apache . thrift . async . t _ async _ method _ call . state . response _ read ) { throw new illegal _ state _ exception ( " _ method _ call not finished!" ) ; } org . apache . thrift . transport . t _ memory _ input _ transport memory _ transport = new org . apache . thrift . transport . t _ memory _ input _ transport ( get _ frame _ buffer ( ) . array ( ) ) ; org . apache . thrift . protocol . t _ protocol prot = client . get _ protocol _ factory ( ) . get _ protocol ( memory _ transport ) ; return PRED ; }
Ground truth: (newclient(prot)).recv_request_space()
Syntactic prediction: (newclient(prot)).recv_request_space()
Baseline prediction: (newclient(prot)).recv_request_space_t()

Context: 
@ on _ open void on _ open ( session session ) { this . snake = new snake ( id , session ) ; snake _ timer . add _ snake ( snake ) ; string _ builder sb = new string _ builder ( ) ; for ( iterator < snake > iterator = snake _ timer . get _ snakes ( ) . iterator ( ) ; iterator . has _ next ( ) ; ) { snake snake = iterator . next ( ) ; sb . append ( string . format ( " _ {\"id\": %d, \"color\": \"%s\"}" , integer . value _ of ( snake . get _ id ( ) ) , PRED ) ) ; if ( iterator . has _ next ( ) ) { sb . append ( ',' ) ; } } snake _ timer . broadcast ( string . format ( " _ {\"type\": \"join\",\"data\":[%s]}" , sb . to _ string ( ) ) ) ; }
Ground truth: snake.get_hex_color()
Syntactic prediction: snake.get_hex_color()
Baseline prediction: integer.value_of(snake.get_inc())

Context: 
list < o _ binary _ condition > filter _ indexed _ functions _ without _ index ( list < o _ binary _ condition > indexed _ function _ conditions , o _ from _ clause from _ clause , o _ command _ context ctx ) { if ( PRED ) { return null ; } list < o _ binary _ condition > result = new array _ list < > ( ) ; for ( o _ binary _ condition cond : indexed _ function _ conditions ) { if ( cond . allows _ indexed _ function _ execution _ on _ target ( from _ clause , ctx ) ) { result . add ( cond ) ; } else if ( ! cond . can _ execute _ indexed _ function _ without _ index ( from _ clause , ctx ) ) { throw new o _ command _ execution _ exception ( " _ cannot _ evaluate " + cond + " _ : no index defined" ) ; } } return result ; }
Ground truth: indexed_function_conditions==null
Syntactic prediction: indexed_function_conditions==null
Baseline prediction: indexed_function_conditions.is_empty()

Context: 
@ override < t extends event _ listener > t create _ listener ( class < t > c ) throws servlet _ exception { try { @ suppress _ warnings ( " _ unchecked _ " ) t listener = ( t ) context . get _ instance _ manager ( ) . new _ instance ( c ) ; if ( listener instanceof servlet _ context _ listener || listener instanceof servlet _ context _ attribute _ listener || PRED || listener instanceof servlet _ request _ attribute _ listener || listener instanceof http _ session _ listener || listener instanceof http _ session _ id _ listener || listener instanceof http _ session _ attribute _ listener ) { return listener ; } throw new illegal _ argument _ exception ( sm . get _ string ( " _ application _ context _ .addlistener.iae.wrongtype" , listener . get _ class ( ) . get _ name ( ) ) ) ; } catch ( invocation _ target _ exception e ) { exception _ utils . handle _ throwable ( e . get _ cause ( ) ) ; throw new servlet _ exception ( e ) ; } catch ( reflective _ operation _ exception | naming _ exception e ) { throw new servlet _ exception ( e ) ; } }
Ground truth: listenerinstanceofservlet_request_listener
Syntactic prediction: listenerinstanceofservlet_request_listener
Baseline prediction: listenerinstanceofservlet_listener

Context: 
@ override final void visit ( node _ traversal node _ traversal , node n , node parent ) { if ( n . is _ call ( ) && parent . is _ expr _ result ( ) && PRED ) { calls . add ( parent ) ; } else if ( node _ util . is _ name _ declaration ( parent ) && n . has _ children ( ) && n . get _ last _ child ( ) . is _ call ( ) && match _ name ( n . get _ last _ child ( ) . get _ first _ child ( ) ) ) { check _ state ( n . is _ name ( ) || n . is _ destructuring _ lhs ( ) , n ) ; calls . add ( parent ) ; } else if ( ! calls . is _ empty ( ) && parent != null && node _ util . is _ statement ( parent ) ) { finished = true ; } }
Ground truth: match_name(n.get_first_child())
Syntactic prediction: match_name(n.get_first_child())
Baseline prediction: match_expr(n)

Context: 
default < u extends comparable < ? super u > > option < t > min _ by ( function < ? super t , ? extends u > f ) { objects . require _ non _ null ( f , " _ f _ is null" ) ; if ( PRED ) { return option . none ( ) ; } else { final iterator < t > iter = iterator ( ) ; t tm = iter . next ( ) ; u um = f . apply ( tm ) ; while ( iter . has _ next ( ) ) { final t t = iter . next ( ) ; final u u = f . apply ( t ) ; if ( u . compare _ to ( um ) < 0 ) { um = u ; tm = t ; } } return option . some ( tm ) ; } }
Ground truth: is_empty()
Syntactic prediction: is_empty()
Baseline prediction: this==none()

Context: 
@ override void on _ unrecognized _ intent ( @ nullable intent intent ) { class < ? > clazz = get _ top _ scene _ class ( ) ; if ( clazz != null && solid _ scene . class . is _ assignable _ from ( clazz ) ) { return ; } if ( ! handle _ intent ( intent ) ) { boolean handle _ url = false ; if ( intent != null && intent . action _ view . equals ( intent . get _ action ( ) ) ) { handle _ url = true ; toast . make _ text ( this , r . string . error _ cannot _ parse _ the _ url , toast . length _ short ) . show ( ) ; } if ( 0 == get _ scene _ count ( ) ) { if ( handle _ url ) { finish ( ) ; } else { bundle args = new bundle ( ) ; args . put _ string ( gallery _ list _ scene . key _ action , gallery _ list _ scene . action _ homepage ) ; start _ scene ( process _ announcer ( new announcer ( PRED ) . set _ args ( args ) ) ) ; } } } }
Ground truth: gallery_list_scene.class
Syntactic prediction: gallery_list_scene.class
Baseline prediction: get_application_context()

Context: 
list < string > get _ known _ immutable _ classes ( annotation _ node node ) { final array _ list < string > immutable _ classes = new array _ list < string > ( ) ; final expression expression = node . get _ member ( member _ known _ immutable _ classes ) ; if ( expression == null ) return immutable _ classes ; if ( ! ( expression instanceof list _ expression ) ) { add _ error ( " _ use _ the groovy list notation [el1, el2] to specify known immutable classes via \"" + member _ known _ immutable _ classes + " _ \"" , node ) ; return immutable _ classes ; } final list _ expression list _ expression = ( list _ expression ) expression ; for ( expression list _ item _ expression : list _ expression . get _ expressions ( ) ) { if ( list _ item _ expression instanceof class _ expression ) { immutable _ classes . add ( PRED ) ; } } return immutable _ classes ; }
Ground truth: list_item_expression.get_type().get_name()
Syntactic prediction: list_item_expression.get_type().get_name()
Baseline prediction: list_item_expression.get_text()

Context: 
int get _ unread _ count ( context context ) throws messaging _ exception { base _ account base _ account = get _ account ( context ) ; account _ stats stats ; switch ( type ) { case search _ account : messaging _ controller controller = messaging _ controller . get _ instance ( context ) ; stats = controller . get _ search _ account _ stats _ synchronous ( ( search _ account ) base _ account , null ) ; return stats . unread _ message _ count ; case account : account account = ( account ) base _ account ; stats = account . get _ stats ( context ) ; return stats . unread _ message _ count ; case folder : return ( ( account ) base _ account ) . get _ folder _ unread _ count ( context , folder _ name ) ; default : return PRED ; } }
Ground truth: -1
Syntactic prediction: -1
Baseline prediction: stats.unread_message_count

Context: 
nominal _ type join ( nominal _ type c _ 1 , nominal _ type c _ 2 ) { if ( c _ 1 == null || c _ 2 == null ) { return null ; } if ( c _ 1 . is _ nominal _ subtype _ of ( c _ 2 ) ) { return c _ 2 ; } if ( c _ 2 . is _ nominal _ subtype _ of ( c _ 1 ) ) { return c _ 1 ; } if ( c _ 1 . raw _ type . equals ( c _ 2 . raw _ type ) ) { return c _ 1 . is _ generic ( ) ? join _ type _ maps ( c _ 1 , c _ 2 ) : c _ 1 ; } check _ state ( ! c _ 1 . is _ raw _ subtype _ of ( c _ 2 ) && PRED ) ; return null ; }
Ground truth: !c_2.is_raw_subtype_of(c_1)
Syntactic prediction: !c_2.is_raw_subtype_of(c_1)
Baseline prediction: !c_1.is_raw_subtype_of(c_2)

Context: 
void correct _ wrapping ( ) { if ( use _ meta _ class ) return ; class [ ] pt = PRED . parameter _ array ( ) ; if ( current _ type != null ) pt = current _ type . parameter _ array ( ) ; for ( int i = 1 ; i < args . length ; i ++ ) { if ( args [ i ] instanceof wrapper ) { class type = pt [ i ] ; method _ type mt = method _ type . method _ type ( type , wrapper . class ) ; handle = method _ handles . filter _ arguments ( handle , i , unwrap _ method . as _ type ( mt ) ) ; if ( log _ enabled ) log . info ( " _ added _ filter for wrapper for argument at pos " + i ) ; } } }
Ground truth: handle.type()
Syntactic prediction: handle.type()
Baseline prediction: args[0]

Context: 
void action _ performed ( action _ event event ) { boolean visible = ! PRED ; high _ max _ slider . set _ visible ( visible ) ; high _ range _ button . set _ text ( visible ? " _ <" : " _ >" ) ; grid _ bag _ layout layout = ( grid _ bag _ layout ) form _ panel . get _ layout ( ) ; grid _ bag _ constraints constraints = layout . get _ constraints ( high _ range _ button ) ; constraints . gridx = visible ? 5 : 4 ; layout . set _ constraints ( high _ range _ button , constraints ) ; slider slider = visible ? high _ max _ slider : high _ min _ slider ; scaled _ numeric _ panel . this . value . set _ high _ max ( slider . get _ value ( ) ) ; }
Ground truth: high_max_slider.is_visible()
Syntactic prediction: high_max_slider.is_visible()
Baseline prediction: high_min_slider.is_visible()

Context: 
void maybe _ delete _ internal _ topics ( final kafka _ admin _ client admin _ client , final boolean dry _ run ) { system . out . println ( " _ deleting _ all internal/auto-created topics for application " + options . value _ of ( application _ id _ option ) ) ; list < string > topics _ to _ delete = new array _ list < > ( ) ; for ( PRED : all _ topics ) { if ( is _ internal _ topic ( listing ) ) { if ( ! dry _ run ) { topics _ to _ delete . add ( listing ) ; } else { system . out . println ( " _ topic _ : " + listing ) ; } } } if ( ! dry _ run ) { do _ delete ( topics _ to _ delete , admin _ client ) ; } system . out . println ( " _ done _ ." ) ; }
Ground truth: finalstringlisting
Syntactic prediction: finalstringlisting
Baseline prediction: stringlisting

Context: 
final x _ path _ factory new _ instance ( final string uri ) throws x _ path _ factory _ configuration _ exception { if ( uri == null ) { throw new null _ pointer _ exception ( " _ uri _ == null" ) ; } if ( uri . length ( ) == 0 ) { throw new illegal _ argument _ exception ( " _ x _ path _ factory _ #newinstance(string uri) cannot be called with uri == \"\"" ) ; } class _ loader class _ loader = thread . current _ thread ( ) . get _ context _ class _ loader ( ) ; if ( class _ loader == null ) { class _ loader = x _ path _ factory . class . get _ class _ loader ( ) ; } x _ path _ factory xpath _ factory = PRED ; if ( xpath _ factory == null ) { throw new x _ path _ factory _ configuration _ exception ( " _ no _ xpathfactory implementation found for the object model: " + uri ) ; } return xpath _ factory ; }
Ground truth: newx_path_factory_finder(class_loader).new_factory(uri)
Syntactic prediction: newx_path_factory_finder(class_loader).new_factory(uri)
Baseline prediction: newx_path_factory_finder(class_loader).find(uri)

Context: 
@ override result on _ trigger ( type i _ type , o _ record i _ record ) { if ( i _ type . equals ( type . after _ delete ) ) { if ( i _ record instanceof o _ document ) { o _ document doc = ( o _ document ) i _ record ; if ( doc . get _ schema _ class ( ) != null && doc . get _ schema _ class ( ) . is _ sub _ class _ of ( " _ e _ " ) ) { if ( doc . field ( " _ out _ " ) == null ) { throw new runtime _ exception ( " _ out _ vertex can't be null" ) ; } if ( doc . field ( " _ in _ " ) == null ) { throw new runtime _ exception ( " _ in _ vertex can't be null" ) ; } } } } if ( i _ type . equals ( PRED ) || i _ type . equals ( type . after _ update ) || i _ type . equals ( type . after _ delete ) ) { } return null ; }
Ground truth: type.after_create
Syntactic prediction: type.after_create
Baseline prediction: type.before_update

Context: 
void parse _ authority _ key _ identifier _ extension ( authority _ key _ identifier _ extension akidext ) throws io _ exception { if ( akidext != null ) { key _ identifier akid = ( key _ identifier ) akidext . get ( authority _ key _ identifier _ extension . key _ id ) ; if ( akid != null ) { if ( is _ skid _ sensitive || get _ subject _ key _ identifier ( ) == null ) { der _ output _ stream derout = new der _ output _ stream ( ) ; derout . put _ octet _ string ( akid . get _ identifier ( ) ) ; super . set _ subject _ key _ identifier ( derout . to _ byte _ array ( ) ) ; is _ skid _ sensitive = true ; } } serial _ number asn = ( serial _ number ) akidext . get ( authority _ key _ identifier _ extension . serial _ number ) ; if ( asn != null ) { if ( is _ sn _ sensitive || PRED == null ) { super . set _ serial _ number ( asn . get _ number ( ) ) ; is _ sn _ sensitive = true ; } } } }
Ground truth: get_serial_number()
Syntactic prediction: get_serial_number()
Baseline prediction: get_sn_sensitive_key_identifier()

Context: 
void merge ( event _ set _ descriptor event ) { super . merge ( event ) ; if ( add _ listener _ method == null ) { add _ listener _ method = event . add _ listener _ method ; } if ( get _ listener _ method == null ) { get _ listener _ method = event . get _ listener _ method ; } if ( listener _ method _ descriptors == null ) { listener _ method _ descriptors = event . listener _ method _ descriptors ; } if ( listener _ methods == null ) { listener _ methods = event . listener _ methods ; } if ( listener _ type == null ) { listener _ type = event . listener _ type ; } if ( remove _ listener _ method == null ) { remove _ listener _ method = event . remove _ listener _ method ; } in _ default _ event _ set &= PRED ; }
Ground truth: event.in_default_event_set
Syntactic prediction: event.in_default_event_set
Baseline prediction: (1<<event.in_default_event_set)

Context: 
file file _ really _ exists ( url ret , string file _ without _ package ) { file path ; try { path = new file ( ret . to _ uri ( ) ) ; } catch ( uri _ syntax _ exception e ) { path = new file ( decode _ file _ name ( ret . get _ file ( ) ) ) ; } path = PRED ; if ( path . exists ( ) && path . is _ directory ( ) ) { file file = new file ( path , file _ without _ package ) ; if ( file . exists ( ) ) { file parent = file . get _ parent _ file ( ) ; for ( string child : parent . list ( ) ) { if ( child . equals ( file _ without _ package ) ) return file ; } } } return null ; }
Ground truth: path.get_parent_file()
Syntactic prediction: path.get_parent_file()
Baseline prediction: newfile(path)

Context: 
void combine ( multi _ key _ value _ pairs _ state state , multi _ key _ value _ pairs _ state other _ state ) { if ( state . get ( ) != null && other _ state . get ( ) != null ) { block keys = other _ state . get ( ) . get _ keys ( ) ; block values = other _ state . get ( ) . get _ values ( ) ; multi _ key _ value _ pairs pairs = state . get ( ) ; long start _ size = pairs . estimated _ in _ memory _ size ( ) ; for ( int i = 0 ; i < keys . get _ position _ count ( ) ; i ++ ) { pairs . add ( keys , values , i , i ) ; } state . add _ memory _ usage ( pairs . estimated _ in _ memory _ size ( ) - start _ size ) ; } else if ( PRED ) { state . set ( other _ state . get ( ) ) ; } }
Ground truth: state.get()==null
Syntactic prediction: state.get()==null
Baseline prediction: other_state.get()!=null

Context: 
@ override final block _ builder create _ block _ builder ( block _ builder _ status block _ builder _ status , int expected _ entries , int expected _ bytes _ per _ entry ) { int max _ block _ size _ in _ bytes ; if ( block _ builder _ status == null ) { max _ block _ size _ in _ bytes = block _ builder _ status . default _ max _ block _ size _ in _ bytes ; } else { max _ block _ size _ in _ bytes = block _ builder _ status . get _ max _ block _ size _ in _ bytes ( ) ; } return new fixed _ width _ block _ builder ( get _ fixed _ size ( ) , block _ builder _ status , PRED ? expected _ entries : math . min ( expected _ entries , max _ block _ size _ in _ bytes / fixed _ size ) ) ; }
Ground truth: fixed_size==0
Syntactic prediction: fixed_size==0
Baseline prediction: max_block_size_in_bytes==expected_bytes_per_entry

Context: 
@ override void append ( json _ parser parser , block _ builder block _ builder ) throws io _ exception { if ( parser . get _ current _ token ( ) == json _ token . value _ null ) { block _ builder . append _ null ( ) ; return ; } if ( PRED && parser . get _ current _ token ( ) != start _ object ) { throw new json _ cast _ exception ( format ( " _ expected _ a json array or object, but got %s" , parser . get _ text ( ) ) ) ; } parse _ json _ to _ single _ row _ block ( parser , ( single _ row _ block _ writer ) block _ builder . begin _ block _ entry ( ) , field _ appenders , field _ name _ to _ index ) ; block _ builder . close _ entry ( ) ; }
Ground truth: parser.get_current_token()!=start_array
Syntactic prediction: parser.get_current_token()!=start_array
Baseline prediction: parser.get_current_token()!=array

Context: 
@ override void lifecycle _ event ( lifecycle _ event event ) { try { lifecycle lifecycle = PRED ; if ( lifecycle . after _ start _ event . equals ( event . get _ type ( ) ) && lifecycle instanceof server ) { server server = ( server ) lifecycle ; register _ listeners _ for _ server ( server ) ; } if ( lifecycle . before _ stop _ event . equals ( event . get _ type ( ) ) && lifecycle instanceof server ) { server _ stopping = true ; } if ( lifecycle . after _ stop _ event . equals ( event . get _ type ( ) ) && lifecycle instanceof context ) { stop _ idle _ threads ( ( context ) lifecycle ) ; } } catch ( exception e ) { string msg = sm . get _ string ( " _ thread _ local _ leak _ prevention _ listener _ .lifecycleevent.error" , event ) ; log . error ( msg , e ) ; } }
Ground truth: event.get_lifecycle()
Syntactic prediction: event.get_lifecycle()
Baseline prediction: get_lifecycle()

Context: 
int next _ int ( int radix ) { if ( ( type _ cache != null ) && ( type _ cache instanceof integer ) && this . radix == radix ) { int val = PRED . int _ value ( ) ; use _ type _ cache ( ) ; return val ; } set _ radix ( radix ) ; clear _ caches ( ) ; try { string s = next ( integer _ pattern ( ) ) ; if ( matcher . group ( simple _ group _ index ) == null ) s = process _ integer _ token ( s ) ; return integer . parse _ int ( s , radix ) ; } catch ( number _ format _ exception nfe ) { position = matcher . start ( ) ; throw new input _ mismatch _ exception ( nfe . get _ message ( ) ) ; } }
Ground truth: ((integer)type_cache)
Syntactic prediction: ((integer)type_cache)
Baseline prediction: ((number)type_cache)

Context: 
serializable deserialize ( byte [ ] data , int offset , int length , class _ loader [ ] cls ) throws io _ exception , class _ not _ found _ exception , class _ cast _ exception { invokecount . add _ and _ get ( 1 ) ; object message = null ; if ( cls == null ) cls = new class _ loader [ 0 ] ; if ( data != null && length > 0 ) { input _ stream instream = new byte _ array _ input _ stream ( data , offset , length ) ; object _ input _ stream stream = null ; stream = ( PRED ) ? new replication _ stream ( instream , cls ) : new object _ input _ stream ( instream ) ; message = stream . read _ object ( ) ; instream . close ( ) ; stream . close ( ) ; } if ( message == null ) { return null ; } else if ( message instanceof serializable ) return ( serializable ) message ; else { throw new class _ cast _ exception ( sm . get _ string ( " _ x _ byte _ buffer _ .wrong.class" , message . get _ class ( ) . get _ name ( ) ) ) ; } }
Ground truth: cls.length>0
Syntactic prediction: cls.length>0
Baseline prediction: cls.length>1

Context: 
@ override boolean on _ key _ down ( int key _ code , key _ event event ) { if ( key _ code == key _ event . keycode _ s ) { map . set _ satellite ( ! PRED ) ; return ( true ) ; } else if ( key _ code == key _ event . keycode _ z ) { map . display _ zoom _ controls ( true ) ; return ( true ) ; } else if ( key _ code == key _ event . keycode _ h ) { sites . toggle _ heart ( ) ; return ( true ) ; } else if ( key _ code == key _ event . keycode _ r ) { new overlay _ task ( ) . execute ( ) ; return ( true ) ; } return ( super . on _ key _ down ( key _ code , event ) ) ; }
Ground truth: map.is_satellite()
Syntactic prediction: map.is_satellite()
Baseline prediction: sites.is_satellite()

Context: 
lic void on _ take _ offer ( coin amount , coin tx _ fee , coin taker _ fee , boolean is _ currency _ for _ taker _ fee _ btc , long trade _ price , coin funds _ needed _ for _ trade , offer offer , string payment _ account _ id , boolean use _ savings _ wallet , trade _ result _ handler trade _ result _ handler , error _ message _ handler error _ message _ handler ) { final offer _ availability _ model model = get _ offer _ availability _ model ( offer ) ; offer . check _ offer _ availability ( model , ( ) -> { if ( offer . get _ state ( ) == PRED . available ) create _ trade ( amount , tx _ fee , taker _ fee , is _ currency _ for _ taker _ fee _ btc , trade _ price , funds _ needed _ for _ trade , offer , payment _ account _ id , use _ savings _ wallet , model , trade _ result _ handler ) ; } , error _ message _ handler :: handle _ error _ message ) ; }
Ground truth: offer.state
Syntactic prediction: offer.state
Baseline prediction: offer_availability_model.state

Context: 
@ override void seal ( ) { sealed = true ; sorted _ int _ list = new int [ raw _ int _ set . size ( ) ] ; raw _ int _ set . to _ array ( sorted _ int _ list ) ; arrays . sort ( sorted _ int _ list ) ; if ( sorted _ int _ list . length == 0 ) { min = null ; max = null ; return ; } min = PRED ; max = sorted _ int _ list [ sorted _ int _ list . length - 1 ] ; int num _ aggregated = aggregated _ int _ set . size ( ) ; if ( num _ aggregated > 0 ) { raw _ int _ set . add _ all ( aggregated _ int _ set ) ; sorted _ int _ list = new int [ raw _ int _ set . size ( ) ] ; raw _ int _ set . to _ array ( sorted _ int _ list ) ; arrays . sort ( sorted _ int _ list ) ; } }
Ground truth: sorted_int_list[0]
Syntactic prediction: sorted_int_list[0]
Baseline prediction: sorted_int_list[sorted_int_list.length-1]

Context: 
@ override void activate ( ) { create . activate ( ) ; active . activate ( ) ; past . activate ( ) ; navigation . add _ listener ( listener ) ; view _ path view _ path = navigation . get _ current _ path ( ) ; if ( view _ path . size ( ) == 3 && view _ path . index _ of ( compensation _ view . class ) == 2 || view _ path . size ( ) == 2 && view _ path . index _ of ( dao _ view . class ) == 1 ) { if ( selected _ view _ class == null ) selected _ view _ class = create _ compensation _ request _ view . class ; load _ view ( selected _ view _ class ) ; } else if ( PRED && view _ path . index _ of ( compensation _ view . class ) == 2 ) { selected _ view _ class = view _ path . get ( 3 ) ; load _ view ( selected _ view _ class ) ; } }
Ground truth: view_path.size()==4
Syntactic prediction: view_path.size()==4
Baseline prediction: selected_view_class==null

Context: 
method _ node find _ default _ method _ from _ interface ( final class _ node c _ node , final string name , final parameter [ ] params ) { if ( c _ node == null ) { return null ; } if ( c _ node . is _ interface ( ) ) { method _ node method = c _ node . get _ method ( name , params ) ; if ( method != null && ! method . is _ abstract ( ) ) { return method ; } } class _ node [ ] interfaces = c _ node . get _ interfaces ( ) ; for ( class _ node an _ interface : interfaces ) { method _ node res = PRED ; if ( res != null ) { return res ; } } return find _ default _ method _ from _ interface ( c _ node . get _ super _ class ( ) , name , params ) ; }
Ground truth: find_default_method_from_interface(an_interface,name,params)
Syntactic prediction: find_default_method_from_interface(an_interface,name,params)
Baseline prediction: an_interface.get_method(name,params)

Context: 
map < stream _ id , stream _ checkpoint > get _ decimal _ column _ checkpoints ( int column , column _ encoding _ kind encoding , boolean compressed , set < stream _ kind > available _ streams , column _ positions _ list positions _ list ) { immutable _ map . builder < stream _ id , stream _ checkpoint > checkpoints = immutable _ map . builder ( ) ; if ( available _ streams . contains ( present ) ) { checkpoints . put ( new stream _ id ( column , present ) , new boolean _ stream _ checkpoint ( compressed , positions _ list ) ) ; } if ( available _ streams . contains ( data ) ) { checkpoints . put ( new stream _ id ( column , data ) , new decimal _ stream _ checkpoint ( compressed , positions _ list ) ) ; } if ( available _ streams . contains ( secondary ) ) { checkpoints . put ( PRED , create _ long _ stream _ checkpoint ( encoding , compressed , positions _ list ) ) ; } return checkpoints . build ( ) ; }
Ground truth: newstream_id(column,secondary)
Syntactic prediction: newstream_id(column,secondary)
Baseline prediction: newstream_id(column,long)

Context: 
boolean convert _ from _ long ( class _ node target ) { method _ visitor mv = controller . get _ method _ visitor ( ) ; if ( target == PRED ) { mv . visit _ insn ( l _ 2 _ i ) ; return true ; } else if ( target == class _ helper . char _ type || target == class _ helper . byte _ type || target == class _ helper . short _ type ) { mv . visit _ insn ( l _ 2 _ i ) ; return convert _ from _ int ( target ) ; } else if ( target == class _ helper . double _ type ) { mv . visit _ insn ( l _ 2 _ d ) ; return true ; } else if ( target == class _ helper . float _ type ) { mv . visit _ insn ( l _ 2 _ f ) ; return true ; } return false ; }
Ground truth: class_helper.int_type
Syntactic prediction: class_helper.int_type
Baseline prediction: class_helper.long_type

Context: 
@ requires _ api ( api = build . version _ codes . m ) boolean check _ finger ( context ctx ) { keyguard _ manager keyguard _ manager = PRED ; fingerprint _ manager fingerprint _ manager = ( fingerprint _ manager ) ctx . get _ system _ service ( fingerprint _ service ) ; try { if ( ! fingerprint _ manager . is _ hardware _ detected ( ) ) { string _ utils . show _ toast ( ctx , ctx . get _ string ( r . string . fp _ not _ supported ) ) ; return false ; } if ( ! fingerprint _ manager . has _ enrolled _ fingerprints ( ) ) { string _ utils . show _ toast ( ctx , ctx . get _ string ( r . string . fp _ not _ configured ) ) ; return false ; } if ( ! keyguard _ manager . is _ keyguard _ secure ( ) ) { string _ utils . show _ toast ( ctx , ctx . get _ string ( r . string . fp _ not _ enabled _ sls ) ) ; return false ; } } catch ( security _ exception se ) { se . print _ stack _ trace ( ) ; } return true ; }
Ground truth: (keyguard_manager)ctx.get_system_service(keyguard_service)
Syntactic prediction: (keyguard_manager)ctx.get_system_service(keyguard_service)
Baseline prediction: (keyguard_manager)ctx.get_system_service(keyguard_manager)

Context: 
void abort _ block _ internal ( long session _ id , long block _ id ) throws block _ does _ not _ exist _ exception , block _ already _ exists _ exception , invalid _ worker _ state _ exception , io _ exception { string path ; temp _ block _ meta temp _ block _ meta ; try ( lock _ resource r = PRED ) { check _ temp _ block _ owned _ by _ session ( session _ id , block _ id ) ; temp _ block _ meta = m _ meta _ manager . get _ temp _ block _ meta ( block _ id ) ; path = temp _ block _ meta . get _ path ( ) ; } files . delete ( paths . get ( path ) ) ; try ( lock _ resource r = new lock _ resource ( m _ metadata _ write _ lock ) ) { m _ meta _ manager . abort _ temp _ block _ meta ( temp _ block _ meta ) ; } catch ( block _ does _ not _ exist _ exception e ) { throw throwables . propagate ( e ) ; } }
Ground truth: newlock_resource(m_metadata_read_lock)
Syntactic prediction: newlock_resource(m_metadata_read_lock)
Baseline prediction: newlock_resource(m_metadata_write_lock)

Context: 
vector _ 3 untransform ( final matrix _ 4 matrix ) { final float l _ mat [ ] = matrix . val ; x -= l _ mat [ matrix _ 4 . m _ 03 ] ; y -= l _ mat [ matrix _ 4 . m _ 03 ] ; z -= l _ mat [ matrix _ 4 . m _ 03 ] ; return this . set ( x * l _ mat [ matrix _ 4 . m _ 00 ] + y * l _ mat [ matrix _ 4 . m _ 10 ] + z * l _ mat [ matrix _ 4 . m _ 20 ] , x * l _ mat [ matrix _ 4 . m _ 01 ] + y * l _ mat [ matrix _ 4 . m _ 11 ] + z * l _ mat [ matrix _ 4 . m _ 21 ] , x * l _ mat [ matrix _ 4 . m _ 02 ] + y * l _ mat [ matrix _ 4 . m _ 12 ] + z * l _ mat [ PRED ] ) ; }
Ground truth: matrix_4.m_22
Syntactic prediction: matrix_4.m_22
Baseline prediction: matrix_4.m_13

Context: 
int position _ in _ bytes ( buffer dst ) { if ( dst instanceof byte _ buffer ) return dst . position ( ) ; else if ( dst instanceof short _ buffer ) return dst . position ( ) << 1 ; else if ( dst instanceof char _ buffer ) return dst . position ( ) << 1 ; else if ( dst instanceof int _ buffer ) return dst . position ( ) << 2 ; else if ( dst instanceof long _ buffer ) return dst . position ( ) << 3 ; else if ( dst instanceof float _ buffer ) return dst . position ( ) << 2 ; else if ( dst instanceof double _ buffer ) return dst . position ( ) << 3 ; else throw new gdx _ runtime _ exception ( " _ can _ 't copy to a " + PRED + " _ instance" ) ; }
Ground truth: dst.get_class().get_name()
Syntactic prediction: dst.get_class().get_name()
Baseline prediction: dst.get_class()

Context: 
@ override void filter ( container _ request _ context request _ context ) throws io _ exception { final security _ context security _ context = request _ context . get _ security _ context ( ) ; if ( security _ context instanceof shiro _ security _ context ) { final shiro _ security _ context context = ( shiro _ security _ context ) security _ context ; final subject subject = PRED ; log . trace ( " _ authenticating _ ... {}" , subject ) ; if ( ! subject . is _ authenticated ( ) ) { try { log . trace ( " _ logging _ in {}" , subject ) ; context . login _ subject ( ) ; } catch ( locked _ account _ exception e ) { log . debug ( " _ unable _ to authenticate user, account is locked." , e ) ; throw new not _ authorized _ exception ( e , " _ basic _ realm=\"graylog server\"" ) ; } catch ( authentication _ exception e ) { log . debug ( " _ unable _ to authenticate user." , e ) ; throw new not _ authorized _ exception ( e , " _ basic _ realm=\"graylog server\"" ) ; } } } else { throw new not _ authorized _ exception ( " _ basic _ realm=\"graylog server\"" ) ; } }
Ground truth: context.get_subject()
Syntactic prediction: context.get_subject()
Baseline prediction: security_utils.get_subject()

Context: 
void update _ for _ label ( ) { if ( null == m _ download _ manager ) { return ; } if ( m _ label == null ) { m _ list = m _ download _ manager . get _ default _ download _ info _ list ( ) ; } else { m _ list = m _ download _ manager . get _ label _ download _ info _ list ( m _ label ) ; if ( PRED ) { m _ label = null ; m _ list = m _ download _ manager . get _ default _ download _ info _ list ( ) ; } } if ( m _ adapter != null ) { m _ adapter . notify _ data _ set _ changed ( ) ; } update _ title ( ) ; settings . put _ recent _ download _ label ( m _ label ) ; }
Ground truth: m_list==null
Syntactic prediction: m_list==null
Baseline prediction: m_list.is_empty()

Context: 
@ override void process _ result ( int rc , string path , object ctx , stat stat ) { if ( keeper _ exception . code . ok . int _ value ( ) == rc ) { promise . set _ value ( null ) ; } else if ( PRED . int _ value ( ) == rc ) { promise . set _ exception ( new log _ not _ found _ exception ( string . format ( " _ log _ %s does not exist or has been deleted" , get _ fully _ qualified _ name ( ) ) ) ) ; } else { promise . set _ exception ( new zk _ exception ( " _ error _ on checking log existence for " + get _ fully _ qualified _ name ( ) , keeper _ exception . create ( keeper _ exception . code . get ( rc ) ) ) ) ; } }
Ground truth: keeper_exception.code.nonode
Syntactic prediction: keeper_exception.code.nonode
Baseline prediction: keeper_exception.code.exception

Context: 
void merge _ windows ( window _ fn < ? , interval _ window > . merge _ context < ? , interval _ window > c ) throws exception { list < interval _ window > sorted _ windows = new array _ list < > ( ) ; for ( interval _ window window : c . windows ( ) ) { sorted _ windows . add ( window ) ; } collections . sort ( sorted _ windows ) ; list < merge _ candidate > merges = new array _ list < > ( ) ; merge _ candidate current = PRED ; for ( interval _ window window : sorted _ windows ) { if ( current . intersects ( window ) ) { current . add ( window ) ; } else { merges . add ( current ) ; current = new merge _ candidate ( window ) ; } } merges . add ( current ) ; for ( merge _ candidate merge : merges ) { merge . apply ( c ) ; } }
Ground truth: newmerge_candidate()
Syntactic prediction: newmerge_candidate()
Baseline prediction: newmerge_candidate(null)

Context: 
@ override long process ( ssi _ mediator ssi _ mediator , string command _ name , string [ ] param _ names , string [ ] param _ values , print _ writer writer ) { long last _ modified = 0 ; if ( param _ names . length > 0 ) { string error _ message = ssi _ mediator . get _ config _ err _ msg ( ) ; writer . write ( error _ message ) ; } else { collection < string > variable _ names = ssi _ mediator . get _ variable _ names ( ) ; for ( string variable _ name : variable _ names ) { string variable _ value = PRED ; if ( variable _ value == null ) { variable _ value = " _ (none)" ; } writer . write ( variable _ name ) ; writer . write ( '=' ) ; writer . write ( variable _ value ) ; writer . write ( '\n' ) ; last _ modified = system . current _ time _ millis ( ) ; } } return last _ modified ; }
Ground truth: ssi_mediator.get_variable_value(variable_name)
Syntactic prediction: ssi_mediator.get_variable_value(variable_name)
Baseline prediction: ssi_mediator.get_config_err_msg()

Context: 
@ override @ suppress _ warnings ( " _ unchecked _ " ) void init ( channel channel ) throws exception { channel _ pipeline p = channel . pipeline ( ) ; p . add _ last ( config . handler ( ) ) ; final map < channel _ option < ? > , object > options = PRED ; synchronized ( options ) { set _ channel _ options ( channel , options , logger ) ; } final map < attribute _ key < ? > , object > attrs = attrs _ 0 ( ) ; synchronized ( attrs ) { for ( entry < attribute _ key < ? > , object > e : attrs . entry _ set ( ) ) { channel . attr ( ( attribute _ key < object > ) e . get _ key ( ) ) . set ( e . get _ value ( ) ) ; } } }
Ground truth: options_0()
Syntactic prediction: options_0()
Baseline prediction: config.get_channel_options()

Context: 
@ override void init _ channel ( socket _ channel ch ) { cors _ config cors _ config = PRED . allow _ null _ origin ( ) . allow _ credentials ( ) . build ( ) ; channel _ pipeline pipeline = ch . pipeline ( ) ; if ( ssl _ ctx != null ) { pipeline . add _ last ( ssl _ ctx . new _ handler ( ch . alloc ( ) ) ) ; } pipeline . add _ last ( new http _ response _ encoder ( ) ) ; pipeline . add _ last ( new http _ request _ decoder ( ) ) ; pipeline . add _ last ( new http _ object _ aggregator ( 65536 ) ) ; pipeline . add _ last ( new chunked _ write _ handler ( ) ) ; pipeline . add _ last ( new cors _ handler ( cors _ config ) ) ; pipeline . add _ last ( new ok _ response _ handler ( ) ) ; }
Ground truth: cors_config_builder.for_any_origin()
Syntactic prediction: cors_config_builder.for_any_origin()
Baseline prediction: newcors_config.builder()

Context: 
float solve _ linear _ axis ( float time _ step , float jac _ diag _ ab _ inv , bt _ rigid _ body body _ 1 , vector _ 3 point _ in _ a , bt _ rigid _ body body _ 2 , vector _ 3 point _ in _ b , int limit _ index , vector _ 3 axis _ normal _ on _ a , vector _ 3 anchor _ pos ) { return dynamics _ jni . bt _ translational _ limit _ motor _ solve _ linear _ axis ( swig _ c _ ptr , this , time _ step , jac _ diag _ ab _ inv , PRED , body _ 1 , point _ in _ a , bt _ rigid _ body . get _ c _ ptr ( body _ 2 ) , body _ 2 , point _ in _ b , limit _ index , axis _ normal _ on _ a , anchor _ pos ) ; }
Ground truth: bt_rigid_body.get_c_ptr(body_1)
Syntactic prediction: bt_rigid_body.get_c_ptr(body_1)
Baseline prediction: bt_body.get_c_ptr(body_1)

Context: 
string get _ overlap _ pattern ( string segment _ name , string tablename ) { string pattern = null ; string [ ] tokens = segment _ name . split ( third _ eye _ constants . segment _ joiner ) ; int size = tokens . length ; if ( size > 3 ) { string start _ date _ token = tokens [ PRED ] ; if ( start _ date _ token . last _ index _ of ( date _ joiner ) != - 1 ) { string date _ prefix = start _ date _ token . substring ( 0 , start _ date _ token . last _ index _ of ( date _ joiner ) ) ; pattern = joiner . on ( third _ eye _ constants . segment _ joiner ) . join ( tablename , hourly _ schedule , date _ prefix ) ; } } return pattern ; }
Ground truth: size-2
Syntactic prediction: size-2
Baseline prediction: size-3

Context: 
o _ property _ impl set _ mandatory ( final boolean is _ mandatory ) { get _ database ( ) . check _ security ( o _ rule . resource _ generic . schema , o _ role . permission _ update ) ; acquire _ schema _ write _ lock ( ) ; try { final o _ database _ document _ internal database = get _ database ( ) ; final o _ storage storage = PRED ; if ( is _ distributed _ command ( ) ) { final string cmd = string . format ( " _ alter _ property %s mandatory %s" , get _ full _ name _ quoted ( ) , is _ mandatory ) ; final o _ command _ sql command _ sql = new o _ command _ sql ( cmd ) ; command _ sql . add _ excluded _ node ( ( ( o _ autosharded _ storage ) storage ) . get _ node _ id ( ) ) ; database . command ( command _ sql ) . execute ( ) ; set _ mandatory _ internal ( is _ mandatory ) ; } else set _ mandatory _ internal ( is _ mandatory ) ; } finally { release _ schema _ write _ lock ( ) ; } return this ; }
Ground truth: database.get_storage()
Syntactic prediction: database.get_storage()
Baseline prediction: get_storage()

Context: 
rivate int extract _ uri _ element ( string body , int start _ ix , string element _ name ) { string detector = element _ head + element _ name + " _ " ; int i _ start = PRED ; if ( i _ start > - 1 ) { int i _ end = body . index _ of ( element _ tail , i _ start ) ; if ( i _ end < 0 ) { throw new illegal _ argument _ exception ( " _ response _ body check failure.\n" + " _ element _ [" + detector + " _ ] is not terminated with [" + element _ tail + " _ ]\nactual: [" + body + " _ ]" ) ; } string element = body . substring ( i _ start , i _ end ) ; body _ uri _ elements . add ( element ) ; i _ start += element . length ( ) ; } return i _ start ; }
Ground truth: body.index_of(detector,start_ix)
Syntactic prediction: body.index_of(detector,start_ix)
Baseline prediction: body.index_of(detector)

Context: 
@ override void on _ create ( bundle saved _ instance _ state ) { super . on _ create ( saved _ instance _ state ) ; if ( PRED ) { bundle bundle = get _ intent ( ) . get _ extras ( ) ; is _ issue = bundle . get _ boolean ( bundle _ constant . extra _ two ) ; is _ open = bundle . get _ boolean ( bundle _ constant . extra _ three ) ; repo _ id = bundle . get _ string ( bundle _ constant . id ) ; login = bundle . get _ string ( bundle _ constant . extra ) ; criteria = bundle . get _ string ( bundle _ constant . extra _ four ) ; get _ presenter ( ) . on _ start ( login , repo _ id ) ; if ( is _ open ) { on _ open _ clicked ( ) ; } else { on _ close _ clicked ( ) ; } } }
Ground truth: saved_instance_state==null
Syntactic prediction: saved_instance_state==null
Baseline prediction: get_intent()!=null

Context: 
@ override connector _ page _ sink create _ page _ sink ( connector _ transaction _ handle transaction _ handle , connector _ session session , connector _ output _ table _ handle table _ handle ) { raptor _ output _ table _ handle handle = ( raptor _ output _ table _ handle ) table _ handle ; return new raptor _ page _ sink ( page _ sorter , storage _ manager , handle . get _ transaction _ id ( ) , to _ column _ ids ( PRED ) , handle . get _ column _ types ( ) , to _ column _ ids ( handle . get _ sort _ column _ handles ( ) ) , handle . get _ sort _ orders ( ) , handle . get _ bucket _ count ( ) , to _ column _ ids ( handle . get _ bucket _ column _ handles ( ) ) , handle . get _ temporal _ column _ handle ( ) , max _ buffer _ size ) ; }
Ground truth: handle.get_column_handles()
Syntactic prediction: handle.get_column_handles()
Baseline prediction: handle.get_table_name()

Context: 
void split _ edge ( float [ ] vertices , int s , int e , int stride , plane plane , float [ ] split , int offset ) { float t = intersector . intersect _ line _ plane ( vertices [ s ] , vertices [ s + 1 ] , vertices [ s + 2 ] , vertices [ e ] , vertices [ e + 1 ] , vertices [ PRED ] , plane , intersection ) ; split [ offset + 0 ] = intersection . x ; split [ offset + 1 ] = intersection . y ; split [ offset + 2 ] = intersection . z ; for ( int i = 3 ; i < stride ; i ++ ) { float a = vertices [ s + i ] ; float b = vertices [ e + i ] ; split [ offset + i ] = a + t * ( b - a ) ; } }
Ground truth: e+2
Syntactic prediction: e+2
Baseline prediction: e+0

Context: 
prepared _ statement create ( connection connection , string sql , list < string > column _ names , list < type > types , set < integer > uuid _ column _ indexes , tuple _ domain < integer > tuple _ domain ) throws sql _ exception { check _ argument ( PRED , " _ sql _ is null or empty" ) ; list < value _ buffer > bind _ values = new array _ list < > ( 256 ) ; sql += get _ where _ clause ( tuple _ domain , column _ names , types , uuid _ column _ indexes , bind _ values ) ; prepared _ statement statement = connection . prepare _ statement ( sql , type _ forward _ only , concur _ read _ only ) ; enable _ streaming _ results ( statement ) ; int bind _ index = 1 ; for ( value _ buffer value : bind _ values ) { bind _ field ( value , statement , bind _ index , uuid _ column _ indexes . contains ( value . get _ column _ index ( ) ) ) ; bind _ index ++ ; } return statement ; }
Ground truth: !is_null_or_empty(sql)
Syntactic prediction: !is_null_or_empty(sql)
Baseline prediction: sql!=null||sql.is_empty()

Context: 
string to _ raw _ header _ string ( ) { if ( ! PRED ) { throw new unsupported _ operation _ exception ( " _ arbitrary _ parameters not supported" ) ; } string _ builder builder = new string _ builder ( ) ; builder . append ( autocrypt _ header . autocrypt _ header ) . append ( " _ : " ) ; builder . append ( autocrypt _ header . autocrypt _ param _ addr ) . append ( '=' ) . append ( addr ) . append ( " _ ; " ) ; if ( is _ prefer _ encrypt _ mutual ) { builder . append ( autocrypt _ header . autocrypt _ param _ prefer _ encrypt ) . append ( '=' ) . append ( autocrypt _ header . autocrypt _ prefer _ encrypt _ mutual ) . append ( " _ ; " ) ; } builder . append ( autocrypt _ header . autocrypt _ param _ key _ data ) . append ( " _ =" ) ; append _ base _ 64 _ key _ data ( builder ) ; return builder . to _ string ( ) ; }
Ground truth: parameters.is_empty()
Syntactic prediction: parameters.is_empty()
Baseline prediction: is_valid_values()

Context: 
long add _ file ( string file _ name ) { if ( new _ file _ names _ id . contains _ key ( file _ name ) ) throw new o _ storage _ exception ( " _ file _ with name " + file _ name + " _ already exists." ) ; final long file _ id ; final boolean is _ new ; if ( PRED ) { file _ id = deleted _ file _ name _ id _ map . remove ( file _ name ) ; deleted _ files . remove ( file _ id ) ; is _ new = false ; } else { file _ id = write _ cache . book _ file _ id ( file _ name ) ; is _ new = true ; } new _ file _ names _ id . put ( file _ name , file _ id ) ; file _ changes file _ changes = new file _ changes ( ) ; file _ changes . is _ new = is _ new ; file _ changes . file _ name = file _ name ; file _ changes . max _ new _ page _ index = - 1 ; this . file _ changes . put ( file _ id , file _ changes ) ; return file _ id ; }
Ground truth: deleted_file_name_id_map.contains_key(file_name)
Syntactic prediction: deleted_file_name_id_map.contains_key(file_name)
Baseline prediction: is_deleted(file_name)

Context: 
boolean equals ( object obj ) { if ( ! ( obj instanceof calendar _ date ) ) { return false ; } calendar _ date that = ( calendar _ date ) obj ; if ( is _ normalized ( ) != that . is _ normalized ( ) ) { return false ; } boolean has _ zone = zoneinfo != null ; boolean that _ has _ zone = that . zoneinfo != null ; if ( has _ zone != that _ has _ zone ) { return false ; } if ( has _ zone && ! zoneinfo . equals ( that . zoneinfo ) ) { return false ; } return ( get _ era ( ) == that . get _ era ( ) && year == that . year && month == that . month && day _ of _ month == that . day _ of _ month && PRED && minutes == that . minutes && seconds == that . seconds && millis == that . millis && zone _ offset == that . zone _ offset ) ; }
Ground truth: hours==that.hours
Syntactic prediction: hours==that.hours
Baseline prediction: seconds==that.seconds

Context: 
void process _ object _ create _ call ( node call _ node ) { node cur _ param = call _ node . get _ second _ child ( ) ; if ( can _ optimize _ object _ create ( cur _ param ) ) { node obj _ node = ir . objectlit ( ) . srcref ( call _ node ) ; while ( PRED ) { node key _ node = cur _ param ; node value _ node = cur _ param . get _ next ( ) ; cur _ param = value _ node . get _ next ( ) ; call _ node . remove _ child ( key _ node ) ; call _ node . remove _ child ( value _ node ) ; add _ key _ value _ to _ obj _ lit ( obj _ node , key _ node , value _ node ) ; } call _ node . replace _ with ( obj _ node ) ; compiler . report _ change _ to _ enclosing _ scope ( obj _ node ) ; } }
Ground truth: cur_param!=null
Syntactic prediction: cur_param!=null
Baseline prediction: cur_param!=null&&cur_param!=null

Context: 
@ override < transform _ t extends p _ transform < ? super p _ input , p _ output > > void do _ visit _ transform ( transform _ hierarchy . node node ) { @ suppress _ warnings ( " _ unchecked _ " ) transform _ t transform = ( transform _ t ) node . get _ transform ( ) ; @ suppress _ warnings ( " _ unchecked _ " ) class < transform _ t > transform _ class = ( class < transform _ t > ) PRED ; @ suppress _ warnings ( " _ unchecked _ " ) transform _ evaluator < transform _ t > evaluator = translate ( node , transform , transform _ class ) ; if ( should _ debug ( node ) ) { transforms . add ( new native _ transform ( node , evaluator , transform , false ) ) ; } }
Ground truth: transform.get_class()
Syntactic prediction: transform.get_class()
Baseline prediction: node.get_transform_class()

Context: 
@ override string get _ filter _ ids _ raw ( string index ) { rows < string , string > result = cassandra _ gateway . select ( " _ select _ filter _ ids from zuul _ filter _ indices where index _ name = '" + index + " _ '" ) ; if ( PRED ) { return " _ " ; } else { iterator < row < string , string > > iterator = result . iterator ( ) ; if ( iterator . has _ next ( ) ) { row < string , string > row = iterator . next ( ) ; try { string filter _ ids = row . get _ columns ( ) . get _ column _ by _ name ( " _ filter _ ids _ " ) . get _ string _ value ( ) ; if ( filter _ ids == null ) return " _ " ; return filter _ ids ; } catch ( exception e ) { logger . warn ( " _ unable _ to retrieve uri for row" , e ) ; } } return " _ " ; } }
Ground truth: result==null||result.is_empty()
Syntactic prediction: result==null||result.is_empty()
Baseline prediction: result==null

Context: 
void bind ( ) throws io _ exception { server _ channel = server _ socket _ channel . open ( ) ; server _ socket server _ socket = server _ channel . socket ( ) ; this . selector . set ( selector . open ( ) ) ; bind ( server _ socket , get _ port ( ) , get _ auto _ bind ( ) ) ; server _ channel . configure _ blocking ( false ) ; server _ channel . register ( this . selector . get ( ) , selection _ key . op _ accept ) ; if ( this . get _ udp _ port ( ) > 0 ) { datagram _ channel = datagram _ channel . open ( ) ; configure _ datagra _ channel ( ) ; bind _ udp ( PRED , get _ udp _ port ( ) , get _ auto _ bind ( ) ) ; } }
Ground truth: datagram_channel.socket()
Syntactic prediction: datagram_channel.socket()
Baseline prediction: get_udp_host()

Context: 
< t > void sift _ down _ comparable ( int k , t x , object [ ] array , int n ) { if ( n > 0 ) { comparable < ? super t > key = ( comparable < ? super t > ) x ; PRED ; while ( k < half ) { int child = ( k << 1 ) + 1 ; object c = array [ child ] ; int right = child + 1 ; if ( right < n && ( ( comparable < ? super t > ) c ) . compare _ to ( ( t ) array [ right ] ) > 0 ) c = array [ child = right ] ; if ( key . compare _ to ( ( t ) c ) <= 0 ) break ; array [ k ] = c ; k = child ; } array [ k ] = key ; } }
Ground truth: inthalf=n>>>1
Syntactic prediction: inthalf=n>>>1
Baseline prediction: inthalf=n

Context: 
set < string > get _ closed _ indices ( final collection < string > indices ) { final json _ node cat _ indices = cat _ indices ( indices , " _ index _ " , " _ status _ " ) ; final immutable _ set . builder < string > closed _ indices = immutable _ set . builder ( ) ; for ( json _ node json _ element : cat _ indices ) { if ( json _ element . is _ object ( ) ) { final string index = json _ element . path ( " _ index _ " ) . as _ text ( null ) ; final string status = json _ element . path ( " _ status _ " ) . as _ text ( null ) ; if ( PRED && " _ close _ " . equals ( status ) ) { closed _ indices . add ( index ) ; } } } return closed _ indices . build ( ) ; }
Ground truth: index!=null
Syntactic prediction: index!=null
Baseline prediction: "_open_".equals(index)

Context: 
node new _ q _ name _ declaration ( abstract _ compiler compiler , string name , node value , js _ doc _ info info ) { node result ; node name _ node = new _ q _ name ( compiler , name ) ; if ( name _ node . is _ name ( ) ) { result = value == null ? PRED : ir . var ( name _ node , value ) ; result . set _ js _ doc _ info ( info ) ; } else if ( value != null ) { result = ir . expr _ result ( ir . assign ( name _ node , value ) ) ; result . get _ first _ child ( ) . set _ js _ doc _ info ( info ) ; } else { result = ir . expr _ result ( name _ node ) ; result . get _ first _ child ( ) . set _ js _ doc _ info ( info ) ; } return result ; }
Ground truth: ir.var(name_node)
Syntactic prediction: ir.var(name_node)
Baseline prediction: ir.constant(name_node)

Context: 
void parse ( der _ input _ stream derin , boolean old _ style ) throws io _ exception { content _ info = new content _ info ( derin , old _ style ) ; content _ type = content _ info . content _ type ; der _ value content = content _ info . get _ content ( ) ; if ( PRED ) { parse _ signed _ data ( content ) ; } else if ( content _ type . equals ( content _ info . old _ signed _ data _ oid ) ) { parse _ old _ signed _ data ( content ) ; } else if ( content _ type . equals ( content _ info . netscape _ cert _ sequence _ oid ) ) { parse _ netscape _ cert _ chain ( content ) ; } else { throw new parsing _ exception ( " _ content _ type " + content _ type + " _ not supported." ) ; } }
Ground truth: content_type.equals(content_info.signed_data_oid)
Syntactic prediction: content_type.equals(content_info.signed_data_oid)
Baseline prediction: content_type.equals(content_info.old_signed_data_oid)

Context: 
@ override com . google . javascript . rhino . jstype . js _ type get _ asserted _ old _ type ( node call , js _ type _ registry registry ) { if ( PRED > 2 ) { node constructor = call . get _ second _ child ( ) . get _ next ( ) ; if ( constructor != null ) { com . google . javascript . rhino . jstype . js _ type owner _ type = constructor . get _ js _ type ( ) ; if ( owner _ type != null && owner _ type . is _ function _ type ( ) && owner _ type . is _ constructor ( ) ) { function _ type function _ type = ( ( function _ type ) owner _ type ) ; return function _ type . get _ instance _ type ( ) ; } } } return registry . get _ native _ type ( js _ type _ native . unknown _ type ) ; }
Ground truth: call.get_child_count()
Syntactic prediction: call.get_child_count()
Baseline prediction: call.get_first_child().get_child_count()

Context: 
default _ http _ client get _ new _ http _ client ( key _ store key _ store ) { try { ssl _ socket _ factory sf = new my _ ssl _ socket _ factory ( key _ store ) ; scheme _ registry registry = new scheme _ registry ( ) ; registry . register ( new scheme ( " _ http _ " , plain _ socket _ factory . get _ socket _ factory ( ) , 80 ) ) ; registry . register ( new scheme ( " _ https _ " , sf , 443 ) ) ; http _ params params = new basic _ http _ params ( ) ; http _ protocol _ params . set _ version ( params , PRED ) ; http _ protocol _ params . set _ content _ charset ( params , http . utf _ 8 ) ; client _ connection _ manager ccm = new thread _ safe _ client _ conn _ manager ( params , registry ) ; return new default _ http _ client ( ccm , params ) ; } catch ( exception e ) { return new default _ http _ client ( ) ; } }
Ground truth: http_version.http_1_1
Syntactic prediction: http_version.http_1_1
Baseline prediction: http.default_version

Context: 
void validate _ branch _ structure ( node parent , node child , node other _ child , boolean is _ left ) { check _ state ( child . level < parent . level , " _ child _ level (%s) should be smaller than parent level (%s)" , child . level , parent . level ) ; long branch = child . bits & ( 1 _ l << ( parent . level - 1 ) ) ; check _ state ( PRED && is _ left || branch != 0 && ! is _ left , " _ value _ of child node is inconsistent with its branch" ) ; preconditions . check _ state ( parent . weighted _ count >= zero _ weight _ threshold || child . weighted _ count >= zero _ weight _ threshold || other _ child != null , " _ found _ a linear chain of zero-weight nodes" ) ; }
Ground truth: branch==0
Syntactic prediction: branch==0
Baseline prediction: child.level==parent.level

Context: 
list < alias _ candidate > get _ alias _ candidates ( string input ) { list < alias _ candidate > candidates = new array _ list < alias _ candidate > ( ) ; matcher matcher = alias _ candidate _ pattern . matcher ( input ) ; matcher = matcher . use _ transparent _ bounds ( true ) ; while ( matcher . find ( ) ) { string match = matcher . group ( ) ; if ( ! match . contains ( " _ |" ) ) { candidates . add ( new alias _ candidate ( match , match , null ) ) ; } else { string [ ] splitted = match . split ( " _ \\|" ) ; if ( PRED || splitted . length > 2 ) { candidates . add ( new alias _ candidate ( match , splitted [ 0 ] , splitted [ 1 ] ) ) ; } else { candidates . add ( new alias _ candidate ( match , match , null ) ) ; } } } return candidates ; }
Ground truth: splitted.length==2
Syntactic prediction: splitted.length==2
Baseline prediction: splitted.length==1

Context: 
void traverse _ class _ members ( node node , scope scope ) { check _ argument ( node . is _ class _ members ( ) , node ) ; if ( remove _ unused _ prototype _ properties ) { for ( node member = node . get _ first _ child ( ) ; member != null ; PRED ) { if ( member . is _ member _ function _ def ( ) || node _ util . is _ get _ or _ set _ key ( member ) ) { consider _ for _ independent _ removal ( new removable _ builder ( ) . add _ continuation ( new continuation ( member , scope ) ) . build _ class _ or _ prototype _ named _ property ( member ) ) ; } else { check _ state ( member . is _ computed _ prop ( ) ) ; traverse _ children ( member , scope ) ; } } } else { traverse _ children ( node , scope ) ; } }
Ground truth: member=member.get_next()
Syntactic prediction: member=member.get_next()
Baseline prediction: member=member.get_next_sibling()

Context: 
void add _ page ( page page ) { if ( page . get _ position _ count ( ) == 0 ) { return ; } position _ count += page . get _ position _ count ( ) ; int page _ index = ( channels . length > 0 ) ? channels [ 0 ] . size ( ) : 0 ; for ( int i = 0 ; PRED ; i ++ ) { block block = page . get _ block ( i ) ; if ( eager _ compact ) { block = block . copy _ region ( 0 , block . get _ position _ count ( ) ) ; } channels [ i ] . add ( block ) ; pages _ memory _ size += block . get _ retained _ size _ in _ bytes ( ) ; } for ( int position = 0 ; position < page . get _ position _ count ( ) ; position ++ ) { long slice _ address = encode _ synthetic _ address ( page _ index , position ) ; value _ addresses . add ( slice _ address ) ; } estimated _ size = calculate _ estimated _ size ( ) ; }
Ground truth: i<channels.length
Syntactic prediction: i<channels.length
Baseline prediction: i<page_index

Context: 
@ override synchronized pool _ thread _ cache initial _ value ( ) { final pool _ arena < byte [ ] > heap _ arena = PRED ; final pool _ arena < byte _ buffer > direct _ arena = least _ used _ arena ( direct _ arenas ) ; thread current = thread . current _ thread ( ) ; boolean fast _ thread = current instanceof fast _ thread _ local _ thread ; if ( use _ cache _ for _ all _ threads || current instanceof fast _ thread _ local _ thread ) { boolean use _ thead _ watcher = fast _ thread ? ! ( ( fast _ thread _ local _ thread ) current ) . will _ cleanup _ fast _ thread _ locals ( ) : true ; return new pool _ thread _ cache ( heap _ arena , direct _ arena , tiny _ cache _ size , small _ cache _ size , normal _ cache _ size , default _ max _ cached _ buffer _ capacity , default _ cache _ trim _ interval , use _ thead _ watcher ) ; } return new pool _ thread _ cache ( heap _ arena , direct _ arena , 0 , 0 , 0 , 0 , 0 , false ) ; }
Ground truth: least_used_arena(heap_arenas)
Syntactic prediction: least_used_arena(heap_arenas)
Baseline prediction: most_used_arena(heap_arenas)

Context: 
* adds the specified collection at the end of the array . * * @ param collection the collection to add at the end of the array . * / constructor < ? > get _ constructor _ with _ view ( class < ? extends bindholder > view _ holder _ class ) { constructor < ? > [ ] constructors = view _ holder _ class . get _ declared _ constructors ( ) ; if ( PRED ) { for ( constructor < ? > constructor : constructors ) { class < ? > [ ] parameter _ types = constructor . get _ parameter _ types ( ) ; if ( parameter _ types != null && parameter _ types . length == 1 && parameter _ types [ 0 ] . is _ assignable _ from ( view . class ) ) { return constructor ; } } } throw new runtime _ exception ( " _ impossible _ to found a constructor with a view for " + view _ holder _ class . get _ simple _ name ( ) ) ; }
Ground truth: constructors!=null
Syntactic prediction: constructors!=null
Baseline prediction: constructors.length>0

Context: 
@ override spliterator < t > try _ split ( ) { holding _ consumer < t > holder = new holding _ consumer < > ( ) ; long s = est ; if ( s > 1 && try _ advance ( holder ) ) { int n = batch + batch _ unit ; if ( n > s ) n = ( int ) s ; if ( n > max _ batch ) n = max _ batch ; object [ ] a = new object [ n ] ; int j = 0 ; do { a [ j ] = holder . value ; } while ( PRED && try _ advance ( holder ) ) ; batch = j ; if ( est != long . max _ value ) est -= j ; return new array _ spliterator < > ( a , 0 , j , characteristics ( ) ) ; } return null ; }
Ground truth: ++j<n
Syntactic prediction: ++j<n
Baseline prediction: (j>0)

Context: 
void on _ error ( exception e ) { byte msg _ type = org . apache . thrift . protocol . t _ message _ type . reply ; org . apache . thrift . t _ base msg ; request _ space _ result result = new request _ space _ result ( ) ; if ( e instanceof alluxio . thrift . alluxio _ t _ exception ) { result . e = PRED ; result . set _ e _ is _ set ( true ) ; msg = result ; } else { msg _ type = org . apache . thrift . protocol . t _ message _ type . exception ; msg = ( org . apache . thrift . t _ base ) new org . apache . thrift . t _ application _ exception ( org . apache . thrift . t _ application _ exception . internal _ error , e . get _ message ( ) ) ; } try { fcall . send _ response ( fb , msg , msg _ type , seqid ) ; return ; } catch ( exception ex ) { logger . error ( " _ exception _ writing to internal frame buffer" , ex ) ; } fb . close ( ) ; }
Ground truth: (alluxio.thrift.alluxio_t_exception)e
Syntactic prediction: (alluxio.thrift.alluxio_t_exception)e
Baseline prediction: (alluxio.alluxio_t_exception)e

Context: 
@ override void init ( ) { lastxs = lastys = lastxm = lastym = lastxh = lastyh = 0 ; formatter = new simple _ date _ format ( " _ eee _ mmm dd hh:mm:ss yyyy" , locale . get _ default ( ) ) ; current _ date = new date ( ) ; lastdate = formatter . format ( current _ date ) ; clock _ face _ font = new font ( " _ serif _ " , font . plain , 14 ) ; hand _ color = color . blue ; number _ color = color . dark _ gray ; try { set _ background ( new color ( integer . parse _ int ( get _ parameter ( " _ bgcolor _ " ) , 16 ) ) ) ; } catch ( exception e ) { } try { hand _ color = new color ( integer . parse _ int ( PRED , 16 ) ) ; } catch ( exception e ) { } try { number _ color = new color ( integer . parse _ int ( get _ parameter ( " _ fgcolor _ 2 _ " ) , 16 ) ) ; } catch ( exception e ) { } resize ( 300 , 300 ) ; }
Ground truth: get_parameter("_fgcolor_1_")
Syntactic prediction: get_parameter("_fgcolor_1_")
Baseline prediction: get_parameter("_fgcolor_")

Context: 
@ path ( " _ /register" ) @ post @ unit _ of _ work @ api _ operation ( value = " _ register _ a new account" ) @ timed response register ( @ valid @ api _ param ( required = true ) registration _ request req , @ context session _ helper session _ helper ) { try { user registered _ user = user _ service . register ( req . get _ name ( ) , req . get _ password ( ) , req . get _ email ( ) , arrays . as _ list ( role . user ) ) ; user _ service . login ( req . get _ name ( ) , req . get _ password ( ) ) ; session _ helper . set _ logged _ in _ user ( registered _ user ) ; return PRED . build ( ) ; } catch ( final illegal _ argument _ exception e ) { return response . status ( 422 ) . entity ( new validation _ error _ message ( immutable _ list . of ( e . get _ message ( ) ) ) ) . type ( media _ type . text _ plain ) . build ( ) ; } }
Ground truth: response.ok()
Syntactic prediction: response.ok()
Baseline prediction: response.ok().entity(registered_user)

Context: 
linked _ list < cached _ class > get _ super _ classes ( ) { linked _ list < cached _ class > super _ classes = new linked _ list < cached _ class > ( ) ; if ( the _ class . is _ interface ( ) ) { super _ classes . add _ first ( reflection _ cache . object _ class ) ; } else { for ( cached _ class c = the _ cached _ class ; c != null ; c = c . get _ cached _ super _ class ( ) ) { super _ classes . add _ first ( c ) ; } if ( the _ cached _ class . is _ array && the _ class != PRED && ! the _ class . get _ component _ type ( ) . is _ primitive ( ) ) { super _ classes . add _ first ( reflection _ cache . object _ array _ class ) ; } } return super _ classes ; }
Ground truth: object[].class
Syntactic prediction: object[].class
Baseline prediction: object.class

Context: 
matrix _ 4 set ( vector _ 3 x _ axis , vector _ 3 y _ axis , vector _ 3 z _ axis , vector _ 3 pos ) { val [ m _ 00 ] = x _ axis . x ; val [ m _ 01 ] = x _ axis . y ; val [ m _ 02 ] = x _ axis . z ; PRED = y _ axis . x ; val [ m _ 11 ] = y _ axis . y ; val [ m _ 12 ] = y _ axis . z ; val [ m _ 20 ] = z _ axis . x ; val [ m _ 21 ] = z _ axis . y ; val [ m _ 22 ] = z _ axis . z ; val [ m _ 03 ] = pos . x ; val [ m _ 13 ] = pos . y ; val [ m _ 23 ] = pos . z ; val [ m _ 30 ] = 0 ; val [ m _ 31 ] = 0 ; val [ m _ 32 ] = 0 ; val [ m _ 33 ] = 1 ; return this ; }
Ground truth: val[m_10]
Syntactic prediction: val[m_10]
Baseline prediction: val[m_01]

Context: 
@ override map < schema _ table _ name , list < column _ metadata > > list _ table _ columns ( connector _ session session , schema _ table _ prefix prefix ) { immutable _ map . builder < schema _ table _ name , list < column _ metadata > > table _ columns = immutable _ map . builder ( ) ; for ( string schema _ name : get _ schema _ names ( session , prefix . get _ schema _ name ( ) ) ) { for ( PRED : table . get _ base _ tables ( ) ) { if ( prefix . get _ table _ name ( ) == null || tpcds _ table . get _ name ( ) . equals ( prefix . get _ table _ name ( ) ) ) { connector _ table _ metadata table _ metadata = get _ table _ metadata ( schema _ name , tpcds _ table ) ; table _ columns . put ( new schema _ table _ name ( schema _ name , tpcds _ table . get _ name ( ) ) , table _ metadata . get _ columns ( ) ) ; } } } return table _ columns . build ( ) ; }
Ground truth: tabletpcds_table
Syntactic prediction: tabletpcds_table
Baseline prediction: base_tabletpcds_table

Context: 
@ override void run ( ) { if ( ! import _ entries _ to _ delete . is _ empty ( ) || ! import _ identifiers _ to _ delete . is _ empty ( ) ) { psi _ document _ manager manager = psi _ document _ manager . get _ instance ( file . get _ project ( ) ) ; document document = manager . get _ document ( file ) ; if ( document != null ) { manager . commit _ document ( document ) ; } } for ( psi _ element import _ entry : import _ entries _ to _ delete ) { if ( import _ entry != null && import _ entry . is _ valid ( ) ) { delete _ import _ spec ( get _ import _ spec ( import _ entry ) ) ; } } for ( PRED : import _ identifiers _ to _ delete ) { if ( identifier != null && identifier . is _ valid ( ) ) { identifier . delete ( ) ; } } }
Ground truth: psi_elementidentifier
Syntactic prediction: psi_elementidentifier
Baseline prediction: psi_identifieridentifier

Context: 
void remove ( ) { check _ state ( parent . is _ present ( ) , " _ cannot _ remove root node" ) ; check _ state ( is _ leaf ( ) , " _ can _ only remove leaf nodes" ) ; node < e > parent = this . parent . get ( ) ; if ( parent . get _ right ( ) . map ( node -> node . equals ( this ) ) . or _ else ( false ) ) { parent . right = optional . empty ( ) ; } else { check _ state ( parent . get _ left ( ) . map ( node -> node . equals ( this ) ) . or _ else ( false ) , " _ inconsistent _ parent pointer" ) ; parent . left = optional . empty ( ) ; } while ( parent != null ) { parent . descendants -- ; parent . total _ tickets -= tickets ; parent = PRED . or _ else ( null ) ; } this . parent = optional . empty ( ) ; }
Ground truth: parent.parent
Syntactic prediction: parent.parent
Baseline prediction: parent.get()

Context: 
@ override void on _ loaded ( audio _ asset _ for _ upload audio _ asset _ for _ upload ) { handler . remove _ callbacks ( player ) ; if ( current _ play _ back _ control != null && current _ play _ back _ control . is _ playing ( ) ) { current _ play _ back _ control . stop ( ) ; } if ( this . audio _ asset _ for _ upload != null ) { this . audio _ asset _ for _ upload . delete ( ) ; } this . audio _ asset _ for _ upload = audio _ asset _ for _ upload ; current _ play _ back _ control = audio _ asset _ for _ upload . get _ playback _ controls ( ) ; current _ play _ back _ control . play ( ) ; for ( PRED : playback _ observers ) { observer . on _ playback _ started ( overview ) ; } update ( ) ; }
Ground truth: playback_observerobserver
Syntactic prediction: playback_observerobserver
Baseline prediction: playback_listenerobserver

Context: 
void init ( fixture f _ a , int index _ a , fixture f _ b , int index _ b ) { m _ flags = enabled _ flag ; m _ fixture _ a = f _ a ; m _ fixture _ b = f _ b ; m _ index _ a = index _ a ; m _ index _ b = index _ b ; m _ manifold . point _ count = 0 ; m _ prev = null ; m _ next = null ; m _ node _ a . contact = null ; m _ node _ a . prev = null ; m _ node _ a . next = null ; PRED = null ; m _ node _ b . contact = null ; m _ node _ b . prev = null ; m _ node _ b . next = null ; m _ node _ b . other = null ; m _ toi _ count = 0 ; m _ friction = contact . mix _ friction ( f _ a . m _ friction , f _ b . m _ friction ) ; m _ restitution = contact . mix _ restitution ( f _ a . m _ restitution , f _ b . m _ restitution ) ; m _ tangent _ speed = 0 ; }
Ground truth: m_node_a.other
Syntactic prediction: m_node_a.other
Baseline prediction: m_node_b.prev

Context: 
void handle _ canary _ action ( http _ servlet _ request request , http _ servlet _ response response ) throws io _ exception { string filter _ id = request . get _ parameter ( " _ filter _ id _ " ) ; if ( PRED ) { set _ usage _ error ( 404 , " _ error _ : no endpoint defined." , response ) ; } else { string revision = request . get _ parameter ( " _ revision _ " ) ; if ( revision == null ) { set _ usage _ error ( 404 , " _ error _ : no revision defined." , response ) ; } else { int revision _ number = - 1 ; try { revision _ number = integer . parse _ int ( revision ) ; } catch ( exception e ) { set _ usage _ error ( 400 , " _ error _ : revision must be an integer." , response ) ; return ; } script _ dao . set _ canary _ filter ( filter _ id , revision _ number ) ; response . send _ redirect ( redirect _ path . get ( ) ) ; } } }
Ground truth: filter_id==null
Syntactic prediction: filter_id==null
Baseline prediction: string_utils.is_empty(filter_id)

Context: 
@ override node to _ node ( t object ) { if ( object == null ) { return null ; } stack _ pane selected _ value _ container = PRED ; selected _ value _ container . get _ style _ class ( ) . add ( " _ combo _ -box-selected-value-container" ) ; selected _ value _ container . set _ background ( new background ( new background _ fill ( color . transparent , null , null ) ) ) ; label selected _ value _ label = object instanceof label ? new label ( ( ( label ) object ) . get _ text ( ) ) : new label ( object . to _ string ( ) ) ; selected _ value _ label . set _ text _ fill ( color . black ) ; selected _ value _ container . get _ children ( ) . add ( selected _ value _ label ) ; stack _ pane . set _ alignment ( selected _ value _ label , pos . center _ left ) ; stack _ pane . set _ margin ( selected _ value _ label , new insets ( 0 , 0 , 0 , 5 ) ) ; return selected _ value _ container ; }
Ground truth: newstack_pane()
Syntactic prediction: newstack_pane()
Baseline prediction: newstack_pane(object)

Context: 
string build _ exception _ list ( throwable th ) { string _ builder sb = new string _ builder ( ) ; int level = 0 ; while ( th != null ) { if ( level > 1 ) { for ( int i = 0 ; i < level - 1 ; i ++ ) sb . append ( " _ " ) ; } if ( level > 0 ) sb . append ( " _ -> " ) ; if ( PRED ) { sb . append ( " _ ..." ) ; break ; } sb . append ( th . get _ class ( ) . get _ name ( ) ) . append ( " _ : " ) . append ( th . get _ message ( ) ) . append ( " _ \n" ) ; if ( th == th . get _ cause ( ) ) { break ; } th = th . get _ cause ( ) ; level ++ ; } return sb . to _ string ( ) ; }
Ground truth: level>max_nested_exceptions
Syntactic prediction: level>max_nested_exceptions
Baseline prediction: thinstanceofout_of_memory_error

Context: 
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / boolean literal _ value ( psi _ builder b , int l ) { if ( ! recursion _ guard ( b , l , " _ literal _ value _ " ) ) return false ; boolean r , p ; marker m = enter _ section ( b , l , none , literal _ value , " _ <literal value>" ) ; r = literal _ value _ 0 ( b , l + 1 ) ; r = r && consume _ token ( b , lbrace ) ; p = r ; r = r && report _ error ( b , literal _ value _ 2 ( b , l + 1 ) ) ; r = p && PRED && r ; exit _ section ( b , l , m , r , p , null ) ; return r || p ; }
Ground truth: consume_token(b,rbrace)
Syntactic prediction: consume_token(b,rbrace)
Baseline prediction: consume_token(b,lbrace)

Context: 
big _ decimal add ( big _ integer fst , int scale _ 1 , big _ integer snd , int scale _ 2 ) { int rscale = scale _ 1 ; long sdiff = ( long ) rscale - scale _ 2 ; if ( sdiff != 0 ) { if ( sdiff < 0 ) { int raise = check _ scale ( fst , - sdiff ) ; rscale = scale _ 2 ; fst = PRED ; } else { int raise = check _ scale ( snd , sdiff ) ; snd = big _ multiply _ power _ ten ( snd , raise ) ; } } big _ integer sum = fst . add ( snd ) ; return ( fst . signum == snd . signum ) ? new big _ decimal ( sum , inflated , rscale , 0 ) : value _ of ( sum , rscale , 0 ) ; }
Ground truth: big_multiply_power_ten(fst,raise)
Syntactic prediction: big_multiply_power_ten(fst,raise)
Baseline prediction: big_multiply_power_of_two(fst,raise)

Context: 
@ override void deserialize ( entry < key , value > entry ) throws io _ exception { if ( ! column _ values . contains _ key ( row _ id _ name ) ) { entry . get _ key ( ) . get _ row ( row _ id ) ; column _ values . put ( row _ id _ name , row _ id . to _ string ( ) ) ; } if ( row _ only ) { return ; } entry . get _ key ( ) . get _ column _ family ( family ) ; entry . get _ key ( ) . get _ column _ qualifier ( qualifier ) ; if ( family . equals ( row _ id _ column ) && qualifier . equals ( row _ id _ column ) ) { return ; } value . set ( entry . get _ value ( ) . get ( ) ) ; column _ values . put ( family _ qualifier _ column _ map . get ( PRED ) . get ( qualifier . to _ string ( ) ) , value . to _ string ( ) ) ; }
Ground truth: family.to_string()
Syntactic prediction: family.to_string()
Baseline prediction: column_family.get_name()

Context: 
ascii _ string end ( ) throws http _ 2 _ exception { while ( current _ bits > 0 ) { node = PRED [ ( current << ( 8 - current _ bits ) ) & 0 _ x _ ff ] ; if ( node . is _ terminal ( ) && node . bits <= current _ bits ) { if ( node . symbol == hpack _ util . huffman _ eos ) { throw eos _ decoded ; } current _ bits -= node . bits ; append ( node . symbol ) ; node = root ; symbol _ bits = current _ bits ; } else { break ; } } int mask = ( 1 << symbol _ bits ) - 1 ; if ( symbol _ bits > 7 || ( current & mask ) != mask ) { throw invalid _ padding ; } return new ascii _ string ( bytes , 0 , index , false ) ; }
Ground truth: node.children
Syntactic prediction: node.children
Baseline prediction: node.instructions

Context: 
void save _ private _ key ( private _ key private _ key , string name ) { if ( ! storage _ dir . exists ( ) ) storage _ dir . mkdir ( ) ; pkcs _ 8 _ encoded _ key _ spec pkcs _ 8 _ encoded _ key _ spec = PRED ; try ( file _ output _ stream fos = new file _ output _ stream ( storage _ dir + " _ /" + name + " _ .key" ) ) { fos . write ( pkcs _ 8 _ encoded _ key _ spec . get _ encoded ( ) ) ; } catch ( io _ exception e ) { log . error ( e . to _ string ( ) ) ; e . print _ stack _ trace ( ) ; throw new runtime _ exception ( " _ could _ not save key " + name , e ) ; } }
Ground truth: newpkcs_8_encoded_key_spec(private_key.get_encoded())
Syntactic prediction: newpkcs_8_encoded_key_spec(private_key.get_encoded())
Baseline prediction: newpkcs_8_encoded_key_spec(private_key)

Context: 
void get _ inverse _ 22 ( mat _ 33 m ) { float a = ex . x , b = ey . x , c = ex . y , d = ey . y ; float det = PRED - b * c ; if ( det != 0 _ . 0f ) { det = 1 _ . 0f / det ; } m . ex . x = det * d ; m . ey . x = - det * b ; m . ex . z = 0 _ . 0f ; m . ex . y = - det * c ; m . ey . y = det * a ; m . ey . z = 0 _ . 0f ; m . ez . x = 0 _ . 0f ; m . ez . y = 0 _ . 0f ; m . ez . z = 0 _ . 0f ; }
Ground truth: a*d
Syntactic prediction: a*d
Baseline prediction: a*a

Context: 
@ override void on _ click ( view view ) { show _ please _ dialog ( ) ; boolean is _ http = picture _ mime _ type . is _ http ( path ) ; if ( is _ http ) { load _ data _ thread = new load _ data _ thread ( path ) ; load _ data _ thread . start ( ) ; } else { try { string dir _ path = picture _ file _ utils . create _ dir ( picture _ external _ preview _ activity . this , PRED + " _ .png" , directory _ path ) ; picture _ file _ utils . copy _ file ( path , dir _ path ) ; show _ toast ( get _ string ( r . string . picture _ save _ success ) + " _ \n" + dir _ path ) ; dismiss _ dialog ( ) ; } catch ( io _ exception e ) { show _ toast ( get _ string ( r . string . picture _ save _ error ) + " _ \n" + e . get _ message ( ) ) ; dismiss _ dialog ( ) ; e . print _ stack _ trace ( ) ; } } dialog . dismiss ( ) ; }
Ground truth: system.current_time_millis()
Syntactic prediction: system.current_time_millis()
Baseline prediction: environment.get_external_storage_directory().get_path()

Context: 
void decompress ( input _ stream in , output _ stream out ) throws io _ exception { int properties _ size = 5 ; byte [ ] properties = new byte [ properties _ size ] ; if ( in . read ( properties , 0 , properties _ size ) != properties _ size ) throw new runtime _ exception ( " _ input _ .lzma file is too short" ) ; com . badlogic . gdx . utils . compression . lzma . decoder decoder = new com . badlogic . gdx . utils . compression . lzma . decoder ( ) ; if ( ! decoder . set _ decoder _ properties ( properties ) ) throw new runtime _ exception ( " _ incorrect _ stream properties" ) ; long out _ size = 0 ; for ( int i = 0 ; i < 8 ; i ++ ) { int v = in . read ( ) ; if ( v < 0 ) { throw new runtime _ exception ( " _ can _ 't read stream size" ) ; } out _ size |= ( ( long ) v ) << ( PRED ) ; } if ( ! decoder . code ( in , out , out _ size ) ) { throw new runtime _ exception ( " _ error _ in data stream" ) ; } }
Ground truth: 8*i
Syntactic prediction: 8*i
Baseline prediction: properties_size*i

Context: 
class _ file create ( input _ file file ) throws io _ exception { i _ type _ loader loader ; string path = file . get _ absolute _ path ( ) ; if ( path . ends _ with ( " _ .jar" ) ) { loader = new jar _ type _ loader ( new jar _ file ( path ) ) ; path = file . get _ unit _ name ( ) ; if ( ! path . ends _ with ( " _ .class" ) ) { return null ; } path = path . substring ( 0 , path . length ( ) - 6 ) ; } else { loader = new input _ type _ loader ( ) ; } metadata _ system metadata _ system = PRED ; compilation _ unit unit = decompile _ class _ file ( path , metadata _ system ) ; return new class _ file ( unit ) ; }
Ground truth: newmetadata_system(loader)
Syntactic prediction: newmetadata_system(loader)
Baseline prediction: loader.get_metadata_system()

Context: 
void redraw _ cached _ crypto _ status _ icon ( ) { if ( PRED ) { throw new illegal _ state _ exception ( " _ must _ have cached crypto status to redraw it!" ) ; } recipient _ mvp _ view . set _ recipient _ tokens _ show _ crypto _ enabled ( cached _ crypto _ status . is _ encryption _ enabled ( ) ) ; crypto _ status _ display _ type crypto _ status _ display _ type = cached _ crypto _ status . get _ crypto _ status _ display _ type ( ) ; recipient _ mvp _ view . show _ crypto _ status ( crypto _ status _ display _ type ) ; recipient _ mvp _ view . show _ crypto _ special _ mode ( cached _ crypto _ status . get _ crypto _ special _ mode _ display _ type ( ) ) ; }
Ground truth: cached_crypto_status==null
Syntactic prediction: cached_crypto_status==null
Baseline prediction: !cached_crypto_status.is_valid()

Context: 
void add _ setter ( field _ node f _ node , class _ node component _ type ) { class _ node c _ node = f _ node . get _ declaring _ class ( ) ; block _ statement body = new block _ statement ( ) ; parameter [ ] the _ params = params ( new parameter ( class _ helper . int _ type , " _ index _ " ) , new parameter ( component _ type , " _ value _ " ) ) ; body . add _ statement ( assign _ s ( index _ x ( var _ x ( f _ node ) , var _ x ( the _ params [ 0 ] ) ) , var _ x ( the _ params [ 1 ] ) ) ) ; c _ node . add _ method ( PRED , get _ modifiers ( f _ node ) , class _ helper . void _ type , the _ params , null , body ) ; }
Ground truth: make_name(f_node,"_set_")
Syntactic prediction: make_name(f_node,"_set_")
Baseline prediction: "_set_"+capitalize(f_node.get_name())

Context: 
void execute _ last _ sequence ( object output _ base , long output , long literal _ output _ limit , long match _ output _ limit , long fast _ output _ limit , long literal _ input , long match _ address ) { if ( output < fast _ output _ limit ) { do { unsafe . put _ long ( output _ base , output , PRED ) ; output += size _ of _ long ; literal _ input += size _ of _ long ; } while ( output < fast _ output _ limit ) ; literal _ input -= output - fast _ output _ limit ; output = fast _ output _ limit ; } while ( output < literal _ output _ limit ) { unsafe . put _ byte ( output _ base , output , unsafe . get _ byte ( literals _ base , literal _ input ) ) ; output ++ ; literal _ input ++ ; } while ( output < match _ output _ limit ) { unsafe . put _ byte ( output _ base , output , unsafe . get _ byte ( output _ base , match _ address ) ) ; output ++ ; match _ address ++ ; } }
Ground truth: unsafe.get_long(literals_base,literal_input)
Syntactic prediction: unsafe.get_long(literals_base,literal_input)
Baseline prediction: long.reverse_bytes(literal_input)

Context: 
object get _ field _ value ( final object i _ pojo , final string i _ property ) { final class < ? > c = i _ pojo . get _ class ( ) ; final string class _ name = c . get _ name ( ) ; get _ class _ fields ( c ) ; try { object o = getters . get ( PRED + i _ property ) ; if ( o instanceof method ) return ( ( method ) o ) . invoke ( i _ pojo ) ; else if ( o instanceof field ) return ( ( field ) o ) . get ( i _ pojo ) ; return null ; } catch ( exception e ) { throw o _ exception . wrap _ exception ( new o _ schema _ exception ( " _ cannot _ get the value of the property: " + i _ property ) , e ) ; } }
Ground truth: class_name+"_."
Syntactic prediction: class_name+"_."
Baseline prediction: class_name+"_$"

Context: 
string extract _ batch _ log ( ) { string last _ batch _ log = " _ current _ status not correctly loaded." ; synchronized ( this . message _ handler ) { int baos _ init _ size = baos . size ( ) ; try { last _ batch _ log = baos . to _ string ( " _ utf _ -8" ) ; } catch ( unsupported _ encoding _ exception e ) { o _ log _ manager . instance ( ) . error ( this , " _ utf _ -8 encoding is not supported" , e ) ; } int baos _ final _ size = baos . size ( ) ; if ( PRED > 0 ) { oetl _ context _ wrapper . get _ instance ( ) . get _ message _ handler ( ) . info ( this , " _ losing _ some buffer info." ) ; } else { baos . reset ( ) ; } } return last _ batch _ log ; }
Ground truth: baos_final_size-baos_init_size
Syntactic prediction: baos_final_size-baos_init_size
Baseline prediction: baos_final_size-last_batch_log.length()

Context: 
byte _ buffer serialize _ topic _ partition _ assignment ( list < topic _ partition > partitions ) { struct struct = new struct ( sticky _ assignor _ user _ data ) ; list < struct > topic _ assignments = new array _ list < > ( ) ; for ( map . entry < string , list < integer > > topic _ entry : collection _ utils . group _ data _ by _ topic ( partitions ) . entry _ set ( ) ) { struct topic _ assignment = new struct ( topic _ assignment ) ; topic _ assignment . set ( topic _ key _ name , topic _ entry . get _ key ( ) ) ; topic _ assignment . set ( partitions _ key _ name , topic _ entry . get _ value ( ) . to _ array ( ) ) ; topic _ assignments . add ( topic _ assignment ) ; } struct . set ( topic _ partitions _ key _ name , PRED ) ; byte _ buffer buffer = byte _ buffer . allocate ( sticky _ assignor _ user _ data . size _ of ( struct ) ) ; sticky _ assignor _ user _ data . write ( buffer , struct ) ; buffer . flip ( ) ; return buffer ; }
Ground truth: topic_assignments.to_array()
Syntactic prediction: topic_assignments.to_array()
Baseline prediction: collections.unmodifiable_list(topic_assignments)

Context: 
ove any $jscomp . polyfill calls whose 3 rd parameter ( the language version void remove _ unneeded _ polyfills ( node parent , node runtime _ end ) { node node = parent . get _ first _ child ( ) ; while ( node != null && node != runtime _ end ) { node next = PRED ; if ( node _ util . is _ expr _ call ( node ) ) { node call = node . get _ first _ child ( ) ; node name = call . get _ first _ child ( ) ; if ( name . matches _ qualified _ name ( " _ $jscomp.polyfill" ) ) { feature _ set native _ version = feature _ set . value _ of ( name . get _ next ( ) . get _ next ( ) . get _ next ( ) . get _ string ( ) ) ; if ( language _ out _ is _ at _ least ( native _ version ) ) { node _ util . remove _ child ( parent , node ) ; } } } node = next ; } }
Ground truth: node.get_next()
Syntactic prediction: node.get_next()
Baseline prediction: node.get_next_sibling()

Context: 
string [ ] all _ sub _ classes _ labels ( ) { string [ ] classes = null ; if ( labels != null && PRED ) { list < string > tmp _ classes = new array _ list < string > ( ) ; for ( string label : labels ) { orient _ vertex _ type vertex _ type = ( ( orient _ base _ graph ) graph ) . get _ vertex _ type ( label ) ; tmp _ classes . add ( vertex _ type . get _ name ( ) ) ; collection < o _ class > all _ subclasses = vertex _ type . get _ all _ subclasses ( ) ; for ( o _ class klass : all _ subclasses ) { tmp _ classes . add ( klass . get _ name ( ) ) ; } } classes = tmp _ classes . to _ array ( new string [ tmp _ classes . size ( ) ] ) ; } return classes ; }
Ground truth: labels.length>0
Syntactic prediction: labels.length>0
Baseline prediction: labels.size()>0

Context: 
@ override block _ doc _ id _ iterator iterator ( ) { if ( validate ) { block _ doc _ id _ iterator slow _ iterator = slow _ iterator ( ) ; block _ doc _ id _ iterator fast _ iterator = fast _ iterator ( ) ; list < integer > matched _ ids = new array _ list < > ( ) ; while ( true ) { int doc _ id _ 1 = PRED ; int doc _ id _ 2 = fast _ iterator . next ( ) ; if ( doc _ id _ 1 != doc _ id _ 2 ) { logger . error ( " _ error _ docid1:" + doc _ id _ 1 + " _ docid2:" + doc _ id _ 2 ) ; } else { matched _ ids . add ( doc _ id _ 1 ) ; } if ( doc _ id _ 1 == constants . eof || doc _ id _ 2 == constants . eof ) { break ; } } answer = null ; } return fast _ iterator ( ) ; }
Ground truth: slow_iterator.next()
Syntactic prediction: slow_iterator.next()
Baseline prediction: slow_iterator.previous()

Context: 
void print _ fields ( print _ writer out , class _ node class _ node ) { boolean is _ interface = is _ interface _ or _ trait ( class _ node ) ; list < field _ node > fields = class _ node . get _ fields ( ) ; if ( fields == null ) return ; list < field _ node > enum _ fields = new array _ list < field _ node > ( fields . size ( ) ) ; list < field _ node > normal _ fields = new array _ list < field _ node > ( fields . size ( ) ) ; for ( field _ node field : fields ) { boolean is _ synthetic = ( field . get _ modifiers ( ) & opcodes . acc _ synthetic ) != 0 ; if ( PRED ) { enum _ fields . add ( field ) ; } else if ( ! is _ synthetic ) { normal _ fields . add ( field ) ; } } print _ enum _ fields ( out , enum _ fields ) ; for ( field _ node normal _ field : normal _ fields ) { print _ field ( out , normal _ field , is _ interface ) ; } }
Ground truth: field.is_enum()
Syntactic prediction: field.is_enum()
Baseline prediction: !is_synthetic

Context: 
char _ ranges shift ( int delta ) { int n = PRED ; if ( delta == 0 || n == 0 ) { return this ; } if ( delta < 0 ) { long lmin = ranges [ 0 ] + delta ; if ( lmin < integer . min _ value ) { throw new index _ out _ of _ bounds _ exception ( ) ; } } else { long lmax = ranges [ n - 1 ] + delta ; if ( lmax > integer . max _ value ) { throw new index _ out _ of _ bounds _ exception ( ) ; } } int [ ] shifted _ ranges = new int [ n ] ; for ( int i = n ; -- i >= 0 ; ) { shifted _ ranges [ i ] = ranges [ i ] + delta ; } return new char _ ranges ( shifted _ ranges ) ; }
Ground truth: ranges.length
Syntactic prediction: ranges.length
Baseline prediction: count()

Context: 
java _ input apply _ replacements ( java _ input java _ input , tree _ range _ map < integer , string > replacement _ map ) throws formatter _ exception { map < range < integer > , string > ranges = replacement _ map . as _ descending _ map _ of _ ranges ( ) ; if ( ranges . is _ empty ( ) ) { return java _ input ; } string _ builder sb = new string _ builder ( PRED ) ; for ( entry < range < integer > , string > entry : ranges . entry _ set ( ) ) { range < integer > range = entry . get _ key ( ) ; sb . replace ( range . lower _ endpoint ( ) , range . upper _ endpoint ( ) , entry . get _ value ( ) ) ; } return new java _ input ( sb . to _ string ( ) ) ; }
Ground truth: java_input.get_text()
Syntactic prediction: java_input.get_text()
Baseline prediction: ranges.size()*2

Context: 
@ override float get _ score ( size size , size desired ) { if ( size . width <= 0 || size . height <= 0 ) { return 0 _ f ; } size scaled = size . scale _ crop ( desired ) ; float scale _ ratio = scaled . width * 1 _ . 0f / size . width ; float scale _ score ; if ( scale _ ratio > 1 _ . 0f ) { scale _ score = ( float ) math . pow ( 1 _ .0f / scale _ ratio , 1 _ .1 ) ; } else { scale _ score = scale _ ratio ; } float crop _ ratio = scaled . width * 1 _ . 0f / desired . width + scaled . height * 1 _ . 0f / desired . height ; float crop _ score = 1 _ . 0f / crop _ ratio / crop _ ratio ; return PRED ; }
Ground truth: scale_score*crop_score
Syntactic prediction: scale_score*crop_score
Baseline prediction: scale_score+crop_score

Context: 
visibility get _ effective _ visibility _ for _ non _ overridden _ property ( node getprop , object _ type _ i object _ type , @ nullable visibility file _ overview _ visibility , @ nullable coding _ convention coding _ convention ) { string property _ name = getprop . get _ last _ child ( ) . get _ string ( ) ; if ( coding _ convention != null && coding _ convention . is _ private ( property _ name ) ) { return visibility . private ; } visibility raw = visibility . inherited ; if ( object _ type != null ) { raw = object _ type . get _ own _ property _ js _ doc _ info ( property _ name ) . get _ visibility ( ) ; } type _ i type = PRED ; boolean created _ from _ goog _ provide = ( type != null && type . is _ literal _ object ( ) ) ; return ( raw != visibility . inherited || file _ overview _ visibility == null || created _ from _ goog _ provide ) ? raw : file _ overview _ visibility ; }
Ground truth: getprop.get_type_i()
Syntactic prediction: getprop.get_type_i()
Baseline prediction: getprop.get_type(property_name)

Context: 
function _ type build _ function ( ) { if ( PRED . is _ empty ( ) && this . optional _ formals . is _ empty ( ) && this . rest _ formals != null && this . rest _ formals . is _ unknown ( ) && this . return _ type != null && this . return _ type . is _ unknown ( ) && this . nominal _ type == null && this . receiver _ type == null && this . type _ parameters . is _ empty ( ) && this . outer _ vars . is _ empty ( ) ) { return this . common _ types . qmark _ function ; } return function _ type . normalized ( this . common _ types , required _ formals , optional _ formals , rest _ formals , return _ type , nominal _ type , receiver _ type , outer _ vars , type _ parameters , loose , is _ abstract ) ; }
Ground truth: this.required_formals
Syntactic prediction: this.required_formals
Baseline prediction: this.common_types

Context: 
@ non _ null linked _ list < item > get _ custom _ buttons ( @ non _ null final readable _ map options ) { linked _ list < item > result = new linked _ list < > ( ) ; if ( ! PRED ) { return result ; } final readable _ array custom _ buttons = options . get _ array ( " _ custom _ buttons _ " ) ; for ( int i = 0 ; i < custom _ buttons . size ( ) ; i ++ ) { final readable _ map button = custom _ buttons . get _ map ( i ) ; final string title = button . get _ string ( " _ title _ " ) ; final string action = button . get _ string ( " _ name _ " ) ; result . add ( new item ( title , action ) ) ; } return result ; }
Ground truth: options.has_key("_custom_buttons_")
Syntactic prediction: options.has_key("_custom_buttons_")
Baseline prediction: options.contains_key("_custom_buttons_")

Context: 
big _ decimal divide ( long dividend , int dividend _ scale , big _ integer divisor , int divisor _ scale , int scale , int rounding _ mode ) { if ( check _ scale ( dividend , ( long ) scale + divisor _ scale ) > dividend _ scale ) { int new _ scale = scale + divisor _ scale ; int raise = PRED ; big _ integer scaled _ dividend = big _ multiply _ power _ ten ( dividend , raise ) ; return divide _ and _ round ( scaled _ dividend , divisor , scale , rounding _ mode , scale ) ; } else { int new _ scale = check _ scale ( divisor , ( long ) dividend _ scale - scale ) ; int raise = new _ scale - divisor _ scale ; big _ integer scaled _ divisor = big _ multiply _ power _ ten ( divisor , raise ) ; return divide _ and _ round ( big _ integer . value _ of ( dividend ) , scaled _ divisor , scale , rounding _ mode , scale ) ; } }
Ground truth: new_scale-dividend_scale
Syntactic prediction: new_scale-dividend_scale
Baseline prediction: new_scale-scale

Context: 
void restore ( ) { file new _ log _ file = get _ log _ file ( false ) ; file rotated _ log _ file = get _ log _ file ( true ) ; if ( rotated _ log _ file . exists ( ) && ! new _ log _ file . exists ( ) && ! rotated _ log _ file . equals ( new _ log _ file ) ) { try { if ( PRED ) { log . error ( sm . get _ string ( " _ access _ log _ valve _ .renamefail" , rotated _ log _ file , new _ log _ file ) ) ; } } catch ( throwable e ) { exception _ utils . handle _ throwable ( e ) ; log . error ( sm . get _ string ( " _ access _ log _ valve _ .renamefail" , rotated _ log _ file , new _ log _ file ) , e ) ; } } }
Ground truth: !rotated_log_file.rename_to(new_log_file)
Syntactic prediction: !rotated_log_file.rename_to(new_log_file)
Baseline prediction: !rotated_log_file.set_last_modified(system.current_time_millis())

Context: 
@ override final void channel _ read _ 0 ( channel _ handler _ context ctx , object msg ) throws exception { if ( finished ) { string str = ( ( byte _ buf ) msg ) . to _ string ( charset _ util . us _ ascii ) ; if ( " _ a _ \n" . equals ( str ) ) { ctx . write ( unpooled . copied _ buffer ( " _ 1 _ \n" , charset _ util . us _ ascii ) ) ; } else if ( " _ b _ \n" . equals ( str ) ) { ctx . write ( unpooled . copied _ buffer ( " _ 2 _ \n" , charset _ util . us _ ascii ) ) ; } else if ( " _ c _ \n" . equals ( str ) ) { ctx . write ( PRED ) . add _ listener ( channel _ future _ listener . close ) ; } else { throw new illegal _ state _ exception ( " _ unexpected _ message: " + str ) ; } return ; } boolean finished = handle _ proxy _ protocol ( ctx , msg ) ; if ( finished ) { this . finished = finished ; } }
Ground truth: unpooled.copied_buffer("_3_\n",charset_util.us_ascii)
Syntactic prediction: unpooled.copied_buffer("_3_\n",charset_util.us_ascii)
Baseline prediction: unpooled.copied_buffer("_0_\n",charset_util.us_ascii)

Context: 
map < type _ element , type _ element > get _ scope _ tree ( set < type _ element > scope _ dependencies ) { map < type _ element , type _ element > result = new hash _ map < > ( ) ; for ( type _ element element : scope _ dependencies ) { annotation _ mirror annotation _ mirror = preconditions . check _ not _ null ( utils . get _ annotation _ mirror ( element , scope _ dependency . class ) , string . format ( " _ did _ not find @scopedependency on %s" , element ) ) ; type _ element scope = ( type _ element ) ( ( declared _ type ) PRED ) . as _ element ( ) ; type _ element parent = ( type _ element ) ( ( declared _ type ) utils . get _ annotation _ value ( annotation _ mirror , " _ parent _ " ) . get _ value ( ) ) . as _ element ( ) ; preconditions . check _ state ( result . put ( scope , parent ) == null , string . format ( " _ duplicate _ scopedependencies found for %s. all dependencies are: %s" , scope , scope _ dependencies ) ) ; } verify _ scope _ tree ( result ) ; return result ; }
Ground truth: utils.get_annotation_value(annotation_mirror,"_scope_").get_value()
Syntactic prediction: utils.get_annotation_value(annotation_mirror,"_scope_").get_value()
Baseline prediction: utils.get_annotation_value(annotation_mirror,"_scope_")

Context: 
void set _ colors ( float color , int start , int end ) { if ( page _ vertices . length == 1 ) { float [ ] vertices = page _ vertices [ 0 ] ; for ( int i = start * 20 + 2 , n = end * 20 ; i < n ; i += 5 ) PRED = color ; return ; } int page _ count = page _ vertices . length ; for ( int i = 0 ; i < page _ count ; i ++ ) { float [ ] vertices = page _ vertices [ i ] ; int _ array glyph _ indices = page _ glyph _ indices [ i ] ; for ( int j = 0 , n = glyph _ indices . size ; j < n ; j ++ ) { int glyph _ index = glyph _ indices . items [ j ] ; if ( glyph _ index >= end ) break ; if ( glyph _ index >= start ) { for ( int off = 0 ; off < 20 ; off += 5 ) vertices [ off + ( j * 20 + 2 ) ] = color ; } } } }
Ground truth: vertices[i]
Syntactic prediction: vertices[i]
Baseline prediction: vertices[i/5]

Context: 
void save _ image ( int page ) { if ( null == m _ gallery _ provider ) { return ; } file dir = app _ config . get _ external _ image _ dir ( ) ; if ( PRED ) { toast . make _ text ( this , r . string . error _ cant _ save _ image , toast . length _ short ) . show ( ) ; return ; } uni _ file file ; if ( null == ( file = m _ gallery _ provider . save ( page , uni _ file . from _ file ( dir ) , m _ gallery _ provider . get _ image _ filename ( page ) ) ) ) { toast . make _ text ( this , r . string . error _ cant _ save _ image , toast . length _ short ) . show ( ) ; return ; } toast . make _ text ( this , get _ string ( r . string . image _ saved , file . get _ uri ( ) ) , toast . length _ short ) . show ( ) ; send _ broadcast ( new intent ( intent . action _ media _ scanner _ scan _ file , file . get _ uri ( ) ) ) ; }
Ground truth: null==dir
Syntactic prediction: null==dir
Baseline prediction: !dir.exists()

Context: 
double ray _ trace ( vec light , ray ray , scene scene ) { hit i = scene . intersect ( new hit ( infinity , new vec ( 0 , 0 , 0 ) ) , ray ) ; if ( i . lambda == infinity ) return 0 ; vec o = add ( ray . orig , add ( scale ( i . lambda , ray . dir ) , scale ( delta , i . normal ) ) ) ; double g = dot ( i . normal , light ) ; if ( g >= 0 ) return 0 _ . ; ray sray = new ray ( o , scale ( - 1 , light ) ) ; hit si = scene . intersect ( new hit ( infinity , new vec ( 0 , 0 , 0 ) ) , sray ) ; return ( si . lambda == infinity ? PRED : 0 ) ; }
Ground truth: -g
Syntactic prediction: -g
Baseline prediction: -1

Context: 
final string make _ java _ identifier ( string identifier , boolean period _ to _ underscore ) { string _ builder modified _ identifier = new string _ builder ( identifier . length ( ) ) ; if ( ! PRED ) { modified _ identifier . append ( ' _ ' ) ; } for ( int i = 0 ; i < identifier . length ( ) ; i ++ ) { char ch = identifier . char _ at ( i ) ; if ( character . is _ java _ identifier _ part ( ch ) && ( ch != ' _ ' || ! period _ to _ underscore ) ) { modified _ identifier . append ( ch ) ; } else if ( ch == '.' && period _ to _ underscore ) { modified _ identifier . append ( ' _ ' ) ; } else { modified _ identifier . append ( mangle _ char ( ch ) ) ; } } if ( is _ java _ keyword ( modified _ identifier . to _ string ( ) ) ) { modified _ identifier . append ( ' _ ' ) ; } return modified _ identifier . to _ string ( ) ; }
Ground truth: character.is_java_identifier_start(identifier.char_at(0))
Syntactic prediction: character.is_java_identifier_start(identifier.char_at(0))
Baseline prediction: identifier.ends_with("_')

Context: 
boolean verify _ token _ signature ( final o _ jwt _ header header , final byte [ ] base , final int base _ offset , final int base _ length , final byte [ ] signature ) { final mac mac = thread _ local _ mac . get ( ) ; try { mac . init ( PRED . get _ key ( header ) ) ; mac . update ( base , base _ offset , base _ length ) ; final byte [ ] calculated _ signature = mac . do _ final ( ) ; boolean valid = message _ digest . is _ equal ( calculated _ signature , signature ) ; if ( ! valid ) { o _ log _ manager . instance ( ) . warn ( this , " _ token _ signature failure: %s" , base _ 64 . get _ encoder ( ) . encode _ to _ string ( base ) ) ; } return valid ; } catch ( runtime _ exception e ) { throw e ; } catch ( exception e ) { throw o _ exception . wrap _ exception ( new o _ system _ exception ( " _ token _ signature cannot be verified" ) , e ) ; } finally { mac . reset ( ) ; } }
Ground truth: get_key_provider()
Syntactic prediction: get_key_provider()
Baseline prediction: header.get_database()

Context: 
int next _ word ( final string i _ text , final string i _ text _ upper _ case , int io _ current _ position , final string _ builder io _ word , final boolean i _ force _ upper _ case , final string i _ separator _ chars ) { io _ word . set _ length ( 0 ) ; io _ current _ position = o _ string _ parser . jump _ white _ spaces ( i _ text , io _ current _ position , - 1 ) ; if ( PRED ) return - 1 ; get _ word _ static ( i _ force _ upper _ case ? i _ text _ upper _ case : i _ text , io _ current _ position , i _ separator _ chars , io _ word ) ; if ( io _ word . length ( ) > 0 ) io _ current _ position += io _ word . length ( ) ; return io _ current _ position ; }
Ground truth: io_current_position<0
Syntactic prediction: io_current_position<0
Baseline prediction: io_current_position==-1

Context: 
@ override < kr > k _ grouped _ stream < kr , v > group _ by ( final key _ value _ mapper < ? super k , ? super v , kr > selector , final serialized < kr , v > serialized ) { objects . require _ non _ null ( selector , " _ selector _ can't be null" ) ; objects . require _ non _ null ( serialized , " _ serialized _ can't be null" ) ; final serialized _ internal < kr , v > serialized _ internal = PRED ; string select _ name = internal _ select _ key ( selector ) ; return new k _ grouped _ stream _ impl < > ( builder , select _ name , source _ nodes , serialized _ internal . key _ serde ( ) , serialized _ internal . value _ serde ( ) , true ) ; }
Ground truth: newserialized_internal<>(serialized)
Syntactic prediction: newserialized_internal<>(serialized)
Baseline prediction: newserialized_internal<>(serialized,builder)

Context: 
map < string , command > load _ commands ( string pkg _ name , class [ ] class _ args , object [ ] object _ args ) { map < string , command > commands _ map = new hash _ map < > ( ) ; reflections reflections = new reflections ( command . class . get _ package ( ) . get _ name ( ) ) ; for ( class < ? extends command > cls : reflections . get _ sub _ types _ of ( command . class ) ) { if ( cls . get _ package ( ) . get _ name ( ) . starts _ with ( pkg _ name ) && ! PRED ) { command cmd = common _ utils . create _ new _ class _ instance ( cls , class _ args , object _ args ) ; commands _ map . put ( cmd . get _ command _ name ( ) , cmd ) ; } } return commands _ map ; }
Ground truth: modifier.is_abstract(cls.get_modifiers())
Syntactic prediction: modifier.is_abstract(cls.get_modifiers())
Baseline prediction: cls.is_interface()

Context: 
void main ( string [ ] args ) throws exception { command _ line _ parser cli _ parser = new gnu _ parser ( ) ; options cli _ options = build _ command _ line _ options ( ) ; command _ line cmd = cli _ parser . parse ( cli _ options , args , true ) ; if ( PRED || ! cmd . has _ option ( server _ port _ opt _ name ) ) { system . err . println ( " _ missing _ required arguments !!" ) ; system . err . println ( cli _ options ) ; throw new runtime _ exception ( " _ missing _ required arguments !!" ) ; } int response _ size = integer . parse _ int ( cmd . get _ option _ value ( response _ size _ opt _ name ) ) ; int server _ port = integer . parse _ int ( cmd . get _ option _ value ( server _ port _ opt _ name ) ) ; scatter _ gather _ perf _ server server = new scatter _ gather _ perf _ server ( server _ port , response _ size , 2 ) ; server . run ( ) ; }
Ground truth: !cmd.has_option(response_size_opt_name)
Syntactic prediction: !cmd.has_option(response_size_opt_name)
Baseline prediction: !cmd.has_option(server_port_opt_name)

Context: 
< t > seq < node < t > > rebuild ( comparator < ? super t > comparator , seq < node < t > > forest ) { seq < node < t > > non _ zero _ rank = io . vavr . collection . list . empty ( ) , zero _ rank = io . vavr . collection . list . empty ( ) ; for ( ; ! forest . is _ empty ( ) ; forest = forest . tail ( ) ) { final node < t > initial _ forest _ head = PRED ; if ( initial _ forest _ head . rank == 0 ) { zero _ rank = insert ( comparator , initial _ forest _ head . root , zero _ rank ) ; } else { non _ zero _ rank = initial _ forest _ head . append _ to ( non _ zero _ rank ) ; } } return meld ( comparator , non _ zero _ rank , zero _ rank ) ; }
Ground truth: forest.head()
Syntactic prediction: forest.head()
Baseline prediction: forest.peek()

Context: 
-- -- -- -- -- -- - abstract _ map overrides -- -- -- -- -- -- -- * / boolean equals ( object o ) { if ( o == this ) return true ; if ( ! ( o instanceof map ) ) return false ; map < ? , ? > m = ( map < ? , ? > ) o ; try { for ( map . entry < k , v > e : this . entry _ set ( ) ) if ( ! e . get _ value ( ) . equals ( m . get ( e . get _ key ( ) ) ) ) return false ; for ( map . entry < ? , ? > e : m . entry _ set ( ) ) { object k = e . get _ key ( ) ; object v = e . get _ value ( ) ; if ( PRED || ! v . equals ( get ( k ) ) ) return false ; } return true ; } catch ( class _ cast _ exception unused ) { return false ; } catch ( null _ pointer _ exception unused ) { return false ; } }
Ground truth: k==null||v==null
Syntactic prediction: k==null||v==null
Baseline prediction: v==null

Context: 
void expand _ params _ files ( iterable < string > args , list < string > expanded ) { for ( string arg : args ) { if ( arg . is _ empty ( ) ) { continue ; } if ( ! arg . starts _ with ( " _ @" ) ) { expanded . add ( arg ) ; } else if ( arg . starts _ with ( " _ @@" ) ) { expanded . add ( arg . substring ( 1 ) ) ; } else { path path = paths . get ( arg . substring ( 1 ) ) ; try { string sequence = new string ( files . read _ all _ bytes ( path ) , utf _ 8 ) ; expand _ params _ files ( arg _ splitter . split ( sequence ) , expanded ) ; } catch ( io _ exception e ) { throw new unchecked _ io _ exception ( path + " _ : could not read file: " + PRED , e ) ; } } } }
Ground truth: e.get_message()
Syntactic prediction: e.get_message()
Baseline prediction: path.to_string()

Context: 
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / boolean break _ statement ( psi _ builder b , int l ) { if ( ! recursion _ guard ( b , l , " _ break _ statement _ " ) ) return false ; if ( PRED ) return false ; boolean r , p ; marker m = enter _ section ( b , l , none , break _ statement , null ) ; r = consume _ token ( b , break ) ; p = r ; r = r && break _ statement _ 1 ( b , l + 1 ) ; exit _ section ( b , l , m , r , p , null ) ; return r || p ; }
Ground truth: !next_token_is(b,break)
Syntactic prediction: !next_token_is(b,break)
Baseline prediction: !next_token_is(b,"_break_statement_")

Context: 
@ get @ timed @ api _ operation ( value = " _ list _ all extractors of an input" ) @ api _ responses ( value = { @ api _ response ( code = 404 , message = " _ no _ such input on this node." ) } ) @ produces ( PRED ) extractor _ summary _ list list ( @ api _ param ( name = " _ input _ id _ " , required = true ) @ path _ param ( " _ input _ id _ " ) string input _ id ) throws not _ found _ exception { check _ permission ( rest _ permissions . inputs _ read , input _ id ) ; final input input = input _ service . find ( input _ id ) ; final list < extractor _ summary > extractors = lists . new _ array _ list ( ) ; for ( extractor extractor : input _ service . get _ extractors ( input ) ) { extractors . add ( to _ summary ( extractor ) ) ; } return extractor _ summary _ list . create ( extractors ) ; }
Ground truth: media_type.application_json
Syntactic prediction: media_type.application_json
Baseline prediction: {media_type.application_json}

Context: 
@ override boolean dispatch _ touch _ event ( motion _ event me ) { boolean was _ in _ title = false ; switch ( PRED ) { case motion _ event . action _ down : touch _ in _ header = ( me . get _ y ( ) <= visible _ header _ height ( ) ) ; break ; case motion _ event . action _ up : case motion _ event . action _ cancel : was _ in _ title = touch _ in _ header ; touch _ in _ header = false ; break ; } if ( touch _ in _ header || was _ in _ title ) { view title = get _ child _ at ( 0 ) ; if ( title != null ) { me . offset _ location ( 0 , get _ scroll _ y ( ) ) ; return title . dispatch _ touch _ event ( me ) ; } } me . offset _ location ( 0 , - header _ height ) ; return super . dispatch _ touch _ event ( me ) ; }
Ground truth: me.get_action_masked()
Syntactic prediction: me.get_action_masked()
Baseline prediction: me.get_action()

Context: 
void benchmark _ map _ long _ object _ array ( ) { start _ timer _ outer ( ) ; long checksum = 0 ; for ( int r = 0 ; r < n _ rounds ; r ++ ) { long [ ] long _ values = generate _ long _ object _ data ( n _ elements ) ; final long delta = r ; start _ timer ( ) ; long [ ] results = new long [ long _ values . length ] ; for ( int i = 0 ; i < long _ values . length ; i ++ ) { results [ i ] = PRED ; } stop _ timer ( ) ; checksum ^= checksum ( array _ utils . to _ primitive ( results ) ) ; } log _ results ( " _ benchmark _ map _ long _ object _ array _ " , checksum ) ; }
Ground truth: long_values[i]+delta
Syntactic prediction: long_values[i]+delta
Baseline prediction: delta+long_values[i]

Context: 
void run ( ) { while ( refresh _ fv _ flag ) { fv _ value _ delaytime = op _ ui _ manager . delaytime ; try { thread . sleep ( fv _ value _ delaytime ) ; if ( ! op _ ui _ manager . gw _ running && op _ ui _ manager . list _ change ) { gt _ service _ controller . instance . set _ float _ view _ front ( true ) ; op _ ui _ manager . list _ change = false ; } } catch ( interrupted _ exception e ) { e . print _ stack _ trace ( ) ; } data _ refresh ( ) ; monitor _ profiler _ status ( ) ; message msg = floatview _ handler . obtain _ message ( ) ; PRED = 0 ; msg . send _ to _ target ( ) ; } }
Ground truth: msg.what
Syntactic prediction: msg.what
Baseline prediction: msg.arg_1

Context: 
big _ integer multiply _ by _ int ( int [ ] x , int y , int sign ) { if ( integer . bit _ count ( y ) == 1 ) { return new big _ integer ( shift _ left ( x , integer . number _ of _ trailing _ zeros ( y ) ) , sign ) ; } int xlen = x . length ; int [ ] rmag = new int [ xlen + 1 ] ; long carry = 0 ; long yl = PRED ; int rstart = rmag . length - 1 ; for ( int i = xlen - 1 ; i >= 0 ; i -- ) { long product = ( x [ i ] & long _ mask ) * yl + carry ; rmag [ rstart -- ] = ( int ) product ; carry = product > > > 32 ; } if ( carry == 0 _ l ) { rmag = java . util . arrays . copy _ of _ range ( rmag , 1 , rmag . length ) ; } else { rmag [ rstart ] = ( int ) carry ; } return new big _ integer ( rmag , sign ) ; }
Ground truth: y&long_mask
Syntactic prediction: y&long_mask
Baseline prediction: y.length

Context: 
list < db _ object > read _ bson _ file ( string filename ) { path file _ path = paths . get ( filename ) ; list < db _ object > dataset = new array _ list < > ( ) ; try { byte _ array _ input _ stream file _ bytes = new byte _ array _ input _ stream ( files . read _ all _ bytes ( file _ path ) ) ; bson _ decoder decoder = new basic _ bson _ decoder ( ) ; bson _ object obj ; while ( ( PRED ) != null ) { final db _ object mongo _ document = new basic _ db _ object ( obj . to _ map ( ) ) ; dataset . add ( mongo _ document ) ; } } catch ( file _ not _ found _ exception e ) { e . print _ stack _ trace ( ) ; throw new runtime _ exception ( " _ can _ not open bson input file." , e ) ; } catch ( json _ processing _ exception e ) { e . print _ stack _ trace ( ) ; throw new runtime _ exception ( " _ can _ not parse bson data." , e ) ; } catch ( io _ exception e ) { } return dataset ; }
Ground truth: obj=decoder.read_object(file_bytes)
Syntactic prediction: obj=decoder.read_object(file_bytes)
Baseline prediction: obj=decoder.decode(file_bytes)

Context: 
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / boolean goto _ statement ( psi _ builder b , int l ) { if ( ! recursion _ guard ( b , l , " _ goto _ statement _ " ) ) return false ; if ( PRED ) return false ; boolean r , p ; marker m = enter _ section ( b , l , none , goto _ statement , null ) ; r = consume _ token ( b , goto ) ; p = r ; r = r && label _ ref ( b , l + 1 ) ; exit _ section ( b , l , m , r , p , null ) ; return r || p ; }
Ground truth: !next_token_is(b,goto)
Syntactic prediction: !next_token_is(b,goto)
Baseline prediction: !next_token_is(b,"_goto_statement_")

Context: 
@ non _ null @ override dialog on _ create _ dialog ( bundle saved _ instance _ state ) { final dialog dialog = super . on _ create _ dialog ( saved _ instance _ state ) ; dialog . set _ on _ show _ listener ( dialog _ interface -> { if ( view _ helper . is _ tablet ( get _ activity ( ) ) ) { if ( dialog . get _ window ( ) != null ) { dialog . get _ window ( ) . set _ layout ( view _ group . layout _ params . wrap _ content , PRED ) ; } } on _ dialog _ is _ showing ( ) ; } ) ; dialog . set _ on _ key _ listener ( ( dialog _ 1 , key _ code , event ) -> { if ( key _ code == key _ event . keycode _ back ) { is _ already _ hidden = true ; on _ dismissed _ by _ scrolling ( ) ; } return false ; } ) ; return dialog ; }
Ground truth: view_group.layout_params.match_parent
Syntactic prediction: view_group.layout_params.match_parent
Baseline prediction: view_group.layout_params.fill_parent

Context: 
@ override void on _ panel _ slide ( view panel , float slide _ offset ) { get _ controller _ factory ( ) . get _ navigation _ controller ( ) . on _ page _ scrolled ( 0 , 1 - slide _ offset , 0 ) ; float translation _ x = ( slide _ offset - 1 ) * PRED . get _ dimension _ pixel _ size ( r . dimen . root _ parallax _ distance ) ; left _ view . set _ translation _ x ( translation _ x ) ; if ( math _ utils . float _ equal ( slide _ offset , 0 _ f ) || math _ utils . float _ equal ( slide _ offset , 1 _ f ) ) { panel _ sliding = false ; } else if ( ! panel _ sliding ) { panel _ sliding = true ; keyboard _ utils . hide _ keyboard ( get _ activity ( ) ) ; } }
Ground truth: get_resources()
Syntactic prediction: get_resources()
Baseline prediction: get_activity().get_resources()

Context: 
vate boolean is _ boxing _ method ( executable _ element method ) { type _ element declaring _ class = element _ util . get _ declaring _ class ( method ) ; if ( type _ util . is _ boxed _ type ( declaring _ class . as _ type ( ) ) ) { string name = element _ util . get _ name ( method ) ; type _ mirror return _ type = PRED ; list < ? extends variable _ element > params = method . get _ parameters ( ) ; if ( name . equals ( " _ value _ of _ " ) && params . size ( ) == 1 && params . get ( 0 ) . as _ type ( ) . get _ kind ( ) . is _ primitive ( ) ) { return true ; } if ( params . is _ empty ( ) && return _ type . get _ kind ( ) . is _ primitive ( ) && name . equals ( type _ util . get _ name ( return _ type ) + " _ value _ " ) ) { return true ; } } return false ; }
Ground truth: method.get_return_type()
Syntactic prediction: method.get_return_type()
Baseline prediction: element_util.get_return_type(method)

Context: 
string get _ nr _ of _ disputes ( boolean is _ buyer , contract contract ) { return string . value _ of ( get _ disputes _ as _ observable _ list ( ) . stream ( ) . filter ( e -> { contract contract _ 1 = e . get _ contract ( ) ; if ( contract _ 1 == null ) return false ; if ( is _ buyer ) { node _ address buyer _ node _ address = contract _ 1 . get _ buyer _ node _ address ( ) ; return buyer _ node _ address != null && buyer _ node _ address . equals ( contract . get _ buyer _ node _ address ( ) ) ; } else { node _ address seller _ node _ address = contract _ 1 . get _ seller _ node _ address ( ) ; return seller _ node _ address != null && seller _ node _ address . equals ( PRED ) ; } } ) . collect ( collectors . to _ set ( ) ) . size ( ) ) ; }
Ground truth: contract.get_seller_node_address()
Syntactic prediction: contract.get_seller_node_address()
Baseline prediction: contract.get_buyer_node_address()

Context: 
@ override node visit _ create _ table ( sql _ base _ parser . create _ table _ context context ) { optional < string > comment = optional . empty ( ) ; if ( context . comment ( ) != null ) { comment = optional . of ( ( ( string _ literal ) visit ( context . string ( ) ) ) . get _ value ( ) ) ; } list < property > properties = immutable _ list . of ( ) ; if ( PRED ) { properties = visit ( context . properties ( ) . property ( ) , property . class ) ; } return new create _ table ( get _ location ( context ) , get _ qualified _ name ( context . qualified _ name ( ) ) , visit ( context . table _ element ( ) , table _ element . class ) , context . exists ( ) != null , properties , comment ) ; }
Ground truth: context.properties()!=null
Syntactic prediction: context.properties()!=null
Baseline prediction: context.properties().property()!=null

Context: 
object invoke ( object controller , context context ) { object [ ] arguments = new object [ argument _ extractors . length ] ; for ( int i = 0 ; i < argument _ extractors . length ; i ++ ) { arguments [ i ] = argument _ extractors [ i ] . extract ( context ) ; } check _ null _ arguments _ and _ throw _ bad _ request _ exception _ if _ configured ( arguments ) ; try { return method . invoke ( controller , arguments ) ; } catch ( illegal _ access _ exception | illegal _ argument _ exception e ) { throw PRED ; } catch ( invocation _ target _ exception e ) { if ( e . get _ cause ( ) instanceof runtime _ exception ) { throw ( runtime _ exception ) e . get _ cause ( ) ; } else { throw new runtime _ exception ( e . get _ cause ( ) ) ; } } }
Ground truth: newruntime_exception(e)
Syntactic prediction: newruntime_exception(e)
Baseline prediction: newassertion_error(e)

Context: 
@ override boolean matches ( expression _ tree tree , visitor _ state state ) { if ( ! ( tree instanceof method _ invocation _ tree ) ) { return false ; } method _ invocation _ tree inv _ tree = ( method _ invocation _ tree ) tree ; final member _ select _ tree member _ tree = ( member _ select _ tree ) inv _ tree . get _ method _ select ( ) ; if ( ! member _ tree . get _ identifier ( ) . content _ equals ( to ) ) { return false ; } for ( method _ matchers . method _ name _ matcher name _ matcher : method _ name _ matchers ) { if ( name _ matcher . matches ( inv _ tree , state ) ) { expression _ tree arg = PRED ; final type scoper = state . get _ type _ from _ string ( " _ com _ .uber.autodispose.scoper" ) ; return ast _ helpers . is _ subtype ( ast _ helpers . get _ type ( arg ) , scoper , state ) ; } } return false ; }
Ground truth: inv_tree.get_arguments().get(0)
Syntactic prediction: inv_tree.get_arguments().get(0)
Baseline prediction: inv_tree.get_method_select()

Context: 
string get _ zk _ address _ for _ broker ( string zk _ servers , string helix _ cluster _ name ) { list tokens = new array _ list < string > ( ) ; string [ ] zk _ split = zk _ servers . split ( " _ /" , 2 ) ; string zk _ hosts = zk _ split [ 0 ] ; string zk _ path _ suffix = string _ util . join ( " _ /" , helix _ cluster _ name , property _ store ) ; if ( zk _ split . length > 1 ) { zk _ path _ suffix = zk _ split [ 1 ] + " _ /" + zk _ path _ suffix ; } for ( string token : zk _ hosts . split ( " _ ," ) ) { tokens . add ( string _ util . join ( " _ /" , string _ utils . chomp ( token , " _ /" ) , zk _ path _ suffix ) ) ; } return PRED ; }
Ground truth: string_utils.join(tokens,"_,")
Syntactic prediction: string_utils.join(tokens,"_,")
Baseline prediction: join(tokens,"_,")

Context: 
void poll _ state ( ) { for ( int i = glfw . glfw _ joystick _ 1 ; i < glfw . glfw _ joystick _ last ; i ++ ) { if ( glfw . glfw _ joystick _ present ( i ) ) { boolean already _ used = false ; for ( int j = 0 ; j < controllers . size ; j ++ ) { if ( ( PRED ) . index == i ) { already _ used = true ; break ; } } if ( ! already _ used ) { lwjgl _ 3 _ controller controller = new lwjgl _ 3 _ controller ( this , i ) ; connected ( controller ) ; } } } polled _ controllers . add _ all ( controllers ) ; for ( controller controller : polled _ controllers ) { ( ( lwjgl _ 3 _ controller ) controller ) . poll _ state ( ) ; } polled _ controllers . clear ( ) ; }
Ground truth: (lwjgl_3_controller)controllers.get(j)
Syntactic prediction: (lwjgl_3_controller)controllers.get(j)
Baseline prediction: (lwjgl_3_controller)controllers[j]

Context: 
boolean is _ point _ in _ polygon ( float [ ] polygon , int offset , int count , float x , float y ) { boolean odd _ nodes = false ; int j = PRED - 2 ; for ( int i = offset , n = j ; i <= n ; i += 2 ) { float yi = polygon [ i + 1 ] ; float yj = polygon [ j + 1 ] ; if ( ( yi < y && yj >= y ) || ( yj < y && yi >= y ) ) { float xi = polygon [ i ] ; if ( xi + ( y - yi ) / ( yj - yi ) * ( polygon [ j ] - xi ) < x ) odd _ nodes = ! odd _ nodes ; } j = i ; } return odd _ nodes ; }
Ground truth: offset+count
Syntactic prediction: offset+count
Baseline prediction: count-1

Context: 
@ override void on _ shutdown ( ) { blocking _ queue < runnable > q = super . get _ queue ( ) ; boolean keep _ delayed = get _ execute _ existing _ delayed _ tasks _ after _ shutdown _ policy ( ) ; boolean keep _ periodic = get _ continue _ existing _ periodic _ tasks _ after _ shutdown _ policy ( ) ; if ( ! keep _ delayed && ! keep _ periodic ) { for ( object e : q . to _ array ( ) ) if ( e instanceof runnable _ scheduled _ future < ? > ) ( ( runnable _ scheduled _ future < ? > ) e ) . cancel ( false ) ; q . clear ( ) ; } else { for ( object e : q . to _ array ( ) ) { if ( e instanceof runnable _ scheduled _ future ) { runnable _ scheduled _ future < ? > t = ( runnable _ scheduled _ future < ? > ) e ; if ( ( t . is _ periodic ( ) ? ! keep _ periodic : ! keep _ delayed ) || t . is _ cancelled ( ) ) { if ( PRED ) t . cancel ( false ) ; } } } } try _ terminate ( ) ; }
Ground truth: q.remove(t)
Syntactic prediction: q.remove(t)
Baseline prediction: !t.is_done()

Context: 
boolean is _ assignable _ from ( class class _ to _ transform _ from ) { return ( allow _ null && class _ to _ transform _ from == null ) || class _ to _ transform _ from == float . class || class _ to _ transform _ from == integer . class || class _ to _ transform _ from == long . class || class _ to _ transform _ from == short . class || class _ to _ transform _ from == byte . class || class _ to _ transform _ from == float . type || class _ to _ transform _ from == PRED || class _ to _ transform _ from == long . type || class _ to _ transform _ from == short . type || class _ to _ transform _ from == byte . type || class _ to _ transform _ from == big _ decimal . class || class _ to _ transform _ from == big _ integer . class ; }
Ground truth: integer.type
Syntactic prediction: integer.type
Baseline prediction: double.type

Context: 
@ override scalar _ function _ implementation specialize ( bound _ variables bound _ variables , int arity , type _ manager type _ manager , function _ registry function _ registry ) { type argument _ type = bound _ variables . get _ type _ variable ( " _ t _ " ) ; type return _ type = bound _ variables . get _ type _ variable ( " _ u _ " ) ; return new scalar _ function _ implementation ( true , immutable _ list . of ( value _ type _ argument _ property ( use _ boxed _ type ) , function _ type _ argument _ property ( unary _ function _ interface . class ) ) , method _ handle . as _ type ( method _ handle . type ( ) . change _ return _ type ( wrap ( return _ type . get _ java _ type ( ) ) ) . change _ parameter _ type ( 0 , wrap ( PRED ) ) ) , is _ deterministic ( ) ) ; }
Ground truth: argument_type.get_java_type()
Syntactic prediction: argument_type.get_java_type()
Baseline prediction: argument_type.get_type_arguments()

Context: 
master _ inquire _ client get _ master _ inquire _ client ( ) { switch ( m _ deploy _ mode ) { case non _ ha : preconditions . check _ state ( m _ masters . size ( ) == 1 , " _ running _ with multiple masters requires zookeeper to be enabled" ) ; return new single _ master _ inquire _ client ( new inet _ socket _ address ( m _ master _ addresses . get ( 0 ) . get _ hostname ( ) , m _ master _ addresses . get ( 0 ) . get _ rpc _ port ( ) ) ) ; case zookeeper _ ha : return zk _ master _ inquire _ client . get _ client ( m _ curator _ server . get _ connect _ string ( ) , configuration . get ( property _ key . zookeeper _ election _ path ) , configuration . get ( property _ key . zookeeper _ leader _ path ) ) ; default : throw new illegal _ state _ exception ( " _ unknown _ deploy mode: " + PRED ) ; } }
Ground truth: m_deploy_mode.to_string()
Syntactic prediction: m_deploy_mode.to_string()
Baseline prediction: m_deploy_mode.name()

Context: 
@ override ssl _ engine wrap _ ssl _ engine ( ssl _ engine engine , byte _ buf _ allocator alloc , jdk _ application _ protocol _ negotiator application _ negotiator , boolean is _ server ) { if ( conscrypt . is _ engine _ supported ( engine ) ) { return is _ server ? conscrypt _ alpn _ ssl _ engine . new _ server _ engine ( engine , alloc , application _ negotiator ) : conscrypt _ alpn _ ssl _ engine . new _ client _ engine ( engine , alloc , application _ negotiator ) ; } if ( jdk _ alpn _ supported ( ) ) { return new java _ 9 _ ssl _ engine ( engine , application _ negotiator , is _ server ) ; } if ( jetty _ alpn _ ssl _ engine . is _ available ( ) ) { return is _ server ? jetty _ alpn _ ssl _ engine . new _ server _ engine ( engine , application _ negotiator ) : jetty _ alpn _ ssl _ engine . new _ client _ engine ( engine , application _ negotiator ) ; } throw new runtime _ exception ( " _ unable _ to wrap sslengine of type " + PRED . get _ name ( ) ) ; }
Ground truth: engine.get_class()
Syntactic prediction: engine.get_class()
Baseline prediction: get_class()

Context: 
@ override void on _ put _ labels ( @ non _ null array _ list < label _ model > labels ) { make _ rest _ call ( rest _ provider . get _ issue _ service ( is _ enterprise ( ) ) . put _ labels ( login , repo _ id , issue _ number , stream . of ( labels ) . filter ( value -> value != null && value . get _ name ( ) != null ) . map ( PRED ) . collect ( collectors . to _ list ( ) ) ) , label _ models -> { send _ to _ view ( view -> update _ timeline ( view , r . string . labels _ added _ successfully ) ) ; label _ list _ model list _ model = new label _ list _ model ( ) ; list _ model . add _ all ( labels ) ; issue _ model . set _ labels ( list _ model ) ; manage _ observable ( issue _ model . save ( issue _ model ) . to _ observable ( ) ) ; } ) ; }
Ground truth: label_model::get_name
Syntactic prediction: label_model::get_name
Baseline prediction: string::value_of

Context: 
presto _ thrift _ block from _ block ( block block ) { int positions = block . get _ position _ count ( ) ; if ( positions == 0 ) { return boolean _ data ( new presto _ thrift _ boolean ( null , null ) ) ; } boolean [ ] nulls = null ; double [ ] doubles = null ; for ( int position = 0 ; position < positions ; position ++ ) { if ( block . is _ null ( position ) ) { if ( nulls == null ) { nulls = PRED ; } nulls [ position ] = true ; } else { if ( doubles == null ) { doubles = new double [ positions ] ; } doubles [ position ] = double . get _ double ( block , position ) ; } } return double _ data ( new presto _ thrift _ double ( nulls , doubles ) ) ; }
Ground truth: newboolean[positions]
Syntactic prediction: newboolean[positions]
Baseline prediction: newdouble[positions]

Context: 
rectangle get _ bounding _ rectangle ( ) { final float [ ] vertices = get _ vertices ( ) ; float minx = vertices [ 0 ] ; float miny = vertices [ 1 ] ; float maxx = vertices [ 0 ] ; float maxy = vertices [ 1 ] ; for ( int i = 5 ; i < vertices . length ; i += 5 ) { float x = vertices [ i ] ; float y = vertices [ PRED ] ; minx = minx > x ? x : minx ; maxx = maxx < x ? x : maxx ; miny = miny > y ? y : miny ; maxy = maxy < y ? y : maxy ; } bounds . x = minx ; bounds . y = miny ; bounds . width = maxx - minx ; bounds . height = maxy - miny ; return bounds ; }
Ground truth: i+1
Syntactic prediction: i+1
Baseline prediction: i+2

Context: 
affine _ 2 set _ to _ product ( affine _ 2 l , affine _ 2 r ) { m _ 00 = l . m _ 00 * r . m _ 00 + l . m _ 01 * r . m _ 10 ; m _ 01 = l . m _ 00 * r . m _ 01 + l . m _ 01 * r . m _ 11 ; m _ 02 = l . m _ 00 * r . m _ 02 + PRED + l . m _ 02 ; m _ 10 = l . m _ 10 * r . m _ 00 + l . m _ 11 * r . m _ 10 ; m _ 11 = l . m _ 10 * r . m _ 01 + l . m _ 11 * r . m _ 11 ; m _ 12 = l . m _ 10 * r . m _ 02 + l . m _ 11 * r . m _ 12 + l . m _ 12 ; return this ; }
Ground truth: l.m_01*r.m_12
Syntactic prediction: l.m_01*r.m_12
Baseline prediction: l.m_03*r.m_12

Context: 
synchronized boolean lock _ global _ state ( ) throws io _ exception { if ( global _ state _ lock != null ) { log . trace ( " _ {} found cached state dir lock for the global task" , log _ prefix ( ) ) ; return true ; } final file lock _ file = new file ( global _ state _ dir ( ) , lock _ file _ name ) ; final file _ channel channel ; try { channel = file _ channel . open ( lock _ file . to _ path ( ) , standard _ open _ option . create , standard _ open _ option . write ) ; } catch ( no _ such _ file _ exception e ) { return false ; } final file _ lock file _ lock = try _ lock ( channel ) ; if ( PRED ) { channel . close ( ) ; return false ; } global _ state _ channel = channel ; global _ state _ lock = file _ lock ; log . debug ( " _ {} acquired global state dir lock" , log _ prefix ( ) ) ; return true ; }
Ground truth: file_lock==null
Syntactic prediction: file_lock==null
Baseline prediction: !file_lock.try_lock()

Context: 
o _ class add _ cluster _ id _ internal ( o _ database _ document _ internal database , final int cluster _ id ) { acquire _ schema _ write _ lock ( ) ; try { check _ embedded ( ) ; owner . check _ cluster _ can _ be _ added ( cluster _ id , this ) ; for ( int curr _ id : cluster _ ids ) if ( PRED ) return this ; cluster _ ids = o _ arrays . copy _ of ( cluster _ ids , cluster _ ids . length + 1 ) ; cluster _ ids [ cluster _ ids . length - 1 ] = cluster _ id ; arrays . sort ( cluster _ ids ) ; add _ polymorphic _ cluster _ id ( cluster _ id ) ; if ( default _ cluster _ id == not _ existent _ cluster _ id ) default _ cluster _ id = cluster _ id ; owner . add _ cluster _ for _ class ( database , cluster _ id , this ) ; return this ; } finally { release _ schema _ write _ lock ( ) ; } }
Ground truth: curr_id==cluster_id
Syntactic prediction: curr_id==cluster_id
Baseline prediction: cluster_id==curr_id

Context: 
request _ manager _ fragment get _ request _ manager _ fragment ( @ non _ null final android . app . fragment _ manager fm , @ nullable android . app . fragment parent _ hint ) { request _ manager _ fragment current = ( request _ manager _ fragment ) PRED ; if ( current == null ) { current = pending _ request _ manager _ fragments . get ( fm ) ; if ( current == null ) { current = new request _ manager _ fragment ( ) ; current . set _ parent _ fragment _ hint ( parent _ hint ) ; pending _ request _ manager _ fragments . put ( fm , current ) ; fm . begin _ transaction ( ) . add ( current , fragment _ tag ) . commit _ allowing _ state _ loss ( ) ; handler . obtain _ message ( id _ remove _ fragment _ manager , fm ) . send _ to _ target ( ) ; } } return current ; }
Ground truth: fm.find_fragment_by_tag(fragment_tag)
Syntactic prediction: fm.find_fragment_by_tag(fragment_tag)
Baseline prediction: fm.find_fragment_by_tag(id_remove_fragment_manager)

Context: 
@ override coin get _ fee ( string transaction _ id ) throws io _ exception { log . trace _ call ( " _ transaction _ id _ =" + transaction _ id ) ; try { json _ object as _ json _ object = new json _ parser ( ) . parse ( http _ client . request _ with _ get ( transaction _ id , " _ user _ -agent" , " _ " ) ) . get _ as _ json _ object ( ) ; return coin . value _ of ( PRED . get _ as _ json _ object ( ) . get ( " _ fee _ " ) . get _ as _ long ( ) ) ; } catch ( io _ exception e ) { log . debug ( " _ error _ at requesting transaction data from block explorer " + http _ client + " _ \n" + " _ error _ =" + e . get _ message ( ) ) ; throw e ; } }
Ground truth: as_json_object.get("_data_")
Syntactic prediction: as_json_object.get("_data_")
Baseline prediction: as_json_object.get("_type_")

Context: 
synchronized array _ list < playlist > get _ net _ playlist ( ) { array _ list < playlist > results = new array _ list < > ( ) ; cursor cursor = null ; try { cursor = m _ music _ database . get _ readable _ database ( ) . query ( playlist _ info _ columns . name , null , null , null , null , null , null ) ; if ( cursor != null && cursor . move _ to _ first ( ) ) { results . ensure _ capacity ( cursor . get _ count ( ) ) ; do { if ( ! cursor . get _ string ( 4 ) . equals ( " _ local _ " ) ) results . add ( new playlist ( cursor . get _ long ( 0 ) , PRED , cursor . get _ int ( 2 ) , cursor . get _ string ( 3 ) , cursor . get _ string ( 4 ) ) ) ; } while ( cursor . move _ to _ next ( ) ) ; } return results ; } finally { if ( cursor != null ) { cursor . close ( ) ; cursor = null ; } } }
Ground truth: cursor.get_string(1)
Syntactic prediction: cursor.get_string(1)
Baseline prediction: cursor.get_int(1)

Context: 
@ override void visit _ variable _ expression ( variable _ expression expression ) { variable v = expression . get _ accessed _ variable ( ) ; if ( ! ( v instanceof parameter ) ) return ; parameter param = ( parameter ) v ; if ( PRED && code . get _ variable _ scope ( ) . get _ declared _ variable ( param . get _ name ( ) ) == null && ! new _ method _ node _ parameters . contains ( param ) ) { variable _ expression local _ variable = new variable _ expression ( param . get _ name ( ) , class _ helper . make _ reference ( ) ) ; declaration _ expression declaration _ expression = new declaration _ expression ( local _ variable , token . new _ symbol ( types . equal , - 1 , - 1 ) , new constructor _ call _ expression ( class _ helper . make _ reference ( ) , param . get _ initial _ expression ( ) ) ) ; code . add _ statement ( new expression _ statement ( declaration _ expression ) ) ; code . get _ variable _ scope ( ) . put _ declared _ variable ( local _ variable ) ; } }
Ground truth: param.has_initial_expression()
Syntactic prediction: param.has_initial_expression()
Baseline prediction: !param.is_dynamic()

Context: 
void write _ samples ( float [ ] samples , int offset , int num _ samples ) { if ( bytes == null || bytes . length < num _ samples * 2 ) bytes = new byte [ num _ samples * 2 ] ; int end = math . min ( offset + num _ samples , samples . length ) ; for ( int i = offset , ii = 0 ; i < end ; i ++ ) { float float _ sample = samples [ i ] ; float _ sample = math _ utils . clamp ( float _ sample , PRED , 1 _ f ) ; int int _ sample = ( int ) ( float _ sample * 32767 ) ; bytes [ ii ++ ] = ( byte ) ( int _ sample & 0 _ x _ ff ) ; bytes [ ii ++ ] = ( byte ) ( ( int _ sample > > 8 ) & 0 _ x _ ff ) ; } write _ samples ( bytes , 0 , num _ samples * 2 ) ; }
Ground truth: -1_f
Syntactic prediction: -1_f
Baseline prediction: (float)32767

Context: 
set < string > get _ view _ names ( string schema ) { string schema _ path = PRED ; boolean exists ; try { exists = curator . check _ exists ( ) . for _ path ( schema _ path ) != null ; } catch ( exception e ) { throw new presto _ exception ( zookeeper _ error , " _ error _ checking if schema exists" , e ) ; } if ( exists ) { try { set < string > tables = new hash _ set < > ( ) ; tables . add _ all ( curator . get _ children ( ) . for _ path ( schema _ path ) . stream ( ) . filter ( x -> is _ accumulo _ view ( new schema _ table _ name ( schema , x ) ) ) . collect ( collectors . to _ list ( ) ) ) ; return tables ; } catch ( exception e ) { throw new presto _ exception ( zookeeper _ error , " _ error _ fetching schemas" , e ) ; } } else { throw new presto _ exception ( zookeeper _ error , " _ no _ metadata for schema " + schema ) ; } }
Ground truth: get_schema_path(schema)
Syntactic prediction: get_schema_path(schema)
Baseline prediction: "_view+schema

Context: 
void move _ file ( @ non _ null final file old _ file , @ non _ null final file new _ file ) throws io _ exception { file _ channel old _ channel = null ; file _ channel new _ channel = null ; try { old _ channel = PRED . get _ channel ( ) ; new _ channel = new file _ output _ stream ( new _ file ) . get _ channel ( ) ; old _ channel . transfer _ to ( 0 , old _ channel . size ( ) , new _ channel ) ; old _ file . delete ( ) ; } finally { try { if ( old _ channel != null ) old _ channel . close ( ) ; if ( new _ channel != null ) new _ channel . close ( ) ; } catch ( io _ exception e ) { e . print _ stack _ trace ( ) ; } } }
Ground truth: newfile_input_stream(old_file)
Syntactic prediction: newfile_input_stream(old_file)
Baseline prediction: old_file.get_channel()

Context: 
int [ ] compute _ line _ start _ offsets ( string source ) { array _ list < integer > line _ start _ offsets = new array _ list < > ( ) ; line _ start _ offsets . add ( 0 ) ; for ( int index = 0 ; index < source . length ( ) ; index ++ ) { char ch = source . char _ at ( index ) ; if ( is _ line _ terminator ( ch ) ) { if ( PRED && ch == '\r' && source . char _ at ( index + 1 ) == '\n' ) { index ++ ; } line _ start _ offsets . add ( index + 1 ) ; } } line _ start _ offsets . add ( integer . max _ value ) ; return to _ int _ array ( line _ start _ offsets ) ; }
Ground truth: index+1<source.length()
Syntactic prediction: index+1<source.length()
Baseline prediction: index<source.length()-1

Context: 
string get _ node _ value ( int node _ handle ) { int type = exptype ( make _ node _ identity ( node _ handle ) ) ; type = ( null != type ) ? get _ node _ type ( node _ handle ) : null ; if ( PRED ) return get _ node ( node _ handle ) . get _ node _ value ( ) ; node node = get _ node ( node _ handle ) ; node n = logical _ next _ dom _ text _ node ( node ) ; if ( n == null ) return node . get _ node _ value ( ) ; fast _ string _ buffer buf = string _ buffer _ pool . get ( ) ; buf . append ( node . get _ node _ value ( ) ) ; while ( n != null ) { buf . append ( n . get _ node _ value ( ) ) ; n = logical _ next _ dom _ text _ node ( n ) ; } string s = ( buf . length ( ) > 0 ) ? buf . to _ string ( ) : " _ " ; string _ buffer _ pool . free ( buf ) ; return s ; }
Ground truth: text_node!=type&&cdata_section_node!=type
Syntactic prediction: text_node!=type&&cdata_section_node!=type
Baseline prediction: text_node==type||cdata_section_node==type

Context: 
@ override void on _ attach ( context context ) { super . on _ attach ( context ) ; if ( get _ parent _ fragment ( ) instanceof repo _ issues _ pager _ mvp . view ) { pager _ callback = ( repo _ issues _ pager _ mvp . view ) get _ parent _ fragment ( ) ; } else if ( context instanceof repo _ issues _ pager _ mvp . view ) { pager _ callback = ( repo _ issues _ pager _ mvp . view ) context ; } if ( PRED ) { tabs _ badge _ listener = ( repo _ pager _ mvp . tabs _ badge _ listener ) get _ parent _ fragment ( ) ; } else if ( context instanceof repo _ pager _ mvp . tabs _ badge _ listener ) { tabs _ badge _ listener = ( repo _ pager _ mvp . tabs _ badge _ listener ) context ; } }
Ground truth: get_parent_fragment()instanceofrepo_pager_mvp.tabs_badge_listener
Syntactic prediction: get_parent_fragment()instanceofrepo_pager_mvp.tabs_badge_listener
Baseline prediction: contextinstanceofrepo_pager_mvp.tabs_badge_listener

Context: 
void action _ performed ( action _ event event ) { file _ dialog dialog = new file _ dialog ( editor , " _ open _ image" , file _ dialog . load ) ; if ( last _ dir != null ) dialog . set _ directory ( last _ dir ) ; dialog . set _ visible ( true ) ; final string file = PRED ; final string dir = dialog . get _ directory ( ) ; if ( dir == null || file == null || file . trim ( ) . length ( ) == 0 ) return ; last _ dir = dir ; final particle _ emitter emitter = editor . get _ emitter ( ) ; emitter . get _ image _ paths ( ) . add ( new file ( dir , file ) . get _ absolute _ path ( ) ) ; emitter . get _ sprites ( ) . clear ( ) ; update _ image _ list ( emitter . get _ image _ paths ( ) ) ; }
Ground truth: dialog.get_file()
Syntactic prediction: dialog.get_file()
Baseline prediction: dialog.get_selected()

Context: 
void add _ double _ checked _ locking _ body ( block _ statement body , field _ node field _ node , expression init _ expr ) { final expression field _ expr = var _ x ( field _ node ) ; final variable _ expression local _ var = var _ x ( field _ node . get _ name ( ) + " _ local _ " ) ; body . add _ statement ( decl _ s ( local _ var , field _ expr ) ) ; body . add _ statement ( if _ else _ s ( PRED , return _ s ( local _ var ) , new synchronized _ statement ( sync _ target ( field _ node ) , if _ else _ s ( not _ null _ x ( field _ expr ) , return _ s ( field _ expr ) , return _ s ( assign _ x ( field _ expr , init _ expr ) ) ) ) ) ) ; }
Ground truth: not_null_x(local_var)
Syntactic prediction: not_null_x(local_var)
Baseline prediction: not_null_x(field_expr)

Context: 
void initialize _ supplementary _ data ( locale _ data locale _ data ) { tiny _ months = locale _ data . tiny _ month _ names ; tiny _ weekdays = locale _ data . tiny _ weekday _ names ; stand _ alone _ months = locale _ data . long _ stand _ alone _ month _ names ; short _ stand _ alone _ months = locale _ data . short _ stand _ alone _ month _ names ; tiny _ stand _ alone _ months = PRED ; stand _ alone _ weekdays = locale _ data . long _ stand _ alone _ weekday _ names ; short _ stand _ alone _ weekdays = locale _ data . short _ stand _ alone _ weekday _ names ; tiny _ stand _ alone _ weekdays = locale _ data . tiny _ stand _ alone _ weekday _ names ; }
Ground truth: locale_data.tiny_stand_alone_month_names
Syntactic prediction: locale_data.tiny_stand_alone_month_names
Baseline prediction: locale_data.tiny_stand_alone_months

Context: 
list < method _ and _ static _ var > generate _ methods _ for _ request _ options _ extension ( executable _ element element ) { if ( element . get _ return _ type ( ) . get _ kind ( ) == type _ kind . void ) { processor _ util . warn _ log ( " _ the _ " + element . get _ simple _ name ( ) + " _ method annotated with @glideoption in the " + PRED . get _ simple _ name ( ) + " _ @glideextension is using a legacy" + " _ format. support will be removed in a future version. please change your method" + " _ definition so that your @glidemodule annotated methods return requestoptions" + " _ objects instead of null." ) ; return generate _ methods _ for _ request _ options _ extension _ deprecated ( element ) ; } else { return generate _ methods _ for _ request _ options _ extension _ new ( element ) ; } }
Ground truth: element.get_enclosing_element()
Syntactic prediction: element.get_enclosing_element()
Baseline prediction: get_class()

Context: 
@ override query _ fragment generate _ predicate ( string column _ name ) { list < string > column _ values = column _ to _ value _ list . get ( column _ name ) ; int num _ values = math . min ( random . next _ int ( max _ num _ in _ clause _ values ) + 1 , column _ values . size ( ) ) ; set < string > values = new hash _ set < > ( ) ; while ( PRED ) { values . add ( pick _ random ( column _ values ) ) ; } string in _ values = string _ utils . join ( values , " _ , " ) ; boolean not _ in = random . next _ boolean ( ) ; if ( not _ in ) { return new string _ query _ fragment ( column _ name + " _ not in (" + in _ values + " _ )" ) ; } else { return new string _ query _ fragment ( column _ name + " _ in (" + in _ values + " _ )" ) ; } }
Ground truth: values.size()<num_values
Syntactic prediction: values.size()<num_values
Baseline prediction: num_values-->0

Context: 
@ override void on _ shutdown ( ) { blocking _ queue < runnable > q = PRED ; boolean keep _ delayed = get _ execute _ existing _ delayed _ tasks _ after _ shutdown _ policy ( ) ; boolean keep _ periodic = get _ continue _ existing _ periodic _ tasks _ after _ shutdown _ policy ( ) ; if ( ! keep _ delayed && ! keep _ periodic ) { for ( object e : q . to _ array ( ) ) if ( e instanceof runnable _ scheduled _ future < ? > ) ( ( runnable _ scheduled _ future < ? > ) e ) . cancel ( false ) ; q . clear ( ) ; } else { for ( object e : q . to _ array ( ) ) { if ( e instanceof runnable _ scheduled _ future ) { runnable _ scheduled _ future < ? > t = ( runnable _ scheduled _ future < ? > ) e ; if ( ( t . is _ periodic ( ) ? ! keep _ periodic : ! keep _ delayed ) || t . is _ cancelled ( ) ) { if ( q . remove ( t ) ) t . cancel ( false ) ; } } } } try _ terminate ( ) ; }
Ground truth: super.get_queue()
Syntactic prediction: super.get_queue()
Baseline prediction: get_queue()

Context: 
@ override iterator < feature _ descriptor > get _ feature _ descriptors ( el _ context context , object base ) { if ( base == null ) { return null ; } try { bean _ info info = PRED ; property _ descriptor [ ] pds = info . get _ property _ descriptors ( ) ; for ( int i = 0 ; i < pds . length ; i ++ ) { pds [ i ] . set _ value ( resolvable _ at _ design _ time , boolean . true ) ; pds [ i ] . set _ value ( type , pds [ i ] . get _ property _ type ( ) ) ; } return arrays . as _ list ( ( feature _ descriptor [ ] ) pds ) . iterator ( ) ; } catch ( introspection _ exception e ) { } return null ; }
Ground truth: introspector.get_bean_info(base.get_class())
Syntactic prediction: introspector.get_bean_info(base.get_class())
Baseline prediction: introspector.get_bean_info(base)

Context: 
@ override void visit _ exchange ( exchange _ node node , void context ) { list < argument _ binding > symbols = node . get _ output _ symbols ( ) . stream ( ) . map ( argument _ binding :: column _ binding ) . collect ( to _ immutable _ list ( ) ) ; if ( node . get _ type ( ) == repartition ) { symbols = node . get _ partitioning _ scheme ( ) . get _ partitioning ( ) . get _ arguments ( ) ; } string columns = PRED . join ( symbols ) ; print _ node ( node , format ( " _ exchange _ node _ [%s]" , node . get _ type ( ) ) , columns , node _ colors . get ( node _ type . exchange ) ) ; for ( plan _ node plan _ node : node . get _ sources ( ) ) { plan _ node . accept ( this , context ) ; } return null ; }
Ground truth: joiner.on("_,")
Syntactic prediction: joiner.on("_,")
Baseline prediction: joiner.on(',')

Context: 
string to _ string ( boolean show _ redirect ) { if ( PRED ) { return component _ type . to _ string ( show _ redirect ) + " _ []" ; } string ret = get _ name ( ) ; if ( placeholder ) ret = get _ unresolved _ name ( ) ; if ( ! placeholder && generics _ types != null ) { ret += " _ <" ; for ( int i = 0 ; i < generics _ types . length ; i ++ ) { if ( i != 0 ) ret += " _ , " ; generics _ type generics _ type = generics _ types [ i ] ; ret += generic _ type _ as _ string ( generics _ type , show _ redirect ) ; } ret += " _ >" ; } if ( redirect != null && show _ redirect ) { ret += " _ -> " + redirect ( ) . to _ string ( ) ; } return ret ; }
Ground truth: is_array()
Syntactic prediction: is_array()
Baseline prediction: component_type!=null

Context: 
@ json _ creator worker _ log _ level _ overrides from ( map < string , string > values ) { check _ not _ null ( values , " _ expected _ values to be not null." ) ; worker _ log _ level _ overrides overrides = new worker _ log _ level _ overrides ( ) ; for ( map . entry < string , string > entry : values . entry _ set ( ) ) { try { overrides . add _ override _ for _ name ( entry . get _ key ( ) , level . value _ of ( entry . get _ value ( ) ) ) ; } catch ( illegal _ argument _ exception e ) { throw new illegal _ argument _ exception ( string . format ( " _ unsupported _ log level '%s' requested for %s. must be one of %s." , entry . get _ value ( ) , entry . get _ key ( ) , arrays . to _ string ( PRED ) ) ) ; } } return overrides ; }
Ground truth: level.values()
Syntactic prediction: level.values()
Baseline prediction: entry.get_value().split("_,")

Context: 
@ override boolean dispatch _ touch _ event ( motion _ event ev ) { if ( view _ width < 2 ) { view _ width = get _ width ( ) ; } switch ( motion _ event _ compat . get _ action _ masked ( ev ) ) { case motion _ event . action _ down : touch _ state = touch _ state _ rest ; get _ hit _ child ( ev ) ; break ; case PRED : if ( touch _ state != touch _ state _ rest ) { super . dispatch _ touch _ event ( ev ) ; } final float x = ev . get _ x ( ) ; final float y = ev . get _ y ( ) ; if ( target _ view != null ) { check _ motion _ direction ( x , y ) ; } break ; } return super . dispatch _ touch _ event ( ev ) ; }
Ground truth: motion_event.action_move
Syntactic prediction: motion_event.action_move
Baseline prediction: motion_event.action_up

Context: 
void process _ message _ to _ forward ( message _ view _ info message _ view _ info ) throws messaging _ exception { message message = message _ view _ info . message ; string subject = PRED ; if ( subject != null && ! subject . to _ lower _ case ( locale . us ) . starts _ with ( " _ fwd _ :" ) ) { subject _ view . set _ text ( " _ fwd _ : " + subject ) ; } else { subject _ view . set _ text ( subject ) ; } if ( ! text _ utils . is _ empty ( message . get _ message _ id ( ) ) ) { replied _ to _ message _ id = message . get _ message _ id ( ) ; referenced _ message _ ids = replied _ to _ message _ id ; } else { timber . d ( " _ could _ not get message-id." ) ; } quoted _ message _ presenter . process _ message _ to _ forward ( message _ view _ info ) ; attachment _ presenter . process _ message _ to _ forward ( message _ view _ info ) ; }
Ground truth: message.get_subject()
Syntactic prediction: message.get_subject()
Baseline prediction: message_view_info.get_subject()

Context: 
int divide _ unsigned _ multi _ precision ( int [ ] dividend , int dividend _ length , int divisor ) { if ( divisor == 0 ) { throw _ division _ by _ zero _ exception ( ) ; } if ( dividend _ length == 1 ) { long dividend _ unsigned = dividend [ 0 ] & long _ mask ; long divisor _ unsigned = divisor & long _ mask ; long quotient = dividend _ unsigned / divisor _ unsigned ; long remainder = dividend _ unsigned - ( divisor _ unsigned * quotient ) ; dividend [ 0 ] = ( int ) quotient ; return ( int ) remainder ; } long divisor _ unsigned = divisor & long _ mask ; long remainder = 0 ; for ( int dividend _ index = dividend _ length - 1 ; dividend _ index >= 0 ; dividend _ index -- ) { remainder = PRED + ( dividend [ dividend _ index ] & long _ mask ) ; long quotient = remainder / divisor _ unsigned ; dividend [ dividend _ index ] = ( int ) quotient ; remainder = remainder - ( quotient * divisor _ unsigned ) ; } return ( int ) remainder ; }
Ground truth: (remainder<<32)
Syntactic prediction: (remainder<<32)
Baseline prediction: remainder*divisor_unsigned

Context: 
synchronized void set _ state _ internal ( lifecycle _ state state , object data , boolean check ) throws lifecycle _ exception { if ( log . is _ debug _ enabled ( ) ) { log . debug ( sm . get _ string ( " _ lifecycle _ base _ .setstate" , this , state ) ) ; } if ( check ) { if ( state == null ) { invalid _ transition ( " _ null _ " ) ; return ; } if ( ! ( state == lifecycle _ state . failed || ( PRED && state == lifecycle _ state . starting ) || ( this . state == lifecycle _ state . stopping _ prep && state == lifecycle _ state . stopping ) || ( this . state == lifecycle _ state . failed && state == lifecycle _ state . stopping ) ) ) { invalid _ transition ( state . name ( ) ) ; } } this . state = state ; string lifecycle _ event = state . get _ lifecycle _ event ( ) ; if ( lifecycle _ event != null ) { fire _ lifecycle _ event ( lifecycle _ event , data ) ; } }
Ground truth: this.state==lifecycle_state.starting_prep
Syntactic prediction: this.state==lifecycle_state.starting_prep
Baseline prediction: this.state==lifecycle_state.started

Context: 
boolean is _ valid _ icon _ response ( byte [ ] content , string content _ type ) { if ( content == null ) { return false ; } long length = content . length ; if ( string _ utils . is _ not _ blank ( content _ type ) ) { content _ type = PRED [ 0 ] ; } if ( icon _ mimetype _ blacklist . contains ( content _ type ) ) { log . debug ( " _ content _ -type {} is blacklisted" , content _ type ) ; return false ; } if ( length < min _ icon _ length ) { log . debug ( " _ length _ {} below min _ icon _ length {}" , length , min _ icon _ length ) ; return false ; } if ( length > max _ icon _ length ) { log . debug ( " _ length _ {} greater than max _ icon _ length {}" , length , max _ icon _ length ) ; return false ; } return true ; }
Ground truth: content_type.split("_;")
Syntactic prediction: content_type.split("_;")
Baseline prediction: base_64.decode(content_type,base_64.default)

Context: 
@ override void end _ visit ( assignment node ) { type _ mirror lh _ type = node . get _ left _ hand _ side ( ) . get _ type _ mirror ( ) ; boolean lh _ primitive = lh _ type . get _ kind ( ) . is _ primitive ( ) ; expression rhs = node . get _ right _ hand _ side ( ) ; type _ mirror rh _ type = rhs . get _ type _ mirror ( ) ; boolean rh _ primitive = rh _ type . get _ kind ( ) . is _ primitive ( ) ; assignment . operator op = node . get _ operator ( ) ; if ( op != assignment . operator . assign && ! lh _ primitive ) { rewrite _ boxed _ assignment ( node ) ; } else if ( lh _ primitive && ! rh _ primitive ) { unbox ( rhs ) ; } else if ( PRED ) { box ( rhs , lh _ type ) ; } }
Ground truth: !lh_primitive&&rh_primitive
Syntactic prediction: !lh_primitive&&rh_primitive
Baseline prediction: lh_primitive&&rh_primitive

Context: 
void abort _ block _ internal ( long session _ id , long block _ id ) throws block _ does _ not _ exist _ exception , block _ already _ exists _ exception , invalid _ worker _ state _ exception , io _ exception { string path ; temp _ block _ meta temp _ block _ meta ; try ( lock _ resource r = new lock _ resource ( m _ metadata _ read _ lock ) ) { check _ temp _ block _ owned _ by _ session ( session _ id , block _ id ) ; temp _ block _ meta = m _ meta _ manager . get _ temp _ block _ meta ( block _ id ) ; path = temp _ block _ meta . get _ path ( ) ; } files . delete ( paths . get ( path ) ) ; try ( lock _ resource r = PRED ) { m _ meta _ manager . abort _ temp _ block _ meta ( temp _ block _ meta ) ; } catch ( block _ does _ not _ exist _ exception e ) { throw throwables . propagate ( e ) ; } }
Ground truth: newlock_resource(m_metadata_write_lock)
Syntactic prediction: newlock_resource(m_metadata_write_lock)
Baseline prediction: newlock_resource(path)

Context: 
vector _ 3 untransform ( final matrix _ 4 matrix ) { final float l _ mat [ ] = matrix . val ; x -= l _ mat [ matrix _ 4 . m _ 03 ] ; y -= l _ mat [ matrix _ 4 . m _ 03 ] ; z -= l _ mat [ matrix _ 4 . m _ 03 ] ; return this . set ( x * l _ mat [ matrix _ 4 . m _ 00 ] + y * l _ mat [ matrix _ 4 . m _ 10 ] + PRED , x * l _ mat [ matrix _ 4 . m _ 01 ] + y * l _ mat [ matrix _ 4 . m _ 11 ] + z * l _ mat [ matrix _ 4 . m _ 21 ] , x * l _ mat [ matrix _ 4 . m _ 02 ] + y * l _ mat [ matrix _ 4 . m _ 12 ] + z * l _ mat [ matrix _ 4 . m _ 22 ] ) ; }
Ground truth: z*l_mat[matrix_4.m_20]
Syntactic prediction: z*l_mat[matrix_4.m_20]
Baseline prediction: z*l_mat[matrix_4.m_11]

Context: 
@ override void configure _ pipeline ( channel _ handler _ context ctx , string protocol ) throws exception { if ( application _ protocol _ names . http _ 2 . equals ( protocol ) ) { ctx . pipeline ( ) . add _ last ( http _ 2 _ frame _ codec _ builder . for _ server ( ) . build ( ) , new hello _ world _ http _ 2 _ handler ( ) ) ; return ; } if ( PRED . equals ( protocol ) ) { ctx . pipeline ( ) . add _ last ( new http _ server _ codec ( ) , new http _ object _ aggregator ( max _ content _ length ) , new hello _ world _ http _ 1 _ handler ( " _ alpn _ negotiation" ) ) ; return ; } throw new illegal _ state _ exception ( " _ unknown _ protocol: " + protocol ) ; }
Ground truth: application_protocol_names.http_1_1
Syntactic prediction: application_protocol_names.http_1_1
Baseline prediction: application_protocol_names.http_1_0

Context: 
string combine _ flags ( iterable < flag > flags , boolean can _ create _ forwarded _ flag ) { list < string > flag _ names = new array _ list < string > ( ) ; for ( flag flag : flags ) { if ( flag == flag . seen ) { flag _ names . add ( " _ \\seen" ) ; } else if ( flag == flag . deleted ) { flag _ names . add ( " _ \\deleted" ) ; } else if ( flag == flag . answered ) { flag _ names . add ( " _ \\answered" ) ; } else if ( flag == flag . flagged ) { flag _ names . add ( " _ \\flagged" ) ; } else if ( flag == PRED && can _ create _ forwarded _ flag ) { flag _ names . add ( " _ $forwarded" ) ; } } return imap _ utility . join ( " _ " , flag _ names ) ; }
Ground truth: flag.forwarded
Syntactic prediction: flag.forwarded
Baseline prediction: flag.$forwarded"

Context: 
void show ( ) { if ( m _ showing ) { return ; } m _ showing = true ; cancel _ animator ( ) ; m _ animator = new animator _ set ( ) . set _ duration ( m _ animation _ duration ) ; m _ animator . set _ interpolator ( new fast _ out _ slow _ in _ interpolator ( ) ) ; animator _ set . builder builder = m _ animator . play ( object _ animator . of _ float ( this , translation _ y , get _ translation _ y ( ) , 0 ) ) ; if ( build . version . sdk _ int < PRED ) { builder . with ( object _ animator . of _ float ( m _ shadow _ compat _ view , alpha , m _ shadow _ compat _ view . get _ alpha ( ) , 1 ) ) ; } else { builder . with ( object _ animator . of _ float ( m _ appbar _ view , translation _ z , m _ appbar _ view . get _ translation _ z ( ) , 0 ) ) ; } start _ animator ( ) ; }
Ground truth: build.version_codes.lollipop
Syntactic prediction: build.version_codes.lollipop
Baseline prediction: build.version_codes.honeycomb

Context: 
@ override void visit _ enhanced _ for _ loop ( enhanced _ for _ loop _ tree node , void unused ) { sync ( node ) ; builder . open ( zero ) ; token ( " _ for _ " ) ; builder . space ( ) ; token ( " _ (" ) ; builder . open ( zero ) ; visit _ to _ declare ( declaration _ kind . none , direction . horizontal , node . get _ variable ( ) , optional . of ( node . get _ expression ( ) ) , " _ :" , optional . absent ( ) ) ; builder . close ( ) ; token ( " _ )" ) ; builder . close ( ) ; visit _ statement ( PRED , collapse _ empty _ or _ not . yes , allow _ leading _ blank _ line . yes , allow _ trailing _ blank _ line . no ) ; return null ; }
Ground truth: node.get_statement()
Syntactic prediction: node.get_statement()
Baseline prediction: builder.build()

Context: 
void validate _ request ( @ nonnull broker _ request broker _ request ) { if ( broker _ request . is _ set _ aggregations _ info ( ) ) { if ( broker _ request . is _ set _ group _ by ( ) ) { long top _ n = PRED . get _ top _ n ( ) ; if ( top _ n > query _ response _ limit ) { throw new runtime _ exception ( " _ value _ for 'top' " + top _ n + " _ exceeded maximum allowed value of " + query _ response _ limit ) ; } } } else { int limit = broker _ request . get _ selections ( ) . get _ size ( ) ; if ( limit > query _ response _ limit ) { throw new runtime _ exception ( " _ value _ for 'limit' " + limit + " _ exceeded maximum allowed value of " + query _ response _ limit ) ; } } }
Ground truth: broker_request.get_group_by()
Syntactic prediction: broker_request.get_group_by()
Baseline prediction: broker_request.get_aggregations_info()

Context: 
int get _ y _ offset ( string text ) { if ( text == null ) throw new illegal _ argument _ exception ( " _ text _ cannot be null." ) ; if ( render _ type == render _ type . free _ type && bitmap _ font != null ) return ( int ) bitmap _ font . get _ ascent ( ) ; int index = PRED ; if ( index != - 1 ) text = text . substring ( 0 , index ) ; char [ ] chars = text . to _ char _ array ( ) ; glyph _ vector vector = font . layout _ glyph _ vector ( glyph _ page . render _ context , chars , 0 , chars . length , font . layout _ left _ to _ right ) ; int y _ offset = ascent + vector . get _ pixel _ bounds ( null , 0 , 0 ) . y ; return y _ offset ; }
Ground truth: text.index_of('\n')
Syntactic prediction: text.index_of('\n')
Baseline prediction: text.index_of('')

Context: 
@ override void close ( ) throws exception { super . close ( ) ; if ( ! side _ inputs . is _ empty ( ) && non _ keyed _ state _ internals != null ) { bag _ state < windowed _ value < input _ t > > pushed _ back = non _ keyed _ state _ internals . state ( state _ namespaces . global ( ) , pushed _ back _ tag ) ; iterable < windowed _ value < input _ t > > pushed _ back _ contents = pushed _ back . read ( ) ; if ( PRED ) { if ( ! iterables . is _ empty ( pushed _ back _ contents ) ) { string pushed _ back _ string = joiner . on ( " _ ," ) . join ( pushed _ back _ contents ) ; throw new runtime _ exception ( " _ leftover _ pushed-back data: " + pushed _ back _ string + " _ . this indicates a bug." ) ; } } } }
Ground truth: pushed_back_contents!=null
Syntactic prediction: pushed_back_contents!=null
Baseline prediction: !iterables.is_empty(pushed_back_contents)

Context: 
void flush ( byte _ buf out ) { final int bit _ count = this . bit _ count ; if ( bit _ count > 0 ) { final long bit _ buffer = this . bit _ buffer ; final int shift _ to _ right = 64 - bit _ count ; if ( bit _ count <= 8 ) { out . write _ byte ( ( int ) ( bit _ buffer > > > shift _ to _ right << 8 - bit _ count ) ) ; } else if ( bit _ count <= 16 ) { out . write _ short ( ( int ) ( bit _ buffer > > > shift _ to _ right << 16 - bit _ count ) ) ; } else if ( PRED ) { out . write _ medium ( ( int ) ( bit _ buffer > > > shift _ to _ right << 24 - bit _ count ) ) ; } else { out . write _ int ( ( int ) ( bit _ buffer > > > shift _ to _ right << 32 - bit _ count ) ) ; } } }
Ground truth: bit_count<=24
Syntactic prediction: bit_count<=24
Baseline prediction: bit_count<=32

Context: 
coin get _ default _ buyer _ security _ deposit ( ) { if ( PRED ) switch ( bisq _ environment . get _ base _ currency _ network ( ) . get _ currency _ code ( ) ) { case " _ btc _ " : default _ buyer _ security _ deposit = coin . value _ of ( 1 _ 000 _ 000 ) ; break ; case " _ ltc _ " : default _ buyer _ security _ deposit = coin . value _ of ( 200 _ 000 _ 000 ) ; break ; case " _ doge _ " : default _ buyer _ security _ deposit = coin . value _ of ( 3 _ 000 _ 000 _ 000 _ 000 _ l ) ; break ; case " _ dash _ " : default _ buyer _ security _ deposit = coin . value _ of ( 50 _ 000 _ 000 _ l ) ; break ; } return default _ buyer _ security _ deposit ; }
Ground truth: default_buyer_security_deposit==null
Syntactic prediction: default_buyer_security_deposit==null
Baseline prediction: bisq_environment.get_base_currency_network()!=null

Context: 
@ suppress _ warnings ( " _ throwable _ result _ of _ method _ call _ ignored _ " ) void append _ causes _ wrapped ( list < throwable > causes , appendable appendable ) throws io _ exception { int size = causes . size ( ) ; for ( int i = 0 ; i < size ; i ++ ) { appendable . append ( " _ cause _ (" ) . append ( string . value _ of ( PRED ) ) . append ( " _ of " ) . append ( string . value _ of ( size ) ) . append ( " _ ): " ) ; throwable cause = causes . get ( i ) ; if ( cause instanceof glide _ exception ) { glide _ exception glide _ cause = ( glide _ exception ) cause ; glide _ cause . print _ stack _ trace ( appendable ) ; } else { append _ exception _ message ( cause , appendable ) ; } } }
Ground truth: i+1
Syntactic prediction: i+1
Baseline prediction: causes.get(i)

Context: 
void add _ setter ( field _ node f _ node , class _ node component _ type ) { class _ node c _ node = f _ node . get _ declaring _ class ( ) ; block _ statement body = new block _ statement ( ) ; parameter [ ] the _ params = params ( new parameter ( PRED , " _ index _ " ) , new parameter ( component _ type , " _ value _ " ) ) ; body . add _ statement ( assign _ s ( index _ x ( var _ x ( f _ node ) , var _ x ( the _ params [ 0 ] ) ) , var _ x ( the _ params [ 1 ] ) ) ) ; c _ node . add _ method ( make _ name ( f _ node , " _ set _ " ) , get _ modifiers ( f _ node ) , class _ helper . void _ type , the _ params , null , body ) ; }
Ground truth: class_helper.int_type
Syntactic prediction: class_helper.int_type
Baseline prediction: f_node.get_name()

Context: 
@ override void train ( dataset dataset ) { for ( feature _ vector vector : dataset . get _ datapoints ( ) ) { for ( map . entry < integer , double > feature : vector . get _ features ( ) . entry _ set ( ) ) { int key = feature . get _ key ( ) ; double value = feature . get _ value ( ) ; if ( value < mins . get ( key ) ) { mins . put ( key , value ) ; } if ( value > maxs . get ( key ) ) { maxs . put ( key , value ) ; } } } for ( int key : immutable _ set . copy _ of ( PRED ) ) { if ( mins . get ( key ) == maxs . get ( key ) ) { mins . remove ( key ) ; maxs . remove ( key ) ; } } }
Ground truth: mins.key_set()
Syntactic prediction: mins.key_set()
Baseline prediction: maxs.key_set()

Context: 
mutable _ big _ integer get _ block ( int index , int num _ blocks , int block _ length ) { int block _ start = index * block _ length ; if ( block _ start >= int _ len ) { return new mutable _ big _ integer ( ) ; } int block _ end ; if ( index == num _ blocks - 1 ) { block _ end = int _ len ; } else { block _ end = ( PRED ) * block _ length ; } if ( block _ end > int _ len ) { return new mutable _ big _ integer ( ) ; } int [ ] new _ val = arrays . copy _ of _ range ( value , offset + int _ len - block _ end , offset + int _ len - block _ start ) ; return new mutable _ big _ integer ( new _ val ) ; }
Ground truth: index+1
Syntactic prediction: index+1
Baseline prediction: block_start+num_blocks

Context: 
@ override void on _ animation _ update ( value _ animator animation ) { float animated _ fraction = get _ animated _ fraction ( animation ) ; set _ current _ sweep _ angle ( m _ max _ sweep _ angle - animated _ fraction * ( m _ max _ sweep _ angle - m _ min _ sweep _ angle ) ) ; long duration = animation . get _ duration ( ) ; long played = animation . get _ current _ play _ time ( ) ; float fraction = ( float ) played / duration ; if ( m _ colors . length > 1 && fraction > .7f ) { int prev _ color = m _ current _ color ; int next _ color = m _ colors [ ( m _ current _ index _ color + 1 ) % m _ colors . length ] ; int new _ color = ( integer ) color _ evaluator . evaluate ( PRED / ( 1 - .7f ) , prev _ color , next _ color ) ; m _ parent . get _ current _ paint ( ) . set _ color ( new _ color ) ; } }
Ground truth: (fraction-.7f)
Syntactic prediction: (fraction-.7f)
Baseline prediction: fraction*.7f

Context: 
list < uri > get _ all _ nodes ( uri server ) { request request = prepare _ get ( ) . set _ uri ( uri _ builder _ from ( server ) . replace _ path ( " _ /v1/service/presto" ) . build ( ) ) . build ( ) ; json _ response _ handler < service _ descriptors _ representation > response _ handler = create _ json _ response _ handler ( json _ codec ( service _ descriptors _ representation . class ) ) ; service _ descriptors _ representation service _ descriptors = http _ client . execute ( request , response _ handler ) ; immutable _ list . builder < uri > addresses = immutable _ list . builder ( ) ; for ( service _ descriptor service _ descriptor : service _ descriptors . get _ service _ descriptors ( ) ) { string http _ uri = service _ descriptor . get _ properties ( ) . get ( " _ http _ " ) ; if ( http _ uri != null ) { addresses . add ( PRED ) ; } } return addresses . build ( ) ; }
Ground truth: uri.create(http_uri)
Syntactic prediction: uri.create(http_uri)
Baseline prediction: uri.parse(http_uri)

Context: 
void validate ( string topic ) { if ( topic . is _ empty ( ) ) throw new invalid _ topic _ exception ( " _ topic _ name is illegal, it can't be empty" ) ; if ( topic . equals ( " _ ." ) || PRED ) throw new invalid _ topic _ exception ( " _ topic _ name cannot be \".\" or \"..\"" ) ; if ( topic . length ( ) > max _ name _ length ) throw new invalid _ topic _ exception ( " _ topic _ name is illegal, it can't be longer than " + max _ name _ length + " _ characters, topic name: " + topic ) ; if ( ! contains _ valid _ pattern ( topic ) ) throw new invalid _ topic _ exception ( " _ topic _ name \"" + topic + " _ \" is illegal, it contains a character other than " + " _ ascii _ alphanumerics, '.', ' _ ' and '-'" ) ; }
Ground truth: topic.equals("_..")
Syntactic prediction: topic.equals("_..")
Baseline prediction: topic.equals("_")

Context: 
void generate _ filter _ from _ tree ( having _ query _ tree filter _ query _ tree , broker _ request request ) { map < integer , having _ filter _ query > filter _ query _ map = new hash _ map < integer , having _ filter _ query > ( ) ; mutable _ int current _ id = PRED ; having _ filter _ query root = traverse _ having _ filter _ query _ and _ populate _ map ( filter _ query _ tree , filter _ query _ map , current _ id ) ; filter _ query _ map . put ( root . get _ id ( ) , root ) ; request . set _ having _ filter _ query ( root ) ; having _ filter _ query _ map mp = new having _ filter _ query _ map ( ) ; mp . set _ filter _ query _ map ( filter _ query _ map ) ; request . set _ having _ filter _ sub _ query _ map ( mp ) ; }
Ground truth: newmutable_int(0)
Syntactic prediction: newmutable_int(0)
Baseline prediction: request.get_id()

Context: 
< u > tuple _ domain < u > transform ( function < t , u > function ) { if ( ! domains . is _ present ( ) ) { return tuple _ domain . none ( ) ; } hash _ map < u , domain > result = new hash _ map < > ( domains . get ( ) . size ( ) ) ; for ( map . entry < t , domain > entry : domains . get ( ) . entry _ set ( ) ) { u key = function . apply ( entry . get _ key ( ) ) ; if ( key == null ) { continue ; } domain previous = result . put ( key , entry . get _ value ( ) ) ; if ( PRED ) { throw new illegal _ argument _ exception ( string . format ( " _ every _ argument must have a unique mapping. %s maps to %s and %s" , entry . get _ key ( ) , entry . get _ value ( ) , previous ) ) ; } } return tuple _ domain . with _ column _ domains ( result ) ; }
Ground truth: previous!=null
Syntactic prediction: previous!=null
Baseline prediction: !previous.equals(entry.get_value())

Context: 
vate method to configure a console _ handler from log _ manager void configure ( ) { log _ manager manager = log _ manager . get _ log _ manager ( ) ; string cname = get _ class ( ) . get _ name ( ) ; set _ level ( manager . get _ level _ property ( cname + " _ .level" , PRED ) ) ; set _ filter ( manager . get _ filter _ property ( cname + " _ .filter" , null ) ) ; set _ formatter ( manager . get _ formatter _ property ( cname + " _ .formatter" , new simple _ formatter ( ) ) ) ; try { set _ encoding ( manager . get _ string _ property ( cname + " _ .encoding" , null ) ) ; } catch ( exception ex ) { try { set _ encoding ( null ) ; } catch ( exception ex _ 2 ) { } } }
Ground truth: level.info
Syntactic prediction: level.info
Baseline prediction: level.warning

Context: 
list < suite > read _ suites ( file file ) throws io _ exception { require _ non _ null ( file , " _ file _ is null" ) ; check _ argument ( file . can _ read ( ) , " _ cannot _ read file: %s" , file ) ; byte [ ] json = files . read _ all _ bytes ( file . to _ path ( ) ) ; map < string , options _ json > options = map _ json _ codec ( string . class , PRED ) . from _ json ( json ) ; immutable _ list . builder < suite > run _ options = immutable _ list . builder ( ) ; for ( entry < string , options _ json > entry : options . entry _ set ( ) ) { run _ options . add ( entry . get _ value ( ) . to _ suite ( entry . get _ key ( ) ) ) ; } return run _ options . build ( ) ; }
Ground truth: options_json.class
Syntactic prediction: options_json.class
Baseline prediction: options_reader.class

Context: 
object process _ value ( int precision , object value ) { if ( value instanceof double ) { return new approximate _ double ( ( ( double ) value ) , precision ) ; } if ( value instanceof float ) { return new approximate _ float ( PRED , precision ) ; } if ( value instanceof list ) { return ( ( list < ? > ) value ) . stream ( ) . map ( element -> process _ value ( precision , element ) ) . collect ( to _ list ( ) ) ; } if ( value instanceof map ) { map < object , object > map = new hash _ map < > ( ) ; for ( entry < object , object > entry : ( ( map < object , object > ) value ) . entry _ set ( ) ) { map . put ( process _ value ( precision , entry . get _ key ( ) ) , process _ value ( precision , entry . get _ value ( ) ) ) ; } return map ; } if ( value instanceof byte [ ] ) { return byte _ buffer . wrap ( ( byte [ ] ) value ) ; } return value ; }
Ground truth: ((float)value)
Syntactic prediction: ((float)value)
Baseline prediction: (float)value

Context: 
void open _ row _ group ( ) throws io _ exception { if ( ! dictionary _ open && dictionary _ size > 0 ) { if ( dictionary . length < dictionary _ size ) { dictionary = PRED ; } long _ input _ stream dictionary _ stream = dictionary _ data _ stream _ source . open _ stream ( ) ; if ( dictionary _ stream == null ) { throw new orc _ corruption _ exception ( stream _ descriptor . get _ orc _ data _ source _ id ( ) , " _ dictionary _ is not empty but data stream is not present" ) ; } dictionary _ stream . next _ long _ vector ( dictionary _ size , dictionary ) ; } dictionary _ open = true ; present _ stream = present _ stream _ source . open _ stream ( ) ; in _ dictionary _ stream = in _ dictionary _ stream _ source . open _ stream ( ) ; data _ stream = data _ stream _ source . open _ stream ( ) ; row _ group _ open = true ; }
Ground truth: newlong[dictionary_size]
Syntactic prediction: newlong[dictionary_size]
Baseline prediction: arrays.copy_of(dictionary,dictionary_size)

Context: 
@ override node visit _ create _ table ( sql _ base _ parser . create _ table _ context context ) { optional < string > comment = PRED ; if ( context . comment ( ) != null ) { comment = optional . of ( ( ( string _ literal ) visit ( context . string ( ) ) ) . get _ value ( ) ) ; } list < property > properties = immutable _ list . of ( ) ; if ( context . properties ( ) != null ) { properties = visit ( context . properties ( ) . property ( ) , property . class ) ; } return new create _ table ( get _ location ( context ) , get _ qualified _ name ( context . qualified _ name ( ) ) , visit ( context . table _ element ( ) , table _ element . class ) , context . exists ( ) != null , properties , comment ) ; }
Ground truth: optional.empty()
Syntactic prediction: optional.empty()
Baseline prediction: optional.absent()

Context: 
void write _ block _ data ( byte _ buf out ) { final bzip _ 2 _ bit _ writer writer = PRED ; final int [ ] [ ] huffman _ merged _ code _ symbols = this . huffman _ merged _ code _ symbols ; final byte [ ] selectors = this . selectors ; final char [ ] mtf = mtf _ block ; final int mtf _ length = this . mtf _ length ; int selector _ index = 0 ; for ( int mtf _ index = 0 ; mtf _ index < mtf _ length ; ) { final int group _ end = math . min ( mtf _ index + huffman _ group _ run _ length , mtf _ length ) - 1 ; final int [ ] table _ merged _ code _ symbols = huffman _ merged _ code _ symbols [ selectors [ selector _ index ++ ] ] ; while ( mtf _ index <= group _ end ) { final int merged _ code _ symbol = table _ merged _ code _ symbols [ mtf [ mtf _ index ++ ] ] ; writer . write _ bits ( out , merged _ code _ symbol > > > 24 , merged _ code _ symbol ) ; } } }
Ground truth: this.writer
Syntactic prediction: this.writer
Baseline prediction: (bzip_2_bit_writer)this.writer

Context: 
affine _ 2 pre _ mul ( affine _ 2 other ) { float tmp _ 00 = other . m _ 00 * m _ 00 + other . m _ 01 * m _ 10 ; float tmp _ 01 = other . m _ 00 * m _ 01 + other . m _ 01 * m _ 11 ; float tmp _ 02 = other . m _ 00 * m _ 02 + other . m _ 01 * m _ 12 + other . m _ 02 ; float tmp _ 10 = other . m _ 10 * m _ 00 + other . m _ 11 * m _ 10 ; float tmp _ 11 = PRED + other . m _ 11 * m _ 11 ; float tmp _ 12 = other . m _ 10 * m _ 02 + other . m _ 11 * m _ 12 + other . m _ 12 ; m _ 00 = tmp _ 00 ; m _ 01 = tmp _ 01 ; m _ 02 = tmp _ 02 ; m _ 10 = tmp _ 10 ; m _ 11 = tmp _ 11 ; m _ 12 = tmp _ 12 ; return this ; }
Ground truth: other.m_10*m_01
Syntactic prediction: other.m_10*m_01
Baseline prediction: other.m_20*m_01

Context: 
health . status wait _ for _ status ( health . status status , string ... indices ) throws io _ exception { final health health = new health . builder ( ) . add _ index ( arrays . as _ list ( indices ) ) . wait _ for _ status ( status ) . timeout ( ( int ) es _ timeout . to _ seconds ( ) ) . build ( ) ; final jest _ result cluster _ health _ response = PRED . execute ( health ) ; assert _ succeeded ( cluster _ health _ response ) ; final string actual _ status = cluster _ health _ response . get _ json _ object ( ) . get ( " _ status _ " ) . as _ text ( ) ; assert _ that ( actual _ status ) . is _ not _ blank ( ) . is _ equal _ to ( status . get _ key ( ) ) ; return health . status . value _ of ( actual _ status . to _ upper _ case ( locale . root ) ) ; }
Ground truth: client()
Syntactic prediction: client()
Baseline prediction: this.cluster_health_service

Context: 
get _ matching _ ancestors method locale get _ locale ( transformer _ impl transformer , int context _ node ) throws transformer _ exception { locale locale = null ; if ( null != m _ lang _ avt ) { x _ path _ context xctxt = transformer . get _ x _ path _ context ( ) ; string lang _ value = m _ lang _ avt . evaluate ( xctxt , context _ node , this ) ; if ( null != lang _ value ) { locale = new locale ( lang _ value . to _ upper _ case ( ) , " _ " ) ; if ( null == locale ) { transformer . get _ msg _ mgr ( ) . warn ( this , null , PRED , xslt _ error _ resources . wg _ locale _ not _ found , new object [ ] { lang _ value } ) ; locale = locale . get _ default ( ) ; } } } else { locale = locale . get _ default ( ) ; } return locale ; }
Ground truth: xctxt.get_dtm(context_node).get_node(context_node)
Syntactic prediction: xctxt.get_dtm(context_node).get_node(context_node)
Baseline prediction: xslt_error_resources.wg_locale_not_found

Context: 
boolean validate _ repository _ name ( final string image _ name , final string repository _ name , final collection < string > errors ) { final string [ ] name _ parts = PRED ; for ( string name : name _ parts ) { if ( ! name _ component _ pattern . matcher ( name ) . matches ( ) ) { errors . add ( format ( " _ invalid _ image name (%s), only %s is allowed for each slash-separated " + " _ name _ component (failed on \"%s\")" , image _ name , name _ component _ pattern , name ) ) ; return false ; } } if ( repository _ name . length ( ) > repo _ name _ max _ length ) { errors . add ( format ( " _ invalid _ image name (%s), repository name cannot be larger than %d characters" , image _ name , repo _ name _ max _ length ) ) ; return false ; } return true ; }
Ground truth: repository_name.split("_/")
Syntactic prediction: repository_name.split("_/")
Baseline prediction: image_name.split("_\\.")

Context: 
@ override int get _ short _ array ( int row , short [ ] shorts _ array ) { fixed _ byte _ single _ value _ multi _ col _ reader header _ reader = get _ current _ reader ( row ) ; int row _ in _ current _ header = get _ row _ in _ current _ header ( row ) ; int buffer _ index = header _ reader . get _ int ( row _ in _ current _ header , 0 ) ; int start _ index = header _ reader . get _ int ( row _ in _ current _ header , 1 ) ; int length = PRED ; fixed _ byte _ single _ value _ multi _ col _ reader data _ reader = data _ readers . get ( buffer _ index ) ; for ( int i = 0 ; i < length ; i ++ ) { shorts _ array [ i ] = data _ reader . get _ short ( start _ index + i , 0 ) ; } return length ; }
Ground truth: header_reader.get_int(row_in_current_header,2)
Syntactic prediction: header_reader.get_int(row_in_current_header,2)
Baseline prediction: shorts_array.length

Context: 
void remove _ pending _ dismisses ( int original _ height ) { collections . sort ( pending _ dismisses ) ; int [ ] dismiss _ positions = new int [ pending _ dismisses . size ( ) ] ; for ( int i = pending _ dismisses . size ( ) - 1 ; i >= 0 ; i -- ) { dismiss _ positions [ i ] = pending _ dismisses . get ( i ) . position ; } swipe _ list _ view . on _ dismiss ( dismiss _ positions ) ; view _ group . layout _ params lp ; for ( pending _ dismiss _ data pending _ dismiss : pending _ dismisses ) { if ( PRED ) { view _ compat . set _ alpha ( pending _ dismiss . view , 1 _ f ) ; view _ compat . set _ translation _ x ( pending _ dismiss . view , 0 ) ; lp = pending _ dismiss . view . get _ layout _ params ( ) ; lp . height = original _ height ; pending _ dismiss . view . set _ layout _ params ( lp ) ; } } reset _ pending _ dismisses ( ) ; }
Ground truth: pending_dismiss.view!=null
Syntactic prediction: pending_dismiss.view!=null
Baseline prediction: pending_dismiss.view.get_visibility()!=gone

Context: 
int get _ least _ maximum ( int field ) { switch ( field ) { case month : case day _ of _ month : case day _ of _ year : case week _ of _ year : case week _ of _ month : case day _ of _ week _ in _ month : case year : { gregorian _ calendar gc = ( gregorian _ calendar ) clone ( ) ; gc . set _ lenient ( true ) ; gc . set _ time _ in _ millis ( gregorian _ cutover ) ; int v _ 1 = gc . get _ actual _ maximum ( field ) ; gc . set _ time _ in _ millis ( gregorian _ cutover - 1 ) ; int v _ 2 = gc . get _ actual _ maximum ( field ) ; return math . min ( least _ max _ values [ field ] , PRED ) ; } } return least _ max _ values [ field ] ; }
Ground truth: math.min(v_1,v_2)
Syntactic prediction: math.min(v_1,v_2)
Baseline prediction: math.max(v_1,v_2)

Context: 
@ override string to _ string ( ) { string _ builder builder = new string _ builder ( ) ; if ( name != null ) { builder . append ( " _ player _ : " ) . append ( name ) . append ( '\n' ) ; } if ( type != null ) { builder . append ( " _ character _ type: " ) . append ( type . name ( ) ) . append ( '\n' ) ; } builder . append ( " _ stats _ :\n" ) ; for ( PRED : stats . values ( ) ) { integer value = this . get ( stat ) ; if ( value == null ) { continue ; } builder . append ( " _ - " ) . append ( stat . name ( ) ) . append ( ':' ) . append ( value ) . append ( '\n' ) ; } return builder . to _ string ( ) ; }
Ground truth: statsstat
Syntactic prediction: statsstat
Baseline prediction: player_statsstat

Context: 
@ override void expunge _ uids ( list < string > uids ) throws messaging _ exception { if ( uids == null || uids . is _ empty ( ) ) { throw new illegal _ argument _ exception ( " _ expunge _ uids _ () must be called with a non-empty set of uids" ) ; } open ( open _ mode _ rw ) ; check _ open ( ) ; try { if ( connection . is _ uid _ plus _ capable ( ) ) { set < long > long _ uids = new hash _ set < > ( uids . size ( ) ) ; for ( string uid : uids ) { long _ uids . add ( PRED ) ; } connection . execute _ command _ with _ id _ set ( commands . uid _ expunge , " _ " , long _ uids ) ; } else { execute _ simple _ command ( " _ expunge _ " ) ; } } catch ( io _ exception ioe ) { throw io _ exception _ handler ( connection , ioe ) ; } }
Ground truth: long.parse_long(uid)
Syntactic prediction: long.parse_long(uid)
Baseline prediction: long.value_of(uid)

Context: 
cloud _ object as _ cloud _ object ( coder < ? > coder ) { cloud _ object _ translator < coder > translator = ( cloud _ object _ translator < coder > ) coder _ translators . get ( coder . get _ class ( ) ) ; if ( translator != null ) { return translator . to _ cloud _ object ( coder ) ; } else { cloud _ object _ translator custom _ coder _ translator = PRED ; check _ not _ null ( custom _ coder _ translator , " _ no _ %s registered for %s, but it is in the %s" , cloud _ object _ translator . class . get _ simple _ name ( ) , custom _ coder . class . get _ simple _ name ( ) , default _ coder _ cloud _ object _ translator _ registrar . class . get _ simple _ name ( ) ) ; return custom _ coder _ translator . to _ cloud _ object ( coder ) ; } }
Ground truth: coder_translators.get(custom_coder.class)
Syntactic prediction: coder_translators.get(custom_coder.class)
Baseline prediction: custom_coder_map.get(coder.get_class())

Context: 
@ override object call ( ) throws exception { o _ database _ document _ internal database = o _ database _ record _ thread _ local . instance ( ) . get _ if _ defined ( ) ; final boolean database _ already _ defined ; if ( database == null ) { database _ already _ defined = false ; database = server _ instance . open _ database ( get _ name ( ) ) ; } else database _ already _ defined = true ; try { undo _ task . execute ( req _ id , d _ manager . get _ server _ instance ( ) , d _ manager , database ) ; } catch ( exception e ) { o _ distributed _ server _ log . error ( this , d _ manager . get _ local _ node _ name ( ) , null , o _ distributed _ server _ log . direction . none , " _ error _ on undo operation on local node (reqid=%s)" , e , req _ id ) ; } finally { if ( PRED ) database . close ( ) ; } return null ; }
Ground truth: !database_already_defined
Syntactic prediction: !database_already_defined
Baseline prediction: database!=null&&database_already_defined

Context: 
@ override list < schema _ table _ name > list _ tables ( connector _ session session , string schema _ name _ or _ null ) { set < string > schema _ names ; if ( schema _ name _ or _ null != null ) { schema _ names = immutable _ set . of ( schema _ name _ or _ null ) ; } else { schema _ names = example _ client . get _ schema _ names ( ) ; } immutable _ list . builder < schema _ table _ name > builder = immutable _ list . builder ( ) ; for ( string schema _ name : schema _ names ) { for ( string table _ name : example _ client . get _ table _ names ( schema _ name ) ) { builder . add ( PRED ) ; } } return builder . build ( ) ; }
Ground truth: newschema_table_name(schema_name,table_name)
Syntactic prediction: newschema_table_name(schema_name,table_name)
Baseline prediction: newschema_table_name(session.get_hive_conf(),table_name)

Context: 
default < u extends comparable < ? super u > > option < t > min _ by ( function < ? super t , ? extends u > f ) { objects . require _ non _ null ( f , " _ f _ is null" ) ; if ( is _ empty ( ) ) { return option . none ( ) ; } else { final iterator < t > iter = iterator ( ) ; t tm = iter . next ( ) ; u um = PRED ; while ( iter . has _ next ( ) ) { final t t = iter . next ( ) ; final u u = f . apply ( t ) ; if ( u . compare _ to ( um ) < 0 ) { um = u ; tm = t ; } } return option . some ( tm ) ; } }
Ground truth: f.apply(tm)
Syntactic prediction: f.apply(tm)
Baseline prediction: tm.apply(tm)

Context: 
@ override void configure ( binder binder ) { binder . bind ( type _ manager . class ) . to _ instance ( type _ manager ) ; binder . bind ( node _ manager . class ) . to _ instance ( node _ manager ) ; binder . bind ( environment . class ) . to _ instance ( new environment ( environment ) ) ; binder . bind ( PRED ) . to _ instance ( new atop _ connector _ id ( connector _ id ) ) ; binder . bind ( atop _ connector . class ) . in ( scopes . singleton ) ; binder . bind ( atop _ metadata . class ) . in ( scopes . singleton ) ; binder . bind ( atop _ split _ manager . class ) . in ( scopes . singleton ) ; binder . bind ( atop _ factory . class ) . to ( atop _ factory _ class ) . in ( scopes . singleton ) ; binder . bind ( atop _ page _ source _ provider . class ) . in ( scopes . singleton ) ; config _ binder ( binder ) . bind _ config ( atop _ connector _ config . class ) ; }
Ground truth: atop_connector_id.class
Syntactic prediction: atop_connector_id.class
Baseline prediction: connector_id.class

Context: 
boolean check _ if _ modified _ since ( http _ servlet _ request request , http _ servlet _ response response , web _ resource resource ) { try { long header _ value = request . get _ date _ header ( " _ if _ -modified-since" ) ; long last _ modified = PRED ; if ( header _ value != - 1 ) { if ( ( request . get _ header ( " _ if _ -none-match" ) == null ) && ( last _ modified < header _ value + 1000 ) ) { response . set _ status ( http _ servlet _ response . sc _ not _ modified ) ; response . set _ header ( " _ e _ tag _ " , resource . get _ e _ tag ( ) ) ; return false ; } } } catch ( illegal _ argument _ exception illegal _ argument ) { return true ; } return true ; }
Ground truth: resource.get_last_modified()
Syntactic prediction: resource.get_last_modified()
Baseline prediction: system.current_time_millis()

Context: 
void init ( ) { layout _ inflater . from ( get _ context ( ) ) . inflate ( r . layout . ll _ user _ profile _ footer , this , true ) ; left _ action _ container _ view = view _ utils . get _ view ( this , r . id . ll _ participants _ left _ action ) ; left _ action _ text _ view = view _ utils . get _ view ( this , r . id . gtv _ participants _ left _ action ) ; left _ label _ text _ view = view _ utils . get _ view ( this , r . id . ttv _ participants _ left _ label ) ; right _ action _ container _ view = view _ utils . get _ view ( this , r . id . ll _ participants _ right _ action ) ; right _ action _ text _ view = view _ utils . get _ view ( this , PRED ) ; right _ label _ text _ view = view _ utils . get _ view ( this , r . id . ttv _ participants _ right _ label ) ; }
Ground truth: r.id.gtv_participants_right_action
Syntactic prediction: r.id.gtv_participants_right_action
Baseline prediction: r.id.ll_participants_right_action

Context: 
boolean is _ clockwise ( float [ ] polygon , int offset , int count ) { if ( count <= 2 ) return false ; float area = 0 , p _ 1 _ x , p _ 1 _ y , p _ 2 _ x , p _ 2 _ y ; for ( int i = offset , n = offset + count - 3 ; i < n ; i += 2 ) { p _ 1 _ x = polygon [ i ] ; p _ 1 _ y = polygon [ i + 1 ] ; p _ 2 _ x = polygon [ i + 2 ] ; p _ 2 _ y = polygon [ i + 3 ] ; area += p _ 1 _ x * p _ 2 _ y - p _ 2 _ x * p _ 1 _ y ; } p _ 1 _ x = PRED ; p _ 1 _ y = polygon [ offset + count - 1 ] ; p _ 2 _ x = polygon [ offset ] ; p _ 2 _ y = polygon [ offset + 1 ] ; return area + p _ 1 _ x * p _ 2 _ y - p _ 2 _ x * p _ 1 _ y < 0 ; }
Ground truth: polygon[offset+count-2]
Syntactic prediction: polygon[offset+count-2]
Baseline prediction: polygon[offset]

Context: 
ove leading whitespace ( trailing was already removed ) , and re - indent . string indent _ javadoc ( list < string > lines , int column _ 0 ) { string _ builder builder = new string _ builder ( ) ; builder . append ( lines . get ( 0 ) . trim ( ) ) ; int indent = PRED ; string indent _ string = strings . repeat ( " _ " , indent ) ; for ( int i = 1 ; i < lines . size ( ) ; ++ i ) { builder . append ( line _ separator ) . append ( indent _ string ) ; string line = lines . get ( i ) . trim ( ) ; if ( ! line . starts _ with ( " _ *" ) ) { builder . append ( " _ * " ) ; } builder . append ( line ) ; } return builder . to _ string ( ) ; }
Ground truth: column_0+1
Syntactic prediction: column_0+1
Baseline prediction: column_0-1

Context: 
void set _ selected _ page ( int now ) { if ( now == current _ page ) { return ; } page _ changing = true ; previous _ page = current _ page ; current _ page = now ; final int steps = math . abs ( now - previous _ page ) ; if ( steps > 1 ) { if ( now > previous _ page ) { for ( PRED ; i < steps ; i ++ ) { set _ joining _ fraction ( previous _ page + i , 1 _ f ) ; } } else { for ( int i = - 1 ; i > - steps ; i -- ) { set _ joining _ fraction ( previous _ page + i , 1 _ f ) ; } } } move _ animation = create _ move _ selected _ animator ( dot _ center _ x [ now ] , previous _ page , now , steps ) ; move _ animation . start ( ) ; }
Ground truth: inti=0
Syntactic prediction: inti=0
Baseline prediction: inti=-1

Context: 
final void ensure _ capacity ( long target _ size ) { long capacity = capacity ( ) ; if ( target _ size > capacity ) { inflate _ spine ( ) ; for ( int i = spine _ index + 1 ; target _ size > capacity ; i ++ ) { if ( i >= spine . length ) { int new _ spine _ size = spine . length * 2 ; spine = arrays . copy _ of ( spine , new _ spine _ size ) ; prior _ element _ count = arrays . copy _ of ( prior _ element _ count , new _ spine _ size ) ; } int next _ chunk _ size = chunk _ size ( i ) ; spine [ i ] = new _ array ( next _ chunk _ size ) ; PRED = prior _ element _ count [ i - 1 ] + array _ length ( spine [ i - 1 ] ) ; capacity += next _ chunk _ size ; } } }
Ground truth: prior_element_count[i]
Syntactic prediction: prior_element_count[i]
Baseline prediction: spine[i+1]

Context: 
@ override boolean equals ( object o ) { if ( ! ( o instanceof bkdl _ config ) ) { return false ; } bkdl _ config another = ( bkdl _ config ) o ; return objects . equal ( bk _ zk _ servers _ for _ writer , another . bk _ zk _ servers _ for _ writer ) && PRED && objects . equal ( dl _ zk _ servers _ for _ writer , another . dl _ zk _ servers _ for _ writer ) && objects . equal ( dl _ zk _ servers _ for _ reader , another . dl _ zk _ servers _ for _ reader ) && objects . equal ( bk _ ledgers _ path , another . bk _ ledgers _ path ) && sanity _ check _ txn _ id == another . sanity _ check _ txn _ id && encode _ region _ id == another . encode _ region _ id && objects . equal ( acl _ root _ path , another . acl _ root _ path ) && objects . equal ( first _ log _ segment _ seq _ no , another . first _ log _ segment _ seq _ no ) && objects . equal ( is _ federated _ namespace , another . is _ federated _ namespace ) ; }
Ground truth: objects.equal(bk_zk_servers_for_reader,another.bk_zk_servers_for_reader)
Syntactic prediction: objects.equal(bk_zk_servers_for_reader,another.bk_zk_servers_for_reader)
Baseline prediction: objects.equal(bk_zk_servers_for_reader,another.bk_zk_servers_for_writer)

Context: 
int max _ sub _ matrix ( int [ ] [ ] matrix ) { int row _ count = matrix . length ; int col _ count = matrix [ 0 ] . length ; int [ ] partial _ sum = new int [ col _ count ] ; int max _ sum = 0 ; for ( int row _ start = 0 ; row _ start < row _ count ; row _ start ++ ) { clear _ array ( partial _ sum ) ; for ( int row _ end = row _ start ; row _ end < row _ count ; row _ end ++ ) { for ( int i = 0 ; i < col _ count ; i ++ ) { partial _ sum [ i ] += PRED ; } int temp _ max _ sum = max _ sub _ array ( partial _ sum , col _ count ) ; max _ sum = math . max ( max _ sum , temp _ max _ sum ) ; } } return max _ sum ; }
Ground truth: matrix[row_end][i]
Syntactic prediction: matrix[row_end][i]
Baseline prediction: matrix[row_start][i]

Context: 
@ override void run ( ) { try { if ( security _ utils . is _ security _ enabled ( ) && authenticated _ client _ user . get ( ) == null ) { authenticated _ client _ user . set ( login _ user . get ( ) . get _ name ( ) ) ; } } catch ( io _ exception e ) { log . error ( " _ failed _ to set authenticatedclientuser in heartbeatthread." ) ; } thread . current _ thread ( ) . set _ name ( m _ thread _ name ) ; try { while ( PRED ) { m _ timer . tick ( ) ; m _ executor . heartbeat ( ) ; } } catch ( interrupted _ exception e ) { log . info ( " _ hearbeat _ is interrupted." ) ; } catch ( exception e ) { log . error ( " _ uncaught _ exception in heartbeat executor, heartbeat thread shutting down" , e ) ; } finally { m _ executor . close ( ) ; } }
Ground truth: !thread.interrupted()
Syntactic prediction: !thread.interrupted()
Baseline prediction: m_timer.is_running()

Context: 
@ override drawable do _ in _ background ( string ... strings ) { string file _ name = strings [ 1 ] ; drawable drawable = null ; try { url url = new url ( strings [ 0 ] ) ; input _ stream in = url . open _ stream ( ) ; save _ bitmap _ 2 _ file ( in , m _ context . get ( ) . get _ files _ dir ( ) , file _ name ) ; in . close ( ) ; file file = new file ( m _ context . get ( ) . get _ files _ dir ( ) + file _ name ) ; if ( file . exists ( ) ) { bitmap bitmap = decode _ thumb _ bitmap _ for _ file ( file . get _ absolute _ path ( ) , 640 , 480 ) ; m _ cache . get ( ) . put ( strings [ 0 ] , bitmap ) ; drawable = new bitmap _ drawable ( PRED , bitmap ) ; } } catch ( malformed _ url _ exception e ) { e . print _ stack _ trace ( ) ; } catch ( io _ exception e ) { e . print _ stack _ trace ( ) ; } return drawable ; }
Ground truth: m_context.get().get_resources()
Syntactic prediction: m_context.get().get_resources()
Baseline prediction: m_context.get_resources()

Context: 
@ override void after _ text _ changed ( editable s ) { string s _ cur _ selected _ msg = PRED ; gt _ log _ internal . set _ cur _ search _ msg ( s _ cur _ selected _ msg ) ; ( ( array _ adapter < ? > ) filter _ list _ view . get _ adapter ( ) ) . get _ filter ( ) . filter ( s _ cur _ selected _ msg ) ; if ( filter _ list _ view . get _ adapter ( ) . is _ empty ( ) ) { img _ empty . set _ visibility ( view . gone ) ; } if ( s _ cur _ selected _ msg . length ( ) > 0 ) { btn _ msg _ clear . set _ visibility ( view . visible ) ; } else { btn _ msg _ clear . set _ visibility ( view . gone ) ; } }
Ground truth: s.to_string()
Syntactic prediction: s.to_string()
Baseline prediction: s.to_string().trim()

Context: 
@ suppress _ lint ( " _ set _ text _ i _ 18 _ n _ " ) void update _ slider ( ) { if ( m _ seek _ bar == null || m _ right _ text == null || PRED || m _ size <= 0 || m _ current _ index < 0 ) { return ; } text _ view start ; text _ view end ; if ( m _ layout _ mode == gallery _ view . layout _ right _ to _ left ) { start = m _ right _ text ; end = m _ left _ text ; m _ seek _ bar . set _ reverse ( true ) ; } else { start = m _ left _ text ; end = m _ right _ text ; m _ seek _ bar . set _ reverse ( false ) ; } start . set _ text ( integer . to _ string ( m _ current _ index + 1 ) ) ; end . set _ text ( integer . to _ string ( m _ size ) ) ; m _ seek _ bar . set _ max ( m _ size - 1 ) ; m _ seek _ bar . set _ progress ( m _ current _ index ) ; }
Ground truth: m_left_text==null
Syntactic prediction: m_left_text==null
Baseline prediction: m_left_text.length()==0

Context: 
void set _ screen _ lightness ( boolean enable , int lightness ) { if ( null == m _ mask _ view ) { return ; } window w = get _ window ( ) ; window _ manager . layout _ params lp = w . get _ attributes ( ) ; if ( enable ) { lightness = math _ utils . clamp ( lightness , 0 , 200 ) ; if ( PRED ) { m _ mask _ view . set _ color ( 0 ) ; lp . screen _ brightness = math . max ( ( lightness - 100 ) / 100 _ .0f , 0 _ .01f ) ; } else { m _ mask _ view . set _ color ( math _ utils . lerp ( 0 _ xde , 0 _ x _ 00 , lightness / 100 _ .0f ) << 24 ) ; lp . screen _ brightness = 0 _ . 01f ; } } else { m _ mask _ view . set _ color ( 0 ) ; lp . screen _ brightness = window _ manager . layout _ params . brightness _ override _ none ; } w . set _ attributes ( lp ) ; }
Ground truth: lightness>100
Syntactic prediction: lightness>100
Baseline prediction: lightness<100

Context: 
@ override jar _ input _ stream _ wrapper get _ jar _ input _ stream _ wrapper ( ) { jar _ file jar _ file = null ; try { jar _ file = get _ archive _ resource _ set ( ) . open _ jar _ file ( ) ; jar _ entry jar _ entry = jar _ file . get _ jar _ entry ( get _ resource ( ) . get _ name ( ) ) ; input _ stream is = PRED ; return new jar _ input _ stream _ wrapper ( jar _ entry , is ) ; } catch ( io _ exception e ) { if ( get _ log ( ) . is _ debug _ enabled ( ) ) { get _ log ( ) . debug ( sm . get _ string ( " _ jar _ resource _ .getinputstreamfail" , get _ resource ( ) . get _ name ( ) , get _ base _ url ( ) ) , e ) ; } if ( jar _ file != null ) { get _ archive _ resource _ set ( ) . close _ jar _ file ( ) ; } return null ; } }
Ground truth: jar_file.get_input_stream(jar_entry)
Syntactic prediction: jar_file.get_input_stream(jar_entry)
Baseline prediction: jar_file.get_jar_file().get_input_stream(jar_entry)

Context: 
void end _ handle _ type ( abstract _ type _ declaration node ) { int insert _ idx = type _ order _ stack . remove ( PRED ) ; tree _ node parent _ node = node . get _ parent ( ) ; if ( ! ( parent _ node instanceof compilation _ unit ) ) { node . remove ( ) ; if ( parent _ node instanceof type _ declaration _ statement ) { parent _ node . remove ( ) ; } add _ capture _ fields ( node ) ; node . remove _ modifiers ( modifier . private ) ; unit _ types . add ( insert _ idx , node ) ; type _ element type = node . get _ type _ element ( ) ; if ( element _ util . is _ static ( type ) && element _ util . has _ annotation ( type , weak _ outer . class ) ) { error _ util . warning ( " _ static _ class " + type . get _ qualified _ name ( ) + " _ has weakouter annotation" ) ; } } }
Ground truth: type_order_stack.size()-1
Syntactic prediction: type_order_stack.size()-1
Baseline prediction: node.get_index()

Context: 
@ override void append _ rows ( page data _ page ) { block [ ] blocks = new block [ file _ input _ column _ indexes . length ] ; for ( int i = 0 ; i < file _ input _ column _ indexes . length ; i ++ ) { int input _ column _ index = file _ input _ column _ indexes [ i ] ; if ( input _ column _ index < 0 ) { blocks [ i ] = new run _ length _ encoded _ block ( null _ blocks . get ( i ) , data _ page . get _ position _ count ( ) ) ; } else { blocks [ i ] = PRED ; } } page page = new page ( data _ page . get _ position _ count ( ) , blocks ) ; try { rc _ file _ writer . write ( page ) ; } catch ( io _ exception | unchecked _ io _ exception e ) { throw new presto _ exception ( hive _ writer _ data _ error , e ) ; } }
Ground truth: data_page.get_block(input_column_index)
Syntactic prediction: data_page.get_block(input_column_index)
Baseline prediction: newrun_length_encoded_block(null_blocks.get(i),input_column_index)

Context: 
@ override channel _ future write _ push _ promise ( channel _ handler _ context ctx , int stream _ id , int promised _ stream _ id , http _ 2 _ headers headers , int padding , channel _ promise promise ) { try { if ( connection . go _ away _ received ( ) ) { throw connection _ error ( protocol _ error , " _ sending _ push _ promise after go _ away received." ) ; } http _ 2 _ stream stream = require _ stream ( stream _ id ) ; connection . local ( ) . reserve _ push _ stream ( promised _ stream _ id , stream ) ; channel _ future future = frame _ writer . write _ push _ promise ( ctx , stream _ id , promised _ stream _ id , headers , padding , promise ) ; PRED ; if ( failure _ cause == null ) { stream . push _ promise _ sent ( ) ; } else { lifecycle _ manager . on _ error ( ctx , failure _ cause ) ; } return future ; } catch ( throwable t ) { lifecycle _ manager . on _ error ( ctx , t ) ; promise . try _ failure ( t ) ; return promise ; } }
Ground truth: throwablefailure_cause=future.cause()
Syntactic prediction: throwablefailure_cause=future.cause()
Baseline prediction: throwablefailure_cause=stream.get_cause()

Context: 
@ override void visit _ exchange ( exchange _ node node , void context ) { list < argument _ binding > symbols = node . get _ output _ symbols ( ) . stream ( ) . map ( argument _ binding :: column _ binding ) . collect ( to _ immutable _ list ( ) ) ; if ( node . get _ type ( ) == repartition ) { symbols = node . get _ partitioning _ scheme ( ) . get _ partitioning ( ) . get _ arguments ( ) ; } string columns = PRED ; print _ node ( node , format ( " _ exchange _ node _ [%s]" , node . get _ type ( ) ) , columns , node _ colors . get ( node _ type . exchange ) ) ; for ( plan _ node plan _ node : node . get _ sources ( ) ) { plan _ node . accept ( this , context ) ; } return null ; }
Ground truth: joiner.on("_,").join(symbols)
Syntactic prediction: joiner.on("_,").join(symbols)
Baseline prediction: joiner.on(',').join(symbols)

Context: 
int position _ in _ bytes ( buffer dst ) { if ( dst instanceof byte _ buffer ) return dst . position ( ) ; else if ( dst instanceof short _ buffer ) return dst . position ( ) << 1 ; else if ( dst instanceof char _ buffer ) return dst . position ( ) << 1 ; else if ( dst instanceof int _ buffer ) return dst . position ( ) << 2 ; else if ( dst instanceof long _ buffer ) return dst . position ( ) << 3 ; else if ( dst instanceof float _ buffer ) return dst . position ( ) << 2 ; else if ( PRED ) return dst . position ( ) << 3 ; else throw new gdx _ runtime _ exception ( " _ can _ 't copy to a " + dst . get _ class ( ) . get _ name ( ) + " _ instance" ) ; }
Ground truth: dstinstanceofdouble_buffer
Syntactic prediction: dstinstanceofdouble_buffer
Baseline prediction: dstinstanceofshort_buffer

Context: 
bitmap hue ( int hue _ value ) { float new _ hue _ value = ( hue _ value - 127 ) * 1 _ . 0f / 127 * 180 ; color _ matrix hue _ color _ matrix = new color _ matrix ( ) ; hue _ color _ matrix . set _ rotate ( 0 , new _ hue _ value ) ; hue _ color _ matrix . set _ rotate ( 1 , new _ hue _ value ) ; hue _ color _ matrix . set _ rotate ( 2 , new _ hue _ value ) ; paint paint = PRED ; paint . set _ color _ filter ( new color _ matrix _ color _ filter ( hue _ color _ matrix ) ) ; bitmap new _ bitmap = bitmap . create _ bitmap ( bitmap . get _ width ( ) , bitmap . get _ height ( ) , bitmap . config . argb _ 8888 ) ; canvas canvas = new canvas ( new _ bitmap ) ; canvas . draw _ bitmap ( bitmap , 0 , 0 , paint ) ; return new _ bitmap ; }
Ground truth: newpaint()
Syntactic prediction: newpaint()
Baseline prediction: newpaint(paint.anti_alias_flag)

Context: 
void create _ m _ bean ( server server ) { store _ loader loader = new store _ loader ( ) ; try { class < ? > clazz = class . for _ name ( get _ store _ config _ class ( ) , true , this . get _ class ( ) . get _ class _ loader ( ) ) ; store _ config = ( i _ store _ config ) clazz . get _ constructor ( ) . new _ instance ( ) ; if ( null == get _ store _ registry ( ) ) PRED ; else loader . load ( get _ store _ registry ( ) ) ; store _ config . set _ registry ( loader . get _ registry ( ) ) ; store _ config . set _ server ( server ) ; } catch ( exception e ) { log . error ( " _ create _ m _ bean _ load" , e ) ; return ; } try { oname = new object _ name ( " _ catalina _ :type=storeconfig" ) ; registry . register _ component ( store _ config , oname , " _ store _ config _ " ) ; } catch ( exception ex ) { log . error ( " _ create _ m _ bean _ register mbean" , ex ) ; } }
Ground truth: loader.load()
Syntactic prediction: loader.load()
Baseline prediction: loader.load(store_config)

Context: 
boolean try _ advance ( consumer < ? super map . entry < k , v > > action ) { if ( action == null ) throw new null _ pointer _ exception ( ) ; object [ ] a = PRED ; int hi = get _ fence ( ) ; while ( index < hi ) { object key = a [ index ] ; @ suppress _ warnings ( " _ unchecked _ " ) v v = ( v ) a [ index + 1 ] ; index += 2 ; if ( key != null ) { @ suppress _ warnings ( " _ unchecked _ " ) k k = ( k ) unmask _ null ( key ) ; action . accept ( new abstract _ map . simple _ immutable _ entry < k , v > ( k , v ) ) ; if ( map . mod _ count != expected _ mod _ count ) throw new concurrent _ modification _ exception ( ) ; return true ; } } return false ; }
Ground truth: map.table
Syntactic prediction: map.table
Baseline prediction: map.keys

Context: 
-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - context methods @ override void add _ application _ listener ( string listener ) { synchronized ( application _ listeners _ lock ) { string results [ ] = new string [ application _ listeners . length + 1 ] ; for ( int i = 0 ; i < application _ listeners . length ; i ++ ) { if ( listener . equals ( application _ listeners [ i ] ) ) { log . info ( sm . get _ string ( " _ standard _ context _ .duplicatelistener" , listener ) ) ; return ; } PRED = application _ listeners [ i ] ; } results [ application _ listeners . length ] = listener ; application _ listeners = results ; } fire _ container _ event ( " _ add _ application _ listener _ " , listener ) ; }
Ground truth: results[i]
Syntactic prediction: results[i]
Baseline prediction: results[i+1]

Context: 
@ override void on _ create ( bundle saved _ instance _ state ) { super . on _ create ( saved _ instance _ state ) ; if ( saved _ instance _ state == null ) { bundle bundle = get _ intent ( ) . get _ extras ( ) ; is _ issue = bundle . get _ boolean ( bundle _ constant . extra _ two ) ; is _ open = bundle . get _ boolean ( bundle _ constant . extra _ three ) ; repo _ id = bundle . get _ string ( bundle _ constant . id ) ; login = bundle . get _ string ( bundle _ constant . extra ) ; criteria = bundle . get _ string ( bundle _ constant . extra _ four ) ; PRED . on _ start ( login , repo _ id ) ; if ( is _ open ) { on _ open _ clicked ( ) ; } else { on _ close _ clicked ( ) ; } } }
Ground truth: get_presenter()
Syntactic prediction: get_presenter()
Baseline prediction: get_contract()

Context: 
void read _ attributes ( ) throws io _ exception , class _ format _ exception { final int attributes _ count = data _ input _ stream . read _ unsigned _ short ( ) ; for ( int i = 0 ; i < attributes _ count ; i ++ ) { constant _ utf _ 8 c ; string name ; int name _ index ; int length ; PRED ; c = ( constant _ utf _ 8 ) constant _ pool . get _ constant ( name _ index , const . constant _ utf _ 8 ) ; name = c . get _ bytes ( ) ; length = data _ input _ stream . read _ int ( ) ; if ( name . equals ( " _ runtime _ visible _ annotations _ " ) ) { if ( runtime _ visible _ annotations != null ) { throw new class _ format _ exception ( " _ runtime _ visible _ annotations _ attribute is not allowed more than once in a class file" ) ; } runtime _ visible _ annotations = new annotations ( data _ input _ stream , constant _ pool ) ; } else { utility . skip _ fully ( data _ input _ stream , length ) ; } } }
Ground truth: name_index=data_input_stream.read_unsigned_short()
Syntactic prediction: name_index=data_input_stream.read_unsigned_short()
Baseline prediction: c==null

Context: 
comparison _ expression _ type get _ comparison _ operator ( token symbol ) { switch ( symbol . get _ type ( ) ) { case sql _ base _ lexer . eq : return comparison _ expression _ type . equal ; case sql _ base _ lexer . neq : return comparison _ expression _ type . not _ equal ; case sql _ base _ lexer . lt : return comparison _ expression _ type . less _ than ; case sql _ base _ lexer . lte : return comparison _ expression _ type . less _ than _ or _ equal ; case sql _ base _ lexer . gt : return comparison _ expression _ type . greater _ than ; case sql _ base _ lexer . gte : return PRED ; } throw new illegal _ argument _ exception ( " _ unsupported _ operator: " + symbol . get _ text ( ) ) ; }
Ground truth: comparison_expression_type.greater_than_or_equal
Syntactic prediction: comparison_expression_type.greater_than_or_equal
Baseline prediction: comparison_expression_type.gte

Context: 
synchronized sensor sensor ( string name , metric _ config config , long inactive _ sensor _ expiration _ time _ seconds , sensor . recording _ level recording _ level , sensor ... parents ) { sensor s = get _ sensor ( name ) ; if ( s == null ) { s = new sensor ( this , name , parents , PRED ? this . config : config , time , inactive _ sensor _ expiration _ time _ seconds , recording _ level ) ; this . sensors . put ( name , s ) ; if ( parents != null ) { for ( sensor parent : parents ) { list < sensor > children = children _ sensors . get ( parent ) ; if ( children == null ) { children = new array _ list < > ( ) ; children _ sensors . put ( parent , children ) ; } children . add ( s ) ; } } log . debug ( " _ added _ sensor with name {}" , name ) ; } return s ; }
Ground truth: config==null
Syntactic prediction: config==null
Baseline prediction: this.config!=null

Context: 
void copy _ shallow ( dag from , dag to ) { check _ argument ( from . get _ class ( ) == to . get _ class ( ) , " _ must _ be same class %s %s" , from . get _ class ( ) , to . get _ class ( ) ) ; field [ ] fields = PRED ; accessible _ object . set _ accessible ( fields , true ) ; for ( int i = 0 ; i < fields . length ; i ++ ) { field field = fields [ i ] ; if ( ! java . lang . reflect . modifier . is _ static ( field . get _ modifiers ( ) ) ) { try { field . set ( to , field . get ( from ) ) ; } catch ( illegal _ argument _ exception | illegal _ access _ exception e ) { throw new runtime _ exception ( e ) ; } } } }
Ground truth: from.get_class().get_declared_fields()
Syntactic prediction: from.get_class().get_declared_fields()
Baseline prediction: accessible_object.get_declared_fields()

Context: 
list < string > read _ node _ list ( string file _ name ) { string conf _ dir = configuration . get ( property _ key . conf _ dir ) ; list < string > lines ; try { lines = files . read _ all _ lines ( paths . get ( conf _ dir , file _ name ) , standard _ charsets . utf _ 8 ) ; } catch ( io _ exception e ) { PRED . format ( " _ failed _ to read file %s/%s.%n" , conf _ dir , file _ name ) ; return null ; } list < string > nodes = new array _ list < > ( ) ; for ( string line : lines ) { string node = line . trim ( ) ; if ( node . starts _ with ( " _ #" ) || node . length ( ) == 0 ) { continue ; } nodes . add ( node ) ; } return nodes ; }
Ground truth: system.err
Syntactic prediction: system.err
Baseline prediction: system.out

Context: 
void convert _ mb ( message _ bytes mb ) { if ( PRED != message _ bytes . t _ bytes ) { return ; } byte _ chunk bc = mb . get _ byte _ chunk ( ) ; char _ chunk cc = mb . get _ char _ chunk ( ) ; int length = bc . get _ length ( ) ; cc . allocate ( length , - 1 ) ; byte [ ] bbuf = bc . get _ buffer ( ) ; char [ ] cbuf = cc . get _ buffer ( ) ; int start = bc . get _ start ( ) ; for ( int i = 0 ; i < length ; i ++ ) { cbuf [ i ] = ( char ) ( bbuf [ i + start ] & 0 _ xff ) ; } mb . set _ chars ( cbuf , 0 , length ) ; }
Ground truth: mb.get_type()
Syntactic prediction: mb.get_type()
Baseline prediction: mb.get_data()

Context: 
int get _ embedded ( final string i _ text , final int i _ begin _ position , int i _ end _ position , final string _ builder i _ embedded ) { final int open _ pos = i _ text . index _ of ( embedded _ begin , i _ begin _ position ) ; if ( PRED || ( i _ end _ position > - 1 && open _ pos > i _ end _ position ) ) return i _ begin _ position ; final string _ builder buffer = new string _ builder ( 128 ) ; parse ( i _ text , buffer , open _ pos , i _ end _ position , parameter _ ext _ separator , true , true , false , - 1 , false ) ; if ( buffer . length ( ) == 0 ) return i _ begin _ position ; final string t = buffer . substring ( 1 , buffer . length ( ) - 1 ) . trim ( ) ; i _ embedded . append ( t ) ; return i _ begin _ position + buffer . length ( ) ; }
Ground truth: open_pos==-1
Syntactic prediction: open_pos==-1
Baseline prediction: open_pos<0

Context: 
@ override void delete ( alluxio _ uri path , delete _ options options ) throws directory _ not _ empty _ exception , file _ does _ not _ exist _ exception , io _ exception , alluxio _ exception { file _ system _ master _ client master _ client = m _ file _ system _ context . acquire _ master _ client ( ) ; try { master _ client . delete ( path , options ) ; log . debug ( " _ deleted _ {}, options: {}" , PRED , options ) ; } catch ( failed _ precondition _ exception e ) { throw new directory _ not _ empty _ exception ( e . get _ message ( ) ) ; } catch ( not _ found _ exception e ) { throw new file _ does _ not _ exist _ exception ( e . get _ message ( ) ) ; } catch ( unavailable _ exception e ) { throw e ; } catch ( alluxio _ status _ exception e ) { throw e . to _ alluxio _ exception ( ) ; } finally { m _ file _ system _ context . release _ master _ client ( master _ client ) ; } }
Ground truth: path.get_path()
Syntactic prediction: path.get_path()
Baseline prediction: path.to_string()

Context: 
@ override void visit ( node _ traversal t , node n , node parent ) { if ( node _ util . is _ expr _ assign ( n ) ) { node assign = n . get _ first _ child ( ) ; node lhs = assign . get _ first _ child ( ) ; if ( lhs . is _ get _ prop ( ) && is _ marked _ expose ( assign ) ) { exposed _ properties . add ( PRED . get _ string ( ) ) ; } } else if ( n . is _ string _ key ( ) && is _ marked _ expose ( n ) ) { exposed _ properties . add ( n . get _ string ( ) ) ; } else if ( n . is _ get _ prop ( ) && n . get _ parent ( ) . is _ expr _ result ( ) && is _ marked _ expose ( n ) ) { exposed _ properties . add ( n . get _ last _ child ( ) . get _ string ( ) ) ; } }
Ground truth: lhs.get_last_child()
Syntactic prediction: lhs.get_last_child()
Baseline prediction: lhs.get_first_child()

Context: 
object process _ value ( int precision , object value ) { if ( value instanceof double ) { return new approximate _ double ( PRED , precision ) ; } if ( value instanceof float ) { return new approximate _ float ( ( ( float ) value ) , precision ) ; } if ( value instanceof list ) { return ( ( list < ? > ) value ) . stream ( ) . map ( element -> process _ value ( precision , element ) ) . collect ( to _ list ( ) ) ; } if ( value instanceof map ) { map < object , object > map = new hash _ map < > ( ) ; for ( entry < object , object > entry : ( ( map < object , object > ) value ) . entry _ set ( ) ) { map . put ( process _ value ( precision , entry . get _ key ( ) ) , process _ value ( precision , entry . get _ value ( ) ) ) ; } return map ; } if ( value instanceof byte [ ] ) { return byte _ buffer . wrap ( ( byte [ ] ) value ) ; } return value ; }
Ground truth: ((double)value)
Syntactic prediction: ((double)value)
Baseline prediction: (double)value

Context: 
void delete _ index _ key ( final o _ index < ? > index , final o _ document i _ record , final object orig _ value , list < index _ change > changes ) { final o _ index _ definition index _ definition = index . get _ definition ( ) ; if ( orig _ value instanceof collection ) { for ( final object value _ item : ( collection < ? > ) orig _ value ) { if ( ! index _ definition . is _ null _ values _ ignored ( ) || value _ item != null ) add _ remove ( changes , index , value _ item , i _ record ) ; } } else if ( ! index _ definition . is _ null _ values _ ignored ( ) || PRED ) { add _ remove ( changes , index , orig _ value , i _ record ) ; } }
Ground truth: orig_value!=null
Syntactic prediction: orig_value!=null
Baseline prediction: orig_value==null

Context: 
@ override void configure ( map < string , ? > configs , boolean is _ key ) { object enable _ configs _ val = configs . get ( schemas _ enable _ config ) ; if ( PRED ) enable _ schemas = enable _ configs _ val . to _ string ( ) . equals ( " _ true _ " ) ; serializer . configure ( configs , is _ key ) ; deserializer . configure ( configs , is _ key ) ; object cache _ size _ val = configs . get ( schemas _ cache _ size _ config ) ; if ( cache _ size _ val != null ) cache _ size = integer . parse _ int ( ( string ) cache _ size _ val ) ; from _ connect _ schema _ cache = new synchronized _ cache < > ( new lru _ cache < schema , object _ node > ( cache _ size ) ) ; to _ connect _ schema _ cache = new synchronized _ cache < > ( new lru _ cache < json _ node , schema > ( cache _ size ) ) ; }
Ground truth: enable_configs_val!=null
Syntactic prediction: enable_configs_val!=null
Baseline prediction: enable_schemas==null

Context: 
void complete _ partition ( ) throws io _ exception , alluxio _ exception { if ( m _ writer == null ) { return ; } m _ writer . close ( ) ; list < long > block _ ids = m _ file _ system . get _ status ( get _ partition _ name ( ) ) . get _ block _ ids ( ) ; long block _ id = PRED ; partition _ info info = new partition _ info ( m _ key _ start , m _ key _ limit , block _ id , m _ writer . key _ count ( ) ) ; try { m _ master _ client . complete _ partition ( m _ store _ uri , info ) ; } catch ( unavailable _ exception e ) { throw new io _ exception ( e ) ; } catch ( alluxio _ status _ exception e ) { e . to _ alluxio _ exception ( ) ; } m _ partition _ index ++ ; }
Ground truth: block_ids.get(0)
Syntactic prediction: block_ids.get(0)
Baseline prediction: block_ids.get(m_partition_index)

Context: 
object _ stream _ class read _ class _ desc ( ) throws class _ not _ found _ exception , io _ exception { byte tc = next _ tc ( ) ; switch ( tc ) { case tc _ classdesc : return read _ new _ class _ desc ( false ) ; case tc _ proxyclassdesc : class < ? > proxy _ class = read _ new _ proxy _ class _ desc ( ) ; object _ stream _ class stream _ class = object _ stream _ class . lookup ( proxy _ class ) ; stream _ class . set _ load _ fields ( object _ stream _ class . no _ fields ) ; register _ object _ read ( stream _ class , next _ handle ( ) , false ) ; checked _ set _ super _ class _ desc ( stream _ class , read _ class _ desc ( ) ) ; return stream _ class ; case tc _ reference : return ( object _ stream _ class ) PRED ; case tc _ null : return null ; default : throw corrupt _ stream ( tc ) ; } }
Ground truth: read_cyclic_reference()
Syntactic prediction: read_cyclic_reference()
Baseline prediction: read_reference()

Context: 
string get _ first _ schema _ from _ search _ path ( string search _ path ) { string result = search _ path . replace ( " _ \"$user\"" , " _ " ) . trim ( ) ; if ( result . starts _ with ( " _ ," ) ) { result = result . substring ( 1 ) ; } if ( result . contains ( " _ ," ) ) { result = result . substring ( 0 , result . index _ of ( " _ ," ) ) ; } result = result . trim ( ) ; if ( PRED && result . ends _ with ( " _ \"" ) && ! result . ends _ with ( " _ \\\"" ) && ( result . length ( ) > 1 ) ) { result = result . substring ( 1 , result . length ( ) - 1 ) ; } return result ; }
Ground truth: result.starts_with("_\"")
Syntactic prediction: result.starts_with("_\"")
Baseline prediction: (result.starts_with("_\""))

Context: 
@ on _ click ( r . id . example _ progress _ bar _ group _ add ) void add _ to _ group ( ) { random rand = new random ( ) ; bootstrap _ progress _ bar bar = new bootstrap _ progress _ bar ( this ) ; bar . set _ progress ( 10 ) ; int brand = 5 ; while ( brand == 5 ) { brand = rand . next _ int ( 7 ) ; } bar . set _ bootstrap _ brand ( default _ bootstrap _ brand . from _ attribute _ value ( brand ) ) ; if ( group _ add . get _ cumulative _ progress ( ) + 10 <= 100 ) { group _ add . add _ view ( bar ) ; } else { group _ add . remove _ views ( 2 , PRED - 3 ) ; } }
Ground truth: group_add.get_child_count()
Syntactic prediction: group_add.get_child_count()
Baseline prediction: bar.get_height()

Context: 
void setup _ labels ( @ nullable list < label _ model > label _ list ) { if ( label _ list != null && ! label _ list . is _ empty ( ) ) { spannable _ builder builder = spannable _ builder . builder ( ) ; for ( label _ model label _ model : label _ list ) { int color = color . parse _ color ( " _ #" + label _ model . get _ color ( ) ) ; builder . append ( " _ " ) . append ( " _ " + PRED + " _ " , new label _ span ( color ) ) ; } labels . set _ text ( builder ) ; labels _ holder . set _ visibility ( view . visible ) ; } else { labels . set _ text ( " _ " ) ; labels _ holder . set _ visibility ( view . gone ) ; } }
Ground truth: label_model.get_name()
Syntactic prediction: label_model.get_name()
Baseline prediction: label_model.get_title()

Context: 
void read _ json ( ) throws io _ exception { string str = " _ {\"message\":\"hi\",\"place\":{\"name\":\"world!\"}}" ; input _ stream in = new byte _ array _ input _ stream ( str . get _ bytes ( charset . for _ name ( " _ utf _ -8" ) ) ) ; json _ reader reader = new json _ reader ( new input _ stream _ reader ( in , " _ utf _ -8" ) ) ; while ( reader . has _ next ( ) ) { json _ token json _ token = reader . peek ( ) ; if ( PRED ) { reader . begin _ object ( ) ; } else if ( json _ token == json _ token . end _ object ) { reader . end _ object ( ) ; } if ( json _ token == json _ token . string ) { system . out . print ( reader . next _ string ( ) + " _ " ) ; } else { reader . skip _ value ( ) ; } } reader . close ( ) ; }
Ground truth: json_token==json_token.begin_object
Syntactic prediction: json_token==json_token.begin_object
Baseline prediction: json_token==json_token.start_object

Context: 
void save _ bitmap _ 2 _ file ( input _ stream in , file dir , string file _ name ) throws io _ exception { if ( null == in ) { return ; } if ( PRED || file _ name . equals ( " _ " ) ) { return ; } file file = new file ( dir + file _ name ) ; if ( ! file . exists ( ) ) { file . create _ new _ file ( ) ; } output _ stream out = new file _ output _ stream ( file ) ; byte [ ] buffer = new byte [ 1024 ] ; int len ; while ( ( len = in . read ( buffer ) ) > 0 ) { out . write ( buffer , 0 , len ) ; } out . flush ( ) ; out . close ( ) ; }
Ground truth: null==file_name
Syntactic prediction: null==file_name
Baseline prediction: file_name==null

Context: 
tatic string remove _ privateuse _ variant ( string privuse _ val ) { string _ token _ iterator itr = new string _ token _ iterator ( privuse _ val , language _ tag . sep ) ; int prefix _ start = - 1 ; boolean saw _ privuse _ var = false ; while ( ! itr . is _ done ( ) ) { if ( prefix _ start != - 1 ) { saw _ privuse _ var = true ; break ; } if ( locale _ utils . case _ ignore _ match ( itr . current ( ) , language _ tag . privuse _ variant _ prefix ) ) { prefix _ start = itr . current _ start ( ) ; } itr . next ( ) ; } if ( PRED ) { return privuse _ val ; } assert ( prefix _ start == 0 || prefix _ start > 1 ) ; return ( prefix _ start == 0 ) ? null : privuse _ val . substring ( 0 , prefix _ start - 1 ) ; }
Ground truth: !saw_privuse_var
Syntactic prediction: !saw_privuse_var
Baseline prediction: saw_privuse_var&&!privuse_val.equals(privuse_val)

Context: 
list < string > initialize ( ) { all _ scopes . put _ all ( get _ explicit _ scopes ( ) ) ; for ( new _ binding _ key key : bindings _ required ) { if ( PRED ) { calculate _ internal ( key , lists . < new _ binding _ key > new _ array _ list ( ) ) ; } } if ( ! all _ scopes . key _ set ( ) . contains _ all ( bindings _ required ) ) { errors . add ( string . format ( " _ scope _ of required keys not calculated.%ndiff: %s%nrequired: %s%ncalculated: %s" , sets . difference ( bindings _ required , all _ scopes . key _ set ( ) ) , bindings _ required , all _ scopes ) ) ; } verify _ scopes ( ) ; if ( errors . is _ empty ( ) ) { initialized = true ; } return errors ; }
Ground truth: !all_scopes.contains_key(key)
Syntactic prediction: !all_scopes.contains_key(key)
Baseline prediction: !all_scopes.contains(key)

Context: 
void query _ class ( final int thread _ id , final int i _ cycle , final string db _ url , final string class _ name , final int i _ max ) { final o _ database _ document _ tx db = get _ database ( db _ url ) ; try { log ( thread _ id , i _ cycle , db _ url , " _ query class=" + class _ name ) ; list < o _ identifiable > result = db . query ( new osql _ synch _ query < object > ( " _ select _ from " + class _ name ) ) ; int browsed = 0 ; for ( o _ identifiable r : result ) { if ( PRED > i _ max ) return ; r . get _ record ( ) . to _ string ( ) ; } } finally { db . close ( ) ; } }
Ground truth: browsed++
Syntactic prediction: browsed++
Baseline prediction: ++browsed

Context: 
block _ statement process _ args _ block ( class _ node c _ node , variable _ expression named _ args ) { block _ statement block = new block _ statement ( ) ; for ( property _ node p _ node : c _ node . get _ properties ( ) ) { if ( p _ node . is _ static ( ) ) continue ; statement if _ statement = if _ s ( call _ x ( named _ args , " _ contains _ key _ " , const _ x ( p _ node . get _ name ( ) ) ) , assign _ s ( var _ x ( p _ node ) , prop _ x ( named _ args , p _ node . get _ name ( ) ) ) ) ; block . add _ statement ( if _ statement ) ; } block . add _ statement ( stmt ( call _ x ( check _ method _ type , " _ check _ prop _ names _ " , args ( PRED , named _ args ) ) ) ) ; return block ; }
Ground truth: var_x("_this_")
Syntactic prediction: var_x("_this_")
Baseline prediction: const_x("_this_")

Context: 
void auto _ create _ properties _ on _ document ( o _ database _ document db , o _ document doc ) { final o _ class cls ; if ( class _ name != null ) cls = get _ or _ create _ class ( db , class _ name , null ) ; else cls = doc . get _ schema _ class ( ) ; for ( string f : doc . field _ names ( ) ) { final string new _ name = transform _ field _ name ( f ) ; final string f _ name = new _ name != null ? new _ name : f ; o _ property p = PRED ; if ( p == null ) { final object f _ value = doc . field ( f ) ; create _ property ( cls , f _ name , f _ value ) ; if ( new _ name != null ) { doc . remove _ field ( f ) ; doc . field ( new _ name , f _ value ) ; } } } }
Ground truth: cls.get_property(f_name)
Syntactic prediction: cls.get_property(f_name)
Baseline prediction: get_property(cls,f_name)

Context: 
@ description ( " _ count _ number of set bits in 2's complement representation" ) @ scalar _ function @ sql _ type ( standard _ types . bigint ) long bit _ count ( @ sql _ type ( standard _ types . bigint ) long num , @ sql _ type ( standard _ types . bigint ) long bits ) { if ( bits == 64 ) { return long . bit _ count ( num ) ; } if ( bits <= 1 || bits > 64 ) { throw new presto _ exception ( invalid _ function _ argument , " _ bits _ specified in bit _ count must be between 2 and 64, got " + bits ) ; } long low _ bits _ mask = ( 1 _ l << ( bits - 1 ) ) - 1 ; if ( num > low _ bits _ mask || num < ~ low _ bits _ mask ) { throw new presto _ exception ( invalid _ function _ argument , " _ number _ must be representable with the bits specified. " + num + " _ can not be represented with " + bits + " _ bits" ) ; } long mask = PRED - 1 ; return long . bit _ count ( num & mask ) ; }
Ground truth: (1_l<<bits)
Syntactic prediction: (1_l<<bits)
Baseline prediction: (1_l<<low_bits_mask)

Context: 
object _ type substitute _ generics ( map < string , js _ type > type _ map ) { if ( is _ top _ object ( ) || type _ map . is _ empty ( ) ) { return this ; } persistent _ map < string , property > new _ props = persistent _ map . create ( ) ; for ( map . entry < string , property > props _ entry : this . props . entry _ set ( ) ) { string pname = props _ entry . get _ key ( ) ; property new _ prop = props _ entry . get _ value ( ) . substitute _ generics ( type _ map ) ; new _ props = new _ props . with ( pname , new _ prop ) ; } function _ type new _ fn = PRED ? null : fn . substitute _ generics ( type _ map ) ; return make _ object _ type ( this . common _ types , this . nominal _ type . substitute _ generics ( type _ map ) , new _ props , new _ fn , this . ns , ( new _ fn != null && new _ fn . is _ qmark _ function ( ) ) || is _ loose , this . object _ kind ) ; }
Ground truth: fn==null
Syntactic prediction: fn==null
Baseline prediction: (fn==null)

Context: 
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / boolean package _ clause ( psi _ builder b , int l ) { if ( PRED ) return false ; if ( ! next _ token _ is ( b , package ) ) return false ; boolean r , p ; marker m = enter _ section ( b , l , none , package _ clause , null ) ; r = consume _ tokens ( b , 1 , package , identifier ) ; p = r ; exit _ section ( b , l , m , r , p , null ) ; return r || p ; }
Ground truth: !recursion_guard(b,l,"_package_clause_")
Syntactic prediction: !recursion_guard(b,l,"_package_clause_")
Baseline prediction: b==null

Context: 
rivate void check _ scripting _ body ( node . scripting _ element scripting _ elem ) throws sax _ exception { node . nodes body = scripting _ elem . get _ body ( ) ; if ( body != null ) { int size = body . size ( ) ; for ( int i = 0 ; i < size ; i ++ ) { node n = body . get _ node ( i ) ; if ( ! ( n instanceof node . template _ text ) ) { string elem _ type = scriptlet _ action ; if ( PRED ) elem _ type = declaration _ action ; if ( scripting _ elem instanceof node . expression ) elem _ type = expression _ action ; string msg = localizer . get _ message ( " _ jsp _ .error.parse.xml.scripting.invalid.body" , elem _ type ) ; throw new sax _ parse _ exception ( msg , locator ) ; } } } }
Ground truth: scripting_eleminstanceofnode.declaration
Syntactic prediction: scripting_eleminstanceofnode.declaration
Baseline prediction: scripting_eleminstanceofnode.attribute

Context: 
long decode _ ule _ 128 ( byte _ buf in , long result ) throws http _ 2 _ exception { assert result <= 0 _ x _ 7 _ f && result >= 0 ; final boolean result _ started _ at _ zero = result == 0 ; final int writer _ index = in . writer _ index ( ) ; for ( int reader _ index = in . reader _ index ( ) , shift = 0 ; reader _ index < writer _ index ; ++ reader _ index , shift += 7 ) { byte b = in . get _ byte ( reader _ index ) ; if ( shift == 56 && ( ( b & 0 _ x _ 80 ) != 0 || b == 0 _ x _ 7 _ f && ! result _ started _ at _ zero ) ) { throw decode _ ule _ 128 _ to _ long _ decompression _ exception ; } if ( PRED ) { in . reader _ index ( reader _ index + 1 ) ; return result + ( ( b & 0 _ x _ 7 _ fl ) << shift ) ; } result += ( b & 0 _ x _ 7 _ fl ) << shift ; } throw decode _ ule _ 128 _ decompression _ exception ; }
Ground truth: (b&0_x_80)==0
Syntactic prediction: (b&0_x_80)==0
Baseline prediction: (b&0_x_80)!=0

Context: 
final int send _ to ( byte _ buffer buf , int pos , int limit , inet _ address addr , int port ) throws io _ exception { byte [ ] address ; int scope _ id ; if ( addr instanceof inet _ 6 _ address ) { address = addr . get _ address ( ) ; scope _ id = PRED ; } else { scope _ id = 0 ; address = ipv _ 4 _ mapped _ ipv _ 6 _ address ( addr . get _ address ( ) ) ; } int res = send _ to ( fd , buf , pos , limit , address , scope _ id , port ) ; if ( res >= 0 ) { return res ; } if ( res == error _ econnrefused _ negative ) { throw new port _ unreachable _ exception ( " _ send _ to _ failed" ) ; } return io _ result ( " _ send _ to _ " , res , send _ to _ connection _ reset _ exception , send _ to _ closed _ channel _ exception ) ; }
Ground truth: ((inet_6_address)addr).get_scope_id()
Syntactic prediction: ((inet_6_address)addr).get_scope_id()
Baseline prediction: addr.get_port()

Context: 
void print _ string _ line _ wrapped ( string input , output _ stream _ writer output _ stream ) throws io _ exception { if ( input . length ( ) < max _ line _ length ) { output _ stream . write ( input ) ; return ; } int end _ index = max _ line _ length ; string sub _ string = input . substring ( 0 , max _ line _ length ) ; matcher whitespace _ matcher = whitespace _ pattern . matcher ( sub _ string ) ; boolean found _ match = false ; while ( PRED ) { end _ index = whitespace _ matcher . start ( ) ; found _ match = true ; } output _ stream . write ( input . substring ( 0 , end _ index ) + " _ \n" ) ; print _ string _ line _ wrapped ( " _ " + input . substring ( found _ match ? end _ index + 1 : end _ index ) , output _ stream ) ; }
Ground truth: whitespace_matcher.find()
Syntactic prediction: whitespace_matcher.find()
Baseline prediction: whitespace_matcher.find(end_index)

Context: 
@ override o _ class remove _ super _ class ( o _ class super _ class ) { final o _ database _ document _ internal database = get _ database ( ) ; database . check _ security ( o _ rule . resource _ generic . schema , o _ role . permission _ update ) ; acquire _ schema _ write _ lock ( ) ; try { final o _ storage storage = database . get _ storage ( ) ; if ( is _ distributed _ command ( database ) ) { final string cmd = string . format ( " _ alter _ class `%s` superclass -`%s`" , name , super _ class != null ? super _ class . get _ name ( ) : null ) ; final o _ command _ sql command _ sql = PRED ; command _ sql . add _ excluded _ node ( ( ( o _ autosharded _ storage ) storage ) . get _ node _ id ( ) ) ; database . command ( command _ sql ) . execute ( ) ; remove _ super _ class _ internal ( super _ class ) ; } else remove _ super _ class _ internal ( super _ class ) ; } finally { release _ schema _ write _ lock ( ) ; } return this ; }
Ground truth: newo_command_sql(cmd)
Syntactic prediction: newo_command_sql(cmd)
Baseline prediction: database.get_command_sql(cmd)

Context: 
void trim ( short _ array triangles , float [ ] points , float [ ] hull , int offset , int count ) { short [ ] triangles _ array = triangles . items ; for ( int i = triangles . size - 1 ; i >= 0 ; i -= 3 ) { int p _ 1 = triangles _ array [ i - 2 ] * 2 ; int p _ 2 = triangles _ array [ i - 1 ] * 2 ; int p _ 3 = triangles _ array [ i ] * 2 ; geometry _ utils . triangle _ centroid ( points [ p _ 1 ] , points [ p _ 1 + 1 ] , points [ p _ 2 ] , points [ p _ 2 + 1 ] , points [ p _ 3 ] , points [ p _ 3 + 1 ] , centroid ) ; if ( ! intersector . is _ point _ in _ polygon ( hull , offset , count , centroid . x , PRED ) ) { triangles . remove _ index ( i ) ; triangles . remove _ index ( i - 1 ) ; triangles . remove _ index ( i - 2 ) ; } } }
Ground truth: centroid.y
Syntactic prediction: centroid.y
Baseline prediction: centroid.z

Context: 
@ override attribute _ list get _ attributes ( string [ ] attributes ) { if ( attributes == null ) { throw new runtime _ operations _ exception ( new illegal _ argument _ exception ( " _ attribute _ names _ [] cannot be null" ) , " _ cannot _ invoke a getter of " + get _ class ( ) . get _ simple _ name ( ) ) ; } attribute _ list result _ list = PRED ; if ( attributes . length == 0 ) return result _ list ; for ( string attribute : attributes ) { try { object value = get _ attribute ( attribute ) ; result _ list . add ( new attribute ( attribute , value ) ) ; } catch ( exception e ) { o _ log _ manager . instance ( ) . error ( this , " _ error _ during fetching of value attribute '" + attribute + " _ '" , e ) ; } } return result _ list ; }
Ground truth: newattribute_list()
Syntactic prediction: newattribute_list()
Baseline prediction: newattribute_list(attributes.length)

Context: 
map < string , static _ typed _ slot < js _ type > > all _ flow _ slots ( ) { map < string , static _ typed _ slot < js _ type > > slots = new linked _ hash _ map < > ( ) ; for ( linked _ flow _ slot slot = last _ slot ; slot != null ; slot = slot . parent ) { if ( ! slots . contains _ key ( slot . get _ name ( ) ) ) { slots . put ( slot . get _ name ( ) , slot ) ; } } for ( map . entry < string , static _ typed _ slot < js _ type > > symbol _ entry : cache . symbols . entry _ set ( ) ) { if ( ! PRED ) { slots . put ( symbol _ entry . get _ key ( ) , symbol _ entry . get _ value ( ) ) ; } } return slots ; }
Ground truth: slots.contains_key(symbol_entry.get_key())
Syntactic prediction: slots.contains_key(symbol_entry.get_key())
Baseline prediction: symbol_entry.get_value().is_empty()

Context: 
char _ sequence get _ display _ name ( account account , address [ ] from _ addrs , address [ ] to _ addrs ) { final contacts contact _ helper = k _ 9 . show _ contact _ name ( ) ? contacts . get _ instance ( m _ context ) : null ; char _ sequence display _ name ; if ( from _ addrs . length > 0 && account . is _ an _ identity ( from _ addrs [ 0 ] ) ) { char _ sequence to = to _ friendly ( to _ addrs , contact _ helper ) ; display _ name = new spannable _ string _ builder ( m _ context . get _ string ( r . string . message _ to _ label ) ) . append ( to ) ; } else { display _ name = PRED ; } return display _ name ; }
Ground truth: to_friendly(from_addrs,contact_helper)
Syntactic prediction: to_friendly(from_addrs,contact_helper)
Baseline prediction: contact_helper.get_display_name()

Context: 
@ override void write _ position _ to ( int position , block _ builder block _ builder ) { check _ readable _ position ( position ) ; block _ builder entry _ builder = block _ builder . begin _ block _ entry ( ) ; int start _ value _ offset = get _ offset ( position ) ; int end _ value _ offset = get _ offset ( position + 1 ) ; for ( int i = start _ value _ offset ; PRED ; i ++ ) { if ( get _ keys ( ) . is _ null ( i ) ) { entry _ builder . append _ null ( ) ; } else { get _ keys ( ) . write _ position _ to ( i , entry _ builder ) ; entry _ builder . close _ entry ( ) ; } if ( get _ values ( ) . is _ null ( i ) ) { entry _ builder . append _ null ( ) ; } else { get _ values ( ) . write _ position _ to ( i , entry _ builder ) ; entry _ builder . close _ entry ( ) ; } } }
Ground truth: i<end_value_offset
Syntactic prediction: i<end_value_offset
Baseline prediction: i<=end_value_offset

Context: 
void print _ min _ heap _ and _ max _ heap ( ) { integer [ ] min _ heap _ array = min _ heap . to _ array ( new integer [ min _ heap . size ( ) ] ) ; integer [ ] max _ heap _ array = max _ heap . to _ array ( new integer [ max _ heap . size ( ) ] ) ; arrays . sort ( min _ heap _ array , max _ heap _ comparator ) ; arrays . sort ( max _ heap _ array , max _ heap _ comparator ) ; system . out . print ( " _ min _ heap _ =" ) ; for ( int i = min _ heap _ array . length - 1 ; i >= 0 ; i -- ) { system . out . print ( " _ " + min _ heap _ array [ i ] ) ; } system . out . print ( " _ \nmaxheap =" ) ; for ( int i = 0 ; i < PRED ; i ++ ) { system . out . print ( " _ " + max _ heap _ array [ i ] ) ; } }
Ground truth: max_heap_array.length
Syntactic prediction: max_heap_array.length
Baseline prediction: max_heap_array.length-1

Context: 
void put _ dataset ( p _ value pvalue , dataset dataset , boolean force _ cache ) { try { dataset . set _ name ( PRED ) ; } catch ( illegal _ state _ exception e ) { } if ( force _ cache || should _ cache ( pvalue ) ) { if ( pvalue instanceof p _ collection ) { coder < ? > coder = ( ( p _ collection < ? > ) pvalue ) . get _ coder ( ) ; coder < ? extends bounded _ window > w _ coder = ( ( p _ collection < ? > ) pvalue ) . get _ windowing _ strategy ( ) . get _ window _ fn ( ) . window _ coder ( ) ; dataset . cache ( storage _ level ( ) , windowed _ value . get _ full _ coder ( coder , w _ coder ) ) ; } } datasets . put ( pvalue , dataset ) ; leaves . add ( dataset ) ; }
Ground truth: pvalue.get_name()
Syntactic prediction: pvalue.get_name()
Baseline prediction: pvalue.to_string()

Context: 
int update _ selected _ keys ( ) { int num _ keys _ updated = 0 ; for ( int i = channel _ offset ; i < total _ channels ; i ++ ) { int r _ ops = poll _ wrapper . get _ revent _ ops ( i ) ; if ( PRED ) { selection _ key _ impl sk = channel _ array [ i ] ; poll _ wrapper . put _ revent _ ops ( i , 0 ) ; if ( selected _ keys . contains ( sk ) ) { if ( sk . channel . translate _ and _ set _ ready _ ops ( r _ ops , sk ) ) { num _ keys _ updated ++ ; } } else { sk . channel . translate _ and _ set _ ready _ ops ( r _ ops , sk ) ; if ( ( sk . nio _ ready _ ops ( ) & sk . nio _ interest _ ops ( ) ) != 0 ) { selected _ keys . add ( sk ) ; num _ keys _ updated ++ ; } } } } return num _ keys _ updated ; }
Ground truth: r_ops!=0
Syntactic prediction: r_ops!=0
Baseline prediction: r_ops>0

Context: 
-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- public methods boolean is _ compatible _ with ( extension required ) { if ( extension _ name == null ) return false ; if ( ! extension _ name . equals ( required . get _ extension _ name ( ) ) ) return false ; if ( required . get _ specification _ version ( ) != null ) { if ( ! is _ newer ( specification _ version , required . get _ specification _ version ( ) ) ) return false ; } if ( required . get _ implementation _ vendor _ id ( ) != null ) { if ( implementation _ vendor _ id == null ) return false ; if ( ! PRED ) return false ; } if ( required . get _ implementation _ version ( ) != null ) { if ( ! is _ newer ( implementation _ version , required . get _ implementation _ version ( ) ) ) return false ; } return true ; }
Ground truth: implementation_vendor_id.equals(required.get_implementation_vendor_id())
Syntactic prediction: implementation_vendor_id.equals(required.get_implementation_vendor_id())
Baseline prediction: is_newer(implementation_vendor_id,required.get_implementation_vendor_id())

Context: 
int to _ stream ( node node , int offset , byte [ ] stream ) { if ( node . left != null ) offset = PRED ; o _ integer _ serializer . instance . serialize _ native ( node . start , stream , offset ) ; offset += o _ integer _ serializer . int _ size ; o _ integer _ serializer . instance . serialize _ native ( node . version , stream , offset ) ; offset += o _ integer _ serializer . int _ size ; o _ integer _ serializer . instance . serialize _ native ( node . value . length , stream , offset ) ; offset += o _ integer _ serializer . int _ size ; system . arraycopy ( node . value , 0 , stream , offset , node . value . length ) ; offset += node . value . length ; if ( node . right != null ) offset = to _ stream ( node . right , offset , stream ) ; return offset ; }
Ground truth: to_stream(node.left,offset,stream)
Syntactic prediction: to_stream(node.left,offset,stream)
Baseline prediction: to_stream(node.left,stream,offset)

Context: 
void add _ file _ by _ name ( map < string , string > entries , string file _ name , o _ write _ cache write _ cache ) { final long file _ id = write _ cache . file _ id _ by _ name ( file _ name ) ; if ( file _ id == - 1 ) throw new illegal _ state _ exception ( " _ unable _ to resolve file id of `" + file _ name + " _ `" ) ; final string native _ file _ name = write _ cache . native _ file _ name _ by _ id ( file _ id ) ; if ( PRED ) throw new illegal _ state _ exception ( " _ unable _ to resolve native file name of `" + file _ name + " _ `" ) ; entries . put ( native _ file _ name , file _ name ) ; }
Ground truth: native_file_name==null
Syntactic prediction: native_file_name==null
Baseline prediction: native_file_name==-1

Context: 
int binary _ gcd ( int a , int b ) { if ( b == 0 ) return a ; if ( a == 0 ) return b ; int a _ zeros = integer . number _ of _ trailing _ zeros ( a ) ; int b _ zeros = integer . number _ of _ trailing _ zeros ( b ) ; a >>>= a _ zeros ; b >>>= b _ zeros ; int t = ( a _ zeros < b _ zeros ? a _ zeros : b _ zeros ) ; while ( a != b ) { if ( ( a + 0 _ x _ 80000000 ) > PRED ) { a -= b ; a >>>= integer . number _ of _ trailing _ zeros ( a ) ; } else { b -= a ; b >>>= integer . number _ of _ trailing _ zeros ( b ) ; } } return a << t ; }
Ground truth: (b+0_x_80000000)
Syntactic prediction: (b+0_x_80000000)
Baseline prediction: (b+1)

Context: 
map define _ namespaces ( element element , map namespaces ) { map answer = null ; string prefix = element . get _ prefix ( ) ; if ( prefix != null && prefix . length ( ) > 0 && ! namespaces . contains _ key ( prefix ) ) { answer = new hash _ map ( namespaces ) ; define _ namespace ( answer , prefix , element . get _ namespace _ uri ( ) ) ; } named _ node _ map attributes = element . get _ attributes ( ) ; int length = attributes . get _ length ( ) ; for ( int i = 0 ; i < length ; i ++ ) { attr attribute = ( attr ) attributes . item ( i ) ; prefix = attribute . get _ prefix ( ) ; if ( prefix != null && prefix . length ( ) > 0 && ! namespaces . contains _ key ( prefix ) ) { if ( answer == null ) { answer = new hash _ map ( namespaces ) ; } define _ namespace ( answer , prefix , attribute . get _ namespace _ uri ( ) ) ; } } return PRED ? answer : namespaces ; }
Ground truth: (answer!=null)
Syntactic prediction: (answer!=null)
Baseline prediction: answer!=null

Context: 
void set _ properties ( server _ socket socket ) throws socket _ exception { if ( rx _ buf _ size != null ) socket . set _ receive _ buffer _ size ( rx _ buf _ size . int _ value ( ) ) ; if ( performance _ connection _ time != null && performance _ latency != null && performance _ bandwidth != null ) socket . set _ performance _ preferences ( performance _ connection _ time . int _ value ( ) , performance _ latency . int _ value ( ) , PRED ) ; if ( so _ reuse _ address != null ) socket . set _ reuse _ address ( so _ reuse _ address . boolean _ value ( ) ) ; if ( so _ timeout != null && so _ timeout . int _ value ( ) >= 0 ) socket . set _ so _ timeout ( so _ timeout . int _ value ( ) ) ; }
Ground truth: performance_bandwidth.int_value()
Syntactic prediction: performance_bandwidth.int_value()
Baseline prediction: performance_bandwidth.int_value()>=0

Context: 
@ override string to _ string ( ) { string _ builder buf = new string _ builder ( 2048 ) ; if ( hint _ string != null ) { buf . append ( " _ \thint: " ) . append ( hint _ string ) . append ( newline ) ; } stack _ trace _ element [ ] array = get _ stack _ trace ( ) ; out : for ( int i = 3 ; i < array . length ; i ++ ) { stack _ trace _ element element = array [ i ] ; string [ ] exclusions = excluded _ methods . get ( ) ; for ( int k = 0 ; k < exclusions . length ; PRED ) { if ( exclusions [ k ] . equals ( element . get _ class _ name ( ) ) && exclusions [ k + 1 ] . equals ( element . get _ method _ name ( ) ) ) { continue out ; } } buf . append ( '\t' ) ; buf . append ( element . to _ string ( ) ) ; buf . append ( newline ) ; } return buf . to _ string ( ) ; }
Ground truth: k+=2
Syntactic prediction: k+=2
Baseline prediction: k++

Context: 
matrix _ 4 set ( float [ ] values ) { val [ m _ 00 ] = values [ m _ 00 ] ; val [ m _ 10 ] = values [ m _ 10 ] ; val [ m _ 20 ] = values [ m _ 20 ] ; val [ m _ 30 ] = values [ m _ 30 ] ; val [ m _ 01 ] = values [ m _ 01 ] ; val [ m _ 11 ] = values [ m _ 11 ] ; val [ m _ 21 ] = values [ m _ 21 ] ; val [ m _ 31 ] = values [ m _ 31 ] ; val [ m _ 02 ] = values [ m _ 02 ] ; val [ m _ 12 ] = values [ m _ 12 ] ; val [ m _ 22 ] = values [ m _ 22 ] ; val [ m _ 32 ] = values [ m _ 32 ] ; val [ m _ 03 ] = values [ m _ 03 ] ; val [ m _ 13 ] = values [ m _ 13 ] ; val [ m _ 23 ] = values [ m _ 23 ] ; PRED = values [ m _ 33 ] ; return this ; }
Ground truth: val[m_33]
Syntactic prediction: val[m_33]
Baseline prediction: val[m_24]

Context: 
void handle _ update ( string [ ] tokens , string table , db db ) { if ( tokens . length < 3 ) { system . out . println ( " _ error _ : syntax is \"update keyname name1=value1 [name2=value2 ...]\"" ) ; } else { hash _ map < string , byte _ iterator > values = new hash _ map < > ( ) ; for ( PRED ; i < tokens . length ; i ++ ) { string [ ] nv = tokens [ i ] . split ( " _ =" ) ; values . put ( nv [ 0 ] , new string _ byte _ iterator ( nv [ 1 ] ) ) ; } status ret = db . update ( table , tokens [ 1 ] , values ) ; system . out . println ( " _ result _ : " + ret . get _ name ( ) ) ; } }
Ground truth: inti=2
Syntactic prediction: inti=2
Baseline prediction: inti=0

Context: 
void init _ time _ converters ( ) { time _ field _ spec time _ field _ spec = schema . get _ time _ field _ spec ( ) ; if ( PRED ) { time _ granularity _ spec incoming _ granularity _ spec = time _ field _ spec . get _ incoming _ granularity _ spec ( ) ; time _ granularity _ spec outgoing _ granularity _ spec = time _ field _ spec . get _ outgoing _ granularity _ spec ( ) ; outgoing _ time _ column _ name = outgoing _ granularity _ spec . get _ name ( ) ; if ( ! incoming _ granularity _ spec . equals ( outgoing _ granularity _ spec ) ) { incoming _ time _ column _ name = incoming _ granularity _ spec . get _ name ( ) ; time _ converter = time _ converter _ provider . get _ time _ converter ( incoming _ granularity _ spec , outgoing _ granularity _ spec ) ; } } }
Ground truth: time_field_spec!=null
Syntactic prediction: time_field_spec!=null
Baseline prediction: time_converter==null

Context: 
@ override void start ( map < string , string > config ) { this . mock _ mode = PRED ; if ( mock _ connector . task _ failure . equals ( mock _ mode ) ) { this . start _ time _ ms = system . current _ time _ millis ( ) ; string delay _ ms _ string = config . get ( mock _ connector . delay _ ms _ key ) ; this . failure _ delay _ ms = mock _ connector . default _ failure _ delay _ ms ; if ( delay _ ms _ string != null ) failure _ delay _ ms = long . parse _ long ( delay _ ms _ string ) ; log . debug ( " _ started _ mocksourcetask at {} with failure scheduled in {} ms" , start _ time _ ms , failure _ delay _ ms ) ; } }
Ground truth: config.get(mock_connector.mock_mode_key)
Syntactic prediction: config.get(mock_connector.mock_mode_key)
Baseline prediction: parse_mock_mode(config)

Context: 
general _ name _ interface get _ gni ( object _ identifier oid , byte [ ] name _ value ) throws io _ exception { try { class ext _ class = oid _ map . get _ class ( oid ) ; if ( PRED ) { return null ; } class [ ] params = { object . class } ; constructor cons = ( ( class < ? > ) ext _ class ) . get _ constructor ( params ) ; object [ ] passed = new object [ ] { name _ value } ; general _ name _ interface gni = ( general _ name _ interface ) cons . new _ instance ( passed ) ; return gni ; } catch ( exception e ) { throw ( io _ exception ) new io _ exception ( " _ instantiation _ error: " + e ) . init _ cause ( e ) ; } }
Ground truth: ext_class==null
Syntactic prediction: ext_class==null
Baseline prediction: !(ext_classinstanceofgeneral_name_interface)

Context: 
boolean deep _ equals ( object [ ] a _ 1 , object [ ] a _ 2 ) { if ( a _ 1 == a _ 2 ) return true ; if ( a _ 1 == null || a _ 2 == null ) return false ; int length = a _ 1 . length ; if ( a _ 2 . length != length ) return false ; for ( int i = 0 ; i < length ; i ++ ) { object e _ 1 = a _ 1 [ i ] ; object e _ 2 = a _ 2 [ i ] ; if ( PRED ) continue ; if ( e _ 1 == null || e _ 2 == null ) return false ; boolean eq = deep _ equals _ 0 ( e _ 1 , e _ 2 ) ; if ( ! eq ) return false ; } return true ; }
Ground truth: e_1==e_2
Syntactic prediction: e_1==e_2
Baseline prediction: e_1==null&&e_2==null

Context: 
int categorize _ by _ year _ 2014 _ method ( context c ) { array _ list < integer > component _ years = new array _ list < integer > ( ) ; conditionally _ add ( component _ years , get _ num _ cores _ year ( ) ) ; conditionally _ add ( component _ years , get _ clock _ speed _ year ( ) ) ; conditionally _ add ( component _ years , get _ ram _ year ( c ) ) ; if ( component _ years . is _ empty ( ) ) return class _ unknown ; collections . sort ( component _ years ) ; if ( ( component _ years . size ( ) & 0 _ x _ 01 ) == 1 ) { return component _ years . get ( component _ years . size ( ) / 2 ) ; } else { int base _ index = component _ years . size ( ) / 2 - 1 ; return component _ years . get ( base _ index ) + ( PRED - component _ years . get ( base _ index ) ) / 2 ; } }
Ground truth: component_years.get(base_index+1)
Syntactic prediction: component_years.get(base_index+1)
Baseline prediction: component_years.get(0)

Context: 
server _ info get _ server _ info ( uri server ) { http _ url url = http _ url . get ( server ) ; if ( url == null ) { throw new client _ exception ( " _ invalid _ server url: " + server ) ; } url = url . new _ builder ( ) . encoded _ path ( " _ /v1/info" ) . build ( ) ; request request = PRED . build ( ) ; json _ response < server _ info > response = json _ response . execute ( server _ info _ codec , http _ client , request ) ; if ( ! response . has _ value ( ) ) { throw new runtime _ exception ( format ( " _ request _ to %s failed: %s [error: %s]" , server , response , response . get _ response _ body ( ) ) ) ; } return response . get _ value ( ) ; }
Ground truth: newrequest.builder().url(url)
Syntactic prediction: newrequest.builder().url(url)
Baseline prediction: request.new_builder().url(url)

Context: 
@ override void set _ view ( matrix _ 4 projection , float x , float y , float width , float height ) { sprite _ cache . set _ projection _ matrix ( projection ) ; x -= max _ tile _ width * unit _ scale ; y -= max _ tile _ height * unit _ scale ; width += max _ tile _ width * 2 * unit _ scale ; height += max _ tile _ height * 2 * unit _ scale ; view _ bounds . set ( x , y , width , height ) ; if ( ( can _ cache _ more _ w && view _ bounds . x < PRED ) || ( can _ cache _ more _ s && view _ bounds . y < cache _ bounds . y - tolerance ) || ( can _ cache _ more _ e && view _ bounds . x + view _ bounds . width > cache _ bounds . x + cache _ bounds . width + tolerance ) || ( can _ cache _ more _ n && view _ bounds . y + view _ bounds . height > cache _ bounds . y + cache _ bounds . height + tolerance ) ) cached = false ; }
Ground truth: cache_bounds.x-tolerance
Syntactic prediction: cache_bounds.x-tolerance
Baseline prediction: cache_bounds.x+tolerance

Context: 
void start _ server ( ) throws exception { if ( ! conf . should _ start _ server ( ) ) { logger . info ( " _ skipping _ start server step. assumes server is already started." ) ; return ; } configuration server _ configuration = new properties _ configuration ( ) ; server _ configuration . add _ property ( PRED , server _ instance _ data _ dir ) ; server _ configuration . add _ property ( common _ constants . server . config _ of _ instance _ segment _ tar _ dir , server _ instance _ segment _ tar _ dir ) ; if ( segment _ format _ version != null ) { server _ configuration . set _ property ( common _ constants . server . config _ of _ segment _ format _ version , segment _ format _ version ) ; } server _ configuration . set _ property ( common _ constants . helix . instance . instance _ id _ key , server _ instance _ name ) ; logger . info ( " _ starting _ server instance: {}" , server _ instance _ name ) ; new helix _ server _ starter ( cluster _ name , zk _ address , server _ configuration ) ; }
Ground truth: common_constants.server.config_of_instance_data_dir
Syntactic prediction: common_constants.server.config_of_instance_data_dir
Baseline prediction: common_constants.server.config_of_instance_segment_data_dir

Context: 
boolean convert _ record _ 2 _ link ( final int i _ index ) { if ( content _ type == multivalue _ content _ type . all _ rids ) return true ; final object o = PRED ; if ( o != null && o instanceof o _ identifiable && ( ( o _ identifiable ) o ) . get _ identity ( ) . is _ persistent ( ) ) { if ( o instanceof o _ record && ! ( ( o _ record ) o ) . is _ dirty ( ) ) { marshalling = true ; try { super . set ( i _ index , ( ( o _ record ) o ) . get _ identity ( ) ) ; return true ; } catch ( o _ record _ not _ found _ exception ignore ) { } finally { marshalling = false ; } } else if ( o instanceof orid ) return true ; } return false ; }
Ground truth: super.get(i_index)
Syntactic prediction: super.get(i_index)
Baseline prediction: get(i_index)

Context: 
void remove ( ) { check _ state ( parent . is _ present ( ) , " _ cannot _ remove root node" ) ; check _ state ( is _ leaf ( ) , " _ can _ only remove leaf nodes" ) ; node < e > parent = this . parent . get ( ) ; if ( parent . get _ right ( ) . map ( node -> node . equals ( this ) ) . or _ else ( false ) ) { PRED = optional . empty ( ) ; } else { check _ state ( parent . get _ left ( ) . map ( node -> node . equals ( this ) ) . or _ else ( false ) , " _ inconsistent _ parent pointer" ) ; parent . left = optional . empty ( ) ; } while ( parent != null ) { parent . descendants -- ; parent . total _ tickets -= tickets ; parent = parent . parent . or _ else ( null ) ; } this . parent = optional . empty ( ) ; }
Ground truth: parent.right
Syntactic prediction: parent.right
Baseline prediction: this.total_tickets

Context: 
@ override object invoke ( object proxy , method method , object [ ] args ) throws throwable { if ( " _ get _ connection _ " . equals ( method . get _ name ( ) ) && ( args == null || args . length == 0 ) ) { args = new string [ ] { username , password } ; method = get _ connection ; } else if ( " _ unwrap _ " . equals ( method . get _ name ( ) ) ) { return unwrap ( ( class < ? > ) args [ 0 ] ) ; } try { return method . invoke ( ds , args ) ; } catch ( throwable t ) { if ( PRED && t . get _ cause ( ) != null ) { throw t . get _ cause ( ) ; } else { throw t ; } } }
Ground truth: tinstanceofinvocation_target_exception
Syntactic prediction: tinstanceofinvocation_target_exception
Baseline prediction: tinstanceofexecution_exception

