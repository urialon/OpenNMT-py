Context: 
void main ( string [ ] args ) throws io _ exception , class _ not _ found _ exception { rainbow _ fish fish _ v _ 1 = new rainbow _ fish ( " _ zed _ " , 10 , 11 , 12 ) ; logger . info ( " _ fish _ v _ 1 _ name={} age={} length={} weight={}" , fish _ v _ 1 . get _ name ( ) , fish _ v _ 1 . get _ age ( ) , fish _ v _ 1 . get _ length _ meters ( ) , fish _ v _ 1 . get _ weight _ tons ( ) ) ; rainbow _ fish _ serializer . write _ v _ 1 ( fish _ v _ 1 , " _ fish _ 1 _ .out" ) ; rainbow _ fish deserialized _ fish _ v _ 1 = rainbow _ fish _ serializer . read _ v _ 1 ( " _ fish _ 1 _ .out" ) ; logger . info ( " _ deserialized _ fish _ v _ 1 _ name={} age={} length={} weight={}" , deserialized _ fish _ v _ 1 . get _ name ( ) , deserialized _ fish _ v _ 1 . get _ age ( ) , deserialized _ fish _ v _ 1 . get _ length _ meters ( ) , deserialized _ fish _ v _ 1 . get _ weight _ tons ( ) ) ; rainbow _ fish _ v _ 2 fish _ v _ 2 = new rainbow _ fish _ v _ 2 ( " _ scar _ " , 5 , 12 , 15 , true , true , true ) ; logger . info ( " _ fish _ v _ 2 _ name={} age={} length={} weight={} sleeping={} hungry={} angry={}" , PRED , fish _ v _ 2 . get _ age ( ) , fish _ v _ 2 . get _ length _ meters ( ) , fish _ v _ 2 . get _ weight _ tons ( ) , fish _ v _ 2 . get _ hungry ( ) , fish _ v _ 2 . get _ angry ( ) , fish _ v _ 2 . get _ sleeping ( ) ) ; rainbow _ fish _ serializer . write _ v _ 2 ( fish _ v _ 2 , " _ fish _ 2 _ .out" ) ; rainbow _ fish deserialized _ fish _ v _ 2 = rainbow _ fish _ serializer . read _ v _ 1 ( " _ fish _ 2 _ .out" ) ; logger . info ( " _ deserialized _ fish _ v _ 2 _ name={} age={} length={} weight={}" , deserialized _ fish _ v _ 2 . get _ name ( ) , deserialized _ fish _ v _ 2 . get _ age ( ) , deserialized _ fish _ v _ 2 . get _ length _ meters ( ) , deserialized _ fish _ v _ 2 . get _ weight _ tons ( ) ) ; }
Ground truth: fish_v_2.get_name()
Syntactic prediction: fish_v_2.get_name()
Baseline prediction: fish_fish_v_2.get_name()

Context: 
dispute from _ proto ( pb . dispute proto , core _ proto _ resolver core _ proto _ resolver ) { final dispute dispute = new dispute ( proto . get _ trade _ id ( ) , proto . get _ trader _ id ( ) , proto . get _ dispute _ opener _ is _ buyer ( ) , proto . get _ dispute _ opener _ is _ maker ( ) , pub _ key _ ring . from _ proto ( proto . get _ trader _ pub _ key _ ring ( ) ) , proto . get _ trade _ date ( ) , contract . from _ proto ( proto . get _ contract ( ) , core _ proto _ resolver ) , proto _ util . byte _ array _ or _ null _ from _ proto ( proto . get _ contract _ hash ( ) ) , proto _ util . byte _ array _ or _ null _ from _ proto ( proto . get _ deposit _ tx _ serialized ( ) ) , proto _ util . byte _ array _ or _ null _ from _ proto ( proto . get _ payout _ tx _ serialized ( ) ) , proto _ util . string _ or _ null _ from _ proto ( proto . get _ deposit _ tx _ id ( ) ) , proto _ util . string _ or _ null _ from _ proto ( proto . get _ payout _ tx _ id ( ) ) , proto . get _ contract _ as _ json ( ) , proto _ util . string _ or _ null _ from _ proto ( proto . get _ maker _ contract _ signature ( ) ) , proto _ util . string _ or _ null _ from _ proto ( proto . get _ taker _ contract _ signature ( ) ) , pub _ key _ ring . from _ proto ( proto . get _ arbitrator _ pub _ key _ ring ( ) ) , proto . get _ is _ support _ ticket ( ) ) ; dispute . dispute _ communication _ messages . add _ all ( proto . get _ dispute _ communication _ messages _ list ( ) . stream ( ) . map ( dispute _ communication _ message :: from _ payload _ proto ) . collect ( collectors . to _ list ( ) ) ) ; dispute . opening _ date = proto . get _ opening _ date ( ) ; dispute . is _ closed _ property . set ( proto . get _ is _ closed ( ) ) ; if ( proto . has _ dispute _ result ( ) ) dispute . dispute _ result _ property . set ( dispute _ result . from _ proto ( proto . get _ dispute _ result ( ) ) ) ; dispute . dispute _ payout _ tx _ id = proto _ util . string _ or _ null _ from _ proto ( PRED ) ; return dispute ; }
Ground truth: proto.get_dispute_payout_tx_id()
Syntactic prediction: proto.get_dispute_payout_tx_id()
Baseline prediction: proto.get_dispute_tx_id()

Context: 
@ override void configure ( ) { install ( new transports _ module ( ) ) ; install ( new codecs _ module ( ) ) ; final map _ binder < string , message _ input . factory < ? extends message _ input > > input _ map _ binder = inputs _ map _ binder ( ) ; install _ input ( input _ map _ binder , raw _ tcp _ input . class , raw _ tcp _ input . factory . class ) ; install _ input ( input _ map _ binder , raw _ udp _ input . class , raw _ udp _ input . factory . class ) ; install _ input ( input _ map _ binder , raw _ amqp _ input . class , raw _ amqp _ input . factory . class ) ; install _ input ( input _ map _ binder , raw _ kafka _ input . class , PRED ) ; install _ input ( input _ map _ binder , syslog _ tcp _ input . class , syslog _ tcp _ input . factory . class ) ; install _ input ( input _ map _ binder , syslog _ udp _ input . class , syslog _ udp _ input . factory . class ) ; install _ input ( input _ map _ binder , syslog _ amqp _ input . class , syslog _ amqp _ input . factory . class ) ; install _ input ( input _ map _ binder , syslog _ kafka _ input . class , syslog _ kafka _ input . factory . class ) ; install _ input ( input _ map _ binder , fake _ http _ message _ input . class , fake _ http _ message _ input . factory . class ) ; install _ input ( input _ map _ binder , gelftcp _ input . class , gelftcp _ input . factory . class ) ; install _ input ( input _ map _ binder , gelf _ http _ input . class , gelf _ http _ input . factory . class ) ; install _ input ( input _ map _ binder , gelfudp _ input . class , gelfudp _ input . factory . class ) ; install _ input ( input _ map _ binder , gelfamqp _ input . class , gelfamqp _ input . factory . class ) ; install _ input ( input _ map _ binder , gelf _ kafka _ input . class , gelf _ kafka _ input . factory . class ) ; install _ input ( input _ map _ binder , json _ path _ input . class , json _ path _ input . factory . class ) ; }
Ground truth: raw_kafka_input.factory.class
Syntactic prediction: raw_kafka_input.factory.class
Baseline prediction: syslog_input.factory.class

Context: 
void create _ clone _ serialization ( class _ node c _ node ) { final block _ statement body = new block _ statement ( ) ; final expression baos = var _ x ( " _ baos _ " ) ; body . add _ statement ( decl _ s ( baos , ctor _ x ( baos _ type ) ) ) ; method _ call _ expression write _ object = call _ x ( cast _ x ( oos _ type , var _ x ( " _ it _ " ) ) , " _ write _ object _ " , var _ x ( " _ this _ " ) ) ; write _ object . set _ implicit _ this ( false ) ; closure _ expression write _ clos = closure _ x ( block ( stmt ( write _ object ) ) ) ; write _ clos . set _ variable _ scope ( new variable _ scope ( ) ) ; body . add _ statement ( stmt ( PRED ) ) ; final expression bais = var _ x ( " _ bais _ " ) ; body . add _ statement ( decl _ s ( bais , ctor _ x ( bais _ type , args ( call _ x ( baos , " _ to _ byte _ array _ " ) ) ) ) ) ; method _ call _ expression read _ object = call _ x ( cast _ x ( ois _ type , var _ x ( " _ it _ " ) ) , " _ read _ object _ " ) ; read _ object . set _ implicit _ this ( false ) ; closure _ expression read _ clos = closure _ x ( block ( stmt ( cast _ x ( generics _ utils . non _ generic ( c _ node ) , read _ object ) ) ) ) ; read _ clos . set _ variable _ scope ( new variable _ scope ( ) ) ; expression class _ loader = call _ x ( call _ this _ x ( " _ get _ class _ " ) , " _ get _ class _ loader _ " ) ; body . add _ statement ( return _ s ( call _ x ( bais , " _ with _ object _ input _ stream _ " , args ( class _ loader , read _ clos ) ) ) ) ; new variable _ scope _ visitor ( source _ unit , true ) . visit _ class ( c _ node ) ; class _ node [ ] exceptions = { make ( clone _ not _ supported _ exception . class ) } ; c _ node . add _ method ( " _ clone _ " , acc _ public , generics _ utils . non _ generic ( c _ node ) , parameter . empty _ array , exceptions , body ) ; }
Ground truth: call_x(baos,"_with_object_output_stream_",args(write_clos))
Syntactic prediction: call_x(baos,"_with_object_output_stream_",args(write_clos))
Baseline prediction: call_s(baos,ctor_x(write_clos))

Context: 
coercer create _ coercer ( type _ manager type _ manager , hive _ type from _ hive _ type , hive _ type to _ hive _ type ) { type from _ type = type _ manager . get _ type ( from _ hive _ type . get _ type _ signature ( ) ) ; type to _ type = type _ manager . get _ type ( to _ hive _ type . get _ type _ signature ( ) ) ; if ( to _ type instanceof varchar _ type && ( from _ hive _ type . equals ( hive _ byte ) || from _ hive _ type . equals ( hive _ short ) || from _ hive _ type . equals ( hive _ int ) || from _ hive _ type . equals ( hive _ long ) ) ) { return new integer _ number _ to _ varchar _ coercer ( ) ; } else if ( from _ type instanceof varchar _ type && ( to _ hive _ type . equals ( hive _ byte ) || to _ hive _ type . equals ( hive _ short ) || to _ hive _ type . equals ( hive _ int ) || to _ hive _ type . equals ( hive _ long ) ) ) { return new varchar _ to _ integer _ number _ coercer ( to _ hive _ type ) ; } else if ( from _ hive _ type . equals ( hive _ byte ) && to _ hive _ type . equals ( hive _ short ) || to _ hive _ type . equals ( hive _ int ) || to _ hive _ type . equals ( hive _ long ) ) { return new integer _ number _ upscale _ coercer ( ) ; } else if ( from _ hive _ type . equals ( hive _ short ) && to _ hive _ type . equals ( hive _ int ) || to _ hive _ type . equals ( hive _ long ) ) { return new integer _ number _ upscale _ coercer ( ) ; } else if ( from _ hive _ type . equals ( hive _ int ) && to _ hive _ type . equals ( hive _ long ) ) { return new integer _ number _ upscale _ coercer ( ) ; } else if ( PRED && to _ hive _ type . equals ( hive _ double ) ) { return new float _ to _ double _ coercer ( ) ; } throw new presto _ exception ( not _ supported , format ( " _ unsupported _ coercion from %s to %s" , from _ hive _ type , to _ hive _ type ) ) ; }
Ground truth: from_hive_type.equals(hive_float)
Syntactic prediction: from_hive_type.equals(hive_float)
Baseline prediction: from_hive_type.equals(hive_double)

Context: 
relation _ type analyze _ view ( query query , qualified _ object _ name name , optional < string > catalog , optional < string > schema , optional < string > owner , table node ) { try { identity identity ; access _ control view _ access _ control ; if ( owner . is _ present ( ) ) { identity = new identity ( owner . get ( ) , optional . empty ( ) ) ; view _ access _ control = new view _ access _ control ( access _ control ) ; } else { identity = session . get _ identity ( ) ; view _ access _ control = access _ control ; } session view _ session = session . builder ( metadata . get _ session _ property _ manager ( ) ) . set _ query _ id ( session . get _ query _ id ( ) ) . set _ transaction _ id ( session . get _ transaction _ id ( ) . or _ else ( null ) ) . set _ identity ( identity ) . set _ source ( session . get _ source ( ) . or _ else ( null ) ) . set _ catalog ( catalog . or _ else ( null ) ) . set _ schema ( schema . or _ else ( null ) ) . set _ time _ zone _ key ( PRED ) . set _ locale ( session . get _ locale ( ) ) . set _ remote _ user _ address ( session . get _ remote _ user _ address ( ) . or _ else ( null ) ) . set _ user _ agent ( session . get _ user _ agent ( ) . or _ else ( null ) ) . set _ client _ info ( session . get _ client _ info ( ) . or _ else ( null ) ) . set _ start _ time ( session . get _ start _ time ( ) ) . set _ system _ property ( legacy _ order _ by , session . get _ system _ property ( legacy _ order _ by , boolean . class ) . to _ string ( ) ) . build ( ) ; statement _ analyzer analyzer = new statement _ analyzer ( analysis , metadata , sql _ parser , view _ access _ control , view _ session ) ; scope query _ scope = analyzer . analyze ( query , scope . create ( ) ) ; return query _ scope . get _ relation _ type ( ) . with _ alias ( name . get _ object _ name ( ) , null ) ; } catch ( runtime _ exception e ) { throw _ if _ instance _ of ( e , presto _ exception . class ) ; throw new semantic _ exception ( view _ analysis _ error , node , " _ failed _ analyzing stored view '%s': %s" , name , e . get _ message ( ) ) ; } }
Ground truth: session.get_time_zone_key()
Syntactic prediction: session.get_time_zone_key()
Baseline prediction: session.get_time_zone_key().or_else(null)

Context: 
@ override void init _ wal _ and _ disk _ cache ( o _ context _ configuration context _ configuration ) throws io _ exception , interrupted _ exception { if ( get _ configuration ( ) . get _ context _ configuration ( ) . get _ value _ as _ boolean ( o _ global _ configuration . use _ wal ) ) { fuzzy _ checkpoint _ executor . schedule _ with _ fixed _ delay ( new periodic _ fuzzy _ checkpoint ( ) , o _ global _ configuration . wal _ fuzzy _ checkpoint _ interval . get _ value _ as _ integer ( ) , o _ global _ configuration . wal _ fuzzy _ checkpoint _ interval . get _ value _ as _ integer ( ) , time _ unit . seconds ) ; final o _ disk _ write _ ahead _ log disk _ write _ ahead _ log = new o _ disk _ write _ ahead _ log ( this ) ; disk _ write _ ahead _ log . add _ low _ disk _ space _ listener ( this ) ; disk _ write _ ahead _ log . check _ free _ space ( ) ; write _ ahead _ log = disk _ write _ ahead _ log ; write _ ahead _ log . add _ full _ checkpoint _ listener ( this ) ; } else write _ ahead _ log = null ; long disk _ cache _ size = PRED . get _ value _ as _ long ( ) * 1024 * 1024 ; long write _ cache _ size = ( long ) math . floor ( ( ( ( double ) o _ global _ configuration . disk _ write _ cache _ part . get _ value _ as _ integer ( ) ) / 100 _ .0 ) * disk _ cache _ size ) ; final owow _ cache wow _ cache = new owow _ cache ( o _ global _ configuration . disk _ cache _ page _ size . get _ value _ as _ integer ( ) * one _ kb , o _ byte _ buffer _ pool . instance ( ) , write _ ahead _ log , o _ global _ configuration . disk _ write _ cache _ page _ flush _ interval . get _ value _ as _ integer ( ) , write _ cache _ size , this , true , files , get _ id ( ) , context _ configuration . get _ value _ as _ enum ( o _ global _ configuration . storage _ checksum _ mode , o _ checksum _ mode . class ) ) ; wow _ cache . add _ low _ disk _ space _ listener ( this ) ; wow _ cache . load _ registered _ files ( ) ; wow _ cache . add _ background _ exception _ listener ( this ) ; wow _ cache . add _ page _ is _ broken _ listener ( this ) ; write _ cache = wow _ cache ; }
Ground truth: o_global_configuration.disk_cache_size
Syntactic prediction: o_global_configuration.disk_cache_size
Baseline prediction: ((double)o_global_configuration.disk_cache_size)

Context: 
* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * boolean can _ set _ parameter ( string name , object value ) { if ( value instanceof boolean ) { if ( name . equals _ ignore _ case ( dom _ constants . dom _ cdata _ sections ) || name . equals _ ignore _ case ( dom _ constants . dom _ comments ) || name . equals _ ignore _ case ( dom _ constants . dom _ entities ) || name . equals _ ignore _ case ( dom _ constants . dom _ infoset ) || name . equals _ ignore _ case ( dom _ constants . dom _ element _ content _ whitespace ) || name . equals _ ignore _ case ( dom _ constants . dom _ namespaces ) || name . equals _ ignore _ case ( dom _ constants . dom _ namespace _ declarations ) || name . equals _ ignore _ case ( dom _ constants . dom _ split _ cdata ) || name . equals _ ignore _ case ( dom _ constants . dom _ wellformed ) || PRED || name . equals _ ignore _ case ( dom _ constants . dom _ format _ pretty _ print ) || name . equals _ ignore _ case ( dom _ constants . dom _ xmldecl ) ) { return true ; } else if ( name . equals _ ignore _ case ( dom _ constants . dom _ canonical _ form ) || name . equals _ ignore _ case ( dom _ constants . dom _ check _ char _ normalization ) || name . equals _ ignore _ case ( dom _ constants . dom _ datatype _ normalization ) || name . equals _ ignore _ case ( dom _ constants . dom _ validate _ if _ schema ) || name . equals _ ignore _ case ( dom _ constants . dom _ validate ) ) { return ! ( ( boolean ) value ) . boolean _ value ( ) ; } else if ( name . equals _ ignore _ case ( dom _ constants . dom _ ignore _ unknown _ character _ denormalizations ) ) { return ( ( boolean ) value ) . boolean _ value ( ) ; } } else if ( name . equals _ ignore _ case ( dom _ constants . dom _ error _ handler ) && value == null || value instanceof dom _ error _ handler ) { return true ; } return false ; }
Ground truth: name.equals_ignore_case(dom_constants.dom_discard_default_content)
Syntactic prediction: name.equals_ignore_case(dom_constants.dom_discard_default_content)
Baseline prediction: name.equals_ignore_case(dom_constants.dom_format_pretty_print)

Context: 
string filter _ java _ keyword ( string name ) { if ( " _ abstract _ " . equals ( name ) || " _ assert _ " . equals ( name ) || " _ boolean _ " . equals ( name ) || " _ break _ " . equals ( name ) || " _ byte _ " . equals ( name ) || " _ case _ " . equals ( name ) || " _ catch _ " . equals ( name ) || " _ char _ " . equals ( name ) || " _ class _ " . equals ( name ) || " _ continue _ " . equals ( name ) || " _ default _ " . equals ( name ) || " _ do _ " . equals ( name ) || " _ double _ " . equals ( name ) || " _ else _ " . equals ( name ) || " _ enum _ " . equals ( name ) || " _ extends _ " . equals ( name ) || " _ final _ " . equals ( name ) || " _ finally _ " . equals ( name ) || " _ float _ " . equals ( name ) || " _ for _ " . equals ( name ) || " _ if _ " . equals ( name ) || " _ implements _ " . equals ( name ) || " _ import _ " . equals ( name ) || " _ instanceof _ " . equals ( name ) || " _ int _ " . equals ( name ) || " _ interface _ " . equals ( name ) || " _ long _ " . equals ( name ) || " _ native _ " . equals ( name ) || " _ new _ " . equals ( name ) || " _ package _ " . equals ( name ) || " _ private _ " . equals ( name ) || " _ protected _ " . equals ( name ) || PRED || " _ return _ " . equals ( name ) || " _ strictfp _ " . equals ( name ) || " _ short _ " . equals ( name ) || " _ static _ " . equals ( name ) || " _ super _ " . equals ( name ) || " _ switch _ " . equals ( name ) || " _ synchronized _ " . equals ( name ) || " _ this _ " . equals ( name ) || " _ throw _ " . equals ( name ) || " _ throws _ " . equals ( name ) || " _ transient _ " . equals ( name ) || " _ try _ " . equals ( name ) || " _ void _ " . equals ( name ) || " _ volatile _ " . equals ( name ) || " _ while _ " . equals ( name ) ) { return " _ $" + name ; } return name ; }
Ground truth: "_public_".equals(name)
Syntactic prediction: "_public_".equals(name)
Baseline prediction: "_protected_".equals(name)

Context: 
void create _ segment ( string realtime _ table _ name , int num _ replicas , int partition _ id , int seq _ num , list < string > server _ instances , long start _ offset , zn _ record partition _ assignment ) { logger . info ( " _ attempting _ to auto-create a segment for partition {} of table {}" , partition _ id , realtime _ table _ name ) ; final list < string > prop _ store _ paths = new array _ list < > ( 1 ) ; final list < zn _ record > prop _ store _ entries = new array _ list < > ( 1 ) ; long now = system . current _ time _ millis ( ) ; final string table _ name = table _ name _ builder . extract _ raw _ table _ name ( realtime _ table _ name ) ; llc _ segment _ name new _ segment _ name = PRED ; final string new _ segment _ name _ str = new _ segment _ name . get _ segment _ name ( ) ; zn _ record new _ zn _ record = make _ zn _ record _ for _ new _ segment ( realtime _ table _ name , num _ replicas , start _ offset , new _ segment _ name , partition _ assignment . get _ list _ fields ( ) . size ( ) ) ; final llc _ realtime _ segment _ zk _ metadata new _ segment _ zk _ metadata = new llc _ realtime _ segment _ zk _ metadata ( new _ zn _ record ) ; update _ flush _ threshold _ for _ segment _ metadata ( new _ segment _ zk _ metadata , partition _ assignment , get _ realtime _ table _ flush _ size _ for _ table ( realtime _ table _ name ) ) ; new _ zn _ record = new _ segment _ zk _ metadata . to _ zn _ record ( ) ; final string new _ znode _ path = zk _ metadata _ provider . construct _ property _ store _ path _ for _ segment ( realtime _ table _ name , new _ segment _ name _ str ) ; prop _ store _ paths . add ( new _ znode _ path ) ; prop _ store _ entries . add ( new _ zn _ record ) ; write _ segments _ to _ property _ store ( prop _ store _ paths , prop _ store _ entries , realtime _ table _ name ) ; update _ ideal _ state ( realtime _ table _ name , server _ instances , null , new _ segment _ name _ str ) ; logger . info ( " _ successful _ auto-create of consuming segment {}" , new _ segment _ name _ str ) ; controller _ metrics . add _ metered _ table _ value ( realtime _ table _ name , controller _ meter . llc _ auto _ created _ partitions , 1 ) ; }
Ground truth: newllc_segment_name(table_name,partition_id,seq_num,now)
Syntactic prediction: newllc_segment_name(table_name,partition_id,seq_num,now)
Baseline prediction: newllc_segment_name(table_name,partition_id,seq_num,seq_num)

Context: 
@ override void init _ channel ( channel ch ) throws exception { channel _ pipeline pipeline = ch . pipeline ( ) ; final long timeout _ ms = configuration . get _ ms ( property _ key . network _ netty _ heartbeat _ timeout _ ms ) ; pipeline . add _ last ( " _ frame _ decoder _ " , rpc _ message . create _ frame _ decoder ( ) ) ; pipeline . add _ last ( " _ rpc _ message _ decoder _ " , new rpc _ message _ decoder ( ) ) ; pipeline . add _ last ( " _ rpc _ message _ encoder _ " , new rpc _ message _ encoder ( ) ) ; pipeline . add _ last ( " _ idle _ event _ handler _ " , new idle _ state _ handler ( timeout _ ms , 0 , 0 , time _ unit . milliseconds ) ) ; pipeline . add _ last ( " _ idle _ read _ handler _ " , new idle _ read _ handler ( ) ) ; pipeline . add _ last ( " _ heartbeat _ handler _ " , new heartbeat _ handler ( ) ) ; pipeline . add _ last ( " _ block _ read _ handler _ " , new block _ read _ handler ( netty _ executors . block _ reader _ executor , m _ worker _ process . get _ worker ( block _ worker . class ) , m _ file _ transfer _ type ) ) ; pipeline . add _ last ( " _ block _ write _ handler _ " , new block _ write _ handler ( PRED , m _ worker _ process . get _ worker ( block _ worker . class ) , m _ worker _ process . get _ ufs _ manager ( ) ) ) ; pipeline . add _ last ( " _ short _ circuit _ block _ read _ handler _ " , new short _ circuit _ block _ read _ handler ( netty _ executors . rpc _ executor , m _ worker _ process . get _ worker ( block _ worker . class ) ) ) ; pipeline . add _ last ( " _ short _ circuit _ block _ write _ handler _ " , new short _ circuit _ block _ write _ handler ( netty _ executors . rpc _ executor , m _ worker _ process . get _ worker ( block _ worker . class ) ) ) ; pipeline . add _ last ( " _ ufs _ file _ write _ handler _ " , new ufs _ file _ write _ handler ( netty _ executors . file _ writer _ executor , m _ worker _ process . get _ ufs _ manager ( ) ) ) ; pipeline . add _ last ( " _ unsupported _ message _ handler _ " , new unsupported _ message _ handler ( ) ) ; }
Ground truth: netty_executors.block_writer_executor
Syntactic prediction: netty_executors.block_writer_executor
Baseline prediction: netty_executors.block_write_executor

Context: 
void setup _ bounds ( ) { int min _ value = math . min ( layout _ width , layout _ height ) ; int x _ offset = layout _ width - min _ value ; int y _ offset = layout _ height - min _ value ; padding _ top = this . get _ padding _ top ( ) + ( y _ offset / 2 ) ; padding _ bottom = this . get _ padding _ bottom ( ) + ( y _ offset / 2 ) ; padding _ left = this . get _ padding _ left ( ) + ( x _ offset / 2 ) ; padding _ right = this . get _ padding _ right ( ) + ( x _ offset / 2 ) ; int width = get _ width ( ) ; int height = get _ height ( ) ; inner _ circle _ bounds = new rect _ f ( padding _ left + ( 1 _ .5f * bar _ width ) , padding _ top + ( 1 _ .5f * bar _ width ) , width - padding _ right - ( 1 _ .5f * bar _ width ) , height - padding _ bottom - ( 1 _ .5f * bar _ width ) ) ; circle _ bounds = new rect _ f ( PRED , padding _ top + bar _ width , width - padding _ right - bar _ width , height - padding _ bottom - bar _ width ) ; circle _ inner _ contour = new rect _ f ( circle _ bounds . left + ( rim _ width / 2 _ .0f ) + ( contour _ size / 2 _ .0f ) , circle _ bounds . top + ( rim _ width / 2 _ .0f ) + ( contour _ size / 2 _ .0f ) , circle _ bounds . right - ( rim _ width / 2 _ .0f ) - ( contour _ size / 2 _ .0f ) , circle _ bounds . bottom - ( rim _ width / 2 _ .0f ) - ( contour _ size / 2 _ .0f ) ) ; circle _ outer _ contour = new rect _ f ( circle _ bounds . left - ( rim _ width / 2 _ .0f ) - ( contour _ size / 2 _ .0f ) , circle _ bounds . top - ( rim _ width / 2 _ .0f ) - ( contour _ size / 2 _ .0f ) , circle _ bounds . right + ( rim _ width / 2 _ .0f ) + ( contour _ size / 2 _ .0f ) , circle _ bounds . bottom + ( rim _ width / 2 _ .0f ) + ( contour _ size / 2 _ .0f ) ) ; full _ radius = ( width - padding _ right - bar _ width ) / 2 ; circle _ radius = ( full _ radius - bar _ width ) + 1 ; }
Ground truth: padding_left+bar_width
Syntactic prediction: padding_left+bar_width
Baseline prediction: padding_left+(1_.5f*bar_width)

Context: 
@ override void on _ create ( @ nullable bundle saved _ instance _ state ) { super . on _ create ( saved _ instance _ state ) ; get _ support _ action _ bar ( ) . set _ display _ home _ as _ up _ enabled ( true ) ; get _ support _ action _ bar ( ) . set _ display _ show _ home _ enabled ( true ) ; get _ support _ action _ bar ( ) . set _ display _ show _ title _ enabled ( true ) ; get _ support _ action _ bar ( ) . set _ display _ use _ logo _ enabled ( false ) ; get _ support _ action _ bar ( ) . set _ title ( " _ tiny _ window _ " ) ; set _ content _ view ( PRED ) ; m _ jz _ video _ player _ standard = find _ view _ by _ id ( r . id . jz _ video ) ; m _ jz _ video _ player _ standard . set _ up ( " _ http _ ://jzvd.nathen.cn/342a5f7ef6124a4a8faf00e738b8bee4/cf6d9db0bd4d41f59d09ea0a81e918fd-5287d2089db37e62345123a1be272f8b.mp4" , jz _ video _ player _ standard . screen _ window _ normal , " _ " ) ; picasso . with ( this ) . load ( " _ http _ ://jzvd-pic.nathen.cn/jzvd-pic/1bb2ebbe-140d-4e2e-abd2-9e7e564f71ac.png" ) . into ( m _ jz _ video _ player _ standard . thumb _ image _ view ) ; m _ btn _ tiny _ window = find _ view _ by _ id ( r . id . tiny _ window ) ; m _ btn _ tiny _ window _ list _ view = find _ view _ by _ id ( r . id . auto _ tiny _ list _ view ) ; m _ btn _ tiny _ window _ list _ view _ multi _ holder = find _ view _ by _ id ( r . id . auto _ tiny _ list _ view _ multi _ holder ) ; m _ btn _ tiny _ window _ recycle = find _ view _ by _ id ( r . id . auto _ tiny _ list _ view _ recycleview ) ; m _ btn _ tiny _ window _ recycle _ multi _ holder = find _ view _ by _ id ( r . id . auto _ tiny _ list _ view _ recycleview _ multiholder ) ; m _ btn _ tiny _ window . set _ on _ click _ listener ( this ) ; m _ btn _ tiny _ window _ list _ view . set _ on _ click _ listener ( this ) ; m _ btn _ tiny _ window _ list _ view _ multi _ holder . set _ on _ click _ listener ( this ) ; m _ btn _ tiny _ window _ recycle . set _ on _ click _ listener ( this ) ; m _ btn _ tiny _ window _ recycle _ multi _ holder . set _ on _ click _ listener ( this ) ; }
Ground truth: r.layout.activity_tiny_window
Syntactic prediction: r.layout.activity_tiny_window
Baseline prediction: r.layout.activity_tiny

Context: 
method _ handle compose ( method _ handle f , method _ handle g , method _ handle h ) { if ( f . type ( ) . parameter _ count ( ) != 2 ) { throw new illegal _ argument _ exception ( string . format ( " _ f _ .parametercount != 2. f: %s" , f . type ( ) ) ) ; } if ( f . type ( ) . parameter _ type ( 0 ) != g . type ( ) . return _ type ( ) ) { throw new illegal _ argument _ exception ( string . format ( " _ f _ .parameter(0) != g.return. f: %s g: %s" , f . type ( ) , g . type ( ) ) ) ; } if ( f . type ( ) . parameter _ type ( 1 ) != h . type ( ) . return _ type ( ) ) { throw new illegal _ argument _ exception ( string . format ( " _ f _ .parameter(0) != h.return. f: %s h: %s" , f . type ( ) , h . type ( ) ) ) ; } method _ type type _ vtu = f . type ( ) . drop _ parameter _ types ( 0 , 1 ) . append _ parameter _ types ( h . type ( ) . parameter _ list ( ) ) . append _ parameter _ types ( f . type ( ) . parameter _ type ( 0 ) ) ; method _ handle f _ vtu = method _ handles . permute _ arguments ( f , type _ vtu , h . type ( ) . parameter _ count ( ) + 1 , 0 ) ; method _ handle fh _ tu = method _ handles . fold _ arguments ( f _ vtu , h ) ; int [ ] reorder = new int [ fh _ tu . type ( ) . parameter _ count ( ) ] ; for ( int i = 0 ; i < reorder . length - 1 ; i ++ ) { reorder [ i ] = i + 1 + g . type ( ) . parameter _ count ( ) ; } reorder [ reorder . length - 1 ] = 0 ; method _ type type _ ust = f . type ( ) . drop _ parameter _ types ( 1 , 2 ) . append _ parameter _ types ( PRED ) . append _ parameter _ types ( h . type ( ) . parameter _ list ( ) ) ; method _ handle fh _ ust = method _ handles . permute _ arguments ( fh _ tu , type _ ust , reorder ) ; return method _ handles . fold _ arguments ( fh _ ust , g ) ; }
Ground truth: g.type().parameter_list()
Syntactic prediction: g.type().parameter_list()
Baseline prediction: type_vtu.type().parameter_list()

Context: 
@ get @ path ( " _ caches _ " ) @ api _ operation ( value = " _ list _ available caches" ) @ requires _ permissions ( rest _ permissions . lookup _ tables _ read ) caches _ page caches ( @ api _ param ( name = " _ page _ " ) @ query _ param ( " _ page _ " ) @ default _ value ( " _ 1 _ " ) int page , @ api _ param ( name = " _ per _ page _ " ) @ query _ param ( " _ per _ page _ " ) @ default _ value ( " _ 50 _ " ) int per _ page , @ api _ param ( name = " _ sort _ " , value = " _ the _ field to sort the result on" , required = true , allowable _ values = " _ title _ ,description,name,id" ) @ default _ value ( cache _ dto . field _ title ) @ query _ param ( " _ sort _ " ) string sort , @ api _ param ( name = " _ order _ " , value = " _ the _ sort direction" , allowable _ values = " _ asc _ , desc" ) @ default _ value ( " _ desc _ " ) @ query _ param ( " _ order _ " ) string order , @ api _ param ( name = " _ query _ " ) @ query _ param ( " _ query _ " ) string query ) { if ( ! cache _ allowable _ sort _ fields . contains ( sort . to _ lower _ case ( locale . english ) ) ) { sort = cache _ dto . field _ title ; } db _ sort . sort _ builder sort _ builder ; if ( " _ desc _ " . equals _ ignore _ case ( order ) ) { sort _ builder = db _ sort . desc ( sort ) ; } else { sort _ builder = db _ sort . asc ( sort ) ; } try { final search _ query search _ query = cache _ search _ query _ parser . parse ( query ) ; final db _ query . query db _ query = search _ query . to _ db _ query ( ) ; paginated _ list < cache _ dto > paginated = db _ cache _ service . find _ paginated ( db _ query , sort _ builder , page , per _ page ) ; return new caches _ page ( query , paginated . pagination ( ) , PRED . map ( cache _ api :: from _ dto ) . collect ( collectors . to _ list ( ) ) ) ; } catch ( illegal _ argument _ exception e ) { throw new bad _ request _ exception ( e . get _ message ( ) , e ) ; } }
Ground truth: paginated.stream()
Syntactic prediction: paginated.stream()
Baseline prediction: paginated.get_items().stream()

Context: 
field _ definition generate _ grouped _ field ( class _ definition definition , method _ definition constructor , method _ definition ensure _ capacity , state _ field state _ field ) { class < ? > big _ array _ type = get _ big _ array _ type ( state _ field . get _ type ( ) ) ; field _ definition field = definition . declare _ field ( a ( private ) , upper _ camel . to ( lower _ camel , state _ field . get _ name ( ) ) + " _ values _ " , big _ array _ type ) ; method _ definition getter = definition . declare _ method ( a ( public ) , state _ field . get _ getter _ name ( ) , type ( state _ field . get _ type ( ) ) ) ; getter . get _ body ( ) . append ( getter . get _ this ( ) . get _ field ( field ) . invoke ( " _ get _ " , state _ field . get _ type ( ) , getter . get _ this ( ) . invoke ( " _ get _ group _ id _ " , long . class ) ) . ret ( ) ) ; parameter value = arg ( " _ value _ " , state _ field . get _ type ( ) ) ; method _ definition setter = definition . declare _ method ( a ( public ) , state _ field . get _ setter _ name ( ) , type ( void . class ) , value ) ; setter . get _ body ( ) . append ( setter . get _ this ( ) . get _ field ( field ) . invoke ( " _ set _ " , void . class , setter . get _ this ( ) . invoke ( " _ get _ group _ id _ " , long . class ) , value ) ) . ret ( ) ; scope ensure _ capacity _ scope = ensure _ capacity . get _ scope ( ) ; ensure _ capacity . get _ body ( ) . append ( ensure _ capacity . get _ this ( ) . get _ field ( field ) . invoke ( " _ ensure _ capacity _ " , void . class , ensure _ capacity _ scope . get _ variable ( " _ size _ " ) ) ) ; constructor . get _ body ( ) . append ( PRED . set _ field ( field , new _ instance ( field . get _ type ( ) , state _ field . initial _ value _ expression ( ) ) ) ) ; return field ; }
Ground truth: constructor.get_this()
Syntactic prediction: constructor.get_this()
Baseline prediction: ensure_capacity_scope.get_this()

Context: 
@ override actual _ properties visit _ table _ scan ( table _ scan _ node node , list < actual _ properties > input _ properties ) { check _ argument ( node . get _ layout ( ) . is _ present ( ) , " _ table _ layout has not yet been chosen" ) ; table _ layout layout = metadata . get _ layout ( session , node . get _ layout ( ) . get ( ) ) ; map < column _ handle , symbol > assignments = immutable _ bi _ map . copy _ of ( node . get _ assignments ( ) ) . inverse ( ) ; actual _ properties . builder properties = actual _ properties . builder ( ) ; map < column _ handle , nullable _ value > global _ constants = new hash _ map < > ( ) ; extract _ fixed _ values ( node . get _ current _ constraint ( ) ) . or _ else ( immutable _ map . of ( ) ) . entry _ set ( ) . stream ( ) . filter ( entry -> ! entry . get _ value ( ) . is _ null ( ) ) . for _ each ( entry -> global _ constants . put ( entry . get _ key ( ) , entry . get _ value ( ) ) ) ; map < symbol , nullable _ value > symbol _ constants = global _ constants . entry _ set ( ) . stream ( ) . filter ( entry -> assignments . contains _ key ( entry . get _ key ( ) ) ) . collect ( to _ map ( entry -> assignments . get ( entry . get _ key ( ) ) , map . entry :: get _ value ) ) ; properties . constants ( symbol _ constants ) ; properties . global ( derive _ global _ properties ( layout , assignments , global _ constants ) ) ; list < local _ property < column _ handle > > constant _ appended _ local _ properties = immutable _ list . < local _ property < column _ handle > > builder ( ) . add _ all ( global _ constants . key _ set ( ) . stream ( ) . map ( column -> new constant _ property < > ( column ) ) . iterator ( ) ) . add _ all ( layout . get _ local _ properties ( ) ) . build ( ) ; properties . local ( local _ properties . translate ( constant _ appended _ local _ properties , column -> optional . of _ nullable ( assignments . get ( column ) ) ) ) ; return PRED ; }
Ground truth: properties.build()
Syntactic prediction: properties.build()
Baseline prediction: newactual_properties(properties.build(),input_properties)

Context: 
pinot _ resource _ manager _ response update _ server _ tenant ( tenant server _ tenant ) { pinot _ resource _ manager _ response res = new pinot _ resource _ manager _ response ( ) ; string realtime _ server _ tag = PRED ; list < string > tagged _ realtime _ servers = helix _ admin . get _ instances _ in _ cluster _ with _ tag ( helix _ cluster _ name , realtime _ server _ tag ) ; string offline _ server _ tag = controller _ tenant _ name _ builder . get _ offline _ tenant _ name _ for _ tenant ( server _ tenant . get _ tenant _ name ( ) ) ; list < string > tagged _ offline _ servers = helix _ admin . get _ instances _ in _ cluster _ with _ tag ( helix _ cluster _ name , offline _ server _ tag ) ; set < string > all _ serving _ servers = new hash _ set < string > ( ) ; all _ serving _ servers . add _ all ( tagged _ offline _ servers ) ; all _ serving _ servers . add _ all ( tagged _ realtime _ servers ) ; boolean is _ current _ tenant _ colocated = ( all _ serving _ servers . size ( ) < tagged _ offline _ servers . size ( ) + tagged _ realtime _ servers . size ( ) ) ; if ( is _ current _ tenant _ colocated != server _ tenant . is _ co _ located ( ) ) { res . status = response _ status . failure ; res . message = " _ not _ support different colocated type request for update request: " + server _ tenant ; logger . error ( res . message ) ; return res ; } if ( server _ tenant . get _ number _ of _ instances ( ) < all _ serving _ servers . size ( ) || server _ tenant . get _ offline _ instances ( ) < tagged _ offline _ servers . size ( ) || server _ tenant . get _ realtime _ instances ( ) < tagged _ realtime _ servers . size ( ) ) { return scale _ down _ server ( server _ tenant , res , tagged _ realtime _ servers , tagged _ offline _ servers , all _ serving _ servers ) ; } return scale _ up _ server _ tenant ( server _ tenant , res , realtime _ server _ tag , tagged _ realtime _ servers , offline _ server _ tag , tagged _ offline _ servers , all _ serving _ servers ) ; }
Ground truth: controller_tenant_name_builder.get_realtime_tenant_name_for_tenant(server_tenant.get_tenant_name())
Syntactic prediction: controller_tenant_name_builder.get_realtime_tenant_name_for_tenant(server_tenant.get_tenant_name())
Baseline prediction: server_tenant.get_realtime_server_tag()

Context: 
@ post @ timed @ consumes ( media _ type . application _ json ) @ produces ( media _ type . application _ json ) @ api _ operation ( value = " _ add _ an extractor to an input" , response = extractor _ created . class ) @ api _ responses ( value = { @ api _ response ( code = 404 , message = " _ no _ such input on this node." ) , @ api _ response ( code = 400 , message = " _ no _ such extractor type." ) , @ api _ response ( code = 400 , message = " _ field _ the extractor should write on is reserved." ) , @ api _ response ( code = 400 , message = " _ missing _ or invalid configuration." ) } ) @ audit _ event ( type = audit _ event _ types . extractor _ create ) response create ( @ api _ param ( name = " _ input _ id _ " , required = true ) @ path _ param ( " _ input _ id _ " ) string input _ id , @ api _ param ( name = " _ json _ body" , required = true ) @ valid @ not _ null create _ extractor _ request cer ) throws not _ found _ exception { check _ permission ( rest _ permissions . inputs _ edit , input _ id ) ; final input mongo _ input = input _ service . find ( input _ id ) ; final string id = new com . eaio . uuid . uuid ( ) . to _ string ( ) ; final extractor extractor = build _ extractor _ from _ request ( cer , id ) ; try { input _ service . add _ extractor ( mongo _ input , extractor ) ; } catch ( validation _ exception e ) { final string msg = " _ extractor _ persist validation failed." ; log . error ( msg , e ) ; throw PRED ; } final string msg = " _ added _ extractor <" + id + " _ > of type [" + cer . extractor _ type ( ) + " _ ] to input <" + input _ id + " _ >." ; log . info ( msg ) ; activity _ writer . write ( new activity ( msg , extractors _ resource . class ) ) ; final extractor _ created result = extractor _ created . create ( id ) ; final uri extractor _ uri = get _ uri _ builder _ to _ self ( ) . path ( extractors _ resource . class ) . path ( " _ {inputid}" ) . build ( mongo _ input . get _ id ( ) ) ; return response . created ( extractor _ uri ) . entity ( result ) . build ( ) ; }
Ground truth: newbad_request_exception(msg,e)
Syntactic prediction: newbad_request_exception(msg,e)
Baseline prediction: newnot_found_exception(msg)

Context: 
user _ payload from _ proto ( pb . user _ payload proto , core _ proto _ resolver core _ proto _ resolver ) { return new user _ payload ( proto _ util . string _ or _ null _ from _ proto ( proto . get _ account _ id ( ) ) , proto . get _ payment _ accounts _ list ( ) . is _ empty ( ) ? new hash _ set < > ( ) : new hash _ set < > ( proto . get _ payment _ accounts _ list ( ) . stream ( ) . map ( e -> payment _ account . from _ proto ( e , core _ proto _ resolver ) ) . collect ( collectors . to _ set ( ) ) ) , proto . has _ current _ payment _ account ( ) ? payment _ account . from _ proto ( proto . get _ current _ payment _ account ( ) , core _ proto _ resolver ) : null , proto . get _ accepted _ language _ locale _ codes _ list ( ) . is _ empty ( ) ? new array _ list < > ( ) : new array _ list < > ( proto . get _ accepted _ language _ locale _ codes _ list ( ) ) , proto . has _ developers _ alert ( ) ? alert . from _ proto ( proto . get _ developers _ alert ( ) ) : null , proto . has _ displayed _ alert ( ) ? alert . from _ proto ( proto . get _ displayed _ alert ( ) ) : null , proto . has _ developers _ filter ( ) ? filter . from _ proto ( proto . get _ developers _ filter ( ) ) : null , proto . has _ registered _ arbitrator ( ) ? arbitrator . from _ proto ( proto . get _ registered _ arbitrator ( ) ) : null , proto . has _ registered _ mediator ( ) ? PRED : null , proto . get _ accepted _ arbitrators _ list ( ) . is _ empty ( ) ? new array _ list < > ( ) : new array _ list < > ( proto . get _ accepted _ arbitrators _ list ( ) . stream ( ) . map ( arbitrator :: from _ proto ) . collect ( collectors . to _ list ( ) ) ) , proto . get _ accepted _ mediators _ list ( ) . is _ empty ( ) ? new array _ list < > ( ) : new array _ list < > ( proto . get _ accepted _ mediators _ list ( ) . stream ( ) . map ( mediator :: from _ proto ) . collect ( collectors . to _ list ( ) ) ) ) ; }
Ground truth: mediator.from_proto(proto.get_registered_mediator())
Syntactic prediction: mediator.from_proto(proto.get_registered_mediator())
Baseline prediction: mediators.from_proto(proto.get_mediator())

Context: 
field _ definition generate _ grouped _ field ( class _ definition definition , method _ definition constructor , method _ definition ensure _ capacity , state _ field state _ field ) { class < ? > big _ array _ type = get _ big _ array _ type ( state _ field . get _ type ( ) ) ; field _ definition field = definition . declare _ field ( a ( private ) , upper _ camel . to ( lower _ camel , state _ field . get _ name ( ) ) + " _ values _ " , big _ array _ type ) ; method _ definition getter = definition . declare _ method ( a ( public ) , state _ field . get _ getter _ name ( ) , type ( state _ field . get _ type ( ) ) ) ; getter . get _ body ( ) . append ( getter . get _ this ( ) . get _ field ( field ) . invoke ( " _ get _ " , state _ field . get _ type ( ) , getter . get _ this ( ) . invoke ( " _ get _ group _ id _ " , long . class ) ) . ret ( ) ) ; parameter value = arg ( " _ value _ " , state _ field . get _ type ( ) ) ; method _ definition setter = definition . declare _ method ( a ( public ) , state _ field . get _ setter _ name ( ) , type ( void . class ) , value ) ; setter . get _ body ( ) . append ( setter . get _ this ( ) . get _ field ( field ) . invoke ( " _ set _ " , void . class , setter . get _ this ( ) . invoke ( " _ get _ group _ id _ " , long . class ) , value ) ) . ret ( ) ; scope ensure _ capacity _ scope = PRED ; ensure _ capacity . get _ body ( ) . append ( ensure _ capacity . get _ this ( ) . get _ field ( field ) . invoke ( " _ ensure _ capacity _ " , void . class , ensure _ capacity _ scope . get _ variable ( " _ size _ " ) ) ) ; constructor . get _ body ( ) . append ( constructor . get _ this ( ) . set _ field ( field , new _ instance ( field . get _ type ( ) , state _ field . initial _ value _ expression ( ) ) ) ) ; return field ; }
Ground truth: ensure_capacity.get_scope()
Syntactic prediction: ensure_capacity.get_scope()
Baseline prediction: ensure_capacity.get_order_scope()

